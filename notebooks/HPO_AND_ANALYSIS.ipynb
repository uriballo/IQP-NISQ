{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/uribagi/Documents/GitHub/Latent-IQP\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uribagi/Documents/GitHub/Latent-IQP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optuna \n",
    "import numpy as np \n",
    "from datasets.bipartites import BipartiteGraphDataset\n",
    "from datasets.utils import vec_to_graph \n",
    "import iqpopt as iqp\n",
    "from iqpopt.utils import initialize_from_data\n",
    "import iqpopt.gen_qml as genq \n",
    "from utils.nisq import aachen_connectivity, efficient_connectivity_gates\n",
    "from utils.hpo import run_hpo\n",
    "from utils import metrics \n",
    "from iqpopt.gen_qml.utils import median_heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 8\n",
    "DATA_BASE_PATH = \"./datasets/bipartite_data/8_nodes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS_HPO = 500\n",
    "N_ITERS_HPO = 250 \n",
    "\n",
    "N_ITERS_FULL_TRAINING = 750"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OPS_MMD = 2000\n",
    "N_SAMPLES_MMD = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FILE_PATH = f\"./notebooks/hpo_and_evaluation_results_{8}_nodes.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_conn = aachen_connectivity()\n",
    "num_qubits = NODES * (NODES - 1) // 2\n",
    "base_key_global = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded from /Users/uribagi/Documents/GitHub/Latent-IQP/datasets/bipartite_data/8_nodes/baseline.pkl\n",
      "\n",
      "============================================================\n",
      "BIPARTITE GRAPH DATASET SUMMARY\n",
      "============================================================\n",
      "Vertices: 8\n",
      "Edge probability ranges: [(0.33, 0.33)]\n",
      "Edge probabilities: [0.33]\n",
      "Connected graphs only: False\n",
      "\n",
      "Base samples: 190\n",
      "Augmented samples: 570\n",
      "Total samples: 760\n",
      "Augmentation: 3 uniform permutation(s) per sample\n",
      "\n",
      "Natural Distribution per Edge Probability:\n",
      "  p=0.33: 190 base + 570 aug = 760 total (100.0%)\n",
      "\n",
      "Uniqueness Analysis:\n",
      "  Unique (isomorphism): 190/760 (25.0%)\n",
      "  Unique (adjacency): 757/760 (99.6%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# --- Main HPO and Evaluation Loop ---\n",
    "all_results = {}\n",
    "file_path = \"/Users/uribagi/Documents/GitHub/Latent-IQP/datasets/bipartite_data/8_nodes/baseline.pkl\"\n",
    "dataset = BipartiteGraphDataset.from_file(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = jnp.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = median_heuristic(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:01:22,133] A new study created in memory with name: no-name-fd80d375-366a-4006-885b-31d091c5662d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0:\n",
      "  Learning Rate: 0.0010059841881131612\n",
      "  Sigma Multiplier: 1.554703206519228\n",
      "  Initialization Multiplier: 0.07722331444476006\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 44.92it/s, loss=-0.000144, elapsed time=0.02, total time=6.24]\n",
      "[I 2025-05-26 14:01:28,665] Trial 0 finished with value: -0.00014414903691610593 and parameters: {'learning_rate': 0.0010059841881131612, 'sigma_multiplier': 1.554703206519228, 'num_layers': 4, 'initialization_multiplier': 0.07722331444476006}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 0 final loss: -0.00014415\n",
      "Trial 1:\n",
      "  Learning Rate: 0.00016782805459779253\n",
      "  Sigma Multiplier: 0.6776416392244446\n",
      "  Initialization Multiplier: 2.881837823129472\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:07<00:00, 34.02it/s, loss=0.042961, elapsed time=0.03, total time=7.47]\n",
      "[I 2025-05-26 14:01:36,156] Trial 1 finished with value: 0.04296099843807263 and parameters: {'learning_rate': 0.00016782805459779253, 'sigma_multiplier': 0.6776416392244446, 'num_layers': 4, 'initialization_multiplier': 2.881837823129472}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 1 final loss: 0.04296100\n",
      "Trial 2:\n",
      "  Learning Rate: 0.0010454672249759708\n",
      "  Sigma Multiplier: 1.105941774089309\n",
      "  Initialization Multiplier: 2.135210707250207\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 50.98it/s, loss=0.066208, elapsed time=0.02, total time=5.05]\n",
      "[I 2025-05-26 14:01:41,286] Trial 2 finished with value: 0.0662084389491481 and parameters: {'learning_rate': 0.0010454672249759708, 'sigma_multiplier': 1.105941774089309, 'num_layers': 1, 'initialization_multiplier': 2.135210707250207}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 2 final loss: 0.06620844\n",
      "Trial 3:\n",
      "  Learning Rate: 3.94690526860616e-05\n",
      "  Sigma Multiplier: 1.7175381119823006\n",
      "  Initialization Multiplier: 1.9152329890583915\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 45.71it/s, loss=0.063673, elapsed time=0.02, total time=5.61]\n",
      "[I 2025-05-26 14:01:46,919] Trial 3 finished with value: 0.06367282177646336 and parameters: {'learning_rate': 3.94690526860616e-05, 'sigma_multiplier': 1.7175381119823006, 'num_layers': 4, 'initialization_multiplier': 1.9152329890583915}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 3 final loss: 0.06367282\n",
      "Trial 4:\n",
      "  Learning Rate: 0.002383824627225584\n",
      "  Sigma Multiplier: 1.7925314844237026\n",
      "  Initialization Multiplier: 0.8556009473410944\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 61.73it/s, loss=-0.000129, elapsed time=0.01, total time=4.18]\n",
      "[I 2025-05-26 14:01:51,108] Trial 4 finished with value: -0.00012880691350977252 and parameters: {'learning_rate': 0.002383824627225584, 'sigma_multiplier': 1.7925314844237026, 'num_layers': 1, 'initialization_multiplier': 0.8556009473410944}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 4 final loss: -0.00012881\n",
      "Trial 5:\n",
      "  Learning Rate: 0.05345079857724226\n",
      "  Sigma Multiplier: 1.0641797057671631\n",
      "  Initialization Multiplier: 0.17723250378522323\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 37.93it/s, loss=0.000680, elapsed time=0.02, total time=6.74]\n",
      "[I 2025-05-26 14:01:57,949] Trial 5 finished with value: 0.0006798302530672595 and parameters: {'learning_rate': 0.05345079857724226, 'sigma_multiplier': 1.0641797057671631, 'num_layers': 5, 'initialization_multiplier': 0.17723250378522323}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 5 final loss: 0.00067983\n",
      "Trial 6:\n",
      "  Learning Rate: 0.014307200352697065\n",
      "  Sigma Multiplier: 0.5079231066016553\n",
      "  Initialization Multiplier: 1.5978241773755704\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:07<00:00, 31.80it/s, loss=0.001462, elapsed time=0.03, total time=8.01]\n",
      "[I 2025-05-26 14:02:06,027] Trial 6 finished with value: 0.0014622796861723324 and parameters: {'learning_rate': 0.014307200352697065, 'sigma_multiplier': 0.5079231066016553, 'num_layers': 3, 'initialization_multiplier': 1.5978241773755704}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 6 final loss: 0.00146228\n",
      "Trial 7:\n",
      "  Learning Rate: 0.0008997505452190181\n",
      "  Sigma Multiplier: 1.805625547471191\n",
      "  Initialization Multiplier: 2.914575197067572\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 46.05it/s, loss=-0.000017, elapsed time=0.02, total time=5.57]\n",
      "[I 2025-05-26 14:02:11,618] Trial 7 finished with value: -1.6621799365723624e-05 and parameters: {'learning_rate': 0.0008997505452190181, 'sigma_multiplier': 1.805625547471191, 'num_layers': 4, 'initialization_multiplier': 2.914575197067572}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 7 final loss: -0.00001662\n",
      "Trial 8:\n",
      "  Learning Rate: 7.578902041337095e-05\n",
      "  Sigma Multiplier: 1.9765746717619048\n",
      "  Initialization Multiplier: 0.11281737691215253\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:03<00:00, 63.68it/s, loss=0.038833, elapsed time=0.01, total time=4.08]\n",
      "[I 2025-05-26 14:02:15,760] Trial 8 finished with value: 0.03883263708519793 and parameters: {'learning_rate': 7.578902041337095e-05, 'sigma_multiplier': 1.9765746717619048, 'num_layers': 2, 'initialization_multiplier': 0.11281737691215253}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 8 final loss: 0.03883264\n",
      "Trial 9:\n",
      "  Learning Rate: 9.253174844272472e-05\n",
      "  Sigma Multiplier: 0.4640953861859183\n",
      "  Initialization Multiplier: 1.9293660785935878\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:08<00:00, 30.79it/s, loss=0.067291, elapsed time=0.03, total time=8.25]\n",
      "[I 2025-05-26 14:02:24,022] Trial 9 finished with value: 0.06729124000471273 and parameters: {'learning_rate': 9.253174844272472e-05, 'sigma_multiplier': 0.4640953861859183, 'num_layers': 3, 'initialization_multiplier': 1.9293660785935878}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 9 final loss: 0.06729124\n",
      "Trial 10:\n",
      "  Learning Rate: 0.004184019363350703\n",
      "  Sigma Multiplier: 1.3820820880817668\n",
      "  Initialization Multiplier: 0.7811524481203072\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 39.43it/s, loss=-0.000039, elapsed time=0.02, total time=6.47]\n",
      "[I 2025-05-26 14:02:30,514] Trial 10 finished with value: -3.9258048404172485e-05 and parameters: {'learning_rate': 0.004184019363350703, 'sigma_multiplier': 1.3820820880817668, 'num_layers': 5, 'initialization_multiplier': 0.7811524481203072}. Best is trial 0 with value: -0.00014414903691610593.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 10 final loss: -0.00003926\n",
      "Trial 11:\n",
      "  Learning Rate: 0.003623097680399549\n",
      "  Sigma Multiplier: 1.4896423693210454\n",
      "  Initialization Multiplier: 0.7848456068195439\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 58.99it/s, loss=-0.000156, elapsed time=0.02, total time=4.37]\n",
      "[I 2025-05-26 14:02:34,892] Trial 11 finished with value: -0.00015641310425017535 and parameters: {'learning_rate': 0.003623097680399549, 'sigma_multiplier': 1.4896423693210454, 'num_layers': 1, 'initialization_multiplier': 0.7848456068195439}. Best is trial 11 with value: -0.00015641310425017535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 11 final loss: -0.00015641\n",
      "Trial 12:\n",
      "  Learning Rate: 0.00037931517913903577\n",
      "  Sigma Multiplier: 1.4364307173862152\n",
      "  Initialization Multiplier: 0.7652986909372116\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.39it/s, loss=0.020059, elapsed time=0.02, total time=4.82]\n",
      "[I 2025-05-26 14:02:39,728] Trial 12 finished with value: 0.020059261761547098 and parameters: {'learning_rate': 0.00037931517913903577, 'sigma_multiplier': 1.4364307173862152, 'num_layers': 2, 'initialization_multiplier': 0.7652986909372116}. Best is trial 11 with value: -0.00015641310425017535.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 12 final loss: 0.02005926\n",
      "Trial 13:\n",
      "  Learning Rate: 0.008865135171043984\n",
      "  Sigma Multiplier: 1.4305570058232706\n",
      "  Initialization Multiplier: 0.5851542711339152\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 54.44it/s, loss=-0.000179, elapsed time=0.02, total time=4.72]\n",
      "[I 2025-05-26 14:02:44,466] Trial 13 finished with value: -0.00017931730111783555 and parameters: {'learning_rate': 0.008865135171043984, 'sigma_multiplier': 1.4305570058232706, 'num_layers': 2, 'initialization_multiplier': 0.5851542711339152}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 13 final loss: -0.00017932\n",
      "Trial 14:\n",
      "  Learning Rate: 0.011273074414617843\n",
      "  Sigma Multiplier: 1.2525219260867833\n",
      "  Initialization Multiplier: 1.133633026502778\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 50.38it/s, loss=0.000238, elapsed time=0.02, total time=5.09] \n",
      "[I 2025-05-26 14:02:49,575] Trial 14 finished with value: 0.0002382210990297193 and parameters: {'learning_rate': 0.011273074414617843, 'sigma_multiplier': 1.2525219260867833, 'num_layers': 2, 'initialization_multiplier': 1.133633026502778}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 14 final loss: 0.00023822\n",
      "Trial 15:\n",
      "  Learning Rate: 0.06691907714285822\n",
      "  Sigma Multiplier: 0.8211363454337457\n",
      "  Initialization Multiplier: 1.225558157415324\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 46.98it/s, loss=0.000149, elapsed time=0.02, total time=5.45]\n",
      "[I 2025-05-26 14:02:55,042] Trial 15 finished with value: 0.00014878965444701871 and parameters: {'learning_rate': 0.06691907714285822, 'sigma_multiplier': 0.8211363454337457, 'num_layers': 1, 'initialization_multiplier': 1.225558157415324}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 15 final loss: 0.00014879\n",
      "Trial 16:\n",
      "  Learning Rate: 0.012454897357138735\n",
      "  Sigma Multiplier: 0.1459026162367525\n",
      "  Initialization Multiplier: 0.49378562949877686\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:07<00:00, 31.86it/s, loss=0.000103, elapsed time=0.03, total time=7.98] \n",
      "[I 2025-05-26 14:03:03,040] Trial 16 finished with value: 0.00010333158366320927 and parameters: {'learning_rate': 0.012454897357138735, 'sigma_multiplier': 0.1459026162367525, 'num_layers': 2, 'initialization_multiplier': 0.49378562949877686}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 16 final loss: 0.00010333\n",
      "Trial 17:\n",
      "  Learning Rate: 0.004638260486433803\n",
      "  Sigma Multiplier: 1.5774432557233553\n",
      "  Initialization Multiplier: 0.4751659475771422\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 57.99it/s, loss=-0.000091, elapsed time=0.01, total time=4.44]\n",
      "[I 2025-05-26 14:03:07,491] Trial 17 finished with value: -9.068125273884273e-05 and parameters: {'learning_rate': 0.004638260486433803, 'sigma_multiplier': 1.5774432557233553, 'num_layers': 1, 'initialization_multiplier': 0.4751659475771422}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 17 final loss: -0.00009068\n",
      "Trial 18:\n",
      "  Learning Rate: 0.029133648729660132\n",
      "  Sigma Multiplier: 1.2568939362130118\n",
      "  Initialization Multiplier: 1.314037899261728\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 45.83it/s, loss=0.000050, elapsed time=0.02, total time=5.59] \n",
      "[I 2025-05-26 14:03:13,102] Trial 18 finished with value: 4.992636673853121e-05 and parameters: {'learning_rate': 0.029133648729660132, 'sigma_multiplier': 1.2568939362130118, 'num_layers': 3, 'initialization_multiplier': 1.314037899261728}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 18 final loss: 0.00004993\n",
      "Trial 19:\n",
      "  Learning Rate: 0.005115325750358642\n",
      "  Sigma Multiplier: 0.8221620619584754\n",
      "  Initialization Multiplier: 0.5461143759750511\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 44.56it/s, loss=0.000091, elapsed time=0.02, total time=5.74] \n",
      "[I 2025-05-26 14:03:18,854] Trial 19 finished with value: 9.131071157218231e-05 and parameters: {'learning_rate': 0.005115325750358642, 'sigma_multiplier': 0.8221620619584754, 'num_layers': 2, 'initialization_multiplier': 0.5461143759750511}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 19 final loss: 0.00009131\n",
      "Trial 20:\n",
      "  Learning Rate: 0.025246391922593845\n",
      "  Sigma Multiplier: 1.249156306051945\n",
      "  Initialization Multiplier: 2.409908908146234\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.34it/s, loss=-0.000076, elapsed time=0.02, total time=4.83]\n",
      "[I 2025-05-26 14:03:23,696] Trial 20 finished with value: -7.556966556138568e-05 and parameters: {'learning_rate': 0.025246391922593845, 'sigma_multiplier': 1.249156306051945, 'num_layers': 1, 'initialization_multiplier': 2.409908908146234}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 20 final loss: -0.00007557\n",
      "Trial 21:\n",
      "  Learning Rate: 0.0004549238016632404\n",
      "  Sigma Multiplier: 1.5538201109542438\n",
      "  Initialization Multiplier: 0.09312617365619857\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 44.77it/s, loss=0.000093, elapsed time=0.02, total time=5.71]\n",
      "[I 2025-05-26 14:03:29,430] Trial 21 finished with value: 9.336719038071898e-05 and parameters: {'learning_rate': 0.0004549238016632404, 'sigma_multiplier': 1.5538201109542438, 'num_layers': 4, 'initialization_multiplier': 0.09312617365619857}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 21 final loss: 0.00009337\n",
      "Trial 22:\n",
      "  Learning Rate: 0.0018073404146559623\n",
      "  Sigma Multiplier: 1.6037931827227163\n",
      "  Initialization Multiplier: 0.32290213704526255\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 55.12it/s, loss=-0.000102, elapsed time=0.02, total time=4.66]\n",
      "[I 2025-05-26 14:03:34,108] Trial 22 finished with value: -0.00010184135866108795 and parameters: {'learning_rate': 0.0018073404146559623, 'sigma_multiplier': 1.6037931827227163, 'num_layers': 2, 'initialization_multiplier': 0.32290213704526255}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 22 final loss: -0.00010184\n",
      "Trial 23:\n",
      "  Learning Rate: 0.0007337680859851431\n",
      "  Sigma Multiplier: 1.983055042982122\n",
      "  Initialization Multiplier: 1.0211852313492549\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.70it/s, loss=0.008422, elapsed time=0.02, total time=4.88]\n",
      "[I 2025-05-26 14:03:39,007] Trial 23 finished with value: 0.008421841380331564 and parameters: {'learning_rate': 0.0007337680859851431, 'sigma_multiplier': 1.983055042982122, 'num_layers': 3, 'initialization_multiplier': 1.0211852313492549}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 23 final loss: 0.00842184\n",
      "Trial 24:\n",
      "  Learning Rate: 0.002824234973671219\n",
      "  Sigma Multiplier: 1.4040679810148418\n",
      "  Initialization Multiplier: 1.5009234453236344\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 48.58it/s, loss=-0.000043, elapsed time=0.02, total time=5.27]\n",
      "[I 2025-05-26 14:03:44,300] Trial 24 finished with value: -4.3132418106181424e-05 and parameters: {'learning_rate': 0.002824234973671219, 'sigma_multiplier': 1.4040679810148418, 'num_layers': 3, 'initialization_multiplier': 1.5009234453236344}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 24 final loss: -0.00004313\n",
      "Trial 25:\n",
      "  Learning Rate: 0.006393068396628797\n",
      "  Sigma Multiplier: 1.7062386200498227\n",
      "  Initialization Multiplier: 0.0016057566168046905\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 43.14it/s, loss=-0.000111, elapsed time=0.02, total time=5.92]\n",
      "[I 2025-05-26 14:03:50,246] Trial 25 finished with value: -0.00011113729692453519 and parameters: {'learning_rate': 0.006393068396628797, 'sigma_multiplier': 1.7062386200498227, 'num_layers': 5, 'initialization_multiplier': 0.0016057566168046905}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 25 final loss: -0.00011114\n",
      "Trial 26:\n",
      "  Learning Rate: 0.001435321660975366\n",
      "  Sigma Multiplier: 1.497036730950094\n",
      "  Initialization Multiplier: 0.5509256227738597\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 58.70it/s, loss=0.000013, elapsed time=0.01, total time=4.39] \n",
      "[I 2025-05-26 14:03:54,649] Trial 26 finished with value: 1.3287673440089847e-05 and parameters: {'learning_rate': 0.001435321660975366, 'sigma_multiplier': 1.497036730950094, 'num_layers': 1, 'initialization_multiplier': 0.5509256227738597}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 26 final loss: 0.00001329\n",
      "Trial 27:\n",
      "  Learning Rate: 0.008700124684754814\n",
      "  Sigma Multiplier: 0.928563451771921\n",
      "  Initialization Multiplier: 0.3804190581639273\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 38.28it/s, loss=0.000401, elapsed time=0.02, total time=6.66]\n",
      "[I 2025-05-26 14:04:01,330] Trial 27 finished with value: 0.00040148438009218946 and parameters: {'learning_rate': 0.008700124684754814, 'sigma_multiplier': 0.928563451771921, 'num_layers': 4, 'initialization_multiplier': 0.3804190581639273}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 27 final loss: 0.00040148\n",
      "Trial 28:\n",
      "  Learning Rate: 0.0003078591885829574\n",
      "  Sigma Multiplier: 1.1681327786986997\n",
      "  Initialization Multiplier: 0.8709937200476043\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 48.99it/s, loss=0.065328, elapsed time=0.02, total time=5.23]\n",
      "[I 2025-05-26 14:04:06,581] Trial 28 finished with value: 0.06532841227748268 and parameters: {'learning_rate': 0.0003078591885829574, 'sigma_multiplier': 1.1681327786986997, 'num_layers': 2, 'initialization_multiplier': 0.8709937200476043}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 28 final loss: 0.06532841\n",
      "Trial 29:\n",
      "  Learning Rate: 0.00016582487576619062\n",
      "  Sigma Multiplier: 1.3458551313121925\n",
      "  Initialization Multiplier: 0.25657326976856365\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 48.09it/s, loss=0.000075, elapsed time=0.02, total time=5.34]\n",
      "[I 2025-05-26 14:04:11,942] Trial 29 finished with value: 7.504520835911562e-05 and parameters: {'learning_rate': 0.00016582487576619062, 'sigma_multiplier': 1.3458551313121925, 'num_layers': 3, 'initialization_multiplier': 0.25657326976856365}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 29 final loss: 0.00007505\n",
      "Trial 30:\n",
      "  Learning Rate: 0.0031141042542007923\n",
      "  Sigma Multiplier: 1.6750408149708347\n",
      "  Initialization Multiplier: 3.097171361546529\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 60.14it/s, loss=0.004964, elapsed time=0.01, total time=4.3] \n",
      "[I 2025-05-26 14:04:16,255] Trial 30 finished with value: 0.004963606458158989 and parameters: {'learning_rate': 0.0031141042542007923, 'sigma_multiplier': 1.6750408149708347, 'num_layers': 1, 'initialization_multiplier': 3.097171361546529}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 30 final loss: 0.00496361\n",
      "Trial 31:\n",
      "  Learning Rate: 0.0022096090859472614\n",
      "  Sigma Multiplier: 1.81660957250297\n",
      "  Initialization Multiplier: 0.7108715563260586\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 61.72it/s, loss=-0.000111, elapsed time=0.01, total time=4.18]\n",
      "[I 2025-05-26 14:04:20,452] Trial 31 finished with value: -0.00011097026637561229 and parameters: {'learning_rate': 0.0022096090859472614, 'sigma_multiplier': 1.81660957250297, 'num_layers': 1, 'initialization_multiplier': 0.7108715563260586}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 31 final loss: -0.00011097\n",
      "Trial 32:\n",
      "  Learning Rate: 0.0012202999709009894\n",
      "  Sigma Multiplier: 1.8815693503090014\n",
      "  Initialization Multiplier: 1.0154132873251693\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 61.86it/s, loss=-0.000134, elapsed time=0.01, total time=4.18]\n",
      "[I 2025-05-26 14:04:24,645] Trial 32 finished with value: -0.0001340470986330808 and parameters: {'learning_rate': 0.0012202999709009894, 'sigma_multiplier': 1.8815693503090014, 'num_layers': 1, 'initialization_multiplier': 1.0154132873251693}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 32 final loss: -0.00013405\n",
      "Trial 33:\n",
      "  Learning Rate: 0.0011986120847060002\n",
      "  Sigma Multiplier: 1.8723858074141528\n",
      "  Initialization Multiplier: 0.979674721671296\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 62.34it/s, loss=-0.000141, elapsed time=0.01, total time=4.14]\n",
      "[I 2025-05-26 14:04:28,799] Trial 33 finished with value: -0.00014084675170649154 and parameters: {'learning_rate': 0.0011986120847060002, 'sigma_multiplier': 1.8723858074141528, 'num_layers': 1, 'initialization_multiplier': 0.979674721671296}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 33 final loss: -0.00014085\n",
      "Trial 34:\n",
      "  Learning Rate: 0.00047441778298561003\n",
      "  Sigma Multiplier: 1.6565345701116598\n",
      "  Initialization Multiplier: 1.4185942336420854\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.85it/s, loss=0.034669, elapsed time=0.02, total time=4.78]\n",
      "[I 2025-05-26 14:04:33,597] Trial 34 finished with value: 0.03466856107864649 and parameters: {'learning_rate': 0.00047441778298561003, 'sigma_multiplier': 1.6565345701116598, 'num_layers': 2, 'initialization_multiplier': 1.4185942336420854}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 34 final loss: 0.03466856\n",
      "Trial 35:\n",
      "  Learning Rate: 0.0007117006062518628\n",
      "  Sigma Multiplier: 1.8625885990376703\n",
      "  Initialization Multiplier: 0.6062953467292977\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 61.13it/s, loss=0.000692, elapsed time=0.02, total time=4.22]\n",
      "[I 2025-05-26 14:04:37,826] Trial 35 finished with value: 0.0006922358121717367 and parameters: {'learning_rate': 0.0007117006062518628, 'sigma_multiplier': 1.8625885990376703, 'num_layers': 1, 'initialization_multiplier': 0.6062953467292977}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 35 final loss: 0.00069224\n",
      "Trial 36:\n",
      "  Learning Rate: 0.024691507171064456\n",
      "  Sigma Multiplier: 1.4917735730938095\n",
      "  Initialization Multiplier: 1.7906434272567742\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 58.27it/s, loss=-0.000142, elapsed time=0.02, total time=4.42]\n",
      "[I 2025-05-26 14:04:42,260] Trial 36 finished with value: -0.00014228766170417285 and parameters: {'learning_rate': 0.024691507171064456, 'sigma_multiplier': 1.4917735730938095, 'num_layers': 1, 'initialization_multiplier': 1.7906434272567742}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 36 final loss: -0.00014229\n",
      "Trial 37:\n",
      "  Learning Rate: 0.021612873994726414\n",
      "  Sigma Multiplier: 1.007541360631848\n",
      "  Initialization Multiplier: 2.3993467830605177\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 39.41it/s, loss=0.000167, elapsed time=0.02, total time=6.47]\n",
      "[I 2025-05-26 14:04:48,757] Trial 37 finished with value: 0.00016703006583733383 and parameters: {'learning_rate': 0.021612873994726414, 'sigma_multiplier': 1.007541360631848, 'num_layers': 4, 'initialization_multiplier': 2.3993467830605177}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 37 final loss: 0.00016703\n",
      "Trial 38:\n",
      "  Learning Rate: 0.0404702025776044\n",
      "  Sigma Multiplier: 1.454373439568684\n",
      "  Initialization Multiplier: 1.8730122996463725\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.98it/s, loss=-0.000023, elapsed time=0.02, total time=4.85]\n",
      "[I 2025-05-26 14:04:53,620] Trial 38 finished with value: -2.2909627680980343e-05 and parameters: {'learning_rate': 0.0404702025776044, 'sigma_multiplier': 1.454373439568684, 'num_layers': 2, 'initialization_multiplier': 1.8730122996463725}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 38 final loss: -0.00002291\n",
      "Trial 39:\n",
      "  Learning Rate: 0.007524814568535567\n",
      "  Sigma Multiplier: 1.1152082771578928\n",
      "  Initialization Multiplier: 1.7107406788596862\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 37.91it/s, loss=0.000053, elapsed time=0.02, total time=6.73] \n",
      "[I 2025-05-26 14:05:00,378] Trial 39 finished with value: 5.291120690587986e-05 and parameters: {'learning_rate': 0.007524814568535567, 'sigma_multiplier': 1.1152082771578928, 'num_layers': 5, 'initialization_multiplier': 1.7107406788596862}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 39 final loss: 0.00005291\n",
      "Trial 40:\n",
      "  Learning Rate: 0.015432355186828554\n",
      "  Sigma Multiplier: 1.5298701595878441\n",
      "  Initialization Multiplier: 2.145710784374413\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 44.16it/s, loss=-0.000038, elapsed time=0.02, total time=5.8] \n",
      "[I 2025-05-26 14:05:06,200] Trial 40 finished with value: -3.7903559413839795e-05 and parameters: {'learning_rate': 0.015432355186828554, 'sigma_multiplier': 1.5298701595878441, 'num_layers': 4, 'initialization_multiplier': 2.145710784374413}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 40 final loss: -0.00003790\n",
      "Trial 41:\n",
      "  Learning Rate: 0.003098016716065099\n",
      "  Sigma Multiplier: 1.7795515832900628\n",
      "  Initialization Multiplier: 1.0285175572671041\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 62.02it/s, loss=-0.000118, elapsed time=0.01, total time=4.16]\n",
      "[I 2025-05-26 14:05:10,371] Trial 41 finished with value: -0.00011825780323599295 and parameters: {'learning_rate': 0.003098016716065099, 'sigma_multiplier': 1.7795515832900628, 'num_layers': 1, 'initialization_multiplier': 1.0285175572671041}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 41 final loss: -0.00011826\n",
      "Trial 42:\n",
      "  Learning Rate: 0.0011539194750662867\n",
      "  Sigma Multiplier: 1.3530281707199148\n",
      "  Initialization Multiplier: 1.668984498924262\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 56.22it/s, loss=0.025298, elapsed time=0.02, total time=4.57]\n",
      "[I 2025-05-26 14:05:14,955] Trial 42 finished with value: 0.02529758924320124 and parameters: {'learning_rate': 0.0011539194750662867, 'sigma_multiplier': 1.3530281707199148, 'num_layers': 1, 'initialization_multiplier': 1.668984498924262}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 42 final loss: 0.02529759\n",
      "Trial 43:\n",
      "  Learning Rate: 0.00019888798390789732\n",
      "  Sigma Multiplier: 1.7365721311830251\n",
      "  Initialization Multiplier: 0.20916744925584885\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:03<00:00, 70.82it/s, loss=0.050244, elapsed time=0.01, total time=3.67]\n",
      "[I 2025-05-26 14:05:18,638] Trial 43 finished with value: 0.05024370732438017 and parameters: {'learning_rate': 0.00019888798390789732, 'sigma_multiplier': 1.7365721311830251, 'num_layers': 1, 'initialization_multiplier': 0.20916744925584885}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 43 final loss: 0.05024371\n",
      "Trial 44:\n",
      "  Learning Rate: 0.001820737331190005\n",
      "  Sigma Multiplier: 1.900555159784913\n",
      "  Initialization Multiplier: 0.8357864707911788\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 61.48it/s, loss=-0.000086, elapsed time=0.02, total time=4.19]\n",
      "[I 2025-05-26 14:05:22,845] Trial 44 finished with value: -8.609268858628944e-05 and parameters: {'learning_rate': 0.001820737331190005, 'sigma_multiplier': 1.900555159784913, 'num_layers': 1, 'initialization_multiplier': 0.8357864707911788}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 44 final loss: -0.00008609\n",
      "Trial 45:\n",
      "  Learning Rate: 0.09670882846085396\n",
      "  Sigma Multiplier: 1.2813962459362185\n",
      "  Initialization Multiplier: 0.680113221002159\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 50.04it/s, loss=0.000203, elapsed time=0.02, total time=5.14] \n",
      "[I 2025-05-26 14:05:28,003] Trial 45 finished with value: 0.00020260452066695744 and parameters: {'learning_rate': 0.09670882846085396, 'sigma_multiplier': 1.2813962459362185, 'num_layers': 2, 'initialization_multiplier': 0.680113221002159}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 45 final loss: 0.00020260\n",
      "Trial 46:\n",
      "  Learning Rate: 0.003923801506782084\n",
      "  Sigma Multiplier: 1.612617479463457\n",
      "  Initialization Multiplier: 0.37452488041102316\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.02it/s, loss=-0.000149, elapsed time=0.01, total time=4.37]\n",
      "[I 2025-05-26 14:05:32,387] Trial 46 finished with value: -0.00014928316137068738 and parameters: {'learning_rate': 0.003923801506782084, 'sigma_multiplier': 1.612617479463457, 'num_layers': 1, 'initialization_multiplier': 0.37452488041102316}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 46 final loss: -0.00014928\n",
      "Trial 47:\n",
      "  Learning Rate: 0.017765820849470253\n",
      "  Sigma Multiplier: 1.6321934168777485\n",
      "  Initialization Multiplier: 0.3899539634039717\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 54.07it/s, loss=-0.000093, elapsed time=0.02, total time=4.75]\n",
      "[I 2025-05-26 14:05:37,160] Trial 47 finished with value: -9.254926384005008e-05 and parameters: {'learning_rate': 0.017765820849470253, 'sigma_multiplier': 1.6321934168777485, 'num_layers': 2, 'initialization_multiplier': 0.3899539634039717}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 47 final loss: -0.00009255\n",
      "Trial 48:\n",
      "  Learning Rate: 0.010332057854723688\n",
      "  Sigma Multiplier: 1.4941766056495727\n",
      "  Initialization Multiplier: 0.0028606547284571876\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 49.30it/s, loss=-0.000101, elapsed time=0.02, total time=5.21]\n",
      "[I 2025-05-26 14:05:42,388] Trial 48 finished with value: -0.00010082013838755435 and parameters: {'learning_rate': 0.010332057854723688, 'sigma_multiplier': 1.4941766056495727, 'num_layers': 3, 'initialization_multiplier': 0.0028606547284571876}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 48 final loss: -0.00010082\n",
      "Trial 49:\n",
      "  Learning Rate: 0.004122065871527011\n",
      "  Sigma Multiplier: 1.1701623871742304\n",
      "  Initialization Multiplier: 2.1180788643647546\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.86it/s, loss=0.004564, elapsed time=0.02, total time=4.87]\n",
      "[I 2025-05-26 14:05:47,269] Trial 49 finished with value: 0.004563619266609985 and parameters: {'learning_rate': 0.004122065871527011, 'sigma_multiplier': 1.1701623871742304, 'num_layers': 1, 'initialization_multiplier': 2.1180788643647546}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 49 final loss: 0.00456362\n",
      "Trial 50:\n",
      "  Learning Rate: 0.040837224612885484\n",
      "  Sigma Multiplier: 0.5394847556035353\n",
      "  Initialization Multiplier: 0.1946827155979734\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:07<00:00, 34.28it/s, loss=0.001146, elapsed time=0.03, total time=7.43]\n",
      "[I 2025-05-26 14:05:54,713] Trial 50 finished with value: 0.0011462814862142202 and parameters: {'learning_rate': 0.040837224612885484, 'sigma_multiplier': 0.5394847556035353, 'num_layers': 2, 'initialization_multiplier': 0.1946827155979734}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 50 final loss: 0.00114628\n",
      "Trial 51:\n",
      "  Learning Rate: 0.0008596424739395933\n",
      "  Sigma Multiplier: 1.7425508068431046\n",
      "  Initialization Multiplier: 1.2065194426490187\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.61it/s, loss=0.000010, elapsed time=0.01, total time=4.33]\n",
      "[I 2025-05-26 14:05:59,053] Trial 51 finished with value: 1.0197572727571282e-05 and parameters: {'learning_rate': 0.0008596424739395933, 'sigma_multiplier': 1.7425508068431046, 'num_layers': 1, 'initialization_multiplier': 1.2065194426490187}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 51 final loss: 0.00001020\n",
      "Trial 52:\n",
      "  Learning Rate: 0.005987711393274834\n",
      "  Sigma Multiplier: 1.5842707368889803\n",
      "  Initialization Multiplier: 0.9086758454450132\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.44it/s, loss=-0.000112, elapsed time=0.02, total time=4.33]\n",
      "[I 2025-05-26 14:06:03,397] Trial 52 finished with value: -0.00011167902739669983 and parameters: {'learning_rate': 0.005987711393274834, 'sigma_multiplier': 1.5842707368889803, 'num_layers': 1, 'initialization_multiplier': 0.9086758454450132}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 52 final loss: -0.00011168\n",
      "Trial 53:\n",
      "  Learning Rate: 3.7326106247432545e-05\n",
      "  Sigma Multiplier: 1.4613068163851002\n",
      "  Initialization Multiplier: 0.38506804306818543\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:03<00:00, 63.19it/s, loss=0.057409, elapsed time=0.01, total time=4.09]\n",
      "[I 2025-05-26 14:06:07,505] Trial 53 finished with value: 0.05740854439276021 and parameters: {'learning_rate': 3.7326106247432545e-05, 'sigma_multiplier': 1.4613068163851002, 'num_layers': 1, 'initialization_multiplier': 0.38506804306818543}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 53 final loss: 0.05740854\n",
      "Trial 54:\n",
      "  Learning Rate: 0.004239835795267371\n",
      "  Sigma Multiplier: 1.3687085770129455\n",
      "  Initialization Multiplier: 0.48243827547437085\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 55.13it/s, loss=-0.000019, elapsed time=0.02, total time=4.67]\n",
      "[I 2025-05-26 14:06:12,192] Trial 54 finished with value: -1.8563387015509458e-05 and parameters: {'learning_rate': 0.004239835795267371, 'sigma_multiplier': 1.3687085770129455, 'num_layers': 1, 'initialization_multiplier': 0.48243827547437085}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 54 final loss: -0.00001856\n",
      "Trial 55:\n",
      "  Learning Rate: 0.0025344912522470334\n",
      "  Sigma Multiplier: 1.9256239715240422\n",
      "  Initialization Multiplier: 0.6434596672663527\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 62.23it/s, loss=-0.000122, elapsed time=0.02, total time=4.16]\n",
      "[I 2025-05-26 14:06:16,363] Trial 55 finished with value: -0.00012188466105971898 and parameters: {'learning_rate': 0.0025344912522470334, 'sigma_multiplier': 1.9256239715240422, 'num_layers': 1, 'initialization_multiplier': 0.6434596672663527}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 55 final loss: -0.00012188\n",
      "Trial 56:\n",
      "  Learning Rate: 0.0014913894561592344\n",
      "  Sigma Multiplier: 1.3011611479093643\n",
      "  Initialization Multiplier: 0.11688632479702404\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.17it/s, loss=0.000067, elapsed time=0.02, total time=4.84] \n",
      "[I 2025-05-26 14:06:21,215] Trial 56 finished with value: 6.705800954853775e-05 and parameters: {'learning_rate': 0.0014913894561592344, 'sigma_multiplier': 1.3011611479093643, 'num_layers': 2, 'initialization_multiplier': 0.11688632479702404}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 56 final loss: 0.00006706\n",
      "Trial 57:\n",
      "  Learning Rate: 0.0006278584165185016\n",
      "  Sigma Multiplier: 1.56919967683614\n",
      "  Initialization Multiplier: 1.3713522512577927\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.23it/s, loss=0.006140, elapsed time=0.01, total time=4.36]\n",
      "[I 2025-05-26 14:06:25,586] Trial 57 finished with value: 0.006140243581708326 and parameters: {'learning_rate': 0.0006278584165185016, 'sigma_multiplier': 1.56919967683614, 'num_layers': 1, 'initialization_multiplier': 1.3713522512577927}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 57 final loss: 0.00614024\n",
      "Trial 58:\n",
      "  Learning Rate: 0.009093716020700564\n",
      "  Sigma Multiplier: 1.6751951026144287\n",
      "  Initialization Multiplier: 0.27218575658352556\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 55.87it/s, loss=-0.000130, elapsed time=0.02, total time=4.6] \n",
      "[I 2025-05-26 14:06:30,207] Trial 58 finished with value: -0.00013015943407774865 and parameters: {'learning_rate': 0.009093716020700564, 'sigma_multiplier': 1.6751951026144287, 'num_layers': 2, 'initialization_multiplier': 0.27218575658352556}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 58 final loss: -0.00013016\n",
      "Trial 59:\n",
      "  Learning Rate: 0.01298061940143309\n",
      "  Sigma Multiplier: 1.9979227673095004\n",
      "  Initialization Multiplier: 1.1474913706036503\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 43.51it/s, loss=-0.000028, elapsed time=0.02, total time=5.87]\n",
      "[I 2025-05-26 14:06:36,107] Trial 59 finished with value: -2.785612919904492e-05 and parameters: {'learning_rate': 0.01298061940143309, 'sigma_multiplier': 1.9979227673095004, 'num_layers': 5, 'initialization_multiplier': 1.1474913706036503}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 59 final loss: -0.00002786\n",
      "Trial 60:\n",
      "  Learning Rate: 0.030705819617700678\n",
      "  Sigma Multiplier: 0.19878180480257857\n",
      "  Initialization Multiplier: 1.7809409671896566\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:08<00:00, 29.69it/s, loss=0.000210, elapsed time=0.03, total time=8.55]\n",
      "[I 2025-05-26 14:06:44,678] Trial 60 finished with value: 0.00021000750378973078 and parameters: {'learning_rate': 0.030705819617700678, 'sigma_multiplier': 0.19878180480257857, 'num_layers': 3, 'initialization_multiplier': 1.7809409671896566}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 60 final loss: 0.00021001\n",
      "Trial 61:\n",
      "  Learning Rate: 0.001144866692289537\n",
      "  Sigma Multiplier: 1.8326701968532204\n",
      "  Initialization Multiplier: 1.0159634616694715\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 62.00it/s, loss=-0.000116, elapsed time=0.01, total time=4.16]\n",
      "[I 2025-05-26 14:06:48,855] Trial 61 finished with value: -0.00011573125227537348 and parameters: {'learning_rate': 0.001144866692289537, 'sigma_multiplier': 1.8326701968532204, 'num_layers': 1, 'initialization_multiplier': 1.0159634616694715}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 61 final loss: -0.00011573\n",
      "Trial 62:\n",
      "  Learning Rate: 0.0034517268730646427\n",
      "  Sigma Multiplier: 1.911233561454674\n",
      "  Initialization Multiplier: 1.5358338379504735\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:03<00:00, 62.59it/s, loss=-0.000123, elapsed time=0.01, total time=4.13]\n",
      "[I 2025-05-26 14:06:53,002] Trial 62 finished with value: -0.0001228676989656782 and parameters: {'learning_rate': 0.0034517268730646427, 'sigma_multiplier': 1.911233561454674, 'num_layers': 1, 'initialization_multiplier': 1.5358338379504735}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 62 final loss: -0.00012287\n",
      "Trial 63:\n",
      "  Learning Rate: 0.0021482048671106137\n",
      "  Sigma Multiplier: 1.758543099289731\n",
      "  Initialization Multiplier: 0.8163308944111702\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.17it/s, loss=-0.000112, elapsed time=0.01, total time=4.35]\n",
      "[I 2025-05-26 14:06:57,368] Trial 63 finished with value: -0.00011167859662281033 and parameters: {'learning_rate': 0.0021482048671106137, 'sigma_multiplier': 1.758543099289731, 'num_layers': 1, 'initialization_multiplier': 0.8163308944111702}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 63 final loss: -0.00011168\n",
      "Trial 64:\n",
      "  Learning Rate: 0.0012238834465993509\n",
      "  Sigma Multiplier: 1.4171373185357516\n",
      "  Initialization Multiplier: 0.9326774346728282\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 57.90it/s, loss=-0.000136, elapsed time=0.02, total time=4.45]\n",
      "[I 2025-05-26 14:07:01,827] Trial 64 finished with value: -0.00013576561929936018 and parameters: {'learning_rate': 0.0012238834465993509, 'sigma_multiplier': 1.4171373185357516, 'num_layers': 1, 'initialization_multiplier': 0.9326774346728282}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 64 final loss: -0.00013577\n",
      "Trial 65:\n",
      "  Learning Rate: 0.00579030556130201\n",
      "  Sigma Multiplier: 1.4102622328688654\n",
      "  Initialization Multiplier: 0.7333759095580057\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 56.45it/s, loss=-0.000148, elapsed time=0.02, total time=4.55]\n",
      "[I 2025-05-26 14:07:06,392] Trial 65 finished with value: -0.00014822727280728673 and parameters: {'learning_rate': 0.00579030556130201, 'sigma_multiplier': 1.4102622328688654, 'num_layers': 1, 'initialization_multiplier': 0.7333759095580057}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 65 final loss: -0.00014823\n",
      "Trial 66:\n",
      "  Learning Rate: 0.006002562583481312\n",
      "  Sigma Multiplier: 1.192268083992628\n",
      "  Initialization Multiplier: 0.4502379492607127\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 49.26it/s, loss=-0.000139, elapsed time=0.02, total time=5.21]\n",
      "[I 2025-05-26 14:07:11,621] Trial 66 finished with value: -0.00013867859317831172 and parameters: {'learning_rate': 0.006002562583481312, 'sigma_multiplier': 1.192268083992628, 'num_layers': 2, 'initialization_multiplier': 0.4502379492607127}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 66 final loss: -0.00013868\n",
      "Trial 67:\n",
      "  Learning Rate: 0.00805014601311267\n",
      "  Sigma Multiplier: 1.528203457469843\n",
      "  Initialization Multiplier: 0.6642312472671972\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 58.16it/s, loss=-0.000113, elapsed time=0.01, total time=4.43]\n",
      "[I 2025-05-26 14:07:16,061] Trial 67 finished with value: -0.00011345809449487477 and parameters: {'learning_rate': 0.00805014601311267, 'sigma_multiplier': 1.528203457469843, 'num_layers': 1, 'initialization_multiplier': 0.6642312472671972}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 67 final loss: -0.00011346\n",
      "Trial 68:\n",
      "  Learning Rate: 0.004638886756440399\n",
      "  Sigma Multiplier: 1.6315603557748029\n",
      "  Initialization Multiplier: 0.7530125258682282\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 50.17it/s, loss=-0.000087, elapsed time=0.02, total time=5.12]\n",
      "[I 2025-05-26 14:07:21,198] Trial 68 finished with value: -8.747148387508754e-05 and parameters: {'learning_rate': 0.004638886756440399, 'sigma_multiplier': 1.6315603557748029, 'num_layers': 3, 'initialization_multiplier': 0.7530125258682282}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 68 final loss: -0.00008747\n",
      "Trial 69:\n",
      "  Learning Rate: 0.01796343778257712\n",
      "  Sigma Multiplier: 1.3199275068126013\n",
      "  Initialization Multiplier: 0.5228360072767473\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 42.87it/s, loss=-0.000044, elapsed time=0.02, total time=5.96]\n",
      "[I 2025-05-26 14:07:27,187] Trial 69 finished with value: -4.374645878836606e-05 and parameters: {'learning_rate': 0.01796343778257712, 'sigma_multiplier': 1.3199275068126013, 'num_layers': 4, 'initialization_multiplier': 0.5228360072767473}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 69 final loss: -0.00004375\n",
      "Trial 70:\n",
      "  Learning Rate: 0.0019093987352089765\n",
      "  Sigma Multiplier: 1.4782076044161994\n",
      "  Initialization Multiplier: 0.5653730997331055\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 58.18it/s, loss=-0.000095, elapsed time=0.02, total time=4.43]\n",
      "[I 2025-05-26 14:07:31,633] Trial 70 finished with value: -9.485101111336991e-05 and parameters: {'learning_rate': 0.0019093987352089765, 'sigma_multiplier': 1.4782076044161994, 'num_layers': 1, 'initialization_multiplier': 0.5653730997331055}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 70 final loss: -0.00009485\n",
      "Trial 71:\n",
      "  Learning Rate: 0.006115181430014744\n",
      "  Sigma Multiplier: 1.2148275330366387\n",
      "  Initialization Multiplier: 0.34271190314013017\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 51.44it/s, loss=-0.000131, elapsed time=0.02, total time=5]   \n",
      "[I 2025-05-26 14:07:36,650] Trial 71 finished with value: -0.00013087991214362713 and parameters: {'learning_rate': 0.006115181430014744, 'sigma_multiplier': 1.2148275330366387, 'num_layers': 2, 'initialization_multiplier': 0.34271190314013017}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 71 final loss: -0.00013088\n",
      "Trial 72:\n",
      "  Learning Rate: 0.005585447382935332\n",
      "  Sigma Multiplier: 1.0315324810988231\n",
      "  Initialization Multiplier: 0.47225715363309845\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 49.07it/s, loss=0.000001, elapsed time=0.02, total time=5.22] \n",
      "[I 2025-05-26 14:07:41,888] Trial 72 finished with value: 1.3970524940950021e-06 and parameters: {'learning_rate': 0.005585447382935332, 'sigma_multiplier': 1.0315324810988231, 'num_layers': 2, 'initialization_multiplier': 0.47225715363309845}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 72 final loss: 0.00000140\n",
      "Trial 73:\n",
      "  Learning Rate: 0.0034397750631711284\n",
      "  Sigma Multiplier: 1.409136790907771\n",
      "  Initialization Multiplier: 0.0808459916318287\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 59.35it/s, loss=-0.000017, elapsed time=0.02, total time=4.35]\n",
      "[I 2025-05-26 14:07:46,249] Trial 73 finished with value: -1.7027732526894887e-05 and parameters: {'learning_rate': 0.0034397750631711284, 'sigma_multiplier': 1.409136790907771, 'num_layers': 1, 'initialization_multiplier': 0.0808459916318287}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 73 final loss: -0.00001703\n",
      "Trial 74:\n",
      "  Learning Rate: 0.007080015175877713\n",
      "  Sigma Multiplier: 1.1939528828848607\n",
      "  Initialization Multiplier: 0.40862706688399286\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 51.32it/s, loss=-0.000141, elapsed time=0.02, total time=5]   \n",
      "[I 2025-05-26 14:07:51,266] Trial 74 finished with value: -0.00014073910423094096 and parameters: {'learning_rate': 0.007080015175877713, 'sigma_multiplier': 1.1939528828848607, 'num_layers': 2, 'initialization_multiplier': 0.40862706688399286}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 74 final loss: -0.00014074\n",
      "Trial 75:\n",
      "  Learning Rate: 0.007529424336404894\n",
      "  Sigma Multiplier: 1.078271632835972\n",
      "  Initialization Multiplier: 0.2740499561716072\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.46it/s, loss=0.000078, elapsed time=0.02, total time=4.89] \n",
      "[I 2025-05-26 14:07:56,173] Trial 75 finished with value: 7.849218312531176e-05 and parameters: {'learning_rate': 0.007529424336404894, 'sigma_multiplier': 1.078271632835972, 'num_layers': 1, 'initialization_multiplier': 0.2740499561716072}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 75 final loss: 0.00007849\n",
      "Trial 76:\n",
      "  Learning Rate: 0.01081369044549138\n",
      "  Sigma Multiplier: 1.598144228510423\n",
      "  Initialization Multiplier: 0.7551805987799579\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 54.50it/s, loss=-0.000150, elapsed time=0.02, total time=4.72]\n",
      "[I 2025-05-26 14:08:00,915] Trial 76 finished with value: -0.000150027971950014 and parameters: {'learning_rate': 0.01081369044549138, 'sigma_multiplier': 1.598144228510423, 'num_layers': 2, 'initialization_multiplier': 0.7551805987799579}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 76 final loss: -0.00015003\n",
      "Trial 77:\n",
      "  Learning Rate: 0.011696964009583649\n",
      "  Sigma Multiplier: 1.533472370198694\n",
      "  Initialization Multiplier: 0.7576643924883022\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 49.13it/s, loss=-0.000043, elapsed time=0.02, total time=5.23]\n",
      "[I 2025-05-26 14:08:06,168] Trial 77 finished with value: -4.250332275657359e-05 and parameters: {'learning_rate': 0.011696964009583649, 'sigma_multiplier': 1.533472370198694, 'num_layers': 3, 'initialization_multiplier': 0.7576643924883022}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 77 final loss: -0.00004250\n",
      "Trial 78:\n",
      "  Learning Rate: 0.015415889846711404\n",
      "  Sigma Multiplier: 1.67704660616167\n",
      "  Initialization Multiplier: 0.9339916337906259\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 60.37it/s, loss=-0.000103, elapsed time=0.01, total time=4.27]\n",
      "[I 2025-05-26 14:08:10,450] Trial 78 finished with value: -0.00010323587854085643 and parameters: {'learning_rate': 0.015415889846711404, 'sigma_multiplier': 1.67704660616167, 'num_layers': 1, 'initialization_multiplier': 0.9339916337906259}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 78 final loss: -0.00010324\n",
      "Trial 79:\n",
      "  Learning Rate: 0.02230210932872459\n",
      "  Sigma Multiplier: 1.6290640170183426\n",
      "  Initialization Multiplier: 1.0999548591408104\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 45.24it/s, loss=-0.000028, elapsed time=0.02, total time=5.66]\n",
      "[I 2025-05-26 14:08:16,140] Trial 79 finished with value: -2.781533130984389e-05 and parameters: {'learning_rate': 0.02230210932872459, 'sigma_multiplier': 1.6290640170183426, 'num_layers': 4, 'initialization_multiplier': 1.0999548591408104}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 79 final loss: -0.00002782\n",
      "Trial 80:\n",
      "  Learning Rate: 5.826600004100122e-05\n",
      "  Sigma Multiplier: 1.710059784230579\n",
      "  Initialization Multiplier: 0.6129122675670953\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 60.87it/s, loss=0.013416, elapsed time=0.01, total time=4.23]\n",
      "[I 2025-05-26 14:08:20,388] Trial 80 finished with value: 0.013416093652002154 and parameters: {'learning_rate': 5.826600004100122e-05, 'sigma_multiplier': 1.710059784230579, 'num_layers': 1, 'initialization_multiplier': 0.6129122675670953}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 80 final loss: 0.01341609\n",
      "Trial 81:\n",
      "  Learning Rate: 0.010708213133839977\n",
      "  Sigma Multiplier: 1.4181255818388248\n",
      "  Initialization Multiplier: 0.7033196105884374\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.98it/s, loss=-0.000164, elapsed time=0.02, total time=4.85]\n",
      "[I 2025-05-26 14:08:25,259] Trial 81 finished with value: -0.00016374364215166712 and parameters: {'learning_rate': 0.010708213133839977, 'sigma_multiplier': 1.4181255818388248, 'num_layers': 2, 'initialization_multiplier': 0.7033196105884374}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 81 final loss: -0.00016374\n",
      "Trial 82:\n",
      "  Learning Rate: 0.011452630386300216\n",
      "  Sigma Multiplier: 1.4345169916527545\n",
      "  Initialization Multiplier: 0.7060505342123242\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.00it/s, loss=-0.000140, elapsed time=0.02, total time=4.85]\n",
      "[I 2025-05-26 14:08:30,123] Trial 82 finished with value: -0.0001402564296566534 and parameters: {'learning_rate': 0.011452630386300216, 'sigma_multiplier': 1.4345169916527545, 'num_layers': 2, 'initialization_multiplier': 0.7060505342123242}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 82 final loss: -0.00014026\n",
      "Trial 83:\n",
      "  Learning Rate: 0.009274699521567207\n",
      "  Sigma Multiplier: 1.5927050194870356\n",
      "  Initialization Multiplier: 0.8530644952286601\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 54.55it/s, loss=-0.000123, elapsed time=0.02, total time=4.72]\n",
      "[I 2025-05-26 14:08:34,862] Trial 83 finished with value: -0.00012326697340705325 and parameters: {'learning_rate': 0.009274699521567207, 'sigma_multiplier': 1.5927050194870356, 'num_layers': 2, 'initialization_multiplier': 0.8530644952286601}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 83 final loss: -0.00012327\n",
      "Trial 84:\n",
      "  Learning Rate: 0.032539187029418624\n",
      "  Sigma Multiplier: 1.507577435105029\n",
      "  Initialization Multiplier: 2.0214125946111756\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 47.98it/s, loss=0.000005, elapsed time=0.02, total time=5.35] \n",
      "[I 2025-05-26 14:08:40,233] Trial 84 finished with value: 5.267188674380663e-06 and parameters: {'learning_rate': 0.032539187029418624, 'sigma_multiplier': 1.507577435105029, 'num_layers': 3, 'initialization_multiplier': 2.0214125946111756}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 84 final loss: 0.00000527\n",
      "Trial 85:\n",
      "  Learning Rate: 0.0026056512396229097\n",
      "  Sigma Multiplier: 1.365092701395327\n",
      "  Initialization Multiplier: 0.5725795089239647\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 57.26it/s, loss=-0.000099, elapsed time=0.02, total time=4.5] \n",
      "[I 2025-05-26 14:08:44,742] Trial 85 finished with value: -9.88689595477974e-05 and parameters: {'learning_rate': 0.0026056512396229097, 'sigma_multiplier': 1.365092701395327, 'num_layers': 1, 'initialization_multiplier': 0.5725795089239647}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 85 final loss: -0.00009887\n",
      "Trial 86:\n",
      "  Learning Rate: 0.003721920676082502\n",
      "  Sigma Multiplier: 1.5756873126187236\n",
      "  Initialization Multiplier: 0.7473969926974071\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 48.56it/s, loss=-0.000066, elapsed time=0.02, total time=5.28]\n",
      "[I 2025-05-26 14:08:50,044] Trial 86 finished with value: -6.58684758993268e-05 and parameters: {'learning_rate': 0.003721920676082502, 'sigma_multiplier': 1.5756873126187236, 'num_layers': 3, 'initialization_multiplier': 0.7473969926974071}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 86 final loss: -0.00006587\n",
      "Trial 87:\n",
      "  Learning Rate: 0.0008822470499548345\n",
      "  Sigma Multiplier: 1.2702740147041924\n",
      "  Initialization Multiplier: 0.6414520841587459\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.07it/s, loss=-0.000172, elapsed time=0.02, total time=4.85]\n",
      "[I 2025-05-26 14:08:54,909] Trial 87 finished with value: -0.00017213973419068682 and parameters: {'learning_rate': 0.0008822470499548345, 'sigma_multiplier': 1.2702740147041924, 'num_layers': 2, 'initialization_multiplier': 0.6414520841587459}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 87 final loss: -0.00017214\n",
      "Trial 88:\n",
      "  Learning Rate: 0.0009039370036618123\n",
      "  Sigma Multiplier: 1.260152208279968\n",
      "  Initialization Multiplier: 0.14038967100111505\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.11it/s, loss=0.000626, elapsed time=0.02, total time=4.85]\n",
      "[I 2025-05-26 14:08:59,772] Trial 88 finished with value: 0.0006255718900232628 and parameters: {'learning_rate': 0.0009039370036618123, 'sigma_multiplier': 1.260152208279968, 'num_layers': 2, 'initialization_multiplier': 0.14038967100111505}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 88 final loss: 0.00062557\n",
      "Trial 89:\n",
      "  Learning Rate: 0.0051205622789837505\n",
      "  Sigma Multiplier: 1.3275294144512935\n",
      "  Initialization Multiplier: 0.29366070507457687\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 50.66it/s, loss=-0.000142, elapsed time=0.02, total time=5.07]\n",
      "[I 2025-05-26 14:09:04,860] Trial 89 finished with value: -0.00014214639162087633 and parameters: {'learning_rate': 0.0051205622789837505, 'sigma_multiplier': 1.3275294144512935, 'num_layers': 2, 'initialization_multiplier': 0.29366070507457687}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 89 final loss: -0.00014215\n",
      "Trial 90:\n",
      "  Learning Rate: 0.00038877771726436426\n",
      "  Sigma Multiplier: 1.4531306831956403\n",
      "  Initialization Multiplier: 2.635494450536493\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.57it/s, loss=0.045859, elapsed time=0.02, total time=4.88]\n",
      "[I 2025-05-26 14:09:09,763] Trial 90 finished with value: 0.045859408904598026 and parameters: {'learning_rate': 0.00038877771726436426, 'sigma_multiplier': 1.4531306831956403, 'num_layers': 2, 'initialization_multiplier': 2.635494450536493}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 90 final loss: 0.04585941\n",
      "Trial 91:\n",
      "  Learning Rate: 0.00480369922588856\n",
      "  Sigma Multiplier: 1.3352707121924694\n",
      "  Initialization Multiplier: 0.3411501770181223\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.33it/s, loss=-0.000087, elapsed time=0.02, total time=4.91]\n",
      "[I 2025-05-26 14:09:14,695] Trial 91 finished with value: -8.670729518718442e-05 and parameters: {'learning_rate': 0.00480369922588856, 'sigma_multiplier': 1.3352707121924694, 'num_layers': 2, 'initialization_multiplier': 0.3411501770181223}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 91 final loss: -0.00008671\n",
      "Trial 92:\n",
      "  Learning Rate: 0.0014466142875602143\n",
      "  Sigma Multiplier: 1.3820323538646264\n",
      "  Initialization Multiplier: 0.05374294158021997\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.81it/s, loss=-0.000026, elapsed time=0.02, total time=4.78]\n",
      "[I 2025-05-26 14:09:19,492] Trial 92 finished with value: -2.612414599173358e-05 and parameters: {'learning_rate': 0.0014466142875602143, 'sigma_multiplier': 1.3820323538646264, 'num_layers': 2, 'initialization_multiplier': 0.05374294158021997}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 92 final loss: -0.00002612\n",
      "Trial 93:\n",
      "  Learning Rate: 0.0005295709475208415\n",
      "  Sigma Multiplier: 1.3001685564842906\n",
      "  Initialization Multiplier: 0.21532231544345065\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 52.69it/s, loss=0.002404, elapsed time=0.02, total time=4.87]\n",
      "[I 2025-05-26 14:09:24,382] Trial 93 finished with value: 0.0024040083925312506 and parameters: {'learning_rate': 0.0005295709475208415, 'sigma_multiplier': 1.3001685564842906, 'num_layers': 2, 'initialization_multiplier': 0.21532231544345065}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 93 final loss: 0.00240401\n",
      "Trial 94:\n",
      "  Learning Rate: 0.01867352344251454\n",
      "  Sigma Multiplier: 1.4795332315848673\n",
      "  Initialization Multiplier: 0.28437566370422185\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.46it/s, loss=-0.000120, elapsed time=0.02, total time=4.82]\n",
      "[I 2025-05-26 14:09:29,216] Trial 94 finished with value: -0.00011965036624129336 and parameters: {'learning_rate': 0.01867352344251454, 'sigma_multiplier': 1.4795332315848673, 'num_layers': 2, 'initialization_multiplier': 0.28437566370422185}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 94 final loss: -0.00011965\n",
      "Trial 95:\n",
      "  Learning Rate: 0.0029852671219815154\n",
      "  Sigma Multiplier: 1.545183546709829\n",
      "  Initialization Multiplier: 0.6338748641622381\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 55.83it/s, loss=-0.000166, elapsed time=0.02, total time=4.61]\n",
      "[I 2025-05-26 14:09:33,844] Trial 95 finished with value: -0.00016613016098638398 and parameters: {'learning_rate': 0.0029852671219815154, 'sigma_multiplier': 1.545183546709829, 'num_layers': 2, 'initialization_multiplier': 0.6338748641622381}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 95 final loss: -0.00016613\n",
      "Trial 96:\n",
      "  Learning Rate: 0.06681938571411464\n",
      "  Sigma Multiplier: 1.5410881256641622\n",
      "  Initialization Multiplier: 0.6030102926800538\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 54.33it/s, loss=0.000050, elapsed time=0.02, total time=4.73] \n",
      "[I 2025-05-26 14:09:38,591] Trial 96 finished with value: 4.957290261919069e-05 and parameters: {'learning_rate': 0.06681938571411464, 'sigma_multiplier': 1.5410881256641622, 'num_layers': 2, 'initialization_multiplier': 0.6030102926800538}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 96 final loss: 0.00004957\n",
      "Trial 97:\n",
      "  Learning Rate: 0.0030160148213299854\n",
      "  Sigma Multiplier: 1.4940541278535469\n",
      "  Initialization Multiplier: 0.6660528673708751\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:05<00:00, 49.10it/s, loss=-0.000073, elapsed time=0.02, total time=5.22]\n",
      "[I 2025-05-26 14:09:43,835] Trial 97 finished with value: -7.296217476825314e-05 and parameters: {'learning_rate': 0.0030160148213299854, 'sigma_multiplier': 1.4940541278535469, 'num_layers': 3, 'initialization_multiplier': 0.6660528673708751}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 97 final loss: -0.00007296\n",
      "Trial 98:\n",
      "  Learning Rate: 0.0022053814441951873\n",
      "  Sigma Multiplier: 1.4012018995782125\n",
      "  Initialization Multiplier: 0.8047494890254899\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:04<00:00, 53.26it/s, loss=-0.000126, elapsed time=0.02, total time=4.82]\n",
      "[I 2025-05-26 14:09:48,678] Trial 98 finished with value: -0.0001262641495646304 and parameters: {'learning_rate': 0.0022053814441951873, 'sigma_multiplier': 1.4012018995782125, 'num_layers': 2, 'initialization_multiplier': 0.8047494890254899}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 98 final loss: -0.00012626\n",
      "Trial 99:\n",
      "  Learning Rate: 0.01398168782012161\n",
      "  Sigma Multiplier: 1.610587786710497\n",
      "  Initialization Multiplier: 0.510807662072922\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 250/250 [00:06<00:00, 40.50it/s, loss=-0.000087, elapsed time=0.02, total time=6.31]\n",
      "[I 2025-05-26 14:09:55,017] Trial 99 finished with value: -8.712415405071614e-05 and parameters: {'learning_rate': 0.01398168782012161, 'sigma_multiplier': 1.610587786710497, 'num_layers': 5, 'initialization_multiplier': 0.510807662072922}. Best is trial 13 with value: -0.00017931730111783555.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 250 steps\n",
      "Trial 99 final loss: -0.00008712\n"
     ]
    }
   ],
   "source": [
    "study = run_hpo(grid_conn, num_qubits, base_sigma, train_ds, n_trials=100, n_iters_hpo=250, n_ops=2000, n_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008865135171043984"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = best_params['learning_rate']\n",
    "sigma_multiplier = best_params['sigma_multiplier']\n",
    "num_layers = best_params['num_layers']\n",
    "initialization_multiplier = best_params['initialization_multiplier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gates = efficient_connectivity_gates(grid_conn, num_qubits, num_layers=num_layers)\n",
    "sigma = base_sigma * sigma_multiplier\n",
    "params_init = initialize_from_data(gates, train_ds) * initialization_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "circ = iqp.IqpSimulator(num_qubits, gates, device='lightning.qubit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_kwarg = {\n",
    "    \"params\": params_init,\n",
    "    \"iqp_circuit\": circ,\n",
    "    \"ground_truth\": train_ds,\n",
    "    \"sigma\": [sigma],\n",
    "    \"n_ops\": 2000,\n",
    "    \"n_samples\": 2000,\n",
    "    \"key\": jax.random.PRNGKey(42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 500/500 [00:08<00:00, 56.38it/s, loss=-0.000115, elapsed time=0.02, total time=9.01]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 500 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss = genq.mmd_loss_iqp\n",
    "\n",
    "trainer = iqp.Trainer(\"Adam\", loss, stepsize=learning_rate)\n",
    "trainer.train(n_iters= 500,loss_kwargs=loss_kwarg, turbo=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_params = trainer.final_params\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(trainer.losses)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = circ.sample(trained_params, shots = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.372"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.bipartite_proportion(samples, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = [vec_to_graph(g, 8) for g in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [vec_to_graph(g, 8) for g in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 0.58)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.sample_diversity(generated_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 0.25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.sample_diversity(ground_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
