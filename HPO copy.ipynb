{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iqpopt as iqp\n",
    "from iqpopt.utils import initialize_from_data, local_gates\n",
    "import iqpopt.gen_qml as genq\n",
    "from iqpopt.gen_qml.utils import median_heuristic\n",
    "import optuna\n",
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from utils.nisq import aachen_connectivity, efficient_connectivity_gates\n",
    "from datasets.bipartites import BipartiteGraphDataset\n",
    "from datasets.er import ErdosRenyiGraphDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 8\n",
    "TYPE = \"Bipartite\"\n",
    "CONN = \"Medium\"\n",
    "NUM_LAYERS = 1\n",
    "QUBITS = NODES * (NODES - 1) //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Loaded 271 samples from ./datasets/raw_data/8N_Bipartite_Medium.pkl\n",
      "  Created: 2025-05-30T13:15:17.387588\n",
      "  Unique graphs: 271\n",
      "  Version: 1.0\n"
     ]
    }
   ],
   "source": [
    "ds_path = f'./datasets/raw_data/{NODES}N_{TYPE}_{CONN}.pkl'\n",
    "train_ds = jnp.array(BipartiteGraphDataset(nodes = 1, edge_prob=0.1).from_file(ds_path).vectors.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_conn = aachen_connectivity()\n",
    "gates = efficient_connectivity_gates(grid_conn, QUBITS, 1) \n",
    "circ = iqp.IqpSimulator(QUBITS, gates, device='lightning.qubit')\n",
    "\n",
    "base_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = median_heuristic(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hpo import run_hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 22:03:32,083] A new study created in memory with name: no-name-f787b184-2c50-4cb3-a9d3-4ad6e2b74f09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0:\n",
      "  Learning Rate: 0.0025567885528974305\n",
      "  Sigma Multiplier: 1.783348193573144\n",
      "  Initialization Multiplier: 0.22222473061580392\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.20it/s, loss=-0.000167, elapsed time=0.03, total time=7.71]\n",
      "[I 2025-06-07 22:03:40,197] Trial 0 finished with value: -0.00016690732082928002 and parameters: {'learning_rate': 0.0025567885528974305, 'sigma_multiplier': 1.783348193573144, 'num_layers': 5, 'initialization_multiplier': 0.22222473061580392}. Best is trial 0 with value: -0.00016690732082928002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 0 final loss: -0.00016691\n",
      "Trial 1:\n",
      "  Learning Rate: 0.01105749832032795\n",
      "  Sigma Multiplier: 1.4072101856106365\n",
      "  Initialization Multiplier: 1.8130626767089446\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.32it/s, loss=-0.000140, elapsed time=0.03, total time=6.99]\n",
      "[I 2025-06-07 22:03:47,300] Trial 1 finished with value: -0.0001401237736701446 and parameters: {'learning_rate': 0.01105749832032795, 'sigma_multiplier': 1.4072101856106365, 'num_layers': 2, 'initialization_multiplier': 1.8130626767089446}. Best is trial 0 with value: -0.00016690732082928002.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 1 final loss: -0.00014012\n",
      "Trial 2:\n",
      "  Learning Rate: 0.028125188346190263\n",
      "  Sigma Multiplier: 1.7983111155356568\n",
      "  Initialization Multiplier: 1.9027821119275237\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:03<00:00, 37.87it/s, loss=-0.000189, elapsed time=0.02, total time=4.19]\n",
      "[I 2025-06-07 22:03:51,562] Trial 2 finished with value: -0.0001893437554216291 and parameters: {'learning_rate': 0.028125188346190263, 'sigma_multiplier': 1.7983111155356568, 'num_layers': 1, 'initialization_multiplier': 1.9027821119275237}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 2 final loss: -0.00018934\n",
      "Trial 3:\n",
      "  Learning Rate: 0.01445603922833321\n",
      "  Sigma Multiplier: 0.25386366186939124\n",
      "  Initialization Multiplier: 1.2993560213751045\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.15it/s, loss=0.001565, elapsed time=0.05, total time=8.02]\n",
      "[I 2025-06-07 22:03:59,599] Trial 3 finished with value: 0.0015654975949777885 and parameters: {'learning_rate': 0.01445603922833321, 'sigma_multiplier': 0.25386366186939124, 'num_layers': 2, 'initialization_multiplier': 1.2993560213751045}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 3 final loss: 0.00156550\n",
      "Trial 4:\n",
      "  Learning Rate: 7.137624680463252e-05\n",
      "  Sigma Multiplier: 0.8946783600711018\n",
      "  Initialization Multiplier: 1.4094285783414464\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.98it/s, loss=0.101139, elapsed time=0.04, total time=6.81]\n",
      "[I 2025-06-07 22:04:06,529] Trial 4 finished with value: 0.10113895457628126 and parameters: {'learning_rate': 7.137624680463252e-05, 'sigma_multiplier': 0.8946783600711018, 'num_layers': 3, 'initialization_multiplier': 1.4094285783414464}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 4 final loss: 0.10113895\n",
      "Trial 5:\n",
      "  Learning Rate: 0.004062221437972854\n",
      "  Sigma Multiplier: 0.4894635555843013\n",
      "  Initialization Multiplier: 1.247292729766109\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.10it/s, loss=0.013728, elapsed time=0.05, total time=8.49]\n",
      "[I 2025-06-07 22:04:15,044] Trial 5 finished with value: 0.013727762925471206 and parameters: {'learning_rate': 0.004062221437972854, 'sigma_multiplier': 0.4894635555843013, 'num_layers': 3, 'initialization_multiplier': 1.247292729766109}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 5 final loss: 0.01372776\n",
      "Trial 6:\n",
      "  Learning Rate: 0.0024645530189435555\n",
      "  Sigma Multiplier: 1.1474889112339182\n",
      "  Initialization Multiplier: 1.5900220039258495\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:04<00:00, 31.10it/s, loss=0.007878, elapsed time=0.02, total time=5.02]\n",
      "[I 2025-06-07 22:04:20,075] Trial 6 finished with value: 0.00787848147178078 and parameters: {'learning_rate': 0.0024645530189435555, 'sigma_multiplier': 1.1474889112339182, 'num_layers': 1, 'initialization_multiplier': 1.5900220039258495}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 6 final loss: 0.00787848\n",
      "Trial 7:\n",
      "  Learning Rate: 0.00010720365853124194\n",
      "  Sigma Multiplier: 0.4077820618442223\n",
      "  Initialization Multiplier: 1.7045901126196836\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.53it/s, loss=0.040150, elapsed time=0.07, total time=9.32]\n",
      "[I 2025-06-07 22:04:29,541] Trial 7 finished with value: 0.040150257731159225 and parameters: {'learning_rate': 0.00010720365853124194, 'sigma_multiplier': 0.4077820618442223, 'num_layers': 4, 'initialization_multiplier': 1.7045901126196836}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 7 final loss: 0.04015026\n",
      "Trial 8:\n",
      "  Learning Rate: 0.0026542031205753435\n",
      "  Sigma Multiplier: 0.7047761721362292\n",
      "  Initialization Multiplier: 1.5941776723709296\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.02it/s, loss=0.004391, elapsed time=0.04, total time=7.34]\n",
      "[I 2025-06-07 22:04:36,904] Trial 8 finished with value: 0.004390632346879258 and parameters: {'learning_rate': 0.0026542031205753435, 'sigma_multiplier': 0.7047761721362292, 'num_layers': 3, 'initialization_multiplier': 1.5941776723709296}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 8 final loss: 0.00439063\n",
      "Trial 9:\n",
      "  Learning Rate: 3.655338942353789e-05\n",
      "  Sigma Multiplier: 1.8822787357169253\n",
      "  Initialization Multiplier: 1.6392082260409053\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.06it/s, loss=0.023162, elapsed time=0.03, total time=5.95]\n",
      "[I 2025-06-07 22:04:42,871] Trial 9 finished with value: 0.023161810396659956 and parameters: {'learning_rate': 3.655338942353789e-05, 'sigma_multiplier': 1.8822787357169253, 'num_layers': 3, 'initialization_multiplier': 1.6392082260409053}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 9 final loss: 0.02316181\n",
      "Trial 10:\n",
      "  Learning Rate: 0.0681249192505627\n",
      "  Sigma Multiplier: 1.4881954444865317\n",
      "  Initialization Multiplier: 0.6924162937177465\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:04<00:00, 36.10it/s, loss=-0.000065, elapsed time=0.02, total time=4.35]\n",
      "[I 2025-06-07 22:04:47,255] Trial 10 finished with value: -6.54219587141118e-05 and parameters: {'learning_rate': 0.0681249192505627, 'sigma_multiplier': 1.4881954444865317, 'num_layers': 1, 'initialization_multiplier': 0.6924162937177465}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 10 final loss: -0.00006542\n",
      "Trial 11:\n",
      "  Learning Rate: 0.0003710752004593702\n",
      "  Sigma Multiplier: 1.999592397165958\n",
      "  Initialization Multiplier: 0.030752919117536442\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.37it/s, loss=0.015309, elapsed time=0.05, total time=7.94]\n",
      "[I 2025-06-07 22:04:55,293] Trial 11 finished with value: 0.015309435066321713 and parameters: {'learning_rate': 0.0003710752004593702, 'sigma_multiplier': 1.999592397165958, 'num_layers': 5, 'initialization_multiplier': 0.030752919117536442}. Best is trial 2 with value: -0.0001893437554216291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 11 final loss: 0.01530944\n",
      "Trial 12:\n",
      "  Learning Rate: 0.0549357762867691\n",
      "  Sigma Multiplier: 1.651826183245932\n",
      "  Initialization Multiplier: 0.6878366220675941\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.80it/s, loss=-0.000313, elapsed time=0.06, total time=8.62]\n",
      "[I 2025-06-07 22:05:03,969] Trial 12 finished with value: -0.0003133227874394899 and parameters: {'learning_rate': 0.0549357762867691, 'sigma_multiplier': 1.651826183245932, 'num_layers': 5, 'initialization_multiplier': 0.6878366220675941}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 12 final loss: -0.00031332\n",
      "Trial 13:\n",
      "  Learning Rate: 0.05330461715630426\n",
      "  Sigma Multiplier: 1.5504681795343647\n",
      "  Initialization Multiplier: 0.7798502681297214\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.52it/s, loss=-0.000193, elapsed time=0.05, total time=9.33]\n",
      "[I 2025-06-07 22:05:13,338] Trial 13 finished with value: -0.00019306572593139756 and parameters: {'learning_rate': 0.05330461715630426, 'sigma_multiplier': 1.5504681795343647, 'num_layers': 4, 'initialization_multiplier': 0.7798502681297214}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 13 final loss: -0.00019307\n",
      "Trial 14:\n",
      "  Learning Rate: 0.0864888977445141\n",
      "  Sigma Multiplier: 1.456579063911973\n",
      "  Initialization Multiplier: 0.7021897182372998\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.45it/s, loss=-0.000074, elapsed time=0.07, total time=10.7]\n",
      "[I 2025-06-07 22:05:24,087] Trial 14 finished with value: -7.430280040869785e-05 and parameters: {'learning_rate': 0.0864888977445141, 'sigma_multiplier': 1.456579063911973, 'num_layers': 4, 'initialization_multiplier': 0.7021897182372998}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 14 final loss: -0.00007430\n",
      "Trial 15:\n",
      "  Learning Rate: 0.030383209851680172\n",
      "  Sigma Multiplier: 1.1871145633741607\n",
      "  Initialization Multiplier: 0.7982011796020455\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 23.17it/s, loss=0.000028, elapsed time=0.03, total time=6.72] \n",
      "[I 2025-06-07 22:05:30,846] Trial 15 finished with value: 2.798423645334503e-05 and parameters: {'learning_rate': 0.030383209851680172, 'sigma_multiplier': 1.1871145633741607, 'num_layers': 4, 'initialization_multiplier': 0.7982011796020455}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 15 final loss: 0.00002798\n",
      "Trial 16:\n",
      "  Learning Rate: 0.0005763075697943925\n",
      "  Sigma Multiplier: 1.612238173944204\n",
      "  Initialization Multiplier: 0.44189353896924677\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.02it/s, loss=0.018505, elapsed time=0.04, total time=7.01]\n",
      "[I 2025-06-07 22:05:37,892] Trial 16 finished with value: 0.0185047300411923 and parameters: {'learning_rate': 0.0005763075697943925, 'sigma_multiplier': 1.612238173944204, 'num_layers': 5, 'initialization_multiplier': 0.44189353896924677}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 16 final loss: 0.01850473\n",
      "Trial 17:\n",
      "  Learning Rate: 0.007770007055989667\n",
      "  Sigma Multiplier: 1.3025255792074875\n",
      "  Initialization Multiplier: 1.0468322507991643\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.97it/s, loss=-0.000223, elapsed time=0.03, total time=6.74]\n",
      "[I 2025-06-07 22:05:44,668] Trial 17 finished with value: -0.0002230208942895938 and parameters: {'learning_rate': 0.007770007055989667, 'sigma_multiplier': 1.3025255792074875, 'num_layers': 4, 'initialization_multiplier': 1.0468322507991643}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 17 final loss: -0.00022302\n",
      "Trial 18:\n",
      "  Learning Rate: 0.006753195798552224\n",
      "  Sigma Multiplier: 1.2675020386024254\n",
      "  Initialization Multiplier: 0.9846919297128365\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.73it/s, loss=-0.000042, elapsed time=0.06, total time=8.71]\n",
      "[I 2025-06-07 22:05:53,421] Trial 18 finished with value: -4.1574364830257644e-05 and parameters: {'learning_rate': 0.006753195798552224, 'sigma_multiplier': 1.2675020386024254, 'num_layers': 5, 'initialization_multiplier': 0.9846919297128365}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 18 final loss: -0.00004157\n",
      "Trial 19:\n",
      "  Learning Rate: 0.01725338782282227\n",
      "  Sigma Multiplier: 0.9863309354335646\n",
      "  Initialization Multiplier: 1.0678773588044104\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.47it/s, loss=0.000469, elapsed time=0.06, total time=9.36]\n",
      "[I 2025-06-07 22:06:02,827] Trial 19 finished with value: 0.00046935938102499154 and parameters: {'learning_rate': 0.01725338782282227, 'sigma_multiplier': 0.9863309354335646, 'num_layers': 4, 'initialization_multiplier': 1.0678773588044104}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 19 final loss: 0.00046936\n",
      "Trial 20:\n",
      "  Learning Rate: 0.0007994233129520713\n",
      "  Sigma Multiplier: 0.8060537053033728\n",
      "  Initialization Multiplier: 0.45259863180349713\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.15it/s, loss=0.032581, elapsed time=0.08, total time=10.8]\n",
      "[I 2025-06-07 22:06:13,704] Trial 20 finished with value: 0.03258111352835142 and parameters: {'learning_rate': 0.0007994233129520713, 'sigma_multiplier': 0.8060537053033728, 'num_layers': 5, 'initialization_multiplier': 0.45259863180349713}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 20 final loss: 0.03258111\n",
      "Trial 21:\n",
      "  Learning Rate: 0.03833772253018618\n",
      "  Sigma Multiplier: 1.6510109866164102\n",
      "  Initialization Multiplier: 0.9392531220158135\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.28it/s, loss=-0.000114, elapsed time=0.05, total time=8.93]\n",
      "[I 2025-06-07 22:06:22,682] Trial 21 finished with value: -0.00011368799630803551 and parameters: {'learning_rate': 0.03833772253018618, 'sigma_multiplier': 1.6510109866164102, 'num_layers': 4, 'initialization_multiplier': 0.9392531220158135}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 21 final loss: -0.00011369\n",
      "Trial 22:\n",
      "  Learning Rate: 0.05750034926280035\n",
      "  Sigma Multiplier: 1.3083564866161552\n",
      "  Initialization Multiplier: 0.5281647644481209\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.59it/s, loss=-0.000214, elapsed time=0.07, total time=9.88]\n",
      "[I 2025-06-07 22:06:32,624] Trial 22 finished with value: -0.00021428751444938608 and parameters: {'learning_rate': 0.05750034926280035, 'sigma_multiplier': 1.3083564866161552, 'num_layers': 4, 'initialization_multiplier': 0.5281647644481209}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 22 final loss: -0.00021429\n",
      "Trial 23:\n",
      "  Learning Rate: 0.008203787386496797\n",
      "  Sigma Multiplier: 1.3058717194678942\n",
      "  Initialization Multiplier: 0.5419398845529613\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.88it/s, loss=-0.000180, elapsed time=0.04, total time=9.4] \n",
      "[I 2025-06-07 22:06:42,105] Trial 23 finished with value: -0.00017950729721892734 and parameters: {'learning_rate': 0.008203787386496797, 'sigma_multiplier': 1.3058717194678942, 'num_layers': 5, 'initialization_multiplier': 0.5419398845529613}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 23 final loss: -0.00017951\n",
      "Trial 24:\n",
      "  Learning Rate: 0.08789634422822785\n",
      "  Sigma Multiplier: 1.071293752369165\n",
      "  Initialization Multiplier: 0.3069991797589396\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.00it/s, loss=0.000283, elapsed time=0.04, total time=7.73]\n",
      "[I 2025-06-07 22:06:49,917] Trial 24 finished with value: 0.0002826602564039448 and parameters: {'learning_rate': 0.08789634422822785, 'sigma_multiplier': 1.071293752369165, 'num_layers': 4, 'initialization_multiplier': 0.3069991797589396}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 24 final loss: 0.00028266\n",
      "Trial 25:\n",
      "  Learning Rate: 0.02089786561242671\n",
      "  Sigma Multiplier: 1.6933696199493125\n",
      "  Initialization Multiplier: 1.1654609476884543\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.51it/s, loss=-0.000278, elapsed time=0.04, total time=7.2] \n",
      "[I 2025-06-07 22:06:57,164] Trial 25 finished with value: -0.00027826016585099907 and parameters: {'learning_rate': 0.02089786561242671, 'sigma_multiplier': 1.6933696199493125, 'num_layers': 4, 'initialization_multiplier': 1.1654609476884543}. Best is trial 12 with value: -0.0003133227874394899.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 25 final loss: -0.00027826\n",
      "Trial 26:\n",
      "  Learning Rate: 0.015208316835819287\n",
      "  Sigma Multiplier: 1.7386064848638172\n",
      "  Initialization Multiplier: 1.1502284775750224\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.71it/s, loss=-0.000377, elapsed time=0.04, total time=8.23]\n",
      "[I 2025-06-07 22:07:05,438] Trial 26 finished with value: -0.00037698664368775723 and parameters: {'learning_rate': 0.015208316835819287, 'sigma_multiplier': 1.7386064848638172, 'num_layers': 5, 'initialization_multiplier': 1.1502284775750224}. Best is trial 26 with value: -0.00037698664368775723.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 26 final loss: -0.00037699\n",
      "Trial 27:\n",
      "  Learning Rate: 0.021106451336123183\n",
      "  Sigma Multiplier: 1.709815623303937\n",
      "  Initialization Multiplier: 1.1681174752013497\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.12it/s, loss=-0.000401, elapsed time=0.12, total time=8.1] \n",
      "[I 2025-06-07 22:07:13,583] Trial 27 finished with value: -0.0004005343397201333 and parameters: {'learning_rate': 0.021106451336123183, 'sigma_multiplier': 1.709815623303937, 'num_layers': 5, 'initialization_multiplier': 1.1681174752013497}. Best is trial 27 with value: -0.0004005343397201333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 27 final loss: -0.00040053\n",
      "Trial 28:\n",
      "  Learning Rate: 0.0012644712517016214\n",
      "  Sigma Multiplier: 1.9899353221578642\n",
      "  Initialization Multiplier: 0.9051066730507569\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.90it/s, loss=0.003217, elapsed time=0.04, total time=8.21]\n",
      "[I 2025-06-07 22:07:21,841] Trial 28 finished with value: 0.003216917614658499 and parameters: {'learning_rate': 0.0012644712517016214, 'sigma_multiplier': 1.9899353221578642, 'num_layers': 5, 'initialization_multiplier': 0.9051066730507569}. Best is trial 27 with value: -0.0004005343397201333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 28 final loss: 0.00321692\n",
      "Trial 29:\n",
      "  Learning Rate: 0.0045563940293539005\n",
      "  Sigma Multiplier: 1.8058592962242597\n",
      "  Initialization Multiplier: 1.282254477867797\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.97it/s, loss=-0.000332, elapsed time=0.04, total time=8.16]\n",
      "[I 2025-06-07 22:07:30,060] Trial 29 finished with value: -0.0003321331412526002 and parameters: {'learning_rate': 0.0045563940293539005, 'sigma_multiplier': 1.8058592962242597, 'num_layers': 5, 'initialization_multiplier': 1.282254477867797}. Best is trial 27 with value: -0.0004005343397201333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 29 final loss: -0.00033213\n",
      "Trial 30:\n",
      "  Learning Rate: 0.004076820101027265\n",
      "  Sigma Multiplier: 1.8138303909482594\n",
      "  Initialization Multiplier: 1.4549483466261603\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.63it/s, loss=-0.000121, elapsed time=0.04, total time=8.28]\n",
      "[I 2025-06-07 22:07:38,393] Trial 30 finished with value: -0.00012065837657242618 and parameters: {'learning_rate': 0.004076820101027265, 'sigma_multiplier': 1.8138303909482594, 'num_layers': 5, 'initialization_multiplier': 1.4549483466261603}. Best is trial 27 with value: -0.0004005343397201333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 30 final loss: -0.00012066\n",
      "Trial 31:\n",
      "  Learning Rate: 0.004841803196493974\n",
      "  Sigma Multiplier: 1.7083833107614552\n",
      "  Initialization Multiplier: 1.1473277159141926\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:18<00:00,  8.17it/s, loss=-0.000512, elapsed time=0.05, total time=18.6]\n",
      "[I 2025-06-07 22:07:57,096] Trial 31 finished with value: -0.0005117636395648089 and parameters: {'learning_rate': 0.004841803196493974, 'sigma_multiplier': 1.7083833107614552, 'num_layers': 5, 'initialization_multiplier': 1.1473277159141926}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 31 final loss: -0.00051176\n",
      "Trial 32:\n",
      "  Learning Rate: 0.011702938199907172\n",
      "  Sigma Multiplier: 1.8767046559714242\n",
      "  Initialization Multiplier: 1.3963044843604016\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.02it/s, loss=-0.000264, elapsed time=0.05, total time=9.34]\n",
      "[I 2025-06-07 22:08:06,499] Trial 32 finished with value: -0.00026426163902990897 and parameters: {'learning_rate': 0.011702938199907172, 'sigma_multiplier': 1.8767046559714242, 'num_layers': 5, 'initialization_multiplier': 1.3963044843604016}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 32 final loss: -0.00026426\n",
      "Trial 33:\n",
      "  Learning Rate: 0.004385328401118367\n",
      "  Sigma Multiplier: 1.7463403748697206\n",
      "  Initialization Multiplier: 1.1611532209901585\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.67it/s, loss=-0.000298, elapsed time=0.06, total time=8.72]\n",
      "[I 2025-06-07 22:08:15,270] Trial 33 finished with value: -0.0002976632469612262 and parameters: {'learning_rate': 0.004385328401118367, 'sigma_multiplier': 1.7463403748697206, 'num_layers': 5, 'initialization_multiplier': 1.1611532209901585}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 33 final loss: -0.00029766\n",
      "Trial 34:\n",
      "  Learning Rate: 0.022252442050367485\n",
      "  Sigma Multiplier: 1.8722876810435451\n",
      "  Initialization Multiplier: 1.285316454234171\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.16it/s, loss=-0.000153, elapsed time=0.03, total time=6.04]\n",
      "[I 2025-06-07 22:08:21,346] Trial 34 finished with value: -0.0001533095111918868 and parameters: {'learning_rate': 0.022252442050367485, 'sigma_multiplier': 1.8722876810435451, 'num_layers': 2, 'initialization_multiplier': 1.285316454234171}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 34 final loss: -0.00015331\n",
      "Trial 35:\n",
      "  Learning Rate: 0.00165117009981167\n",
      "  Sigma Multiplier: 1.5381192375752735\n",
      "  Initialization Multiplier: 1.1486966931528078\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.18it/s, loss=-0.000008, elapsed time=0.04, total time=9.01]\n",
      "[I 2025-06-07 22:08:30,422] Trial 35 finished with value: -7.537186033726149e-06 and parameters: {'learning_rate': 0.00165117009981167, 'sigma_multiplier': 1.5381192375752735, 'num_layers': 5, 'initialization_multiplier': 1.1486966931528078}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 35 final loss: -0.00000754\n",
      "Trial 36:\n",
      "  Learning Rate: 0.006066136921539601\n",
      "  Sigma Multiplier: 1.7489988792851965\n",
      "  Initialization Multiplier: 1.498911367336564\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.18it/s, loss=-0.000343, elapsed time=0.04, total time=8.47]\n",
      "[I 2025-06-07 22:08:38,950] Trial 36 finished with value: -0.00034308373028931214 and parameters: {'learning_rate': 0.006066136921539601, 'sigma_multiplier': 1.7489988792851965, 'num_layers': 5, 'initialization_multiplier': 1.498911367336564}. Best is trial 31 with value: -0.0005117636395648089.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 36 final loss: -0.00034308\n",
      "Trial 37:\n",
      "  Learning Rate: 0.012529922603919507\n",
      "  Sigma Multiplier: 1.4402562057733146\n",
      "  Initialization Multiplier: 1.9680596739001786\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.74it/s, loss=-0.000584, elapsed time=0.07, total time=9.17]\n",
      "[I 2025-06-07 22:08:48,168] Trial 37 finished with value: -0.0005842494105895364 and parameters: {'learning_rate': 0.012529922603919507, 'sigma_multiplier': 1.4402562057733146, 'num_layers': 5, 'initialization_multiplier': 1.9680596739001786}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 37 final loss: -0.00058425\n",
      "Trial 38:\n",
      "  Learning Rate: 0.011606287234049568\n",
      "  Sigma Multiplier: 1.4440328575214068\n",
      "  Initialization Multiplier: 1.9966070914676461\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.83it/s, loss=-0.000201, elapsed time=0.05, total time=9.22]\n",
      "[I 2025-06-07 22:08:57,451] Trial 38 finished with value: -0.00020093989038575918 and parameters: {'learning_rate': 0.011606287234049568, 'sigma_multiplier': 1.4440328575214068, 'num_layers': 5, 'initialization_multiplier': 1.9966070914676461}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 38 final loss: -0.00020094\n",
      "Trial 39:\n",
      "  Learning Rate: 0.03701092636262711\n",
      "  Sigma Multiplier: 1.3702046034300543\n",
      "  Initialization Multiplier: 1.8639660365162882\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.36it/s, loss=-0.000186, elapsed time=0.06, total time=9.5] \n",
      "[I 2025-06-07 22:09:06,999] Trial 39 finished with value: -0.00018607923125758713 and parameters: {'learning_rate': 0.03701092636262711, 'sigma_multiplier': 1.3702046034300543, 'num_layers': 5, 'initialization_multiplier': 1.8639660365162882}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 39 final loss: -0.00018608\n",
      "Trial 40:\n",
      "  Learning Rate: 0.002656432816941807\n",
      "  Sigma Multiplier: 1.5339498323923155\n",
      "  Initialization Multiplier: 1.755118199220644\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.47it/s, loss=0.000614, elapsed time=0.05, total time=7.92]\n",
      "[I 2025-06-07 22:09:14,963] Trial 40 finished with value: 0.0006140396708353135 and parameters: {'learning_rate': 0.002656432816941807, 'sigma_multiplier': 1.5339498323923155, 'num_layers': 3, 'initialization_multiplier': 1.755118199220644}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 40 final loss: 0.00061404\n",
      "Trial 41:\n",
      "  Learning Rate: 0.005836697760031179\n",
      "  Sigma Multiplier: 1.7353641251762846\n",
      "  Initialization Multiplier: 1.481219118558474\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.85it/s, loss=-0.000364, elapsed time=0.05, total time=9.18]\n",
      "[I 2025-06-07 22:09:24,212] Trial 41 finished with value: -0.0003637576196678706 and parameters: {'learning_rate': 0.005836697760031179, 'sigma_multiplier': 1.7353641251762846, 'num_layers': 5, 'initialization_multiplier': 1.481219118558474}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 41 final loss: -0.00036376\n",
      "Trial 42:\n",
      "  Learning Rate: 0.014023874493731932\n",
      "  Sigma Multiplier: 1.5976172354058615\n",
      "  Initialization Multiplier: 1.366128283540769\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.19it/s, loss=-0.000327, elapsed time=0.06, total time=9.54]\n",
      "[I 2025-06-07 22:09:33,797] Trial 42 finished with value: -0.0003267906082841856 and parameters: {'learning_rate': 0.014023874493731932, 'sigma_multiplier': 1.5976172354058615, 'num_layers': 5, 'initialization_multiplier': 1.366128283540769}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 42 final loss: -0.00032679\n",
      "Trial 43:\n",
      "  Learning Rate: 0.008312715741666685\n",
      "  Sigma Multiplier: 1.9080493446110842\n",
      "  Initialization Multiplier: 1.5510458015662814\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.37it/s, loss=-0.000002, elapsed time=0.03, total time=6.5] \n",
      "[I 2025-06-07 22:09:40,343] Trial 43 finished with value: -2.488357184431328e-06 and parameters: {'learning_rate': 0.008312715741666685, 'sigma_multiplier': 1.9080493446110842, 'num_layers': 2, 'initialization_multiplier': 1.5510458015662814}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 43 final loss: -0.00000249\n",
      "Trial 44:\n",
      "  Learning Rate: 0.022942048018567127\n",
      "  Sigma Multiplier: 0.1395879163440651\n",
      "  Initialization Multiplier: 1.187280251668335\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.60it/s, loss=-0.000062, elapsed time=0.09, total time=14.4]\n",
      "[I 2025-06-07 22:09:54,834] Trial 44 finished with value: -6.216670074021733e-05 and parameters: {'learning_rate': 0.022942048018567127, 'sigma_multiplier': 0.1395879163440651, 'num_layers': 5, 'initialization_multiplier': 1.187280251668335}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 44 final loss: -0.00006217\n",
      "Trial 45:\n",
      "  Learning Rate: 0.003008110175771984\n",
      "  Sigma Multiplier: 1.7395178723350015\n",
      "  Initialization Multiplier: 1.9707455674416576\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.12it/s, loss=-0.000019, elapsed time=0.07, total time=10.9]\n",
      "[I 2025-06-07 22:10:05,822] Trial 45 finished with value: -1.8796332659282585e-05 and parameters: {'learning_rate': 0.003008110175771984, 'sigma_multiplier': 1.7395178723350015, 'num_layers': 5, 'initialization_multiplier': 1.9707455674416576}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 45 final loss: -0.00001880\n",
      "Trial 46:\n",
      "  Learning Rate: 0.013209506323717325\n",
      "  Sigma Multiplier: 1.6435572869351018\n",
      "  Initialization Multiplier: 1.7080079788292832\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.27it/s, loss=-0.000227, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 22:10:16,066] Trial 46 finished with value: -0.00022723617421588574 and parameters: {'learning_rate': 0.013209506323717325, 'sigma_multiplier': 1.6435572869351018, 'num_layers': 4, 'initialization_multiplier': 1.7080079788292832}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 46 final loss: -0.00022724\n",
      "Trial 47:\n",
      "  Learning Rate: 0.0017801482878866623\n",
      "  Sigma Multiplier: 1.4092594139588919\n",
      "  Initialization Multiplier: 1.368874344593956\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.90it/s, loss=-0.000079, elapsed time=0.11, total time=15.4]\n",
      "[I 2025-06-07 22:10:31,562] Trial 47 finished with value: -7.928887704186303e-05 and parameters: {'learning_rate': 0.0017801482878866623, 'sigma_multiplier': 1.4092594139588919, 'num_layers': 5, 'initialization_multiplier': 1.368874344593956}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 47 final loss: -0.00007929\n",
      "Trial 48:\n",
      "  Learning Rate: 0.005396182502225106\n",
      "  Sigma Multiplier: 1.9345264807844633\n",
      "  Initialization Multiplier: 0.8629545442845292\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.35it/s, loss=0.001557, elapsed time=0.04, total time=7.82]\n",
      "[I 2025-06-07 22:10:39,447] Trial 48 finished with value: 0.0015573582626654235 and parameters: {'learning_rate': 0.005396182502225106, 'sigma_multiplier': 1.9345264807844633, 'num_layers': 1, 'initialization_multiplier': 0.8629545442845292}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 48 final loss: 0.00155736\n",
      "Trial 49:\n",
      "  Learning Rate: 0.00015521194626377227\n",
      "  Sigma Multiplier: 1.6804154053586122\n",
      "  Initialization Multiplier: 1.0547288841967037\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.40it/s, loss=0.039138, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 22:10:49,597] Trial 49 finished with value: 0.03913805529285837 and parameters: {'learning_rate': 0.00015521194626377227, 'sigma_multiplier': 1.6804154053586122, 'num_layers': 4, 'initialization_multiplier': 1.0547288841967037}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 49 final loss: 0.03913806\n",
      "Trial 50:\n",
      "  Learning Rate: 0.009616049035070432\n",
      "  Sigma Multiplier: 1.8195576647062186\n",
      "  Initialization Multiplier: 1.6203078951482002\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.26it/s, loss=-0.000349, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 22:11:00,546] Trial 50 finished with value: -0.00034866648873064387 and parameters: {'learning_rate': 0.009616049035070432, 'sigma_multiplier': 1.8195576647062186, 'num_layers': 5, 'initialization_multiplier': 1.6203078951482002}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 50 final loss: -0.00034867\n",
      "Trial 51:\n",
      "  Learning Rate: 0.010221295437447025\n",
      "  Sigma Multiplier: 1.8178733776684441\n",
      "  Initialization Multiplier: 1.8232957074385563\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.17it/s, loss=-0.000265, elapsed time=0.05, total time=8.99]\n",
      "[I 2025-06-07 22:11:09,612] Trial 51 finished with value: -0.0002647690800080762 and parameters: {'learning_rate': 0.010221295437447025, 'sigma_multiplier': 1.8178733776684441, 'num_layers': 5, 'initialization_multiplier': 1.8232957074385563}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 51 final loss: -0.00026477\n",
      "Trial 52:\n",
      "  Learning Rate: 0.017554719514039353\n",
      "  Sigma Multiplier: 1.5112107379752833\n",
      "  Initialization Multiplier: 1.6126363039387033\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.35it/s, loss=-0.000238, elapsed time=0.05, total time=8.94]\n",
      "[I 2025-06-07 22:11:18,605] Trial 52 finished with value: -0.00023828972140513526 and parameters: {'learning_rate': 0.017554719514039353, 'sigma_multiplier': 1.5112107379752833, 'num_layers': 5, 'initialization_multiplier': 1.6126363039387033}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 52 final loss: -0.00023829\n",
      "Trial 53:\n",
      "  Learning Rate: 0.030115520534273042\n",
      "  Sigma Multiplier: 1.5860601962228582\n",
      "  Initialization Multiplier: 1.5139257463660374\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.90it/s, loss=-0.000138, elapsed time=0.05, total time=8.61]\n",
      "[I 2025-06-07 22:11:27,294] Trial 53 finished with value: -0.00013767265636067616 and parameters: {'learning_rate': 0.030115520534273042, 'sigma_multiplier': 1.5860601962228582, 'num_layers': 5, 'initialization_multiplier': 1.5139257463660374}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 53 final loss: -0.00013767\n",
      "Trial 54:\n",
      "  Learning Rate: 0.00593150156455367\n",
      "  Sigma Multiplier: 1.7258788735531811\n",
      "  Initialization Multiplier: 1.75161833109152\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.54it/s, loss=-0.000361, elapsed time=0.04, total time=9.86]\n",
      "[I 2025-06-07 22:11:37,222] Trial 54 finished with value: -0.00036110979467653565 and parameters: {'learning_rate': 0.00593150156455367, 'sigma_multiplier': 1.7258788735531811, 'num_layers': 5, 'initialization_multiplier': 1.75161833109152}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 54 final loss: -0.00036111\n",
      "Trial 55:\n",
      "  Learning Rate: 0.0030631988592356987\n",
      "  Sigma Multiplier: 0.6042447232026906\n",
      "  Initialization Multiplier: 1.776180132750585\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.45it/s, loss=0.003807, elapsed time=0.08, total time=12.3]\n",
      "[I 2025-06-07 22:11:49,580] Trial 55 finished with value: 0.003806970209396945 and parameters: {'learning_rate': 0.0030631988592356987, 'sigma_multiplier': 0.6042447232026906, 'num_layers': 5, 'initialization_multiplier': 1.776180132750585}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 55 final loss: 0.00380697\n",
      "Trial 56:\n",
      "  Learning Rate: 0.006875370866277081\n",
      "  Sigma Multiplier: 1.69515320797615\n",
      "  Initialization Multiplier: 1.928044722537964\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.10it/s, loss=-0.000447, elapsed time=0.06, total time=9.03]\n",
      "[I 2025-06-07 22:11:58,658] Trial 56 finished with value: -0.00044674874153465173 and parameters: {'learning_rate': 0.006875370866277081, 'sigma_multiplier': 1.69515320797615, 'num_layers': 4, 'initialization_multiplier': 1.928044722537964}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 56 final loss: -0.00044675\n",
      "Trial 57:\n",
      "  Learning Rate: 0.01676448348888097\n",
      "  Sigma Multiplier: 1.1991327301113057\n",
      "  Initialization Multiplier: 1.8948471905097661\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.61it/s, loss=-0.000044, elapsed time=0.05, total time=9.89]\n",
      "[I 2025-06-07 22:12:08,593] Trial 57 finished with value: -4.37452225348326e-05 and parameters: {'learning_rate': 0.01676448348888097, 'sigma_multiplier': 1.1991327301113057, 'num_layers': 4, 'initialization_multiplier': 1.8948471905097661}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 57 final loss: -0.00004375\n",
      "Trial 58:\n",
      "  Learning Rate: 0.04279578306584678\n",
      "  Sigma Multiplier: 1.3767473255944895\n",
      "  Initialization Multiplier: 1.2192655366228982\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.90it/s, loss=-0.000196, elapsed time=0.05, total time=8.64]\n",
      "[I 2025-06-07 22:12:17,280] Trial 58 finished with value: -0.0001956983824431428 and parameters: {'learning_rate': 0.04279578306584678, 'sigma_multiplier': 1.3767473255944895, 'num_layers': 3, 'initialization_multiplier': 1.2192655366228982}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 58 final loss: -0.00019570\n",
      "Trial 59:\n",
      "  Learning Rate: 0.0020459369591399896\n",
      "  Sigma Multiplier: 1.9554975907565622\n",
      "  Initialization Multiplier: 1.9398291060906745\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.41it/s, loss=0.000014, elapsed time=0.04, total time=8.43]\n",
      "[I 2025-06-07 22:12:25,762] Trial 59 finished with value: 1.4350127632982684e-05 and parameters: {'learning_rate': 0.0020459369591399896, 'sigma_multiplier': 1.9554975907565622, 'num_layers': 4, 'initialization_multiplier': 1.9398291060906745}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 59 final loss: 0.00001435\n",
      "Trial 60:\n",
      "  Learning Rate: 0.0011082109316928029\n",
      "  Sigma Multiplier: 1.591705871523518\n",
      "  Initialization Multiplier: 1.0838383940937213\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.74it/s, loss=0.013458, elapsed time=0.06, total time=9.25]\n",
      "[I 2025-06-07 22:12:35,065] Trial 60 finished with value: 0.013458091886481054 and parameters: {'learning_rate': 0.0011082109316928029, 'sigma_multiplier': 1.591705871523518, 'num_layers': 4, 'initialization_multiplier': 1.0838383940937213}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 60 final loss: 0.01345809\n",
      "Trial 61:\n",
      "  Learning Rate: 0.006442010308651362\n",
      "  Sigma Multiplier: 1.7149037729846885\n",
      "  Initialization Multiplier: 1.6913161263982601\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.86it/s, loss=-0.000182, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 22:12:45,465] Trial 61 finished with value: -0.0001816301140638193 and parameters: {'learning_rate': 0.006442010308651362, 'sigma_multiplier': 1.7149037729846885, 'num_layers': 5, 'initialization_multiplier': 1.6913161263982601}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 61 final loss: -0.00018163\n",
      "Trial 62:\n",
      "  Learning Rate: 0.0035065536295566403\n",
      "  Sigma Multiplier: 1.6738622220472998\n",
      "  Initialization Multiplier: 1.849347520949663\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.48it/s, loss=-0.000333, elapsed time=0.05, total time=9.98]\n",
      "[I 2025-06-07 22:12:55,500] Trial 62 finished with value: -0.00033289724128203533 and parameters: {'learning_rate': 0.0035065536295566403, 'sigma_multiplier': 1.6738622220472998, 'num_layers': 5, 'initialization_multiplier': 1.849347520949663}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 62 final loss: -0.00033290\n",
      "Trial 63:\n",
      "  Learning Rate: 0.0052358613521128325\n",
      "  Sigma Multiplier: 1.4802531236638112\n",
      "  Initialization Multiplier: 1.7005351334039895\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.92it/s, loss=-0.000111, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 22:13:05,886] Trial 63 finished with value: -0.00011060045178605772 and parameters: {'learning_rate': 0.0052358613521128325, 'sigma_multiplier': 1.4802531236638112, 'num_layers': 5, 'initialization_multiplier': 1.7005351334039895}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 63 final loss: -0.00011060\n",
      "Trial 64:\n",
      "  Learning Rate: 0.006879556774207171\n",
      "  Sigma Multiplier: 1.842994588086008\n",
      "  Initialization Multiplier: 1.935937494154895\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.98it/s, loss=-0.000372, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 22:13:16,291] Trial 64 finished with value: -0.0003715943664891626 and parameters: {'learning_rate': 0.006879556774207171, 'sigma_multiplier': 1.842994588086008, 'num_layers': 5, 'initialization_multiplier': 1.935937494154895}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 64 final loss: -0.00037159\n",
      "Trial 65:\n",
      "  Learning Rate: 0.008104311661842313\n",
      "  Sigma Multiplier: 1.7803791930602377\n",
      "  Initialization Multiplier: 0.9843848303763698\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.91it/s, loss=-0.000285, elapsed time=0.04, total time=8.24]\n",
      "[I 2025-06-07 22:13:24,578] Trial 65 finished with value: -0.00028478431775125234 and parameters: {'learning_rate': 0.008104311661842313, 'sigma_multiplier': 1.7803791930602377, 'num_layers': 3, 'initialization_multiplier': 0.9843848303763698}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 65 final loss: -0.00028478\n",
      "Trial 66:\n",
      "  Learning Rate: 0.026547241743484242\n",
      "  Sigma Multiplier: 1.9071632887479704\n",
      "  Initialization Multiplier: 1.909508835598454\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.77it/s, loss=-0.000264, elapsed time=0.06, total time=10.4]\n",
      "[I 2025-06-07 22:13:35,065] Trial 66 finished with value: -0.0002636795266488511 and parameters: {'learning_rate': 0.026547241743484242, 'sigma_multiplier': 1.9071632887479704, 'num_layers': 5, 'initialization_multiplier': 1.909508835598454}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 66 final loss: -0.00026368\n",
      "Trial 67:\n",
      "  Learning Rate: 0.010055232242945812\n",
      "  Sigma Multiplier: 1.8299347184860522\n",
      "  Initialization Multiplier: 1.9988210023225599\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.19it/s, loss=-0.000135, elapsed time=0.05, total time=9.51]\n",
      "[I 2025-06-07 22:13:44,631] Trial 67 finished with value: -0.00013462536200789817 and parameters: {'learning_rate': 0.010055232242945812, 'sigma_multiplier': 1.8299347184860522, 'num_layers': 4, 'initialization_multiplier': 1.9988210023225599}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 67 final loss: -0.00013463\n",
      "Trial 68:\n",
      "  Learning Rate: 0.01556353582494675\n",
      "  Sigma Multiplier: 1.6323530945831817\n",
      "  Initialization Multiplier: 1.3043550900653806\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.63it/s, loss=-0.000378, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 22:13:55,297] Trial 68 finished with value: -0.0003784896974287022 and parameters: {'learning_rate': 0.01556353582494675, 'sigma_multiplier': 1.6323530945831817, 'num_layers': 5, 'initialization_multiplier': 1.3043550900653806}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 68 final loss: -0.00037849\n",
      "Trial 69:\n",
      "  Learning Rate: 0.016710637374099255\n",
      "  Sigma Multiplier: 1.6408752786979435\n",
      "  Initialization Multiplier: 1.3410459360266822\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.96it/s, loss=-0.000302, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 22:14:05,672] Trial 69 finished with value: -0.0003016749137453978 and parameters: {'learning_rate': 0.016710637374099255, 'sigma_multiplier': 1.6408752786979435, 'num_layers': 5, 'initialization_multiplier': 1.3410459360266822}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 69 final loss: -0.00030167\n",
      "Trial 70:\n",
      "  Learning Rate: 0.020753177878291496\n",
      "  Sigma Multiplier: 1.998030728683398\n",
      "  Initialization Multiplier: 1.090385840112616\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.01it/s, loss=-0.000279, elapsed time=0.05, total time=9.11]\n",
      "[I 2025-06-07 22:14:14,834] Trial 70 finished with value: -0.00027903154917907576 and parameters: {'learning_rate': 0.020753177878291496, 'sigma_multiplier': 1.998030728683398, 'num_layers': 4, 'initialization_multiplier': 1.090385840112616}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 70 final loss: -0.00027903\n",
      "Trial 71:\n",
      "  Learning Rate: 0.014161274287033836\n",
      "  Sigma Multiplier: 1.8492370095940618\n",
      "  Initialization Multiplier: 1.1245266421492515\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.50it/s, loss=-0.000201, elapsed time=0.06, total time=9.99]\n",
      "[I 2025-06-07 22:14:24,885] Trial 71 finished with value: -0.0002013521905447555 and parameters: {'learning_rate': 0.014161274287033836, 'sigma_multiplier': 1.8492370095940618, 'num_layers': 5, 'initialization_multiplier': 1.1245266421492515}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 71 final loss: -0.00020135\n",
      "Trial 72:\n",
      "  Learning Rate: 0.00785107318624881\n",
      "  Sigma Multiplier: 1.7802135954777059\n",
      "  Initialization Multiplier: 1.2562206238457971\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.12it/s, loss=-0.000320, elapsed time=0.04, total time=10.3]\n",
      "[I 2025-06-07 22:14:35,214] Trial 72 finished with value: -0.0003202161937645119 and parameters: {'learning_rate': 0.00785107318624881, 'sigma_multiplier': 1.7802135954777059, 'num_layers': 5, 'initialization_multiplier': 1.2562206238457971}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 72 final loss: -0.00032022\n",
      "Trial 73:\n",
      "  Learning Rate: 3.111819087882262e-05\n",
      "  Sigma Multiplier: 1.58373247951347\n",
      "  Initialization Multiplier: 1.3112150657041495\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.47it/s, loss=0.057523, elapsed time=0.06, total time=10.1]\n",
      "[I 2025-06-07 22:14:45,314] Trial 73 finished with value: 0.0575231600276218 and parameters: {'learning_rate': 3.111819087882262e-05, 'sigma_multiplier': 1.58373247951347, 'num_layers': 5, 'initialization_multiplier': 1.3112150657041495}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 73 final loss: 0.05752316\n",
      "Trial 74:\n",
      "  Learning Rate: 0.004205244706125702\n",
      "  Sigma Multiplier: 1.695556933868408\n",
      "  Initialization Multiplier: 1.2229493526995687\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.58it/s, loss=0.001210, elapsed time=0.05, total time=9.94]\n",
      "[I 2025-06-07 22:14:55,314] Trial 74 finished with value: 0.00120977601224497 and parameters: {'learning_rate': 0.004205244706125702, 'sigma_multiplier': 1.695556933868408, 'num_layers': 5, 'initialization_multiplier': 1.2229493526995687}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 74 final loss: 0.00120978\n",
      "Trial 75:\n",
      "  Learning Rate: 0.012360604420595691\n",
      "  Sigma Multiplier: 1.7723446306418216\n",
      "  Initialization Multiplier: 0.9805830995861233\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.07it/s, loss=-0.000154, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 22:15:05,591] Trial 75 finished with value: -0.00015445581484523757 and parameters: {'learning_rate': 0.012360604420595691, 'sigma_multiplier': 1.7723446306418216, 'num_layers': 5, 'initialization_multiplier': 0.9805830995861233}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 75 final loss: -0.00015446\n",
      "Trial 76:\n",
      "  Learning Rate: 0.007173932750605358\n",
      "  Sigma Multiplier: 0.8907279456263817\n",
      "  Initialization Multiplier: 1.4522336119886257\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.96it/s, loss=0.000609, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 22:15:16,669] Trial 76 finished with value: 0.0006086811753909946 and parameters: {'learning_rate': 0.007173932750605358, 'sigma_multiplier': 0.8907279456263817, 'num_layers': 5, 'initialization_multiplier': 1.4522336119886257}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 76 final loss: 0.00060868\n",
      "Trial 77:\n",
      "  Learning Rate: 0.025545241216651533\n",
      "  Sigma Multiplier: 1.5356667874723395\n",
      "  Initialization Multiplier: 1.4451632157410044\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.30it/s, loss=-0.000251, elapsed time=0.07, total time=10.1]\n",
      "[I 2025-06-07 22:15:26,851] Trial 77 finished with value: -0.00025080279709363985 and parameters: {'learning_rate': 0.025545241216651533, 'sigma_multiplier': 1.5356667874723395, 'num_layers': 5, 'initialization_multiplier': 1.4451632157410044}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 77 final loss: -0.00025080\n",
      "Trial 78:\n",
      "  Learning Rate: 0.037893661562045926\n",
      "  Sigma Multiplier: 1.6311274718730533\n",
      "  Initialization Multiplier: 1.7916116660048513\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.61it/s, loss=-0.000284, elapsed time=0.04, total time=9.99]\n",
      "[I 2025-06-07 22:15:36,905] Trial 78 finished with value: -0.0002842614376090371 and parameters: {'learning_rate': 0.037893661562045926, 'sigma_multiplier': 1.6311274718730533, 'num_layers': 5, 'initialization_multiplier': 1.7916116660048513}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 78 final loss: -0.00028426\n",
      "Trial 79:\n",
      "  Learning Rate: 0.005179243589698433\n",
      "  Sigma Multiplier: 1.447678198987766\n",
      "  Initialization Multiplier: 0.8429464411494934\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.59it/s, loss=0.004078, elapsed time=0.06, total time=9.88]\n",
      "[I 2025-06-07 22:15:46,831] Trial 79 finished with value: 0.0040779257162024286 and parameters: {'learning_rate': 0.005179243589698433, 'sigma_multiplier': 1.447678198987766, 'num_layers': 5, 'initialization_multiplier': 0.8429464411494934}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 79 final loss: 0.00407793\n",
      "Trial 80:\n",
      "  Learning Rate: 0.01799804226617657\n",
      "  Sigma Multiplier: 1.869696694956377\n",
      "  Initialization Multiplier: 1.1204819871974334\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.57it/s, loss=-0.000183, elapsed time=0.05, total time=9.38]\n",
      "[I 2025-06-07 22:15:56,261] Trial 80 finished with value: -0.00018287121724193213 and parameters: {'learning_rate': 0.01799804226617657, 'sigma_multiplier': 1.869696694956377, 'num_layers': 4, 'initialization_multiplier': 1.1204819871974334}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 80 final loss: -0.00018287\n",
      "Trial 81:\n",
      "  Learning Rate: 0.00935395773813779\n",
      "  Sigma Multiplier: 1.7095327982656938\n",
      "  Initialization Multiplier: 1.9360621267100127\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.02it/s, loss=-0.000208, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 22:16:06,648] Trial 81 finished with value: -0.00020847758187596542 and parameters: {'learning_rate': 0.00935395773813779, 'sigma_multiplier': 1.7095327982656938, 'num_layers': 5, 'initialization_multiplier': 1.9360621267100127}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 81 final loss: -0.00020848\n",
      "Trial 82:\n",
      "  Learning Rate: 0.005970328480375231\n",
      "  Sigma Multiplier: 1.735390213107322\n",
      "  Initialization Multiplier: 1.8791293519073022\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.97it/s, loss=-0.000116, elapsed time=0.06, total time=10.4]\n",
      "[I 2025-06-07 22:16:17,105] Trial 82 finished with value: -0.00011644263630474374 and parameters: {'learning_rate': 0.005970328480375231, 'sigma_multiplier': 1.735390213107322, 'num_layers': 5, 'initialization_multiplier': 1.8791293519073022}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 82 final loss: -0.00011644\n",
      "Trial 83:\n",
      "  Learning Rate: 0.0037024512697230354\n",
      "  Sigma Multiplier: 1.659949881504735\n",
      "  Initialization Multiplier: 1.74240266744932\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.01it/s, loss=-0.000043, elapsed time=0.04, total time=9.64]\n",
      "[I 2025-06-07 22:16:26,800] Trial 83 finished with value: -4.271591523588522e-05 and parameters: {'learning_rate': 0.0037024512697230354, 'sigma_multiplier': 1.659949881504735, 'num_layers': 5, 'initialization_multiplier': 1.74240266744932}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 83 final loss: -0.00004272\n",
      "Trial 84:\n",
      "  Learning Rate: 0.0022766641662732025\n",
      "  Sigma Multiplier: 1.5637096263336208\n",
      "  Initialization Multiplier: 0.061610004381664085\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.22it/s, loss=0.000056, elapsed time=0.05, total time=10.1] \n",
      "[I 2025-06-07 22:16:36,952] Trial 84 finished with value: 5.551126637697755e-05 and parameters: {'learning_rate': 0.0022766641662732025, 'sigma_multiplier': 1.5637096263336208, 'num_layers': 5, 'initialization_multiplier': 0.061610004381664085}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 84 final loss: 0.00005551\n",
      "Trial 85:\n",
      "  Learning Rate: 0.006847105783113455\n",
      "  Sigma Multiplier: 1.946310001382183\n",
      "  Initialization Multiplier: 1.659025920856826\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.09it/s, loss=-0.000195, elapsed time=0.08, total time=10.2]\n",
      "[I 2025-06-07 22:16:47,207] Trial 85 finished with value: -0.00019480849924726244 and parameters: {'learning_rate': 0.006847105783113455, 'sigma_multiplier': 1.946310001382183, 'num_layers': 5, 'initialization_multiplier': 1.659025920856826}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 85 final loss: -0.00019481\n",
      "Trial 86:\n",
      "  Learning Rate: 0.011333197531916332\n",
      "  Sigma Multiplier: 1.7593152222219806\n",
      "  Initialization Multiplier: 1.5653104592186808\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.06it/s, loss=-0.000292, elapsed time=0.08, total time=10.2]\n",
      "[I 2025-06-07 22:16:57,476] Trial 86 finished with value: -0.00029210693510890886 and parameters: {'learning_rate': 0.011333197531916332, 'sigma_multiplier': 1.7593152222219806, 'num_layers': 5, 'initialization_multiplier': 1.5653104592186808}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 86 final loss: -0.00029211\n",
      "Trial 87:\n",
      "  Learning Rate: 0.01460866177072218\n",
      "  Sigma Multiplier: 1.8546197752710856\n",
      "  Initialization Multiplier: 1.8360682485005075\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.08it/s, loss=-0.000210, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 22:17:07,804] Trial 87 finished with value: -0.00021017903000380102 and parameters: {'learning_rate': 0.01460866177072218, 'sigma_multiplier': 1.8546197752710856, 'num_layers': 5, 'initialization_multiplier': 1.8360682485005075}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 87 final loss: -0.00021018\n",
      "Trial 88:\n",
      "  Learning Rate: 0.008839402113420549\n",
      "  Sigma Multiplier: 1.6185802014218522\n",
      "  Initialization Multiplier: 1.0377774729905334\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.32it/s, loss=-0.000109, elapsed time=0.06, total time=10]  \n",
      "[I 2025-06-07 22:17:17,896] Trial 88 finished with value: -0.00010940208829397597 and parameters: {'learning_rate': 0.008839402113420549, 'sigma_multiplier': 1.6185802014218522, 'num_layers': 5, 'initialization_multiplier': 1.0377774729905334}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 88 final loss: -0.00010940\n",
      "Trial 89:\n",
      "  Learning Rate: 0.003061880812862843\n",
      "  Sigma Multiplier: 1.4973153299765996\n",
      "  Initialization Multiplier: 1.962186946139384\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.33it/s, loss=0.009076, elapsed time=0.07, total time=6.99]\n",
      "[I 2025-06-07 22:17:24,927] Trial 89 finished with value: 0.009076494783371853 and parameters: {'learning_rate': 0.003061880812862843, 'sigma_multiplier': 1.4973153299765996, 'num_layers': 2, 'initialization_multiplier': 1.962186946139384}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 89 final loss: 0.00907649\n",
      "Trial 90:\n",
      "  Learning Rate: 0.005233344187450868\n",
      "  Sigma Multiplier: 0.338549680935055\n",
      "  Initialization Multiplier: 1.4108007670200298\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.29it/s, loss=0.002600, elapsed time=0.08, total time=13.6]\n",
      "[I 2025-06-07 22:17:38,543] Trial 90 finished with value: 0.0026001362244346695 and parameters: {'learning_rate': 0.005233344187450868, 'sigma_multiplier': 0.338549680935055, 'num_layers': 5, 'initialization_multiplier': 1.4108007670200298}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 90 final loss: 0.00260014\n",
      "Trial 91:\n",
      "  Learning Rate: 0.010292092154055426\n",
      "  Sigma Multiplier: 1.8079910055272683\n",
      "  Initialization Multiplier: 1.5069444319463874\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.86it/s, loss=-0.000294, elapsed time=0.05, total time=9.74]\n",
      "[I 2025-06-07 22:17:48,338] Trial 91 finished with value: -0.000293862383262655 and parameters: {'learning_rate': 0.010292092154055426, 'sigma_multiplier': 1.8079910055272683, 'num_layers': 5, 'initialization_multiplier': 1.5069444319463874}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 91 final loss: -0.00029386\n",
      "Trial 92:\n",
      "  Learning Rate: 0.0194437819874175\n",
      "  Sigma Multiplier: 1.7176047353496346\n",
      "  Initialization Multiplier: 1.6211645381378188\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.51it/s, loss=-0.000168, elapsed time=0.04, total time=8.87]\n",
      "[I 2025-06-07 22:17:57,255] Trial 92 finished with value: -0.00016789059299597532 and parameters: {'learning_rate': 0.0194437819874175, 'sigma_multiplier': 1.7176047353496346, 'num_layers': 5, 'initialization_multiplier': 1.6211645381378188}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 92 final loss: -0.00016789\n",
      "Trial 93:\n",
      "  Learning Rate: 0.01496360529658561\n",
      "  Sigma Multiplier: 1.9066069024835979\n",
      "  Initialization Multiplier: 1.212010380558872\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.02it/s, loss=-0.000396, elapsed time=0.05, total time=7.74]\n",
      "[I 2025-06-07 22:18:05,076] Trial 93 finished with value: -0.0003955664034844372 and parameters: {'learning_rate': 0.01496360529658561, 'sigma_multiplier': 1.9066069024835979, 'num_layers': 5, 'initialization_multiplier': 1.212010380558872}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 93 final loss: -0.00039557\n",
      "Trial 94:\n",
      "  Learning Rate: 0.031700896748372204\n",
      "  Sigma Multiplier: 1.9322530521031993\n",
      "  Initialization Multiplier: 1.1805464259438363\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.26it/s, loss=-0.000209, elapsed time=0.05, total time=7.28]\n",
      "[I 2025-06-07 22:18:12,414] Trial 94 finished with value: -0.00020856526813746608 and parameters: {'learning_rate': 0.031700896748372204, 'sigma_multiplier': 1.9322530521031993, 'num_layers': 5, 'initialization_multiplier': 1.1805464259438363}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 94 final loss: -0.00020857\n",
      "Trial 95:\n",
      "  Learning Rate: 0.01518199254419617\n",
      "  Sigma Multiplier: 1.8922927344055653\n",
      "  Initialization Multiplier: 1.3340080418830602\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.39it/s, loss=-0.000180, elapsed time=0.05, total time=7.99]\n",
      "[I 2025-06-07 22:18:20,453] Trial 95 finished with value: -0.00017963553966033217 and parameters: {'learning_rate': 0.01518199254419617, 'sigma_multiplier': 1.8922927344055653, 'num_layers': 5, 'initialization_multiplier': 1.3340080418830602}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 95 final loss: -0.00017964\n",
      "Trial 96:\n",
      "  Learning Rate: 0.04577754279697202\n",
      "  Sigma Multiplier: 1.6788621801292047\n",
      "  Initialization Multiplier: 1.264583366182922\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.24it/s, loss=-0.000225, elapsed time=0.04, total time=7.64]\n",
      "[I 2025-06-07 22:18:28,136] Trial 96 finished with value: -0.00022525856455140898 and parameters: {'learning_rate': 0.04577754279697202, 'sigma_multiplier': 1.6788621801292047, 'num_layers': 4, 'initialization_multiplier': 1.264583366182922}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 96 final loss: -0.00022526\n",
      "Trial 97:\n",
      "  Learning Rate: 0.07112085518583944\n",
      "  Sigma Multiplier: 1.7910397233665916\n",
      "  Initialization Multiplier: 1.9171034270232459\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.81it/s, loss=-0.000074, elapsed time=0.06, total time=8.22]\n",
      "[I 2025-06-07 22:18:36,430] Trial 97 finished with value: -7.423620188887881e-05 and parameters: {'learning_rate': 0.07112085518583944, 'sigma_multiplier': 1.7910397233665916, 'num_layers': 5, 'initialization_multiplier': 1.9171034270232459}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 97 final loss: -0.00007424\n",
      "Trial 98:\n",
      "  Learning Rate: 0.012753772325256147\n",
      "  Sigma Multiplier: 1.8427960823750733\n",
      "  Initialization Multiplier: 1.1920639091870442\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.14it/s, loss=-0.000380, elapsed time=0.05, total time=8.54]\n",
      "[I 2025-06-07 22:18:45,018] Trial 98 finished with value: -0.00037953682128703787 and parameters: {'learning_rate': 0.012753772325256147, 'sigma_multiplier': 1.8427960823750733, 'num_layers': 5, 'initialization_multiplier': 1.1920639091870442}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 98 final loss: -0.00037954\n",
      "Trial 99:\n",
      "  Learning Rate: 0.0242490421154761\n",
      "  Sigma Multiplier: 1.8297819909944701\n",
      "  Initialization Multiplier: 1.2113810527126294\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.74it/s, loss=-0.000193, elapsed time=0.05, total time=7.85]\n",
      "[I 2025-06-07 22:18:52,930] Trial 99 finished with value: -0.0001930098887073218 and parameters: {'learning_rate': 0.0242490421154761, 'sigma_multiplier': 1.8297819909944701, 'num_layers': 5, 'initialization_multiplier': 1.2113810527126294}. Best is trial 37 with value: -0.0005842494105895364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 99 final loss: -0.00019301\n"
     ]
    }
   ],
   "source": [
    "study = run_hpo(\n",
    "    grid_conn,\n",
    "    QUBITS,\n",
    "    base_sigma,\n",
    "    train_ds = train_ds,\n",
    "    n_trials = 100,\n",
    "    n_iters_hpo = 150,\n",
    "    n_ops = 2000,\n",
    "    n_samples = 2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Best hyperparameters found: {'learning_rate': 0.012529922603919507, 'sigma_multiplier': 1.4402562057733146, 'num_layers': 5, 'initialization_multiplier': 1.9680596739001786}\n",
      "Best loss value: -0.0005842494105895364\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = study.best_params\n",
    "best_loss_value = study.best_value\n",
    "\n",
    "print(\"\\nOptimization Finished!\")\n",
    "print(f\"Best hyperparameters found: {best_hyperparams}\")\n",
    "print(f\"Best loss value: {best_loss_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = best_hyperparams['learning_rate']\n",
    "SIGMA_M = best_hyperparams['sigma_multiplier']\n",
    "NUM_LAYERS = best_hyperparams['num_layers']\n",
    "INIT_M = best_hyperparams['initialization_multiplier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_dataset(dataset=train_ds):\n",
    "    grid_conn= aachen_connectivity()\n",
    "    num_qubits = NODES * (NODES - 1) // 2\n",
    "    gates = efficient_connectivity_gates(grid_conn, num_qubits, NUM_LAYERS)\n",
    "    \n",
    "    circuit = iqp.IqpSimulator(num_qubits, gates, device=\"lightning.qubit\")\n",
    "    \n",
    "    initial_params = initialize_from_data(gates, dataset) * INIT_M\n",
    "    loss = iqp.gen_qml.mmd_loss_iqp\n",
    "    learning_rate = LR\n",
    "    sigma = median_heuristic(dataset) * SIGMA_M\n",
    "    \n",
    "    loss_kwarg = {\n",
    "        \"params\": initial_params,\n",
    "        \"iqp_circuit\": circuit,\n",
    "        \"ground_truth\": dataset,\n",
    "        \"sigma\": [sigma],\n",
    "        \"n_ops\": 2000,\n",
    "        \"n_samples\": 2000,\n",
    "        \"key\": jax.random.PRNGKey(42),\n",
    "    }\n",
    "    \n",
    "    trainer = iqp.Trainer(\"Adam\", loss, stepsize=learning_rate)\n",
    "    trainer.train(n_iters= 2000,loss_kwargs=loss_kwarg, turbo=1)\n",
    "    \n",
    "    return trainer.final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 2000/2000 [01:41<00:00, 19.76it/s, loss=-0.000174, elapsed time=0.04, total time=101] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 2000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = train_on_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'./results/params/params_{NODES}N_{TYPE}_{CONN}_LR{LR}_SIGMA{SIGMA_M}_INIT{INIT_M}_MAX_WEIGHT{NUM_LAYERS}.npy', params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results/params/params_8N_Bipartite_Medium_LR0.012529922603919507_SIGMA1.4402562057733146_INIT1.9680596739001786_NUMLAYERS5.npy'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'./results/params/params_{NODES}N_{TYPE}_{CONN}_LR{LR}_SIGMA{SIGMA_M}_INIT{INIT_M}_NUMLAYERS{NUM_LAYERS}.npy'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
