{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/uribagi/Documents/GitHub/Latent-IQP/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import iqpopt as iqp\n",
    "from iqpopt.utils import initialize_from_data, local_gates\n",
    "import iqpopt.gen_qml as genq\n",
    "from iqpopt.gen_qml.utils import median_heuristic\n",
    "import optuna\n",
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from utils.nisq import aachen_connectivity, efficient_connectivity_gates\n",
    "from datasets.bipartites import BipartiteGraphDataset\n",
    "from datasets.er import ErdosRenyiGraphDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 10\n",
    "TYPE = \"Bipartite\"\n",
    "CONN = \"Sparse\"\n",
    "NUM_LAYERS = 1\n",
    "QUBITS = NODES * (NODES - 1) //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Loaded 473 samples from ./datasets/raw_data/10N_Bipartite_Sparse.pkl\n",
      "  Created: 2025-05-30T13:15:39.349125\n",
      "  Unique graphs: 473\n",
      "  Version: 1.0\n"
     ]
    }
   ],
   "source": [
    "ds_path = f'./datasets/raw_data/{NODES}N_{TYPE}_{CONN}.pkl'\n",
    "train_ds = jnp.array(BipartiteGraphDataset(nodes = 1, edge_prob=0.1).from_file(ds_path).vectors.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_conn = aachen_connectivity()\n",
    "gates = efficient_connectivity_gates(grid_conn, QUBITS, 1) \n",
    "circ = iqp.IqpSimulator(QUBITS, gates, device='lightning.qubit')\n",
    "\n",
    "base_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = median_heuristic(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hpo import run_hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 12:35:39,396] A new study created in memory with name: no-name-b129ab4d-6a9f-419c-943a-539c7fbb9e1a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0:\n",
      "  Learning Rate: 6.935503216398411e-05\n",
      "  Sigma Multiplier: 0.4412836533228413\n",
      "  Initialization Multiplier: 1.3825780687684395\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.00it/s, loss=0.085865, elapsed time=0.06, total time=13.8]\n",
      "[I 2025-06-07 12:35:53,795] Trial 0 finished with value: 0.08586518143064445 and parameters: {'learning_rate': 6.935503216398411e-05, 'sigma_multiplier': 0.4412836533228413, 'num_layers': 2, 'initialization_multiplier': 1.3825780687684395}. Best is trial 0 with value: 0.08586518143064445.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 0 final loss: 0.08586518\n",
      "Trial 1:\n",
      "  Learning Rate: 0.0004503969869841552\n",
      "  Sigma Multiplier: 0.6893098576089395\n",
      "  Initialization Multiplier: 0.1635306173615728\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.91it/s, loss=0.045908, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 12:36:04,182] Trial 1 finished with value: 0.04590808221316834 and parameters: {'learning_rate': 0.0004503969869841552, 'sigma_multiplier': 0.6893098576089395, 'num_layers': 2, 'initialization_multiplier': 0.1635306173615728}. Best is trial 1 with value: 0.04590808221316834.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 1 final loss: 0.04590808\n",
      "Trial 2:\n",
      "  Learning Rate: 8.729806907676517e-05\n",
      "  Sigma Multiplier: 0.1096369182249704\n",
      "  Initialization Multiplier: 1.8475919564360936\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:18<00:00,  8.32it/s, loss=0.000003, elapsed time=0.12, total time=18.3] \n",
      "[I 2025-06-07 12:36:22,694] Trial 2 finished with value: 2.930511707352784e-06 and parameters: {'learning_rate': 8.729806907676517e-05, 'sigma_multiplier': 0.1096369182249704, 'num_layers': 4, 'initialization_multiplier': 1.8475919564360936}. Best is trial 2 with value: 2.930511707352784e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 2 final loss: 0.00000293\n",
      "Trial 3:\n",
      "  Learning Rate: 0.03259557303412773\n",
      "  Sigma Multiplier: 0.17564814509798837\n",
      "  Initialization Multiplier: 1.7779550803245565\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:20<00:00,  7.40it/s, loss=-0.000067, elapsed time=0.12, total time=20.8]\n",
      "[I 2025-06-07 12:36:43,636] Trial 3 finished with value: -6.728708824589416e-05 and parameters: {'learning_rate': 0.03259557303412773, 'sigma_multiplier': 0.17564814509798837, 'num_layers': 5, 'initialization_multiplier': 1.7779550803245565}. Best is trial 3 with value: -6.728708824589416e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 3 final loss: -0.00006729\n",
      "Trial 4:\n",
      "  Learning Rate: 0.0020988318194136916\n",
      "  Sigma Multiplier: 0.9816040453773254\n",
      "  Initialization Multiplier: 0.6470935599256601\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.94it/s, loss=-0.000274, elapsed time=0.06, total time=9.81]\n",
      "[I 2025-06-07 12:36:53,532] Trial 4 finished with value: -0.0002739699475439886 and parameters: {'learning_rate': 0.0020988318194136916, 'sigma_multiplier': 0.9816040453773254, 'num_layers': 1, 'initialization_multiplier': 0.6470935599256601}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 4 final loss: -0.00027397\n",
      "Trial 5:\n",
      "  Learning Rate: 0.012961055154117739\n",
      "  Sigma Multiplier: 0.7537358141801683\n",
      "  Initialization Multiplier: 1.894349747886663\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.00it/s, loss=0.000079, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 12:37:04,573] Trial 5 finished with value: 7.932762713785821e-05 and parameters: {'learning_rate': 0.012961055154117739, 'sigma_multiplier': 0.7537358141801683, 'num_layers': 1, 'initialization_multiplier': 1.894349747886663}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 5 final loss: 0.00007933\n",
      "Trial 6:\n",
      "  Learning Rate: 0.001540571904798215\n",
      "  Sigma Multiplier: 1.472753281514465\n",
      "  Initialization Multiplier: 0.8279204339529765\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.23it/s, loss=0.011734, elapsed time=0.08, total time=15]  \n",
      "[I 2025-06-07 12:37:19,632] Trial 6 finished with value: 0.011734189946271468 and parameters: {'learning_rate': 0.001540571904798215, 'sigma_multiplier': 1.472753281514465, 'num_layers': 4, 'initialization_multiplier': 0.8279204339529765}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 6 final loss: 0.01173419\n",
      "Trial 7:\n",
      "  Learning Rate: 6.909710333814888e-05\n",
      "  Sigma Multiplier: 1.4955849574834732\n",
      "  Initialization Multiplier: 0.03783925898591827\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.36it/s, loss=0.083156, elapsed time=0.07, total time=10.1]\n",
      "[I 2025-06-07 12:37:29,724] Trial 7 finished with value: 0.08315623430177585 and parameters: {'learning_rate': 6.909710333814888e-05, 'sigma_multiplier': 1.4955849574834732, 'num_layers': 2, 'initialization_multiplier': 0.03783925898591827}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 7 final loss: 0.08315623\n",
      "Trial 8:\n",
      "  Learning Rate: 0.00018490879919956768\n",
      "  Sigma Multiplier: 0.7582374424488165\n",
      "  Initialization Multiplier: 1.9129659518436648\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.78it/s, loss=0.138716, elapsed time=0.11, total time=17.4]\n",
      "[I 2025-06-07 12:37:47,195] Trial 8 finished with value: 0.13871582003327854 and parameters: {'learning_rate': 0.00018490879919956768, 'sigma_multiplier': 0.7582374424488165, 'num_layers': 4, 'initialization_multiplier': 1.9129659518436648}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 8 final loss: 0.13871582\n",
      "Trial 9:\n",
      "  Learning Rate: 0.010443273466725597\n",
      "  Sigma Multiplier: 1.278693691321831\n",
      "  Initialization Multiplier: 0.09674668654126828\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.33it/s, loss=-0.000227, elapsed time=0.06, total time=12.6]\n",
      "[I 2025-06-07 12:37:59,980] Trial 9 finished with value: -0.00022656437555830294 and parameters: {'learning_rate': 0.010443273466725597, 'sigma_multiplier': 1.278693691321831, 'num_layers': 3, 'initialization_multiplier': 0.09674668654126828}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 9 final loss: -0.00022656\n",
      "Trial 10:\n",
      "  Learning Rate: 0.0023414740349941704\n",
      "  Sigma Multiplier: 1.8160719886395822\n",
      "  Initialization Multiplier: 0.6773856986937976\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.70it/s, loss=-0.000146, elapsed time=0.07, total time=8.32]\n",
      "[I 2025-06-07 12:38:08,334] Trial 10 finished with value: -0.00014609374324446828 and parameters: {'learning_rate': 0.0023414740349941704, 'sigma_multiplier': 1.8160719886395822, 'num_layers': 1, 'initialization_multiplier': 0.6773856986937976}. Best is trial 4 with value: -0.0002739699475439886.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 10 final loss: -0.00014609\n",
      "Trial 11:\n",
      "  Learning Rate: 0.00601628639667007\n",
      "  Sigma Multiplier: 1.2280720951257398\n",
      "  Initialization Multiplier: 0.46141554017996406\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.68it/s, loss=-0.000404, elapsed time=0.08, total time=13.2]\n",
      "[I 2025-06-07 12:38:21,529] Trial 11 finished with value: -0.00040403594016146156 and parameters: {'learning_rate': 0.00601628639667007, 'sigma_multiplier': 1.2280720951257398, 'num_layers': 3, 'initialization_multiplier': 0.46141554017996406}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 11 final loss: -0.00040404\n",
      "Trial 12:\n",
      "  Learning Rate: 0.0031043252958263623\n",
      "  Sigma Multiplier: 1.091922720235438\n",
      "  Initialization Multiplier: 0.49259637275970314\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.18it/s, loss=-0.000323, elapsed time=0.11, total time=13.7]\n",
      "[I 2025-06-07 12:38:35,293] Trial 12 finished with value: -0.00032295688029716774 and parameters: {'learning_rate': 0.0031043252958263623, 'sigma_multiplier': 1.091922720235438, 'num_layers': 3, 'initialization_multiplier': 0.49259637275970314}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 12 final loss: -0.00032296\n",
      "Trial 13:\n",
      "  Learning Rate: 0.0788773545858736\n",
      "  Sigma Multiplier: 1.3052103512228208\n",
      "  Initialization Multiplier: 0.342572899647249\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.71it/s, loss=-0.000209, elapsed time=0.06, total time=13.1]\n",
      "[I 2025-06-07 12:38:48,457] Trial 13 finished with value: -0.0002087590084874756 and parameters: {'learning_rate': 0.0788773545858736, 'sigma_multiplier': 1.3052103512228208, 'num_layers': 3, 'initialization_multiplier': 0.342572899647249}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 13 final loss: -0.00020876\n",
      "Trial 14:\n",
      "  Learning Rate: 0.006531540639123406\n",
      "  Sigma Multiplier: 1.9600734474114039\n",
      "  Initialization Multiplier: 1.1540066773221667\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.02it/s, loss=-0.000186, elapsed time=0.08, total time=12.8]\n",
      "[I 2025-06-07 12:39:01,287] Trial 14 finished with value: -0.00018645537345529463 and parameters: {'learning_rate': 0.006531540639123406, 'sigma_multiplier': 1.9600734474114039, 'num_layers': 3, 'initialization_multiplier': 1.1540066773221667}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 14 final loss: -0.00018646\n",
      "Trial 15:\n",
      "  Learning Rate: 0.0007048334204669984\n",
      "  Sigma Multiplier: 1.1101875061675435\n",
      "  Initialization Multiplier: 0.43589733609211123\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:18<00:00,  8.20it/s, loss=0.018043, elapsed time=0.1, total time=18.5] \n",
      "[I 2025-06-07 12:39:19,887] Trial 15 finished with value: 0.018042540736518092 and parameters: {'learning_rate': 0.0007048334204669984, 'sigma_multiplier': 1.1101875061675435, 'num_layers': 5, 'initialization_multiplier': 0.43589733609211123}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 15 final loss: 0.01804254\n",
      "Trial 16:\n",
      "  Learning Rate: 0.0052520322411228415\n",
      "  Sigma Multiplier: 1.6843969047841196\n",
      "  Initialization Multiplier: 1.0362315688955381\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.28it/s, loss=-0.000155, elapsed time=0.09, total time=14.9]\n",
      "[I 2025-06-07 12:39:34,810] Trial 16 finished with value: -0.0001547980462264047 and parameters: {'learning_rate': 0.0052520322411228415, 'sigma_multiplier': 1.6843969047841196, 'num_layers': 4, 'initialization_multiplier': 1.0362315688955381}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 16 final loss: -0.00015480\n",
      "Trial 17:\n",
      "  Learning Rate: 0.025534332389243415\n",
      "  Sigma Multiplier: 0.9628062704707541\n",
      "  Initialization Multiplier: 0.39294181503442877\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.41it/s, loss=-0.000307, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 12:39:46,304] Trial 17 finished with value: -0.00030677684405406235 and parameters: {'learning_rate': 0.025534332389243415, 'sigma_multiplier': 0.9628062704707541, 'num_layers': 2, 'initialization_multiplier': 0.39294181503442877}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 17 final loss: -0.00030678\n",
      "Trial 18:\n",
      "  Learning Rate: 0.0006411625603632361\n",
      "  Sigma Multiplier: 1.1897144024640798\n",
      "  Initialization Multiplier: 0.6165926935313628\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.83it/s, loss=0.036659, elapsed time=0.07, total time=12.9]\n",
      "[I 2025-06-07 12:39:59,290] Trial 18 finished with value: 0.0366585088183388 and parameters: {'learning_rate': 0.0006411625603632361, 'sigma_multiplier': 1.1897144024640798, 'num_layers': 3, 'initialization_multiplier': 0.6165926935313628}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 18 final loss: 0.03665851\n",
      "Trial 19:\n",
      "  Learning Rate: 0.003950766486571736\n",
      "  Sigma Multiplier: 1.5405221234866646\n",
      "  Initialization Multiplier: 1.371375137590764\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.84it/s, loss=-0.000235, elapsed time=0.08, total time=13]  \n",
      "[I 2025-06-07 12:40:12,364] Trial 19 finished with value: -0.00023514756789297343 and parameters: {'learning_rate': 0.003950766486571736, 'sigma_multiplier': 1.5405221234866646, 'num_layers': 3, 'initialization_multiplier': 1.371375137590764}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 19 final loss: -0.00023515\n",
      "Trial 20:\n",
      "  Learning Rate: 0.020224874120187128\n",
      "  Sigma Multiplier: 0.5448051855454472\n",
      "  Initialization Multiplier: 0.25481052007570726\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.44it/s, loss=0.000123, elapsed time=0.09, total time=18.1]\n",
      "[I 2025-06-07 12:40:30,545] Trial 20 finished with value: 0.00012299931126798623 and parameters: {'learning_rate': 0.020224874120187128, 'sigma_multiplier': 0.5448051855454472, 'num_layers': 4, 'initialization_multiplier': 0.25481052007570726}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 20 final loss: 0.00012300\n",
      "Trial 21:\n",
      "  Learning Rate: 0.03618575064067154\n",
      "  Sigma Multiplier: 0.9852373280759166\n",
      "  Initialization Multiplier: 0.4649000571177765\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000284, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 12:40:42,642] Trial 21 finished with value: -0.00028412622606069495 and parameters: {'learning_rate': 0.03618575064067154, 'sigma_multiplier': 0.9852373280759166, 'num_layers': 2, 'initialization_multiplier': 0.4649000571177765}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 21 final loss: -0.00028413\n",
      "Trial 22:\n",
      "  Learning Rate: 0.04859109593949148\n",
      "  Sigma Multiplier: 0.9064556106199673\n",
      "  Initialization Multiplier: 0.8467884287537462\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.55it/s, loss=-0.000065, elapsed time=0.08, total time=12.2]\n",
      "[I 2025-06-07 12:40:54,922] Trial 22 finished with value: -6.527172042888055e-05 and parameters: {'learning_rate': 0.04859109593949148, 'sigma_multiplier': 0.9064556106199673, 'num_layers': 2, 'initialization_multiplier': 0.8467884287537462}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 22 final loss: -0.00006527\n",
      "Trial 23:\n",
      "  Learning Rate: 0.0139678687744889\n",
      "  Sigma Multiplier: 1.3464788125874865\n",
      "  Initialization Multiplier: 0.5355061134964305\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.35it/s, loss=-0.000243, elapsed time=0.07, total time=10.7]\n",
      "[I 2025-06-07 12:41:05,683] Trial 23 finished with value: -0.00024262488217650525 and parameters: {'learning_rate': 0.0139678687744889, 'sigma_multiplier': 1.3464788125874865, 'num_layers': 2, 'initialization_multiplier': 0.5355061134964305}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 23 final loss: -0.00024262\n",
      "Trial 24:\n",
      "  Learning Rate: 0.09921228097444976\n",
      "  Sigma Multiplier: 1.117584119735634\n",
      "  Initialization Multiplier: 0.2715099983565834\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.36it/s, loss=0.000034, elapsed time=0.15, total time=13.5] \n",
      "[I 2025-06-07 12:41:19,256] Trial 24 finished with value: 3.387575873658467e-05 and parameters: {'learning_rate': 0.09921228097444976, 'sigma_multiplier': 1.117584119735634, 'num_layers': 3, 'initialization_multiplier': 0.2715099983565834}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 24 final loss: 0.00003388\n",
      "Trial 25:\n",
      "  Learning Rate: 0.0012231710805051103\n",
      "  Sigma Multiplier: 0.8896824045873469\n",
      "  Initialization Multiplier: 0.7520938226250309\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.98it/s, loss=0.010910, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 12:41:31,205] Trial 25 finished with value: 0.010910261210857045 and parameters: {'learning_rate': 0.0012231710805051103, 'sigma_multiplier': 0.8896824045873469, 'num_layers': 2, 'initialization_multiplier': 0.7520938226250309}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 25 final loss: 0.01091026\n",
      "Trial 26:\n",
      "  Learning Rate: 0.0032775414420593493\n",
      "  Sigma Multiplier: 0.6047243281404783\n",
      "  Initialization Multiplier: 0.38142888822229903\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.85it/s, loss=0.000197, elapsed time=0.09, total time=15.6] \n",
      "[I 2025-06-07 12:41:46,832] Trial 26 finished with value: 0.00019699188606328303 and parameters: {'learning_rate': 0.0032775414420593493, 'sigma_multiplier': 0.6047243281404783, 'num_layers': 3, 'initialization_multiplier': 0.38142888822229903}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 26 final loss: 0.00019699\n",
      "Trial 27:\n",
      "  Learning Rate: 0.008406930090508581\n",
      "  Sigma Multiplier: 0.3742174638099932\n",
      "  Initialization Multiplier: 0.9256013610432375\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.07it/s, loss=0.000535, elapsed time=0.06, total time=12.7]\n",
      "[I 2025-06-07 12:41:59,588] Trial 27 finished with value: 0.0005354823576969233 and parameters: {'learning_rate': 0.008406930090508581, 'sigma_multiplier': 0.3742174638099932, 'num_layers': 1, 'initialization_multiplier': 0.9256013610432375}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 27 final loss: 0.00053548\n",
      "Trial 28:\n",
      "  Learning Rate: 0.02231684357074658\n",
      "  Sigma Multiplier: 1.1896006677690656\n",
      "  Initialization Multiplier: 0.20611172294311747\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000233, elapsed time=0.05, total time=11.5]\n",
      "[I 2025-06-07 12:42:11,089] Trial 28 finished with value: -0.00023316602909782887 and parameters: {'learning_rate': 0.02231684357074658, 'sigma_multiplier': 1.1896006677690656, 'num_layers': 2, 'initialization_multiplier': 0.20611172294311747}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 28 final loss: -0.00023317\n",
      "Trial 29:\n",
      "  Learning Rate: 0.0050270762657906864\n",
      "  Sigma Multiplier: 0.8999545320651758\n",
      "  Initialization Multiplier: 1.2597142540442507\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.56it/s, loss=0.000137, elapsed time=0.09, total time=14.5] \n",
      "[I 2025-06-07 12:42:25,665] Trial 29 finished with value: 0.00013729817685592826 and parameters: {'learning_rate': 0.0050270762657906864, 'sigma_multiplier': 0.8999545320651758, 'num_layers': 3, 'initialization_multiplier': 1.2597142540442507}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 29 final loss: 0.00013730\n",
      "Trial 30:\n",
      "  Learning Rate: 0.019460473600169448\n",
      "  Sigma Multiplier: 0.42103324474157255\n",
      "  Initialization Multiplier: 0.5320692759951572\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:16<00:00,  9.15it/s, loss=0.000792, elapsed time=0.09, total time=16.7]\n",
      "[I 2025-06-07 12:42:42,437] Trial 30 finished with value: 0.0007922599249176321 and parameters: {'learning_rate': 0.019460473600169448, 'sigma_multiplier': 0.42103324474157255, 'num_layers': 3, 'initialization_multiplier': 0.5320692759951572}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 30 final loss: 0.00079226\n",
      "Trial 31:\n",
      "  Learning Rate: 0.04503596944115113\n",
      "  Sigma Multiplier: 0.9861974266493174\n",
      "  Initialization Multiplier: 0.41168385708773525\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.55it/s, loss=-0.000226, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 12:42:53,892] Trial 31 finished with value: -0.00022568021275996532 and parameters: {'learning_rate': 0.04503596944115113, 'sigma_multiplier': 0.9861974266493174, 'num_layers': 2, 'initialization_multiplier': 0.41168385708773525}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 31 final loss: -0.00022568\n",
      "Trial 32:\n",
      "  Learning Rate: 0.038776057352315124\n",
      "  Sigma Multiplier: 1.0316835719637782\n",
      "  Initialization Multiplier: 0.4937894224824023\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000276, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 12:43:05,367] Trial 32 finished with value: -0.000275726243885327 and parameters: {'learning_rate': 0.038776057352315124, 'sigma_multiplier': 1.0316835719637782, 'num_layers': 2, 'initialization_multiplier': 0.4937894224824023}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 32 final loss: -0.00027573\n",
      "Trial 33:\n",
      "  Learning Rate: 0.02621923044708749\n",
      "  Sigma Multiplier: 0.7440483047399687\n",
      "  Initialization Multiplier: 0.13678965912908647\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.94it/s, loss=0.000038, elapsed time=0.06, total time=12.8] \n",
      "[I 2025-06-07 12:43:18,256] Trial 33 finished with value: 3.8307643145158296e-05 and parameters: {'learning_rate': 0.02621923044708749, 'sigma_multiplier': 0.7440483047399687, 'num_layers': 2, 'initialization_multiplier': 0.13678965912908647}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 33 final loss: 0.00003831\n",
      "Trial 34:\n",
      "  Learning Rate: 3.555053602322373e-05\n",
      "  Sigma Multiplier: 1.3772570018864156\n",
      "  Initialization Multiplier: 1.6695262076289783\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.84it/s, loss=0.102114, elapsed time=0.04, total time=8.65]\n",
      "[I 2025-06-07 12:43:26,931] Trial 34 finished with value: 0.10211409664683399 and parameters: {'learning_rate': 3.555053602322373e-05, 'sigma_multiplier': 1.3772570018864156, 'num_layers': 1, 'initialization_multiplier': 1.6695262076289783}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 34 final loss: 0.10211410\n",
      "Trial 35:\n",
      "  Learning Rate: 0.06402484540785403\n",
      "  Sigma Multiplier: 0.835955375387138\n",
      "  Initialization Multiplier: 0.6016180784441945\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:16<00:00,  8.89it/s, loss=0.000396, elapsed time=0.1, total time=17.2]  \n",
      "[I 2025-06-07 12:43:44,189] Trial 35 finished with value: 0.0003961378147011599 and parameters: {'learning_rate': 0.06402484540785403, 'sigma_multiplier': 0.835955375387138, 'num_layers': 4, 'initialization_multiplier': 0.6016180784441945}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 35 final loss: 0.00039614\n",
      "Trial 36:\n",
      "  Learning Rate: 0.00845387737899802\n",
      "  Sigma Multiplier: 1.1678603376572692\n",
      "  Initialization Multiplier: 0.32651278039555076\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.06it/s, loss=-0.000284, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 12:43:55,182] Trial 36 finished with value: -0.00028421633099531645 and parameters: {'learning_rate': 0.00845387737899802, 'sigma_multiplier': 1.1678603376572692, 'num_layers': 2, 'initialization_multiplier': 0.32651278039555076}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 36 final loss: -0.00028422\n",
      "Trial 37:\n",
      "  Learning Rate: 0.0032117528008769737\n",
      "  Sigma Multiplier: 1.201217402518478\n",
      "  Initialization Multiplier: 0.015346810953481727\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.70it/s, loss=0.000799, elapsed time=0.04, total time=8.83]\n",
      "[I 2025-06-07 12:44:04,043] Trial 37 finished with value: 0.0007988971466899698 and parameters: {'learning_rate': 0.0032117528008769737, 'sigma_multiplier': 1.201217402518478, 'num_layers': 1, 'initialization_multiplier': 0.015346810953481727}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 37 final loss: 0.00079890\n",
      "Trial 38:\n",
      "  Learning Rate: 0.0011125070046469868\n",
      "  Sigma Multiplier: 1.4280865065326913\n",
      "  Initialization Multiplier: 0.2704492008632767\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.86it/s, loss=-0.000195, elapsed time=0.09, total time=11.1]\n",
      "[I 2025-06-07 12:44:15,214] Trial 38 finished with value: -0.00019481235293969864 and parameters: {'learning_rate': 0.0011125070046469868, 'sigma_multiplier': 1.4280865065326913, 'num_layers': 2, 'initialization_multiplier': 0.2704492008632767}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 38 final loss: -0.00019481\n",
      "Trial 39:\n",
      "  Learning Rate: 0.008014603505281315\n",
      "  Sigma Multiplier: 1.5846212722828636\n",
      "  Initialization Multiplier: 0.3367077203691803\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.54it/s, loss=-0.000292, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 12:44:27,466] Trial 39 finished with value: -0.00029199890245680104 and parameters: {'learning_rate': 0.008014603505281315, 'sigma_multiplier': 1.5846212722828636, 'num_layers': 3, 'initialization_multiplier': 0.3367077203691803}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 39 final loss: -0.00029200\n",
      "Trial 40:\n",
      "  Learning Rate: 0.012682147148384565\n",
      "  Sigma Multiplier: 1.6062866008620102\n",
      "  Initialization Multiplier: 0.7295943667243358\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.29it/s, loss=-0.000284, elapsed time=0.07, total time=14.8]\n",
      "[I 2025-06-07 12:44:42,377] Trial 40 finished with value: -0.00028372597440580097 and parameters: {'learning_rate': 0.012682147148384565, 'sigma_multiplier': 1.6062866008620102, 'num_layers': 4, 'initialization_multiplier': 0.7295943667243358}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 40 final loss: -0.00028373\n",
      "Trial 41:\n",
      "  Learning Rate: 0.00881457698462545\n",
      "  Sigma Multiplier: 1.1079652992542992\n",
      "  Initialization Multiplier: 0.15764330349428374\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.49it/s, loss=-0.000245, elapsed time=0.06, total time=13.4]\n",
      "[I 2025-06-07 12:44:55,849] Trial 41 finished with value: -0.00024516048346907154 and parameters: {'learning_rate': 0.00881457698462545, 'sigma_multiplier': 1.1079652992542992, 'num_layers': 3, 'initialization_multiplier': 0.15764330349428374}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 41 final loss: -0.00024516\n",
      "Trial 42:\n",
      "  Learning Rate: 0.0022125841555668967\n",
      "  Sigma Multiplier: 1.7059973596798281\n",
      "  Initialization Multiplier: 0.32513818980926656\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.22it/s, loss=-0.000245, elapsed time=0.08, total time=12.6]\n",
      "[I 2025-06-07 12:45:08,487] Trial 42 finished with value: -0.0002454552839371866 and parameters: {'learning_rate': 0.0022125841555668967, 'sigma_multiplier': 1.7059973596798281, 'num_layers': 3, 'initialization_multiplier': 0.32513818980926656}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 42 final loss: -0.00024546\n",
      "Trial 43:\n",
      "  Learning Rate: 0.00622866914471922\n",
      "  Sigma Multiplier: 1.184639771460511\n",
      "  Initialization Multiplier: 0.5559365999850404\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.53it/s, loss=-0.000143, elapsed time=0.11, total time=18.1]\n",
      "[I 2025-06-07 12:45:26,680] Trial 43 finished with value: -0.0001429195314988308 and parameters: {'learning_rate': 0.00622866914471922, 'sigma_multiplier': 1.184639771460511, 'num_layers': 5, 'initialization_multiplier': 0.5559365999850404}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 43 final loss: -0.00014292\n",
      "Trial 44:\n",
      "  Learning Rate: 0.015014637774892646\n",
      "  Sigma Multiplier: 1.2743781515831547\n",
      "  Initialization Multiplier: 0.37902422416559356\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.04it/s, loss=-0.000376, elapsed time=0.08, total time=12.8]\n",
      "[I 2025-06-07 12:45:39,539] Trial 44 finished with value: -0.00037551081724091775 and parameters: {'learning_rate': 0.015014637774892646, 'sigma_multiplier': 1.2743781515831547, 'num_layers': 3, 'initialization_multiplier': 0.37902422416559356}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 44 final loss: -0.00037551\n",
      "Trial 45:\n",
      "  Learning Rate: 0.01565069153303194\n",
      "  Sigma Multiplier: 1.2732601876941163\n",
      "  Initialization Multiplier: 0.6893140580283861\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.12it/s, loss=-0.000288, elapsed time=0.07, total time=12.6]\n",
      "[I 2025-06-07 12:45:52,236] Trial 45 finished with value: -0.0002882106041697411 and parameters: {'learning_rate': 0.01565069153303194, 'sigma_multiplier': 1.2732601876941163, 'num_layers': 3, 'initialization_multiplier': 0.6893140580283861}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 45 final loss: -0.00028821\n",
      "Trial 46:\n",
      "  Learning Rate: 0.00020684656788286888\n",
      "  Sigma Multiplier: 1.8486750010484585\n",
      "  Initialization Multiplier: 0.12035317943802842\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.65it/s, loss=0.004572, elapsed time=0.1, total time=14.4] \n",
      "[I 2025-06-07 12:46:06,725] Trial 46 finished with value: 0.004572023097272563 and parameters: {'learning_rate': 0.00020684656788286888, 'sigma_multiplier': 1.8486750010484585, 'num_layers': 4, 'initialization_multiplier': 0.12035317943802842}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 46 final loss: 0.00457202\n",
      "Trial 47:\n",
      "  Learning Rate: 0.003833388172213931\n",
      "  Sigma Multiplier: 1.545841139006155\n",
      "  Initialization Multiplier: 0.817716366200639\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.09it/s, loss=0.000461, elapsed time=0.06, total time=12.8]\n",
      "[I 2025-06-07 12:46:19,533] Trial 47 finished with value: 0.00046076695614497156 and parameters: {'learning_rate': 0.003833388172213931, 'sigma_multiplier': 1.545841139006155, 'num_layers': 3, 'initialization_multiplier': 0.817716366200639}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 47 final loss: 0.00046077\n",
      "Trial 48:\n",
      "  Learning Rate: 0.0014867463132049415\n",
      "  Sigma Multiplier: 1.4337378679738382\n",
      "  Initialization Multiplier: 0.43921892083433095\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.60it/s, loss=0.000005, elapsed time=0.11, total time=14.5]\n",
      "[I 2025-06-07 12:46:34,100] Trial 48 finished with value: 5.006415680179538e-06 and parameters: {'learning_rate': 0.0014867463132049415, 'sigma_multiplier': 1.4337378679738382, 'num_layers': 4, 'initialization_multiplier': 0.43921892083433095}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 48 final loss: 0.00000501\n",
      "Trial 49:\n",
      "  Learning Rate: 0.010672324498379418\n",
      "  Sigma Multiplier: 1.2501843811772302\n",
      "  Initialization Multiplier: 0.23302171063211363\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.15it/s, loss=-0.000254, elapsed time=0.09, total time=12.7]\n",
      "[I 2025-06-07 12:46:46,822] Trial 49 finished with value: -0.0002540138130441341 and parameters: {'learning_rate': 0.010672324498379418, 'sigma_multiplier': 1.2501843811772302, 'num_layers': 3, 'initialization_multiplier': 0.23302171063211363}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 49 final loss: -0.00025401\n",
      "Trial 50:\n",
      "  Learning Rate: 0.028042792519536276\n",
      "  Sigma Multiplier: 1.0427552020915947\n",
      "  Initialization Multiplier: 0.05494467885840232\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.05it/s, loss=-0.000234, elapsed time=0.06, total time=13.8]\n",
      "[I 2025-06-07 12:47:00,706] Trial 50 finished with value: -0.00023403083316274903 and parameters: {'learning_rate': 0.028042792519536276, 'sigma_multiplier': 1.0427552020915947, 'num_layers': 3, 'initialization_multiplier': 0.05494467885840232}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 50 final loss: -0.00023403\n",
      "Trial 51:\n",
      "  Learning Rate: 0.014092198464333301\n",
      "  Sigma Multiplier: 1.2851377337082015\n",
      "  Initialization Multiplier: 0.6670538137055075\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.84it/s, loss=-0.000238, elapsed time=0.06, total time=12.9]\n",
      "[I 2025-06-07 12:47:13,667] Trial 51 finished with value: -0.00023824685070455772 and parameters: {'learning_rate': 0.014092198464333301, 'sigma_multiplier': 1.2851377337082015, 'num_layers': 3, 'initialization_multiplier': 0.6670538137055075}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 51 final loss: -0.00023825\n",
      "Trial 52:\n",
      "  Learning Rate: 0.01886420321421628\n",
      "  Sigma Multiplier: 1.3742807256879286\n",
      "  Initialization Multiplier: 0.36818765277346904\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.94it/s, loss=-0.000308, elapsed time=0.07, total time=12.9]\n",
      "[I 2025-06-07 12:47:26,665] Trial 52 finished with value: -0.0003081348975383179 and parameters: {'learning_rate': 0.01886420321421628, 'sigma_multiplier': 1.3742807256879286, 'num_layers': 3, 'initialization_multiplier': 0.36818765277346904}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 52 final loss: -0.00030813\n",
      "Trial 53:\n",
      "  Learning Rate: 0.006812596397754811\n",
      "  Sigma Multiplier: 1.3766896044408419\n",
      "  Initialization Multiplier: 0.38780720861683954\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.13it/s, loss=-0.000279, elapsed time=0.09, total time=12.8]\n",
      "[I 2025-06-07 12:47:39,461] Trial 53 finished with value: -0.00027855420608745984 and parameters: {'learning_rate': 0.006812596397754811, 'sigma_multiplier': 1.3766896044408419, 'num_layers': 3, 'initialization_multiplier': 0.38780720861683954}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 53 final loss: -0.00027855\n",
      "Trial 54:\n",
      "  Learning Rate: 0.004748008783268205\n",
      "  Sigma Multiplier: 1.6420788489175202\n",
      "  Initialization Multiplier: 0.310182727845027\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.25it/s, loss=-0.000277, elapsed time=0.11, total time=14.9]\n",
      "[I 2025-06-07 12:47:54,449] Trial 54 finished with value: -0.00027718842130039614 and parameters: {'learning_rate': 0.004748008783268205, 'sigma_multiplier': 1.6420788489175202, 'num_layers': 4, 'initialization_multiplier': 0.310182727845027}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 54 final loss: -0.00027719\n",
      "Trial 55:\n",
      "  Learning Rate: 0.002513617978295668\n",
      "  Sigma Multiplier: 1.445669164853109\n",
      "  Initialization Multiplier: 0.6145925599354591\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.25it/s, loss=-0.000096, elapsed time=0.1, total time=12.5] \n",
      "[I 2025-06-07 12:48:07,034] Trial 55 finished with value: -9.631565643485914e-05 and parameters: {'learning_rate': 0.002513617978295668, 'sigma_multiplier': 1.445669164853109, 'num_layers': 3, 'initialization_multiplier': 0.6145925599354591}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 55 final loss: -0.00009632\n",
      "Trial 56:\n",
      "  Learning Rate: 0.017331593021658293\n",
      "  Sigma Multiplier: 1.523295468623846\n",
      "  Initialization Multiplier: 0.48686018309954204\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.36it/s, loss=-0.000168, elapsed time=0.09, total time=12.4]\n",
      "[I 2025-06-07 12:48:19,532] Trial 56 finished with value: -0.00016833612191222968 and parameters: {'learning_rate': 0.017331593021658293, 'sigma_multiplier': 1.523295468623846, 'num_layers': 3, 'initialization_multiplier': 0.48686018309954204}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 56 final loss: -0.00016834\n",
      "Trial 57:\n",
      "  Learning Rate: 0.053175976196239844\n",
      "  Sigma Multiplier: 1.7744826409455885\n",
      "  Initialization Multiplier: 0.20109247057596163\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.20it/s, loss=-0.000112, elapsed time=0.09, total time=12.6]\n",
      "[I 2025-06-07 12:48:32,133] Trial 57 finished with value: -0.00011186127844038069 and parameters: {'learning_rate': 0.053175976196239844, 'sigma_multiplier': 1.7744826409455885, 'num_layers': 3, 'initialization_multiplier': 0.20109247057596163}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 57 final loss: -0.00011186\n",
      "Trial 58:\n",
      "  Learning Rate: 0.025752939655338168\n",
      "  Sigma Multiplier: 1.081940771850219\n",
      "  Initialization Multiplier: 1.5967707866771899\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.95it/s, loss=-0.000175, elapsed time=0.11, total time=15.4]\n",
      "[I 2025-06-07 12:48:47,601] Trial 58 finished with value: -0.0001751921023991026 and parameters: {'learning_rate': 0.025752939655338168, 'sigma_multiplier': 1.081940771850219, 'num_layers': 4, 'initialization_multiplier': 1.5967707866771899}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 58 final loss: -0.00017519\n",
      "Trial 59:\n",
      "  Learning Rate: 0.007249818472407206\n",
      "  Sigma Multiplier: 0.9322421196039871\n",
      "  Initialization Multiplier: 0.40693055345803375\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.34it/s, loss=-0.000306, elapsed time=0.11, total time=13.6]\n",
      "[I 2025-06-07 12:49:01,233] Trial 59 finished with value: -0.0003061478827549741 and parameters: {'learning_rate': 0.007249818472407206, 'sigma_multiplier': 0.9322421196039871, 'num_layers': 3, 'initialization_multiplier': 0.40693055345803375}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 59 final loss: -0.00030615\n",
      "Trial 60:\n",
      "  Learning Rate: 0.01115586560481812\n",
      "  Sigma Multiplier: 0.829394848846822\n",
      "  Initialization Multiplier: 0.44054574495729365\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.83it/s, loss=-0.000192, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 12:49:13,236] Trial 60 finished with value: -0.00019207126014509043 and parameters: {'learning_rate': 0.01115586560481812, 'sigma_multiplier': 0.829394848846822, 'num_layers': 2, 'initialization_multiplier': 0.44054574495729365}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 60 final loss: -0.00019207\n",
      "Trial 61:\n",
      "  Learning Rate: 0.006891538680178833\n",
      "  Sigma Multiplier: 0.9321642466100014\n",
      "  Initialization Multiplier: 0.36317671307193006\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.26it/s, loss=-0.000376, elapsed time=0.09, total time=13.7]\n",
      "[I 2025-06-07 12:49:26,949] Trial 61 finished with value: -0.0003759212929444612 and parameters: {'learning_rate': 0.006891538680178833, 'sigma_multiplier': 0.9321642466100014, 'num_layers': 3, 'initialization_multiplier': 0.36317671307193006}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 61 final loss: -0.00037592\n",
      "Trial 62:\n",
      "  Learning Rate: 0.002804348539577881\n",
      "  Sigma Multiplier: 0.9392864077044984\n",
      "  Initialization Multiplier: 0.5485568723659696\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.99it/s, loss=-0.000281, elapsed time=0.09, total time=14]  \n",
      "[I 2025-06-07 12:49:41,024] Trial 62 finished with value: -0.0002806942277757086 and parameters: {'learning_rate': 0.002804348539577881, 'sigma_multiplier': 0.9392864077044984, 'num_layers': 3, 'initialization_multiplier': 0.5485568723659696}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 62 final loss: -0.00028069\n",
      "Trial 63:\n",
      "  Learning Rate: 0.00540676606932078\n",
      "  Sigma Multiplier: 0.8187934796856888\n",
      "  Initialization Multiplier: 0.35920386301558704\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.97it/s, loss=-0.000295, elapsed time=0.1, total time=14]   \n",
      "[I 2025-06-07 12:49:55,087] Trial 63 finished with value: -0.000294836419708281 and parameters: {'learning_rate': 0.00540676606932078, 'sigma_multiplier': 0.8187934796856888, 'num_layers': 3, 'initialization_multiplier': 0.35920386301558704}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 63 final loss: -0.00029484\n",
      "Trial 64:\n",
      "  Learning Rate: 0.001919082709550501\n",
      "  Sigma Multiplier: 0.9922814261912639\n",
      "  Initialization Multiplier: 0.48417754204105057\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.33it/s, loss=-0.000216, elapsed time=0.09, total time=13.6]\n",
      "[I 2025-06-07 12:50:08,703] Trial 64 finished with value: -0.0002159487778356426 and parameters: {'learning_rate': 0.001919082709550501, 'sigma_multiplier': 0.9922814261912639, 'num_layers': 3, 'initialization_multiplier': 0.48417754204105057}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 64 final loss: -0.00021595\n",
      "Trial 65:\n",
      "  Learning Rate: 0.004343022196008278\n",
      "  Sigma Multiplier: 0.608239877882254\n",
      "  Initialization Multiplier: 1.0999397778604567\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.59it/s, loss=0.000882, elapsed time=0.1, total time=15.9] \n",
      "[I 2025-06-07 12:50:24,672] Trial 65 finished with value: 0.0008822318041677884 and parameters: {'learning_rate': 0.004343022196008278, 'sigma_multiplier': 0.608239877882254, 'num_layers': 3, 'initialization_multiplier': 1.0999397778604567}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 65 final loss: 0.00088223\n",
      "Trial 66:\n",
      "  Learning Rate: 0.01930860486793095\n",
      "  Sigma Multiplier: 0.686889447273987\n",
      "  Initialization Multiplier: 0.20716915010338993\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:16<00:00,  9.24it/s, loss=0.000116, elapsed time=0.1, total time=16.5]  \n",
      "[I 2025-06-07 12:50:41,256] Trial 66 finished with value: 0.00011637808379932924 and parameters: {'learning_rate': 0.01930860486793095, 'sigma_multiplier': 0.686889447273987, 'num_layers': 4, 'initialization_multiplier': 0.20716915010338993}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 66 final loss: 0.00011638\n",
      "Trial 67:\n",
      "  Learning Rate: 0.031339802480535556\n",
      "  Sigma Multiplier: 1.1354421120792708\n",
      "  Initialization Multiplier: 0.5712933504829955\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.25it/s, loss=-0.000192, elapsed time=0.08, total time=12.5]\n",
      "[I 2025-06-07 12:50:53,798] Trial 67 finished with value: -0.000191717616181651 and parameters: {'learning_rate': 0.031339802480535556, 'sigma_multiplier': 1.1354421120792708, 'num_layers': 3, 'initialization_multiplier': 0.5712933504829955}. Best is trial 11 with value: -0.00040403594016146156.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 67 final loss: -0.00019172\n",
      "Trial 68:\n",
      "  Learning Rate: 0.006995060776731667\n",
      "  Sigma Multiplier: 0.9448800111325177\n",
      "  Initialization Multiplier: 0.39133378957110393\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.84it/s, loss=-0.000422, elapsed time=0.09, total time=11.1]\n",
      "[I 2025-06-07 12:51:04,949] Trial 68 finished with value: -0.00042194392083188094 and parameters: {'learning_rate': 0.006995060776731667, 'sigma_multiplier': 0.9448800111325177, 'num_layers': 2, 'initialization_multiplier': 0.39133378957110393}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 68 final loss: -0.00042194\n",
      "Trial 69:\n",
      "  Learning Rate: 0.01097565461723887\n",
      "  Sigma Multiplier: 1.3362292684461674\n",
      "  Initialization Multiplier: 0.27661818876339395\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.44it/s, loss=-0.000353, elapsed time=0.05, total time=10]  \n",
      "[I 2025-06-07 12:51:15,010] Trial 69 finished with value: -0.000353446888859723 and parameters: {'learning_rate': 0.01097565461723887, 'sigma_multiplier': 1.3362292684461674, 'num_layers': 2, 'initialization_multiplier': 0.27661818876339395}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 69 final loss: -0.00035345\n",
      "Trial 70:\n",
      "  Learning Rate: 0.010190000553925944\n",
      "  Sigma Multiplier: 1.077590489169792\n",
      "  Initialization Multiplier: 0.2644359819951408\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000413, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 12:51:26,417] Trial 70 finished with value: -0.00041270066262819353 and parameters: {'learning_rate': 0.010190000553925944, 'sigma_multiplier': 1.077590489169792, 'num_layers': 2, 'initialization_multiplier': 0.2644359819951408}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 70 final loss: -0.00041270\n",
      "Trial 71:\n",
      "  Learning Rate: 0.011312933852425043\n",
      "  Sigma Multiplier: 1.2187504257582256\n",
      "  Initialization Multiplier: 0.2736283082483747\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.81it/s, loss=-0.000297, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 12:51:37,600] Trial 71 finished with value: -0.0002966708807717484 and parameters: {'learning_rate': 0.011312933852425043, 'sigma_multiplier': 1.2187504257582256, 'num_layers': 2, 'initialization_multiplier': 0.2736283082483747}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 71 final loss: -0.00029667\n",
      "Trial 72:\n",
      "  Learning Rate: 0.005467645888559063\n",
      "  Sigma Multiplier: 1.3341064350960348\n",
      "  Initialization Multiplier: 0.06606132638851414\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.03it/s, loss=-0.000210, elapsed time=0.05, total time=10.4]\n",
      "[I 2025-06-07 12:51:47,997] Trial 72 finished with value: -0.00021017384393113816 and parameters: {'learning_rate': 0.005467645888559063, 'sigma_multiplier': 1.3341064350960348, 'num_layers': 2, 'initialization_multiplier': 0.06606132638851414}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 72 final loss: -0.00021017\n",
      "Trial 73:\n",
      "  Learning Rate: 0.009591338686540557\n",
      "  Sigma Multiplier: 1.0374299729475243\n",
      "  Initialization Multiplier: 0.28481513218559856\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.55it/s, loss=-0.000287, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 12:51:59,407] Trial 73 finished with value: -0.0002872488165147127 and parameters: {'learning_rate': 0.009591338686540557, 'sigma_multiplier': 1.0374299729475243, 'num_layers': 2, 'initialization_multiplier': 0.28481513218559856}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 73 final loss: -0.00028725\n",
      "Trial 74:\n",
      "  Learning Rate: 0.003720476680265146\n",
      "  Sigma Multiplier: 1.379428568456352\n",
      "  Initialization Multiplier: 0.16769102897350996\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.89it/s, loss=0.000002, elapsed time=0.04, total time=8.2] \n",
      "[I 2025-06-07 12:52:07,636] Trial 74 finished with value: 1.909606060659595e-06 and parameters: {'learning_rate': 0.003720476680265146, 'sigma_multiplier': 1.379428568456352, 'num_layers': 1, 'initialization_multiplier': 0.16769102897350996}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 74 final loss: 0.00000191\n",
      "Trial 75:\n",
      "  Learning Rate: 0.015680274013307363\n",
      "  Sigma Multiplier: 1.1369749254906434\n",
      "  Initialization Multiplier: 0.3619839602380344\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.92it/s, loss=-0.000338, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 12:52:18,753] Trial 75 finished with value: -0.0003377881221787719 and parameters: {'learning_rate': 0.015680274013307363, 'sigma_multiplier': 1.1369749254906434, 'num_layers': 2, 'initialization_multiplier': 0.3619839602380344}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 75 final loss: -0.00033779\n",
      "Trial 76:\n",
      "  Learning Rate: 0.006747141644804938\n",
      "  Sigma Multiplier: 1.079079429069544\n",
      "  Initialization Multiplier: 0.501776542883589\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.03it/s, loss=-0.000417, elapsed time=0.07, total time=11]  \n",
      "[I 2025-06-07 12:52:29,829] Trial 76 finished with value: -0.0004166588131721579 and parameters: {'learning_rate': 0.006747141644804938, 'sigma_multiplier': 1.079079429069544, 'num_layers': 2, 'initialization_multiplier': 0.501776542883589}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 76 final loss: -0.00041666\n",
      "Trial 77:\n",
      "  Learning Rate: 0.012177359311680038\n",
      "  Sigma Multiplier: 0.8720366627034208\n",
      "  Initialization Multiplier: 0.09907863506677345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.74it/s, loss=0.000027, elapsed time=0.1, total time=13.2]  \n",
      "[I 2025-06-07 12:52:43,044] Trial 77 finished with value: 2.7012437522046718e-05 and parameters: {'learning_rate': 0.012177359311680038, 'sigma_multiplier': 0.8720366627034208, 'num_layers': 2, 'initialization_multiplier': 0.09907863506677345}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 77 final loss: 0.00002701\n",
      "Trial 78:\n",
      "  Learning Rate: 0.015247916141308215\n",
      "  Sigma Multiplier: 1.1276008088086416\n",
      "  Initialization Multiplier: 0.22910610333617643\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000421, elapsed time=0.11, total time=11.9]\n",
      "[I 2025-06-07 12:52:55,005] Trial 78 finished with value: -0.0004206568713232515 and parameters: {'learning_rate': 0.015247916141308215, 'sigma_multiplier': 1.1276008088086416, 'num_layers': 2, 'initialization_multiplier': 0.22910610333617643}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 78 final loss: -0.00042066\n",
      "Trial 79:\n",
      "  Learning Rate: 0.006408903978684393\n",
      "  Sigma Multiplier: 1.0468300219496904\n",
      "  Initialization Multiplier: 0.2332497968803172\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.02it/s, loss=-0.000276, elapsed time=0.04, total time=9.83]\n",
      "[I 2025-06-07 12:53:04,866] Trial 79 finished with value: -0.000276233266926373 and parameters: {'learning_rate': 0.006408903978684393, 'sigma_multiplier': 1.0468300219496904, 'num_layers': 1, 'initialization_multiplier': 0.2332497968803172}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 79 final loss: -0.00027623\n",
      "Trial 80:\n",
      "  Learning Rate: 0.008173085828337522\n",
      "  Sigma Multiplier: 1.2455588930022552\n",
      "  Initialization Multiplier: 0.005482497315404178\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000228, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 12:53:15,647] Trial 80 finished with value: -0.0002276838732652825 and parameters: {'learning_rate': 0.008173085828337522, 'sigma_multiplier': 1.2455588930022552, 'num_layers': 2, 'initialization_multiplier': 0.005482497315404178}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 80 final loss: -0.00022768\n",
      "Trial 81:\n",
      "  Learning Rate: 0.015298685779728441\n",
      "  Sigma Multiplier: 1.1460363739050972\n",
      "  Initialization Multiplier: 0.31140073742763175\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.38it/s, loss=-0.000287, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 12:53:27,234] Trial 81 finished with value: -0.00028668030862238095 and parameters: {'learning_rate': 0.015298685779728441, 'sigma_multiplier': 1.1460363739050972, 'num_layers': 2, 'initialization_multiplier': 0.31140073742763175}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 81 final loss: -0.00028668\n",
      "Trial 82:\n",
      "  Learning Rate: 0.02235518620345133\n",
      "  Sigma Multiplier: 1.0853648098405835\n",
      "  Initialization Multiplier: 0.16348443925635392\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.77it/s, loss=-0.000259, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 12:53:38,452] Trial 82 finished with value: -0.0002586914016188834 and parameters: {'learning_rate': 0.02235518620345133, 'sigma_multiplier': 1.0853648098405835, 'num_layers': 2, 'initialization_multiplier': 0.16348443925635392}. Best is trial 68 with value: -0.00042194392083188094.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 82 final loss: -0.00025869\n",
      "Trial 83:\n",
      "  Learning Rate: 0.01034060271052533\n",
      "  Sigma Multiplier: 1.002927561339537\n",
      "  Initialization Multiplier: 0.4997361142121278\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000436, elapsed time=0.04, total time=11.5]\n",
      "[I 2025-06-07 12:53:50,026] Trial 83 finished with value: -0.0004358480575217573 and parameters: {'learning_rate': 0.01034060271052533, 'sigma_multiplier': 1.002927561339537, 'num_layers': 2, 'initialization_multiplier': 0.4997361142121278}. Best is trial 83 with value: -0.0004358480575217573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 83 final loss: -0.00043585\n",
      "Trial 84:\n",
      "  Learning Rate: 0.009254146510582331\n",
      "  Sigma Multiplier: 0.9945679795759385\n",
      "  Initialization Multiplier: 0.5229809130709924\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000461, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 12:54:01,377] Trial 84 finished with value: -0.00046138953332195543 and parameters: {'learning_rate': 0.009254146510582331, 'sigma_multiplier': 0.9945679795759385, 'num_layers': 2, 'initialization_multiplier': 0.5229809130709924}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 84 final loss: -0.00046139\n",
      "Trial 85:\n",
      "  Learning Rate: 0.006067826046929111\n",
      "  Sigma Multiplier: 1.0033971338226577\n",
      "  Initialization Multiplier: 1.9858642050541906\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.53it/s, loss=-0.000198, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 12:54:13,826] Trial 85 finished with value: -0.00019772702646600444 and parameters: {'learning_rate': 0.006067826046929111, 'sigma_multiplier': 1.0033971338226577, 'num_layers': 2, 'initialization_multiplier': 1.9858642050541906}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 85 final loss: -0.00019773\n",
      "Trial 86:\n",
      "  Learning Rate: 0.009133108505542383\n",
      "  Sigma Multiplier: 0.761566120814016\n",
      "  Initialization Multiplier: 0.5036084835229179\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.83it/s, loss=-0.000317, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 12:54:25,839] Trial 86 finished with value: -0.0003173802935722265 and parameters: {'learning_rate': 0.009133108505542383, 'sigma_multiplier': 0.761566120814016, 'num_layers': 2, 'initialization_multiplier': 0.5036084835229179}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 86 final loss: -0.00031738\n",
      "Trial 87:\n",
      "  Learning Rate: 0.0045318725785337905\n",
      "  Sigma Multiplier: 0.9408885986020492\n",
      "  Initialization Multiplier: 0.7346011328713532\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.01it/s, loss=-0.000337, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 12:54:37,674] Trial 87 finished with value: -0.00033738445250070903 and parameters: {'learning_rate': 0.0045318725785337905, 'sigma_multiplier': 0.9408885986020492, 'num_layers': 2, 'initialization_multiplier': 0.7346011328713532}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 87 final loss: -0.00033738\n",
      "Trial 88:\n",
      "  Learning Rate: 0.007236034742048763\n",
      "  Sigma Multiplier: 0.8679838692897354\n",
      "  Initialization Multiplier: 0.6341521083111059\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.39it/s, loss=-0.000179, elapsed time=0.06, total time=10.1]\n",
      "[I 2025-06-07 12:54:47,767] Trial 88 finished with value: -0.00017944139536046718 and parameters: {'learning_rate': 0.007236034742048763, 'sigma_multiplier': 0.8679838692897354, 'num_layers': 1, 'initialization_multiplier': 0.6341521083111059}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 88 final loss: -0.00017944\n",
      "Trial 89:\n",
      "  Learning Rate: 0.013405964698252799\n",
      "  Sigma Multiplier: 1.080427839124186\n",
      "  Initialization Multiplier: 0.4489610346527031\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.19it/s, loss=-0.000382, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 12:54:58,737] Trial 89 finished with value: -0.000381576933765169 and parameters: {'learning_rate': 0.013405964698252799, 'sigma_multiplier': 1.080427839124186, 'num_layers': 2, 'initialization_multiplier': 0.4489610346527031}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 89 final loss: -0.00038158\n",
      "Trial 90:\n",
      "  Learning Rate: 0.012963231849760278\n",
      "  Sigma Multiplier: 0.2134784508721681\n",
      "  Initialization Multiplier: 0.455983117099927\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.15it/s, loss=0.000006, elapsed time=0.09, total time=15.1] \n",
      "[I 2025-06-07 12:55:13,863] Trial 90 finished with value: 6.4473206627984334e-06 and parameters: {'learning_rate': 0.012963231849760278, 'sigma_multiplier': 0.2134784508721681, 'num_layers': 2, 'initialization_multiplier': 0.455983117099927}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 90 final loss: 0.00000645\n",
      "Trial 91:\n",
      "  Learning Rate: 0.009752997829079313\n",
      "  Sigma Multiplier: 0.9759050001393603\n",
      "  Initialization Multiplier: 0.41188322269564615\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.45it/s, loss=-0.000318, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 12:55:25,382] Trial 91 finished with value: -0.00031837910233559907 and parameters: {'learning_rate': 0.009752997829079313, 'sigma_multiplier': 0.9759050001393603, 'num_layers': 2, 'initialization_multiplier': 0.41188322269564615}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 91 final loss: -0.00031838\n",
      "Trial 92:\n",
      "  Learning Rate: 0.022016189093109848\n",
      "  Sigma Multiplier: 1.0750420948133144\n",
      "  Initialization Multiplier: 0.5703287531640742\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=-0.000345, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 12:55:36,697] Trial 92 finished with value: -0.0003448788150196307 and parameters: {'learning_rate': 0.022016189093109848, 'sigma_multiplier': 1.0750420948133144, 'num_layers': 2, 'initialization_multiplier': 0.5703287531640742}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 92 final loss: -0.00034488\n",
      "Trial 93:\n",
      "  Learning Rate: 0.01478112659703949\n",
      "  Sigma Multiplier: 1.2121298404648946\n",
      "  Initialization Multiplier: 0.4388325530751623\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.12it/s, loss=-0.000332, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 12:55:47,727] Trial 93 finished with value: -0.00033168635284483574 and parameters: {'learning_rate': 0.01478112659703949, 'sigma_multiplier': 1.2121298404648946, 'num_layers': 2, 'initialization_multiplier': 0.4388325530751623}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 93 final loss: -0.00033169\n",
      "Trial 94:\n",
      "  Learning Rate: 0.0075134502681018\n",
      "  Sigma Multiplier: 1.1551931122732655\n",
      "  Initialization Multiplier: 0.5172755900419516\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.29it/s, loss=-0.000255, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 12:55:58,563] Trial 94 finished with value: -0.00025481703634649944 and parameters: {'learning_rate': 0.0075134502681018, 'sigma_multiplier': 1.1551931122732655, 'num_layers': 2, 'initialization_multiplier': 0.5172755900419516}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 94 final loss: -0.00025482\n",
      "Trial 95:\n",
      "  Learning Rate: 0.03663468318178892\n",
      "  Sigma Multiplier: 1.0081275359659947\n",
      "  Initialization Multiplier: 0.6981271445203362\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.88it/s, loss=-0.000207, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 12:56:10,597] Trial 95 finished with value: -0.00020666814611722687 and parameters: {'learning_rate': 0.03663468318178892, 'sigma_multiplier': 1.0081275359659947, 'num_layers': 2, 'initialization_multiplier': 0.6981271445203362}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 95 final loss: -0.00020667\n",
      "Trial 96:\n",
      "  Learning Rate: 0.003554669762006773\n",
      "  Sigma Multiplier: 1.0969519255072815\n",
      "  Initialization Multiplier: 0.6027545577195912\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.08it/s, loss=-0.000413, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 12:56:21,654] Trial 96 finished with value: -0.0004131770970476987 and parameters: {'learning_rate': 0.003554669762006773, 'sigma_multiplier': 1.0969519255072815, 'num_layers': 2, 'initialization_multiplier': 0.6027545577195912}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 96 final loss: -0.00041318\n",
      "Trial 97:\n",
      "  Learning Rate: 0.0036467075813148334\n",
      "  Sigma Multiplier: 1.0879409863343354\n",
      "  Initialization Multiplier: 0.7821668623998594\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.69it/s, loss=-0.000183, elapsed time=0.1, total time=11.2] \n",
      "[I 2025-06-07 12:56:32,946] Trial 97 finished with value: -0.00018313764447451961 and parameters: {'learning_rate': 0.0036467075813148334, 'sigma_multiplier': 1.0879409863343354, 'num_layers': 2, 'initialization_multiplier': 0.7821668623998594}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 97 final loss: -0.00018314\n",
      "Trial 98:\n",
      "  Learning Rate: 0.00562221044225364\n",
      "  Sigma Multiplier: 0.9109256232276735\n",
      "  Initialization Multiplier: 0.5873412763345793\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.82it/s, loss=-0.000268, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 12:56:44,997] Trial 98 finished with value: -0.0002675906045665627 and parameters: {'learning_rate': 0.00562221044225364, 'sigma_multiplier': 0.9109256232276735, 'num_layers': 2, 'initialization_multiplier': 0.5873412763345793}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 98 final loss: -0.00026759\n",
      "Trial 99:\n",
      "  Learning Rate: 0.004554810440243455\n",
      "  Sigma Multiplier: 0.7886222992457967\n",
      "  Initialization Multiplier: 0.8780848986258634\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.84it/s, loss=0.000011, elapsed time=0.07, total time=13]  \n",
      "[I 2025-06-07 12:56:58,000] Trial 99 finished with value: 1.0687164004176679e-05 and parameters: {'learning_rate': 0.004554810440243455, 'sigma_multiplier': 0.7886222992457967, 'num_layers': 2, 'initialization_multiplier': 0.8780848986258634}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 99 final loss: 0.00001069\n",
      "Trial 100:\n",
      "  Learning Rate: 0.008677635940661463\n",
      "  Sigma Multiplier: 1.0207688610979329\n",
      "  Initialization Multiplier: 0.4686990075859617\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.08it/s, loss=-0.000340, elapsed time=0.06, total time=9.62]\n",
      "[I 2025-06-07 12:57:07,658] Trial 100 finished with value: -0.00033985142181461737 and parameters: {'learning_rate': 0.008677635940661463, 'sigma_multiplier': 1.0207688610979329, 'num_layers': 1, 'initialization_multiplier': 0.4686990075859617}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 100 final loss: -0.00033985\n",
      "Trial 101:\n",
      "  Learning Rate: 0.012914797470423626\n",
      "  Sigma Multiplier: 1.2358314411132758\n",
      "  Initialization Multiplier: 0.3999260723860827\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.18it/s, loss=-0.000381, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 12:57:18,553] Trial 101 finished with value: -0.00038116690863198823 and parameters: {'learning_rate': 0.012914797470423626, 'sigma_multiplier': 1.2358314411132758, 'num_layers': 2, 'initialization_multiplier': 0.3999260723860827}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 101 final loss: -0.00038117\n",
      "Trial 102:\n",
      "  Learning Rate: 0.010186031738683838\n",
      "  Sigma Multiplier: 0.9643750810595577\n",
      "  Initialization Multiplier: 0.6485217964443553\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.41it/s, loss=-0.000390, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 12:57:30,059] Trial 102 finished with value: -0.0003899440163234097 and parameters: {'learning_rate': 0.010186031738683838, 'sigma_multiplier': 0.9643750810595577, 'num_layers': 2, 'initialization_multiplier': 0.6485217964443553}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 102 final loss: -0.00038994\n",
      "Trial 103:\n",
      "  Learning Rate: 0.012977653147937179\n",
      "  Sigma Multiplier: 1.1824080142280262\n",
      "  Initialization Multiplier: 0.6585579393878418\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000215, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 12:57:41,349] Trial 103 finished with value: -0.00021493738743859876 and parameters: {'learning_rate': 0.012977653147937179, 'sigma_multiplier': 1.1824080142280262, 'num_layers': 2, 'initialization_multiplier': 0.6585579393878418}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 103 final loss: -0.00021494\n",
      "Trial 104:\n",
      "  Learning Rate: 0.01814404423134324\n",
      "  Sigma Multiplier: 1.0650096410761454\n",
      "  Initialization Multiplier: 0.5140322475189562\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.71it/s, loss=-0.000321, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 12:57:52,638] Trial 104 finished with value: -0.0003205710275571777 and parameters: {'learning_rate': 0.01814404423134324, 'sigma_multiplier': 1.0650096410761454, 'num_layers': 2, 'initialization_multiplier': 0.5140322475189562}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 104 final loss: -0.00032057\n",
      "Trial 105:\n",
      "  Learning Rate: 0.002843904616590867\n",
      "  Sigma Multiplier: 1.109038694963662\n",
      "  Initialization Multiplier: 0.6266156601417815\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000386, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 12:58:03,899] Trial 105 finished with value: -0.00038584325939448904 and parameters: {'learning_rate': 0.002843904616590867, 'sigma_multiplier': 1.109038694963662, 'num_layers': 2, 'initialization_multiplier': 0.6266156601417815}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 105 final loss: -0.00038584\n",
      "Trial 106:\n",
      "  Learning Rate: 0.002438402620341387\n",
      "  Sigma Multiplier: 1.1131080488766565\n",
      "  Initialization Multiplier: 0.9596471236162019\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.87it/s, loss=0.012557, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 12:58:15,079] Trial 106 finished with value: 0.012556883090963864 and parameters: {'learning_rate': 0.002438402620341387, 'sigma_multiplier': 1.1131080488766565, 'num_layers': 2, 'initialization_multiplier': 0.9596471236162019}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 106 final loss: 0.01255688\n",
      "Trial 107:\n",
      "  Learning Rate: 0.001630035761075183\n",
      "  Sigma Multiplier: 0.9581391141357644\n",
      "  Initialization Multiplier: 0.6054751484223495\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.72it/s, loss=-0.000057, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 12:58:26,269] Trial 107 finished with value: -5.749936991523352e-05 and parameters: {'learning_rate': 0.001630035761075183, 'sigma_multiplier': 0.9581391141357644, 'num_layers': 2, 'initialization_multiplier': 0.6054751484223495}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 107 final loss: -0.00005750\n",
      "Trial 108:\n",
      "  Learning Rate: 0.0010184509661522638\n",
      "  Sigma Multiplier: 1.1181742538405113\n",
      "  Initialization Multiplier: 0.53559674090194\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.65it/s, loss=0.002347, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 12:58:37,586] Trial 108 finished with value: 0.002347216844761741 and parameters: {'learning_rate': 0.0010184509661522638, 'sigma_multiplier': 1.1181742538405113, 'num_layers': 2, 'initialization_multiplier': 0.53559674090194}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 108 final loss: 0.00234722\n",
      "Trial 109:\n",
      "  Learning Rate: 0.0033239421281114007\n",
      "  Sigma Multiplier: 0.8820044836069157\n",
      "  Initialization Multiplier: 0.6741025059321561\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.20it/s, loss=-0.000030, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 12:58:49,322] Trial 109 finished with value: -2.9663466265314434e-05 and parameters: {'learning_rate': 0.0033239421281114007, 'sigma_multiplier': 0.8820044836069157, 'num_layers': 2, 'initialization_multiplier': 0.6741025059321561}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 109 final loss: -0.00002966\n",
      "Trial 110:\n",
      "  Learning Rate: 0.0027532297003252893\n",
      "  Sigma Multiplier: 1.0429357721590067\n",
      "  Initialization Multiplier: 0.7744253945403478\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.78it/s, loss=-0.000132, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 12:59:00,620] Trial 110 finished with value: -0.00013163008577665023 and parameters: {'learning_rate': 0.0027532297003252893, 'sigma_multiplier': 1.0429357721590067, 'num_layers': 2, 'initialization_multiplier': 0.7744253945403478}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 110 final loss: -0.00013163\n",
      "Trial 111:\n",
      "  Learning Rate: 0.006013132197117702\n",
      "  Sigma Multiplier: 1.230047183160232\n",
      "  Initialization Multiplier: 0.4068418911162422\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.30it/s, loss=-0.000316, elapsed time=0.07, total time=12.5]\n",
      "[I 2025-06-07 12:59:13,139] Trial 111 finished with value: -0.0003157852387870899 and parameters: {'learning_rate': 0.006013132197117702, 'sigma_multiplier': 1.230047183160232, 'num_layers': 2, 'initialization_multiplier': 0.4068418911162422}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 111 final loss: -0.00031579\n",
      "Trial 112:\n",
      "  Learning Rate: 0.009893307365027868\n",
      "  Sigma Multiplier: 1.3003767200734226\n",
      "  Initialization Multiplier: 0.6316924382911594\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.73it/s, loss=-0.000341, elapsed time=0.08, total time=11.3]\n",
      "[I 2025-06-07 12:59:24,470] Trial 112 finished with value: -0.00034084029321844065 and parameters: {'learning_rate': 0.009893307365027868, 'sigma_multiplier': 1.3003767200734226, 'num_layers': 2, 'initialization_multiplier': 0.6316924382911594}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 112 final loss: -0.00034084\n",
      "Trial 113:\n",
      "  Learning Rate: 0.010818528036094701\n",
      "  Sigma Multiplier: 1.1772849918756816\n",
      "  Initialization Multiplier: 0.47069722622345456\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000352, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 12:59:35,866] Trial 113 finished with value: -0.0003523586632644904 and parameters: {'learning_rate': 0.010818528036094701, 'sigma_multiplier': 1.1772849918756816, 'num_layers': 2, 'initialization_multiplier': 0.47069722622345456}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 113 final loss: -0.00035236\n",
      "Trial 114:\n",
      "  Learning Rate: 0.005083685559735996\n",
      "  Sigma Multiplier: 0.9722840875822073\n",
      "  Initialization Multiplier: 0.5615326058787473\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000340, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 12:59:47,327] Trial 114 finished with value: -0.00034037528528538 and parameters: {'learning_rate': 0.005083685559735996, 'sigma_multiplier': 0.9722840875822073, 'num_layers': 2, 'initialization_multiplier': 0.5615326058787473}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 114 final loss: -0.00034038\n",
      "Trial 115:\n",
      "  Learning Rate: 0.004197549473649547\n",
      "  Sigma Multiplier: 1.0143617022617717\n",
      "  Initialization Multiplier: 0.34669575964609695\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000328, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 12:59:58,665] Trial 115 finished with value: -0.00032791216247539157 and parameters: {'learning_rate': 0.004197549473649547, 'sigma_multiplier': 1.0143617022617717, 'num_layers': 2, 'initialization_multiplier': 0.34669575964609695}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 115 final loss: -0.00032791\n",
      "Trial 116:\n",
      "  Learning Rate: 0.007943855461719735\n",
      "  Sigma Multiplier: 1.0984789555957823\n",
      "  Initialization Multiplier: 0.7152516223935625\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.53it/s, loss=-0.000254, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:00:10,127] Trial 116 finished with value: -0.0002540326382487349 and parameters: {'learning_rate': 0.007943855461719735, 'sigma_multiplier': 1.0984789555957823, 'num_layers': 2, 'initialization_multiplier': 0.7152516223935625}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 116 final loss: -0.00025403\n",
      "Trial 117:\n",
      "  Learning Rate: 0.01704232872691364\n",
      "  Sigma Multiplier: 1.1626723657852789\n",
      "  Initialization Multiplier: 0.4095058679988388\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000330, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 13:00:21,306] Trial 117 finished with value: -0.00032960084680489524 and parameters: {'learning_rate': 0.01704232872691364, 'sigma_multiplier': 1.1626723657852789, 'num_layers': 2, 'initialization_multiplier': 0.4095058679988388}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 117 final loss: -0.00032960\n",
      "Trial 118:\n",
      "  Learning Rate: 0.011570133185592892\n",
      "  Sigma Multiplier: 1.061270817812024\n",
      "  Initialization Multiplier: 0.22396088486436222\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.13it/s, loss=-0.000232, elapsed time=0.07, total time=10.9]\n",
      "[I 2025-06-07 13:00:32,231] Trial 118 finished with value: -0.0002319545592097548 and parameters: {'learning_rate': 0.011570133185592892, 'sigma_multiplier': 1.061270817812024, 'num_layers': 2, 'initialization_multiplier': 0.22396088486436222}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 118 final loss: -0.00023195\n",
      "Trial 119:\n",
      "  Learning Rate: 0.013173709115107396\n",
      "  Sigma Multiplier: 1.229291778185644\n",
      "  Initialization Multiplier: 0.5951111385451988\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.41it/s, loss=-0.000280, elapsed time=0.04, total time=8.85]\n",
      "[I 2025-06-07 13:00:41,115] Trial 119 finished with value: -0.00027971736057881314 and parameters: {'learning_rate': 0.013173709115107396, 'sigma_multiplier': 1.229291778185644, 'num_layers': 1, 'initialization_multiplier': 0.5951111385451988}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 119 final loss: -0.00027972\n",
      "Trial 120:\n",
      "  Learning Rate: 0.007229967833861746\n",
      "  Sigma Multiplier: 0.8454030812850829\n",
      "  Initialization Multiplier: 0.3028171570921243\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.88it/s, loss=-0.000281, elapsed time=0.09, total time=12]  \n",
      "[I 2025-06-07 13:00:53,134] Trial 120 finished with value: -0.00028069923516507625 and parameters: {'learning_rate': 0.007229967833861746, 'sigma_multiplier': 0.8454030812850829, 'num_layers': 2, 'initialization_multiplier': 0.3028171570921243}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 120 final loss: -0.00028070\n",
      "Trial 121:\n",
      "  Learning Rate: 0.006279370641707235\n",
      "  Sigma Multiplier: 0.9273285887723399\n",
      "  Initialization Multiplier: 0.5083267442451966\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000282, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:01:04,756] Trial 121 finished with value: -0.0002824534249501237 and parameters: {'learning_rate': 0.006279370641707235, 'sigma_multiplier': 0.9273285887723399, 'num_layers': 2, 'initialization_multiplier': 0.5083267442451966}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 121 final loss: -0.00028245\n",
      "Trial 122:\n",
      "  Learning Rate: 0.00929093913376486\n",
      "  Sigma Multiplier: 0.9731578706804389\n",
      "  Initialization Multiplier: 0.3410585280981402\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000381, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:01:16,204] Trial 122 finished with value: -0.00038126875282393246 and parameters: {'learning_rate': 0.00929093913376486, 'sigma_multiplier': 0.9731578706804389, 'num_layers': 2, 'initialization_multiplier': 0.3410585280981402}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 122 final loss: -0.00038127\n",
      "Trial 123:\n",
      "  Learning Rate: 0.0002989212533066769\n",
      "  Sigma Multiplier: 0.9754429536253945\n",
      "  Initialization Multiplier: 0.422964179711691\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.74it/s, loss=0.007749, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:01:27,467] Trial 123 finished with value: 0.0077489115894434375 and parameters: {'learning_rate': 0.0002989212533066769, 'sigma_multiplier': 0.9754429536253945, 'num_layers': 2, 'initialization_multiplier': 0.422964179711691}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 123 final loss: 0.00774891\n",
      "Trial 124:\n",
      "  Learning Rate: 0.00911920296357168\n",
      "  Sigma Multiplier: 1.12348772642328\n",
      "  Initialization Multiplier: 0.3421130786145985\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.13it/s, loss=-0.000289, elapsed time=0.15, total time=10.9]\n",
      "[I 2025-06-07 13:01:38,460] Trial 124 finished with value: -0.00028879155132476665 and parameters: {'learning_rate': 0.00911920296357168, 'sigma_multiplier': 1.12348772642328, 'num_layers': 2, 'initialization_multiplier': 0.3421130786145985}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 124 final loss: -0.00028879\n",
      "Trial 125:\n",
      "  Learning Rate: 9.504741610541282e-05\n",
      "  Sigma Multiplier: 1.0506594965268894\n",
      "  Initialization Multiplier: 0.2522136992506916\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.30it/s, loss=0.041831, elapsed time=0.04, total time=10.8]\n",
      "[I 2025-06-07 13:01:49,330] Trial 125 finished with value: 0.04183114542888386 and parameters: {'learning_rate': 9.504741610541282e-05, 'sigma_multiplier': 1.0506594965268894, 'num_layers': 2, 'initialization_multiplier': 0.2522136992506916}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 125 final loss: 0.04183115\n",
      "Trial 126:\n",
      "  Learning Rate: 0.009500692240386379\n",
      "  Sigma Multiplier: 1.0254524866881396\n",
      "  Initialization Multiplier: 0.45510527354901614\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.01it/s, loss=-0.000321, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 13:02:00,349] Trial 126 finished with value: -0.00032148562646619385 and parameters: {'learning_rate': 0.009500692240386379, 'sigma_multiplier': 1.0254524866881396, 'num_layers': 2, 'initialization_multiplier': 0.45510527354901614}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 126 final loss: -0.00032149\n",
      "Trial 127:\n",
      "  Learning Rate: 0.005308149765854036\n",
      "  Sigma Multiplier: 1.1465918882158896\n",
      "  Initialization Multiplier: 0.5218087054412168\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.78it/s, loss=-0.000249, elapsed time=0.11, total time=17.5]\n",
      "[I 2025-06-07 13:02:17,877] Trial 127 finished with value: -0.0002494249474774158 and parameters: {'learning_rate': 0.005308149765854036, 'sigma_multiplier': 1.1465918882158896, 'num_layers': 5, 'initialization_multiplier': 0.5218087054412168}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 127 final loss: -0.00024942\n",
      "Trial 128:\n",
      "  Learning Rate: 0.023284335209668546\n",
      "  Sigma Multiplier: 0.9002212367159351\n",
      "  Initialization Multiplier: 0.37984845348771284\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000325, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:02:29,387] Trial 128 finished with value: -0.000325296098015644 and parameters: {'learning_rate': 0.023284335209668546, 'sigma_multiplier': 0.9002212367159351, 'num_layers': 2, 'initialization_multiplier': 0.37984845348771284}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 128 final loss: -0.00032530\n",
      "Trial 129:\n",
      "  Learning Rate: 0.013795919766993455\n",
      "  Sigma Multiplier: 1.270716220661025\n",
      "  Initialization Multiplier: 0.3167611509807127\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.45it/s, loss=-0.000280, elapsed time=0.07, total time=10.6]\n",
      "[I 2025-06-07 13:02:40,064] Trial 129 finished with value: -0.0002802512413069352 and parameters: {'learning_rate': 0.013795919766993455, 'sigma_multiplier': 1.270716220661025, 'num_layers': 2, 'initialization_multiplier': 0.3167611509807127}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 129 final loss: -0.00028025\n",
      "Trial 130:\n",
      "  Learning Rate: 0.0031368007634018703\n",
      "  Sigma Multiplier: 0.9929395834865977\n",
      "  Initialization Multiplier: 0.1879758235005965\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.39it/s, loss=-0.000071, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:02:51,627] Trial 130 finished with value: -7.131073929159269e-05 and parameters: {'learning_rate': 0.0031368007634018703, 'sigma_multiplier': 0.9929395834865977, 'num_layers': 2, 'initialization_multiplier': 0.1879758235005965}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 130 final loss: -0.00007131\n",
      "Trial 131:\n",
      "  Learning Rate: 0.006758618510932284\n",
      "  Sigma Multiplier: 0.9377895955473199\n",
      "  Initialization Multiplier: 0.36994302361100984\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000286, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:03:03,234] Trial 131 finished with value: -0.00028554479423180515 and parameters: {'learning_rate': 0.006758618510932284, 'sigma_multiplier': 0.9377895955473199, 'num_layers': 2, 'initialization_multiplier': 0.36994302361100984}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 131 final loss: -0.00028554\n",
      "Trial 132:\n",
      "  Learning Rate: 0.007642445506576176\n",
      "  Sigma Multiplier: 1.1953748849806167\n",
      "  Initialization Multiplier: 0.4816022428221309\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.72it/s, loss=-0.000389, elapsed time=0.06, total time=10.5]\n",
      "[I 2025-06-07 13:03:13,733] Trial 132 finished with value: -0.00038867940232596465 and parameters: {'learning_rate': 0.007642445506576176, 'sigma_multiplier': 1.1953748849806167, 'num_layers': 2, 'initialization_multiplier': 0.4816022428221309}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 132 final loss: -0.00038868\n",
      "Trial 133:\n",
      "  Learning Rate: 0.0019766359220990794\n",
      "  Sigma Multiplier: 1.1958472331388885\n",
      "  Initialization Multiplier: 0.48884260803462587\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.57it/s, loss=-0.000266, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 13:03:24,389] Trial 133 finished with value: -0.00026573229739722926 and parameters: {'learning_rate': 0.0019766359220990794, 'sigma_multiplier': 1.1958472331388885, 'num_layers': 2, 'initialization_multiplier': 0.48884260803462587}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 133 final loss: -0.00026573\n",
      "Trial 134:\n",
      "  Learning Rate: 0.00804017431125495\n",
      "  Sigma Multiplier: 1.0823869074832622\n",
      "  Initialization Multiplier: 0.5510870164412311\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.11it/s, loss=-0.000351, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 13:03:35,327] Trial 134 finished with value: -0.00035140123579418853 and parameters: {'learning_rate': 0.00804017431125495, 'sigma_multiplier': 1.0823869074832622, 'num_layers': 2, 'initialization_multiplier': 0.5510870164412311}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 134 final loss: -0.00035140\n",
      "Trial 135:\n",
      "  Learning Rate: 0.010648665161700255\n",
      "  Sigma Multiplier: 1.318602190129601\n",
      "  Initialization Multiplier: 1.348028511043892\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.44it/s, loss=-0.000307, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 13:03:46,056] Trial 135 finished with value: -0.0003072481560047811 and parameters: {'learning_rate': 0.010648665161700255, 'sigma_multiplier': 1.318602190129601, 'num_layers': 2, 'initialization_multiplier': 1.348028511043892}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 135 final loss: -0.00030725\n",
      "Trial 136:\n",
      "  Learning Rate: 0.012187694694605828\n",
      "  Sigma Multiplier: 1.1133443112433101\n",
      "  Initialization Multiplier: 0.6351205898983753\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000363, elapsed time=0.04, total time=11.2]\n",
      "[I 2025-06-07 13:03:57,261] Trial 136 finished with value: -0.0003630058391024758 and parameters: {'learning_rate': 0.012187694694605828, 'sigma_multiplier': 1.1133443112433101, 'num_layers': 2, 'initialization_multiplier': 0.6351205898983753}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 136 final loss: -0.00036301\n",
      "Trial 137:\n",
      "  Learning Rate: 0.01614372665588024\n",
      "  Sigma Multiplier: 1.1946622452288707\n",
      "  Initialization Multiplier: 0.4372254581781787\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.50it/s, loss=-0.000324, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 13:04:07,908] Trial 137 finished with value: -0.0003240993626618702 and parameters: {'learning_rate': 0.01614372665588024, 'sigma_multiplier': 1.1946622452288707, 'num_layers': 2, 'initialization_multiplier': 0.4372254581781787}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 137 final loss: -0.00032410\n",
      "Trial 138:\n",
      "  Learning Rate: 0.003922644835044014\n",
      "  Sigma Multiplier: 1.2534095302355384\n",
      "  Initialization Multiplier: 0.46993082329946667\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.30it/s, loss=-0.000373, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 13:04:18,771] Trial 138 finished with value: -0.0003733984306457231 and parameters: {'learning_rate': 0.003922644835044014, 'sigma_multiplier': 1.2534095302355384, 'num_layers': 2, 'initialization_multiplier': 0.46993082329946667}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 138 final loss: -0.00037340\n",
      "Trial 139:\n",
      "  Learning Rate: 0.008143813897639306\n",
      "  Sigma Multiplier: 1.1502057377660675\n",
      "  Initialization Multiplier: 0.5560485902866609\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.10it/s, loss=-0.000351, elapsed time=0.08, total time=11.8]\n",
      "[I 2025-06-07 13:04:30,624] Trial 139 finished with value: -0.00035112408706174694 and parameters: {'learning_rate': 0.008143813897639306, 'sigma_multiplier': 1.1502057377660675, 'num_layers': 2, 'initialization_multiplier': 0.5560485902866609}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 139 final loss: -0.00035112\n",
      "Trial 140:\n",
      "  Learning Rate: 0.0048314592190217285\n",
      "  Sigma Multiplier: 1.062167209885277\n",
      "  Initialization Multiplier: 0.2969879480962616\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.65it/s, loss=-0.000258, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:04:42,031] Trial 140 finished with value: -0.00025783014704629036 and parameters: {'learning_rate': 0.0048314592190217285, 'sigma_multiplier': 1.062167209885277, 'num_layers': 2, 'initialization_multiplier': 0.2969879480962616}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 140 final loss: -0.00025783\n",
      "Trial 141:\n",
      "  Learning Rate: 0.00709324990113282\n",
      "  Sigma Multiplier: 0.9659343274505039\n",
      "  Initialization Multiplier: 0.39576528670808203\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.49it/s, loss=-0.000379, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:04:53,503] Trial 141 finished with value: -0.0003787144331715102 and parameters: {'learning_rate': 0.00709324990113282, 'sigma_multiplier': 0.9659343274505039, 'num_layers': 2, 'initialization_multiplier': 0.39576528670808203}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 141 final loss: -0.00037871\n",
      "Trial 142:\n",
      "  Learning Rate: 0.010004847032735846\n",
      "  Sigma Multiplier: 1.0094071411119374\n",
      "  Initialization Multiplier: 0.3900891900210533\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000394, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:05:04,849] Trial 142 finished with value: -0.00039430105668191665 and parameters: {'learning_rate': 0.010004847032735846, 'sigma_multiplier': 1.0094071411119374, 'num_layers': 2, 'initialization_multiplier': 0.3900891900210533}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 142 final loss: -0.00039430\n",
      "Trial 143:\n",
      "  Learning Rate: 0.010076787982187361\n",
      "  Sigma Multiplier: 0.9996205741249455\n",
      "  Initialization Multiplier: 0.49710769995110776\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.53it/s, loss=-0.000384, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:05:16,292] Trial 143 finished with value: -0.0003843108299383832 and parameters: {'learning_rate': 0.010076787982187361, 'sigma_multiplier': 0.9996205741249455, 'num_layers': 2, 'initialization_multiplier': 0.49710769995110776}. Best is trial 84 with value: -0.00046138953332195543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 143 final loss: -0.00038431\n",
      "Trial 144:\n",
      "  Learning Rate: 0.009833198081501033\n",
      "  Sigma Multiplier: 1.001516945448479\n",
      "  Initialization Multiplier: 0.5924641213537045\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.67it/s, loss=-0.000483, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 13:05:27,606] Trial 144 finished with value: -0.0004832216293692365 and parameters: {'learning_rate': 0.009833198081501033, 'sigma_multiplier': 1.001516945448479, 'num_layers': 2, 'initialization_multiplier': 0.5924641213537045}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 144 final loss: -0.00048322\n",
      "Trial 145:\n",
      "  Learning Rate: 0.011005639789831538\n",
      "  Sigma Multiplier: 1.0019753122597954\n",
      "  Initialization Multiplier: 0.5900955043643455\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.32it/s, loss=-0.000331, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 13:05:39,217] Trial 145 finished with value: -0.00033100286900275913 and parameters: {'learning_rate': 0.011005639789831538, 'sigma_multiplier': 1.0019753122597954, 'num_layers': 2, 'initialization_multiplier': 0.5900955043643455}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 145 final loss: -0.00033100\n",
      "Trial 146:\n",
      "  Learning Rate: 0.005845509192875578\n",
      "  Sigma Multiplier: 1.0310274210373342\n",
      "  Initialization Multiplier: 0.6496259705348878\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.73it/s, loss=-0.000317, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 13:05:50,476] Trial 146 finished with value: -0.00031705165062899436 and parameters: {'learning_rate': 0.005845509192875578, 'sigma_multiplier': 1.0310274210373342, 'num_layers': 2, 'initialization_multiplier': 0.6496259705348878}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 146 final loss: -0.00031705\n",
      "Trial 147:\n",
      "  Learning Rate: 0.010137562856494557\n",
      "  Sigma Multiplier: 1.095337823267927\n",
      "  Initialization Multiplier: 0.5305969710087918\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.31it/s, loss=-0.000373, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:06:02,021] Trial 147 finished with value: -0.00037293490198940185 and parameters: {'learning_rate': 0.010137562856494557, 'sigma_multiplier': 1.095337823267927, 'num_layers': 2, 'initialization_multiplier': 0.5305969710087918}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 147 final loss: -0.00037293\n",
      "Trial 148:\n",
      "  Learning Rate: 0.018139225666797414\n",
      "  Sigma Multiplier: 0.9026618266270058\n",
      "  Initialization Multiplier: 0.4906445409424721\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.38it/s, loss=-0.000280, elapsed time=0.07, total time=12.6]\n",
      "[I 2025-06-07 13:06:14,620] Trial 148 finished with value: -0.00028033884069035987 and parameters: {'learning_rate': 0.018139225666797414, 'sigma_multiplier': 0.9026618266270058, 'num_layers': 2, 'initialization_multiplier': 0.4906445409424721}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 148 final loss: -0.00028034\n",
      "Trial 149:\n",
      "  Learning Rate: 0.008528578365318203\n",
      "  Sigma Multiplier: 1.0542830997337058\n",
      "  Initialization Multiplier: 0.6051658603559411\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.93it/s, loss=-0.000380, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 13:06:26,522] Trial 149 finished with value: -0.00037996354756766453 and parameters: {'learning_rate': 0.008528578365318203, 'sigma_multiplier': 1.0542830997337058, 'num_layers': 2, 'initialization_multiplier': 0.6051658603559411}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 149 final loss: -0.00037996\n",
      "Trial 150:\n",
      "  Learning Rate: 0.01376245185403636\n",
      "  Sigma Multiplier: 1.011695284525096\n",
      "  Initialization Multiplier: 0.689181317663432\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.82it/s, loss=-0.000261, elapsed time=0.09, total time=12]  \n",
      "[I 2025-06-07 13:06:38,607] Trial 150 finished with value: -0.00026104363143363273 and parameters: {'learning_rate': 0.01376245185403636, 'sigma_multiplier': 1.011695284525096, 'num_layers': 2, 'initialization_multiplier': 0.689181317663432}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 150 final loss: -0.00026104\n",
      "Trial 151:\n",
      "  Learning Rate: 0.009675819915839204\n",
      "  Sigma Multiplier: 0.9649436116934765\n",
      "  Initialization Multiplier: 0.43486433096594357\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.46it/s, loss=-0.000372, elapsed time=0.05, total time=12.3]\n",
      "[I 2025-06-07 13:06:50,997] Trial 151 finished with value: -0.00037182704568062923 and parameters: {'learning_rate': 0.009675819915839204, 'sigma_multiplier': 0.9649436116934765, 'num_layers': 2, 'initialization_multiplier': 0.43486433096594357}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 151 final loss: -0.00037183\n",
      "Trial 152:\n",
      "  Learning Rate: 0.006659174176263613\n",
      "  Sigma Multiplier: 0.9473395769258184\n",
      "  Initialization Multiplier: 0.47210743636236346\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.70it/s, loss=-0.000405, elapsed time=0.13, total time=12.2]\n",
      "[I 2025-06-07 13:07:03,273] Trial 152 finished with value: -0.0004054935430587671 and parameters: {'learning_rate': 0.006659174176263613, 'sigma_multiplier': 0.9473395769258184, 'num_layers': 2, 'initialization_multiplier': 0.47210743636236346}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 152 final loss: -0.00040549\n",
      "Trial 153:\n",
      "  Learning Rate: 0.007036448410886705\n",
      "  Sigma Multiplier: 0.8553436466045401\n",
      "  Initialization Multiplier: 0.5056713489746221\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.10it/s, loss=-0.000254, elapsed time=0.07, total time=12.7]\n",
      "[I 2025-06-07 13:07:16,031] Trial 153 finished with value: -0.00025430660048079317 and parameters: {'learning_rate': 0.007036448410886705, 'sigma_multiplier': 0.8553436466045401, 'num_layers': 2, 'initialization_multiplier': 0.5056713489746221}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 153 final loss: -0.00025431\n",
      "Trial 154:\n",
      "  Learning Rate: 0.006045220815360686\n",
      "  Sigma Multiplier: 0.92547404100045\n",
      "  Initialization Multiplier: 0.5509083732310489\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.48it/s, loss=-0.000386, elapsed time=0.08, total time=12.3]\n",
      "[I 2025-06-07 13:07:28,382] Trial 154 finished with value: -0.0003855440571829513 and parameters: {'learning_rate': 0.006045220815360686, 'sigma_multiplier': 0.92547404100045, 'num_layers': 2, 'initialization_multiplier': 0.5509083732310489}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 154 final loss: -0.00038554\n",
      "Trial 155:\n",
      "  Learning Rate: 0.005681418817296294\n",
      "  Sigma Multiplier: 0.7996481142792959\n",
      "  Initialization Multiplier: 0.5732297206925372\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.36it/s, loss=-0.000295, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 13:07:40,887] Trial 155 finished with value: -0.000294763827278016 and parameters: {'learning_rate': 0.005681418817296294, 'sigma_multiplier': 0.7996481142792959, 'num_layers': 2, 'initialization_multiplier': 0.5732297206925372}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 155 final loss: -0.00029476\n",
      "Trial 156:\n",
      "  Learning Rate: 0.004454131129935002\n",
      "  Sigma Multiplier: 0.9261161907434194\n",
      "  Initialization Multiplier: 0.54826041737173\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.57it/s, loss=-0.000357, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 13:07:53,238] Trial 156 finished with value: -0.0003574976537619843 and parameters: {'learning_rate': 0.004454131129935002, 'sigma_multiplier': 0.9261161907434194, 'num_layers': 2, 'initialization_multiplier': 0.54826041737173}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 156 final loss: -0.00035750\n",
      "Trial 157:\n",
      "  Learning Rate: 0.006184366925812076\n",
      "  Sigma Multiplier: 0.8716277934771446\n",
      "  Initialization Multiplier: 0.6247393228789481\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.56it/s, loss=-0.000309, elapsed time=0.08, total time=12.3]\n",
      "[I 2025-06-07 13:08:05,558] Trial 157 finished with value: -0.00030937097278256744 and parameters: {'learning_rate': 0.006184366925812076, 'sigma_multiplier': 0.8716277934771446, 'num_layers': 2, 'initialization_multiplier': 0.6247393228789481}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 157 final loss: -0.00030937\n",
      "Trial 158:\n",
      "  Learning Rate: 0.007770079544344371\n",
      "  Sigma Multiplier: 0.9088092534059359\n",
      "  Initialization Multiplier: 0.47213060885042496\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.74it/s, loss=-0.000363, elapsed time=0.05, total time=12.2]\n",
      "[I 2025-06-07 13:08:17,796] Trial 158 finished with value: -0.000363423467525939 and parameters: {'learning_rate': 0.007770079544344371, 'sigma_multiplier': 0.9088092534059359, 'num_layers': 2, 'initialization_multiplier': 0.47213060885042496}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 158 final loss: -0.00036342\n",
      "Trial 159:\n",
      "  Learning Rate: 0.003777806217897407\n",
      "  Sigma Multiplier: 1.0223215838208366\n",
      "  Initialization Multiplier: 0.7504527983292429\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000248, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:08:29,370] Trial 159 finished with value: -0.00024771008171941997 and parameters: {'learning_rate': 0.003777806217897407, 'sigma_multiplier': 1.0223215838208366, 'num_layers': 2, 'initialization_multiplier': 0.7504527983292429}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 159 final loss: -0.00024771\n",
      "Trial 160:\n",
      "  Learning Rate: 0.006724355634343228\n",
      "  Sigma Multiplier: 0.9433290369429085\n",
      "  Initialization Multiplier: 0.5295975402077375\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000418, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 13:08:40,806] Trial 160 finished with value: -0.000418012206748761 and parameters: {'learning_rate': 0.006724355634343228, 'sigma_multiplier': 0.9433290369429085, 'num_layers': 2, 'initialization_multiplier': 0.5295975402077375}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 160 final loss: -0.00041801\n",
      "Trial 161:\n",
      "  Learning Rate: 0.005313605737589059\n",
      "  Sigma Multiplier: 0.9507251569284879\n",
      "  Initialization Multiplier: 0.5233163347190549\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.69it/s, loss=-0.000378, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 13:08:52,943] Trial 161 finished with value: -0.0003776891007675604 and parameters: {'learning_rate': 0.005313605737589059, 'sigma_multiplier': 0.9507251569284879, 'num_layers': 2, 'initialization_multiplier': 0.5233163347190549}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 161 final loss: -0.00037769\n",
      "Trial 162:\n",
      "  Learning Rate: 0.0064568959773591795\n",
      "  Sigma Multiplier: 0.9793584609989379\n",
      "  Initialization Multiplier: 0.5915446933941023\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.64it/s, loss=-0.000362, elapsed time=0.05, total time=12.2]\n",
      "[I 2025-06-07 13:09:05,197] Trial 162 finished with value: -0.000362180499960893 and parameters: {'learning_rate': 0.0064568959773591795, 'sigma_multiplier': 0.9793584609989379, 'num_layers': 2, 'initialization_multiplier': 0.5915446933941023}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 162 final loss: -0.00036218\n",
      "Trial 163:\n",
      "  Learning Rate: 0.007788435559031669\n",
      "  Sigma Multiplier: 0.82598378761833\n",
      "  Initialization Multiplier: 0.652934932628503\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.44it/s, loss=-0.000321, elapsed time=0.06, total time=12.3]\n",
      "[I 2025-06-07 13:09:17,553] Trial 163 finished with value: -0.000320959464549475 and parameters: {'learning_rate': 0.007788435559031669, 'sigma_multiplier': 0.82598378761833, 'num_layers': 2, 'initialization_multiplier': 0.652934932628503}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 163 final loss: -0.00032096\n",
      "Trial 164:\n",
      "  Learning Rate: 0.008967062637496465\n",
      "  Sigma Multiplier: 1.1266195706421867\n",
      "  Initialization Multiplier: 0.5135502019440258\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.11it/s, loss=-0.000375, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 13:09:28,576] Trial 164 finished with value: -0.0003747708979702221 and parameters: {'learning_rate': 0.008967062637496465, 'sigma_multiplier': 1.1266195706421867, 'num_layers': 2, 'initialization_multiplier': 0.5135502019440258}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 164 final loss: -0.00037477\n",
      "Trial 165:\n",
      "  Learning Rate: 0.011232795209722134\n",
      "  Sigma Multiplier: 1.0095162379320102\n",
      "  Initialization Multiplier: 0.5571434494416845\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.83it/s, loss=-0.000284, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 13:09:39,698] Trial 165 finished with value: -0.0002838395199711149 and parameters: {'learning_rate': 0.011232795209722134, 'sigma_multiplier': 1.0095162379320102, 'num_layers': 2, 'initialization_multiplier': 0.5571434494416845}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 165 final loss: -0.00028384\n",
      "Trial 166:\n",
      "  Learning Rate: 0.0029142384734710857\n",
      "  Sigma Multiplier: 0.9367586594355207\n",
      "  Initialization Multiplier: 0.4663245421297305\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.66it/s, loss=-0.000332, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 13:09:51,912] Trial 166 finished with value: -0.00033207746709716315 and parameters: {'learning_rate': 0.0029142384734710857, 'sigma_multiplier': 0.9367586594355207, 'num_layers': 2, 'initialization_multiplier': 0.4663245421297305}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 166 final loss: -0.00033208\n",
      "Trial 167:\n",
      "  Learning Rate: 0.00487130007411567\n",
      "  Sigma Multiplier: 1.0521113827178603\n",
      "  Initialization Multiplier: 0.12115023017676757\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000240, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:10:03,418] Trial 167 finished with value: -0.00024013815573288265 and parameters: {'learning_rate': 0.00487130007411567, 'sigma_multiplier': 1.0521113827178603, 'num_layers': 2, 'initialization_multiplier': 0.12115023017676757}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 167 final loss: -0.00024014\n",
      "Trial 168:\n",
      "  Learning Rate: 0.007038967212299826\n",
      "  Sigma Multiplier: 0.7047730320313139\n",
      "  Initialization Multiplier: 0.4276460226333556\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.23it/s, loss=-0.000042, elapsed time=0.09, total time=12.7]\n",
      "[I 2025-06-07 13:10:16,165] Trial 168 finished with value: -4.162060105024127e-05 and parameters: {'learning_rate': 0.007038967212299826, 'sigma_multiplier': 0.7047730320313139, 'num_layers': 2, 'initialization_multiplier': 0.4276460226333556}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 168 final loss: -0.00004162\n",
      "Trial 169:\n",
      "  Learning Rate: 0.010114217759937445\n",
      "  Sigma Multiplier: 0.883206303475045\n",
      "  Initialization Multiplier: 0.4985413710386699\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.24it/s, loss=-0.000273, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:10:27,832] Trial 169 finished with value: -0.00027305603638739796 and parameters: {'learning_rate': 0.010114217759937445, 'sigma_multiplier': 0.883206303475045, 'num_layers': 2, 'initialization_multiplier': 0.4985413710386699}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 169 final loss: -0.00027306\n",
      "Trial 170:\n",
      "  Learning Rate: 0.005858585718799565\n",
      "  Sigma Multiplier: 1.093894712867753\n",
      "  Initialization Multiplier: 0.6141411476399342\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.21it/s, loss=-0.000389, elapsed time=0.09, total time=10.8]\n",
      "[I 2025-06-07 13:10:38,666] Trial 170 finished with value: -0.00038870631170790813 and parameters: {'learning_rate': 0.005858585718799565, 'sigma_multiplier': 1.093894712867753, 'num_layers': 2, 'initialization_multiplier': 0.6141411476399342}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 170 final loss: -0.00038871\n",
      "Trial 171:\n",
      "  Learning Rate: 0.006032096580244899\n",
      "  Sigma Multiplier: 1.0898158334673638\n",
      "  Initialization Multiplier: 0.6042375628813715\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.22it/s, loss=-0.000422, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 13:10:49,534] Trial 171 finished with value: -0.000422137714987613 and parameters: {'learning_rate': 0.006032096580244899, 'sigma_multiplier': 1.0898158334673638, 'num_layers': 2, 'initialization_multiplier': 0.6042375628813715}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 171 final loss: -0.00042214\n",
      "Trial 172:\n",
      "  Learning Rate: 0.004346687974036646\n",
      "  Sigma Multiplier: 1.0969515718982301\n",
      "  Initialization Multiplier: 0.6670847320711606\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000252, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 13:11:01,118] Trial 172 finished with value: -0.0002523896528033417 and parameters: {'learning_rate': 0.004346687974036646, 'sigma_multiplier': 1.0969515718982301, 'num_layers': 2, 'initialization_multiplier': 0.6670847320711606}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 172 final loss: -0.00025239\n",
      "Trial 173:\n",
      "  Learning Rate: 0.005767133736551449\n",
      "  Sigma Multiplier: 1.172969578881301\n",
      "  Initialization Multiplier: 0.5912985197798022\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.64it/s, loss=-0.000351, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 13:11:12,511] Trial 173 finished with value: -0.00035108155253792063 and parameters: {'learning_rate': 0.005767133736551449, 'sigma_multiplier': 1.172969578881301, 'num_layers': 2, 'initialization_multiplier': 0.5912985197798022}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 173 final loss: -0.00035108\n",
      "Trial 174:\n",
      "  Learning Rate: 0.0064412786884657175\n",
      "  Sigma Multiplier: 1.1360404264143384\n",
      "  Initialization Multiplier: 0.7260150080555867\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000395, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:11:24,263] Trial 174 finished with value: -0.00039528468674098665 and parameters: {'learning_rate': 0.0064412786884657175, 'sigma_multiplier': 1.1360404264143384, 'num_layers': 2, 'initialization_multiplier': 0.7260150080555867}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 174 final loss: -0.00039528\n",
      "Trial 175:\n",
      "  Learning Rate: 0.007950710196329399\n",
      "  Sigma Multiplier: 1.1383348316939137\n",
      "  Initialization Multiplier: 0.6896025902514669\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.13it/s, loss=-0.000373, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 13:11:36,139] Trial 175 finished with value: -0.0003729569456014823 and parameters: {'learning_rate': 0.007950710196329399, 'sigma_multiplier': 1.1383348316939137, 'num_layers': 2, 'initialization_multiplier': 0.6896025902514669}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 175 final loss: -0.00037296\n",
      "Trial 176:\n",
      "  Learning Rate: 0.0035659346082625235\n",
      "  Sigma Multiplier: 1.0968667990493421\n",
      "  Initialization Multiplier: 0.6238556898682205\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.89it/s, loss=-0.000445, elapsed time=0.05, total time=12]  \n",
      "[I 2025-06-07 13:11:48,130] Trial 176 finished with value: -0.0004447638276188901 and parameters: {'learning_rate': 0.0035659346082625235, 'sigma_multiplier': 1.0968667990493421, 'num_layers': 2, 'initialization_multiplier': 0.6238556898682205}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 176 final loss: -0.00044476\n",
      "Trial 177:\n",
      "  Learning Rate: 0.003444222572909579\n",
      "  Sigma Multiplier: 1.0703064585015738\n",
      "  Initialization Multiplier: 0.8239678243577675\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000090, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:11:59,869] Trial 177 finished with value: -8.975950081712196e-05 and parameters: {'learning_rate': 0.003444222572909579, 'sigma_multiplier': 1.0703064585015738, 'num_layers': 2, 'initialization_multiplier': 0.8239678243577675}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 177 final loss: -0.00008976\n",
      "Trial 178:\n",
      "  Learning Rate: 0.005152691028036414\n",
      "  Sigma Multiplier: 1.1796351518161243\n",
      "  Initialization Multiplier: 0.7353066032032123\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=-0.000397, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:12:11,338] Trial 178 finished with value: -0.0003970673147528531 and parameters: {'learning_rate': 0.005152691028036414, 'sigma_multiplier': 1.1796351518161243, 'num_layers': 2, 'initialization_multiplier': 0.7353066032032123}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 178 final loss: -0.00039707\n",
      "Trial 179:\n",
      "  Learning Rate: 0.004968719884368472\n",
      "  Sigma Multiplier: 1.1564079453686031\n",
      "  Initialization Multiplier: 0.797381552231321\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.36it/s, loss=-0.000394, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:12:22,851] Trial 179 finished with value: -0.0003942300503526515 and parameters: {'learning_rate': 0.004968719884368472, 'sigma_multiplier': 1.1564079453686031, 'num_layers': 2, 'initialization_multiplier': 0.797381552231321}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 179 final loss: -0.00039423\n",
      "Trial 180:\n",
      "  Learning Rate: 0.004846213574925601\n",
      "  Sigma Multiplier: 1.1431796266228105\n",
      "  Initialization Multiplier: 0.876325711083547\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000214, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 13:12:34,720] Trial 180 finished with value: -0.0002137133703455438 and parameters: {'learning_rate': 0.004846213574925601, 'sigma_multiplier': 1.1431796266228105, 'num_layers': 2, 'initialization_multiplier': 0.876325711083547}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 180 final loss: -0.00021371\n",
      "Trial 181:\n",
      "  Learning Rate: 0.004928133782887947\n",
      "  Sigma Multiplier: 1.0389241658842994\n",
      "  Initialization Multiplier: 0.7287054933531762\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.93it/s, loss=-0.000291, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 13:12:46,782] Trial 181 finished with value: -0.00029086897347214 and parameters: {'learning_rate': 0.004928133782887947, 'sigma_multiplier': 1.0389241658842994, 'num_layers': 2, 'initialization_multiplier': 0.7287054933531762}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 181 final loss: -0.00029087\n",
      "Trial 182:\n",
      "  Learning Rate: 0.003792654544992188\n",
      "  Sigma Multiplier: 1.1714646876371466\n",
      "  Initialization Multiplier: 0.7208218555197576\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000356, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:12:58,133] Trial 182 finished with value: -0.0003562244669251541 and parameters: {'learning_rate': 0.003792654544992188, 'sigma_multiplier': 1.1714646876371466, 'num_layers': 2, 'initialization_multiplier': 0.7208218555197576}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 182 final loss: -0.00035622\n",
      "Trial 183:\n",
      "  Learning Rate: 0.006567740685143082\n",
      "  Sigma Multiplier: 1.090891989815432\n",
      "  Initialization Multiplier: 0.8034051574195906\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.07it/s, loss=-0.000134, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:13:09,902] Trial 183 finished with value: -0.00013393803952561697 and parameters: {'learning_rate': 0.006567740685143082, 'sigma_multiplier': 1.090891989815432, 'num_layers': 2, 'initialization_multiplier': 0.8034051574195906}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 183 final loss: -0.00013394\n",
      "Trial 184:\n",
      "  Learning Rate: 0.005253868702157325\n",
      "  Sigma Multiplier: 1.060570000572347\n",
      "  Initialization Multiplier: 0.7822937276362212\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.17it/s, loss=-0.000253, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:13:21,630] Trial 184 finished with value: -0.00025313430532576453 and parameters: {'learning_rate': 0.005253868702157325, 'sigma_multiplier': 1.060570000572347, 'num_layers': 2, 'initialization_multiplier': 0.7822937276362212}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 184 final loss: -0.00025313\n",
      "Trial 185:\n",
      "  Learning Rate: 0.004237769812805874\n",
      "  Sigma Multiplier: 1.1238302315313138\n",
      "  Initialization Multiplier: 0.6959849265716278\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.63it/s, loss=-0.000243, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 13:13:33,011] Trial 185 finished with value: -0.00024303256779424463 and parameters: {'learning_rate': 0.004237769812805874, 'sigma_multiplier': 1.1238302315313138, 'num_layers': 2, 'initialization_multiplier': 0.6959849265716278}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 185 final loss: -0.00024303\n",
      "Trial 186:\n",
      "  Learning Rate: 0.006690443741494444\n",
      "  Sigma Multiplier: 1.2231183099045122\n",
      "  Initialization Multiplier: 0.6348055770083223\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.31it/s, loss=-0.000396, elapsed time=0.04, total time=10.8]\n",
      "[I 2025-06-07 13:13:43,863] Trial 186 finished with value: -0.0003956699167798849 and parameters: {'learning_rate': 0.006690443741494444, 'sigma_multiplier': 1.2231183099045122, 'num_layers': 2, 'initialization_multiplier': 0.6348055770083223}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 186 final loss: -0.00039567\n",
      "Trial 187:\n",
      "  Learning Rate: 0.008889436328523518\n",
      "  Sigma Multiplier: 1.214273343215771\n",
      "  Initialization Multiplier: 0.8483935439230259\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.73it/s, loss=-0.000116, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:13:55,090] Trial 187 finished with value: -0.00011602447491095969 and parameters: {'learning_rate': 0.008889436328523518, 'sigma_multiplier': 1.214273343215771, 'num_layers': 2, 'initialization_multiplier': 0.8483935439230259}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 187 final loss: -0.00011602\n",
      "Trial 188:\n",
      "  Learning Rate: 0.006504982172105326\n",
      "  Sigma Multiplier: 1.255323755207514\n",
      "  Initialization Multiplier: 0.7674433762290169\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.87it/s, loss=-0.000363, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 13:14:06,261] Trial 188 finished with value: -0.00036341680938440025 and parameters: {'learning_rate': 0.006504982172105326, 'sigma_multiplier': 1.255323755207514, 'num_layers': 2, 'initialization_multiplier': 0.7674433762290169}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 188 final loss: -0.00036342\n",
      "Trial 189:\n",
      "  Learning Rate: 0.011679472332489638\n",
      "  Sigma Multiplier: 1.1801946879190761\n",
      "  Initialization Multiplier: 0.6696999069355639\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.02it/s, loss=-0.000292, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 13:14:17,278] Trial 189 finished with value: -0.00029175765464874197 and parameters: {'learning_rate': 0.011679472332489638, 'sigma_multiplier': 1.1801946879190761, 'num_layers': 2, 'initialization_multiplier': 0.6696999069355639}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 189 final loss: -0.00029176\n",
      "Trial 190:\n",
      "  Learning Rate: 0.00733633562369188\n",
      "  Sigma Multiplier: 1.2866560000891776\n",
      "  Initialization Multiplier: 0.6446408083415407\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.25it/s, loss=-0.000351, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 13:14:28,139] Trial 190 finished with value: -0.0003506040057640069 and parameters: {'learning_rate': 0.00733633562369188, 'sigma_multiplier': 1.2866560000891776, 'num_layers': 2, 'initialization_multiplier': 0.6446408083415407}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 190 final loss: -0.00035060\n",
      "Trial 191:\n",
      "  Learning Rate: 0.005528175231564317\n",
      "  Sigma Multiplier: 1.1016765508878625\n",
      "  Initialization Multiplier: 0.612943573851359\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.02it/s, loss=-0.000280, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 13:14:39,207] Trial 191 finished with value: -0.0002795022529801921 and parameters: {'learning_rate': 0.005528175231564317, 'sigma_multiplier': 1.1016765508878625, 'num_layers': 2, 'initialization_multiplier': 0.612943573851359}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 191 final loss: -0.00027950\n",
      "Trial 192:\n",
      "  Learning Rate: 0.00862264346308188\n",
      "  Sigma Multiplier: 1.2215855215007134\n",
      "  Initialization Multiplier: 0.7239625690958283\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.57it/s, loss=-0.000280, elapsed time=0.11, total time=17.8]\n",
      "[I 2025-06-07 13:14:57,138] Trial 192 finished with value: -0.00028041793839018097 and parameters: {'learning_rate': 0.00862264346308188, 'sigma_multiplier': 1.2215855215007134, 'num_layers': 5, 'initialization_multiplier': 0.7239625690958283}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 192 final loss: -0.00028042\n",
      "Trial 193:\n",
      "  Learning Rate: 0.0062811028216532006\n",
      "  Sigma Multiplier: 1.0305980939903663\n",
      "  Initialization Multiplier: 0.6134318841673971\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.34it/s, loss=-0.000289, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 13:15:08,732] Trial 193 finished with value: -0.00028877429145722847 and parameters: {'learning_rate': 0.0062811028216532006, 'sigma_multiplier': 1.0305980939903663, 'num_layers': 2, 'initialization_multiplier': 0.6134318841673971}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 193 final loss: -0.00028877\n",
      "Trial 194:\n",
      "  Learning Rate: 0.004236232336319594\n",
      "  Sigma Multiplier: 1.1614749753972544\n",
      "  Initialization Multiplier: 0.5774036691089092\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.07it/s, loss=-0.000334, elapsed time=0.09, total time=11.1]\n",
      "[I 2025-06-07 13:15:19,837] Trial 194 finished with value: -0.000333692404134574 and parameters: {'learning_rate': 0.004236232336319594, 'sigma_multiplier': 1.1614749753972544, 'num_layers': 2, 'initialization_multiplier': 0.5774036691089092}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 194 final loss: -0.00033369\n",
      "Trial 195:\n",
      "  Learning Rate: 0.005423841821505817\n",
      "  Sigma Multiplier: 1.9859869044658471\n",
      "  Initialization Multiplier: 0.6460586257230498\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.65it/s, loss=-0.000233, elapsed time=0.06, total time=9.9] \n",
      "[I 2025-06-07 13:15:29,780] Trial 195 finished with value: -0.0002326101478147409 and parameters: {'learning_rate': 0.005423841821505817, 'sigma_multiplier': 1.9859869044658471, 'num_layers': 2, 'initialization_multiplier': 0.6460586257230498}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 195 final loss: -0.00023261\n",
      "Trial 196:\n",
      "  Learning Rate: 0.007145790759620278\n",
      "  Sigma Multiplier: 0.9743911272710244\n",
      "  Initialization Multiplier: 0.6912045199089528\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000290, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 13:15:41,390] Trial 196 finished with value: -0.00028955444902170884 and parameters: {'learning_rate': 0.007145790759620278, 'sigma_multiplier': 0.9743911272710244, 'num_layers': 2, 'initialization_multiplier': 0.6912045199089528}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 196 final loss: -0.00028955\n",
      "Trial 197:\n",
      "  Learning Rate: 0.008339389949058468\n",
      "  Sigma Multiplier: 1.0848957238103771\n",
      "  Initialization Multiplier: 0.5438688329931908\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.86it/s, loss=-0.000446, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 13:15:52,634] Trial 197 finished with value: -0.00044607856217723806 and parameters: {'learning_rate': 0.008339389949058468, 'sigma_multiplier': 1.0848957238103771, 'num_layers': 2, 'initialization_multiplier': 0.5438688329931908}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 197 final loss: -0.00044608\n",
      "Trial 198:\n",
      "  Learning Rate: 0.008491681717536968\n",
      "  Sigma Multiplier: 0.9956651896514976\n",
      "  Initialization Multiplier: 0.5509204785532639\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.31it/s, loss=-0.000437, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:16:04,250] Trial 198 finished with value: -0.00043701791175349334 and parameters: {'learning_rate': 0.008491681717536968, 'sigma_multiplier': 0.9956651896514976, 'num_layers': 2, 'initialization_multiplier': 0.5509204785532639}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 198 final loss: -0.00043702\n",
      "Trial 199:\n",
      "  Learning Rate: 0.008449413871679749\n",
      "  Sigma Multiplier: 1.0592769008827303\n",
      "  Initialization Multiplier: 1.0138645042067145\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000200, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:16:15,894] Trial 199 finished with value: -0.0001997922953760184 and parameters: {'learning_rate': 0.008449413871679749, 'sigma_multiplier': 1.0592769008827303, 'num_layers': 2, 'initialization_multiplier': 1.0138645042067145}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 199 final loss: -0.00019979\n",
      "Trial 200:\n",
      "  Learning Rate: 0.011878755659679895\n",
      "  Sigma Multiplier: 1.0064182788391824\n",
      "  Initialization Multiplier: 0.5517090241934941\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.95it/s, loss=-0.000426, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:16:26,988] Trial 200 finished with value: -0.0004262872623524529 and parameters: {'learning_rate': 0.011878755659679895, 'sigma_multiplier': 1.0064182788391824, 'num_layers': 2, 'initialization_multiplier': 0.5517090241934941}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 200 final loss: -0.00042629\n",
      "Trial 201:\n",
      "  Learning Rate: 0.012066548886487784\n",
      "  Sigma Multiplier: 1.0072530173493368\n",
      "  Initialization Multiplier: 0.5689258981476302\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=-0.000372, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 13:16:38,313] Trial 201 finished with value: -0.0003715714626479868 and parameters: {'learning_rate': 0.012066548886487784, 'sigma_multiplier': 1.0072530173493368, 'num_layers': 2, 'initialization_multiplier': 0.5689258981476302}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 201 final loss: -0.00037157\n",
      "Trial 202:\n",
      "  Learning Rate: 0.015431302659860594\n",
      "  Sigma Multiplier: 1.1310479904626647\n",
      "  Initialization Multiplier: 0.532723699051992\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.16it/s, loss=-0.000306, elapsed time=0.07, total time=10.9]\n",
      "[I 2025-06-07 13:16:49,257] Trial 202 finished with value: -0.0003064069183508089 and parameters: {'learning_rate': 0.015431302659860594, 'sigma_multiplier': 1.1310479904626647, 'num_layers': 2, 'initialization_multiplier': 0.532723699051992}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 202 final loss: -0.00030641\n",
      "Trial 203:\n",
      "  Learning Rate: 0.008528603832340198\n",
      "  Sigma Multiplier: 1.0339159112353624\n",
      "  Initialization Multiplier: 0.5431990340830738\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.57it/s, loss=-0.000261, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:17:00,718] Trial 203 finished with value: -0.0002607175329729004 and parameters: {'learning_rate': 0.008528603832340198, 'sigma_multiplier': 1.0339159112353624, 'num_layers': 2, 'initialization_multiplier': 0.5431990340830738}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 203 final loss: -0.00026072\n",
      "Trial 204:\n",
      "  Learning Rate: 0.009930505750210162\n",
      "  Sigma Multiplier: 0.9893690868984302\n",
      "  Initialization Multiplier: 1.1283561512843818\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=0.000422, elapsed time=0.08, total time=11.5]\n",
      "[I 2025-06-07 13:17:12,228] Trial 204 finished with value: 0.0004215560255652815 and parameters: {'learning_rate': 0.009930505750210162, 'sigma_multiplier': 0.9893690868984302, 'num_layers': 2, 'initialization_multiplier': 1.1283561512843818}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 204 final loss: 0.00042156\n",
      "Trial 205:\n",
      "  Learning Rate: 0.00695098436080208\n",
      "  Sigma Multiplier: 1.0817934503054363\n",
      "  Initialization Multiplier: 0.4583925326068157\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.36it/s, loss=-0.000328, elapsed time=0.07, total time=10.7]\n",
      "[I 2025-06-07 13:17:22,976] Trial 205 finished with value: -0.00032817036698349174 and parameters: {'learning_rate': 0.00695098436080208, 'sigma_multiplier': 1.0817934503054363, 'num_layers': 2, 'initialization_multiplier': 0.4583925326068157}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 205 final loss: -0.00032817\n",
      "Trial 206:\n",
      "  Learning Rate: 0.012200603542799367\n",
      "  Sigma Multiplier: 1.1466446219874227\n",
      "  Initialization Multiplier: 1.6202193702529408\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.77it/s, loss=-0.000106, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:17:34,252] Trial 206 finished with value: -0.00010590239841997685 and parameters: {'learning_rate': 0.012200603542799367, 'sigma_multiplier': 1.1466446219874227, 'num_layers': 2, 'initialization_multiplier': 1.6202193702529408}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 206 final loss: -0.00010590\n",
      "Trial 207:\n",
      "  Learning Rate: 0.0076430758037775125\n",
      "  Sigma Multiplier: 0.9525862391107832\n",
      "  Initialization Multiplier: 0.526426405350286\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000377, elapsed time=0.14, total time=11.2]\n",
      "[I 2025-06-07 13:17:45,516] Trial 207 finished with value: -0.00037682267643539144 and parameters: {'learning_rate': 0.0076430758037775125, 'sigma_multiplier': 0.9525862391107832, 'num_layers': 2, 'initialization_multiplier': 0.526426405350286}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 207 final loss: -0.00037682\n",
      "Trial 208:\n",
      "  Learning Rate: 0.008826102799157194\n",
      "  Sigma Multiplier: 1.034536989634885\n",
      "  Initialization Multiplier: 0.5931277143742403\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.96it/s, loss=-0.000335, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 13:17:56,600] Trial 208 finished with value: -0.0003354884960004625 and parameters: {'learning_rate': 0.008826102799157194, 'sigma_multiplier': 1.034536989634885, 'num_layers': 2, 'initialization_multiplier': 0.5931277143742403}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 208 final loss: -0.00033549\n",
      "Trial 209:\n",
      "  Learning Rate: 0.004742225910577647\n",
      "  Sigma Multiplier: 1.1085811659968985\n",
      "  Initialization Multiplier: 0.5693116153474013\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.11it/s, loss=-0.000268, elapsed time=0.07, total time=10.8]\n",
      "[I 2025-06-07 13:18:07,501] Trial 209 finished with value: -0.0002680093399395446 and parameters: {'learning_rate': 0.004742225910577647, 'sigma_multiplier': 1.1085811659968985, 'num_layers': 2, 'initialization_multiplier': 0.5693116153474013}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 209 final loss: -0.00026801\n",
      "Trial 210:\n",
      "  Learning Rate: 0.006424437614391984\n",
      "  Sigma Multiplier: 1.206553887604692\n",
      "  Initialization Multiplier: 0.9477844373102983\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.82it/s, loss=-0.000234, elapsed time=0.04, total time=11.2]\n",
      "[I 2025-06-07 13:18:18,717] Trial 210 finished with value: -0.0002337712508175193 and parameters: {'learning_rate': 0.006424437614391984, 'sigma_multiplier': 1.206553887604692, 'num_layers': 2, 'initialization_multiplier': 0.9477844373102983}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 210 final loss: -0.00023377\n",
      "Trial 211:\n",
      "  Learning Rate: 0.010751270385683779\n",
      "  Sigma Multiplier: 0.9907053389230194\n",
      "  Initialization Multiplier: 0.6442527985131975\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.20it/s, loss=-0.000213, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:18:30,405] Trial 211 finished with value: -0.00021288913249006502 and parameters: {'learning_rate': 0.010751270385683779, 'sigma_multiplier': 0.9907053389230194, 'num_layers': 2, 'initialization_multiplier': 0.6442527985131975}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 211 final loss: -0.00021289\n",
      "Trial 212:\n",
      "  Learning Rate: 0.01394617340085623\n",
      "  Sigma Multiplier: 0.9503166793714445\n",
      "  Initialization Multiplier: 0.5043476434804055\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000293, elapsed time=0.09, total time=11.5]\n",
      "[I 2025-06-07 13:18:41,921] Trial 212 finished with value: -0.0002928384411379973 and parameters: {'learning_rate': 0.01394617340085623, 'sigma_multiplier': 0.9503166793714445, 'num_layers': 2, 'initialization_multiplier': 0.5043476434804055}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 212 final loss: -0.00029284\n",
      "Trial 213:\n",
      "  Learning Rate: 0.010104897416904105\n",
      "  Sigma Multiplier: 1.0627232875453234\n",
      "  Initialization Multiplier: 0.42710034128929286\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.23it/s, loss=-0.000287, elapsed time=0.08, total time=10.9]\n",
      "[I 2025-06-07 13:18:52,868] Trial 213 finished with value: -0.0002870356027815798 and parameters: {'learning_rate': 0.010104897416904105, 'sigma_multiplier': 1.0627232875453234, 'num_layers': 2, 'initialization_multiplier': 0.42710034128929286}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 213 final loss: -0.00028704\n",
      "Trial 214:\n",
      "  Learning Rate: 0.007812963849720021\n",
      "  Sigma Multiplier: 0.90654161871217\n",
      "  Initialization Multiplier: 1.7985914541015084\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.82it/s, loss=-0.000027, elapsed time=0.08, total time=12]  \n",
      "[I 2025-06-07 13:19:04,904] Trial 214 finished with value: -2.733418022073179e-05 and parameters: {'learning_rate': 0.007812963849720021, 'sigma_multiplier': 0.90654161871217, 'num_layers': 2, 'initialization_multiplier': 1.7985914541015084}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 214 final loss: -0.00002733\n",
      "Trial 215:\n",
      "  Learning Rate: 0.009772449247521083\n",
      "  Sigma Multiplier: 0.9868798306329232\n",
      "  Initialization Multiplier: 0.5976150064465336\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.08it/s, loss=-0.000376, elapsed time=0.07, total time=10.9]\n",
      "[I 2025-06-07 13:19:15,893] Trial 215 finished with value: -0.00037553342305905713 and parameters: {'learning_rate': 0.009772449247521083, 'sigma_multiplier': 0.9868798306329232, 'num_layers': 2, 'initialization_multiplier': 0.5976150064465336}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 215 final loss: -0.00037553\n",
      "Trial 216:\n",
      "  Learning Rate: 0.01225409082770821\n",
      "  Sigma Multiplier: 1.0156457215292087\n",
      "  Initialization Multiplier: 0.5516675697286407\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.06it/s, loss=-0.000356, elapsed time=0.08, total time=10.9]\n",
      "[I 2025-06-07 13:19:26,875] Trial 216 finished with value: -0.00035557505657559264 and parameters: {'learning_rate': 0.01225409082770821, 'sigma_multiplier': 1.0156457215292087, 'num_layers': 2, 'initialization_multiplier': 0.5516675697286407}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 216 final loss: -0.00035558\n",
      "Trial 217:\n",
      "  Learning Rate: 0.006716101331774957\n",
      "  Sigma Multiplier: 1.0874095663643137\n",
      "  Initialization Multiplier: 0.6735300170209555\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.50it/s, loss=-0.000374, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 13:19:39,218] Trial 217 finished with value: -0.00037353473112654024 and parameters: {'learning_rate': 0.006716101331774957, 'sigma_multiplier': 1.0874095663643137, 'num_layers': 2, 'initialization_multiplier': 0.6735300170209555}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 217 final loss: -0.00037353\n",
      "Trial 218:\n",
      "  Learning Rate: 0.005506893160409773\n",
      "  Sigma Multiplier: 0.9466171790508833\n",
      "  Initialization Multiplier: 0.2373984993394417\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.29it/s, loss=-0.000112, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:19:50,822] Trial 218 finished with value: -0.00011172629652882929 and parameters: {'learning_rate': 0.005506893160409773, 'sigma_multiplier': 0.9466171790508833, 'num_layers': 2, 'initialization_multiplier': 0.2373984993394417}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 218 final loss: -0.00011173\n",
      "Trial 219:\n",
      "  Learning Rate: 0.008913190847400318\n",
      "  Sigma Multiplier: 1.1616881014734803\n",
      "  Initialization Multiplier: 0.48052909636928604\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.16it/s, loss=-0.000378, elapsed time=0.08, total time=10.9]\n",
      "[I 2025-06-07 13:20:01,769] Trial 219 finished with value: -0.00037838688960205145 and parameters: {'learning_rate': 0.008913190847400318, 'sigma_multiplier': 1.1616881014734803, 'num_layers': 2, 'initialization_multiplier': 0.48052909636928604}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 219 final loss: -0.00037839\n",
      "Trial 220:\n",
      "  Learning Rate: 0.007284557458866054\n",
      "  Sigma Multiplier: 1.0354519354197165\n",
      "  Initialization Multiplier: 0.7448095397872533\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.90it/s, loss=-0.000168, elapsed time=0.09, total time=11.1]\n",
      "[I 2025-06-07 13:20:12,890] Trial 220 finished with value: -0.0001680204690573719 and parameters: {'learning_rate': 0.007284557458866054, 'sigma_multiplier': 1.0354519354197165, 'num_layers': 2, 'initialization_multiplier': 0.7448095397872533}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 220 final loss: -0.00016802\n",
      "Trial 221:\n",
      "  Learning Rate: 0.005759636654486016\n",
      "  Sigma Multiplier: 1.1227801994879762\n",
      "  Initialization Multiplier: 0.6101947776740495\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.48it/s, loss=-0.000366, elapsed time=0.06, total time=10.6]\n",
      "[I 2025-06-07 13:20:23,602] Trial 221 finished with value: -0.00036601321459305957 and parameters: {'learning_rate': 0.005759636654486016, 'sigma_multiplier': 1.1227801994879762, 'num_layers': 2, 'initialization_multiplier': 0.6101947776740495}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 221 final loss: -0.00036601\n",
      "Trial 222:\n",
      "  Learning Rate: 0.005965173172629259\n",
      "  Sigma Multiplier: 1.0767034453287452\n",
      "  Initialization Multiplier: 0.6269730564129321\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.97it/s, loss=-0.000416, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 13:20:34,725] Trial 222 finished with value: -0.0004159762689535751 and parameters: {'learning_rate': 0.005965173172629259, 'sigma_multiplier': 1.0767034453287452, 'num_layers': 2, 'initialization_multiplier': 0.6269730564129321}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 222 final loss: -0.00041598\n",
      "Trial 223:\n",
      "  Learning Rate: 0.00488094097880744\n",
      "  Sigma Multiplier: 1.087775712448107\n",
      "  Initialization Multiplier: 0.6452937890096035\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.50it/s, loss=-0.000344, elapsed time=0.09, total time=10.6]\n",
      "[I 2025-06-07 13:20:45,383] Trial 223 finished with value: -0.00034380482842155246 and parameters: {'learning_rate': 0.00488094097880744, 'sigma_multiplier': 1.087775712448107, 'num_layers': 2, 'initialization_multiplier': 0.6452937890096035}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 223 final loss: -0.00034380\n",
      "Trial 224:\n",
      "  Learning Rate: 0.0036618364181504946\n",
      "  Sigma Multiplier: 1.0585278643898808\n",
      "  Initialization Multiplier: 0.5186551970555112\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.27it/s, loss=-0.000341, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 13:20:56,260] Trial 224 finished with value: -0.0003408068374121803 and parameters: {'learning_rate': 0.0036618364181504946, 'sigma_multiplier': 1.0585278643898808, 'num_layers': 2, 'initialization_multiplier': 0.5186551970555112}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 224 final loss: -0.00034081\n",
      "Trial 225:\n",
      "  Learning Rate: 0.006390061164351219\n",
      "  Sigma Multiplier: 1.0005409945296515\n",
      "  Initialization Multiplier: 0.5662782953305112\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000388, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 13:21:07,582] Trial 225 finished with value: -0.0003883680789697001 and parameters: {'learning_rate': 0.006390061164351219, 'sigma_multiplier': 1.0005409945296515, 'num_layers': 2, 'initialization_multiplier': 0.5662782953305112}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 225 final loss: -0.00038837\n",
      "Trial 226:\n",
      "  Learning Rate: 3.878946483012222e-05\n",
      "  Sigma Multiplier: 1.1905359088849243\n",
      "  Initialization Multiplier: 0.6938601473402894\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.62it/s, loss=0.087551, elapsed time=0.06, total time=10.5]\n",
      "[I 2025-06-07 13:21:18,134] Trial 226 finished with value: 0.08755121520992501 and parameters: {'learning_rate': 3.878946483012222e-05, 'sigma_multiplier': 1.1905359088849243, 'num_layers': 2, 'initialization_multiplier': 0.6938601473402894}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 226 final loss: 0.08755122\n",
      "Trial 227:\n",
      "  Learning Rate: 0.011129102535710735\n",
      "  Sigma Multiplier: 1.130072395458976\n",
      "  Initialization Multiplier: 0.6313089060545966\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.60it/s, loss=-0.000304, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 13:21:28,855] Trial 227 finished with value: -0.0003041932940233681 and parameters: {'learning_rate': 0.011129102535710735, 'sigma_multiplier': 1.130072395458976, 'num_layers': 2, 'initialization_multiplier': 0.6313089060545966}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 227 final loss: -0.00030419\n",
      "Trial 228:\n",
      "  Learning Rate: 0.007557069819615291\n",
      "  Sigma Multiplier: 0.9735397012130388\n",
      "  Initialization Multiplier: 0.5371262418926869\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.83it/s, loss=-0.000354, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 13:21:40,002] Trial 228 finished with value: -0.0003543653109957008 and parameters: {'learning_rate': 0.007557069819615291, 'sigma_multiplier': 0.9735397012130388, 'num_layers': 2, 'initialization_multiplier': 0.5371262418926869}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 228 final loss: -0.00035437\n",
      "Trial 229:\n",
      "  Learning Rate: 0.008744453557970957\n",
      "  Sigma Multiplier: 1.0668906668068443\n",
      "  Initialization Multiplier: 0.3873586169196638\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.89it/s, loss=-0.000295, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:21:51,117] Trial 229 finished with value: -0.00029514916121762516 and parameters: {'learning_rate': 0.008744453557970957, 'sigma_multiplier': 1.0668906668068443, 'num_layers': 2, 'initialization_multiplier': 0.3873586169196638}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 229 final loss: -0.00029515\n",
      "Trial 230:\n",
      "  Learning Rate: 0.0007870749996047186\n",
      "  Sigma Multiplier: 1.2342098067840657\n",
      "  Initialization Multiplier: 0.44779147988055623\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.67it/s, loss=0.001046, elapsed time=0.04, total time=10.6]\n",
      "[I 2025-06-07 13:22:01,708] Trial 230 finished with value: 0.0010455628259859076 and parameters: {'learning_rate': 0.0007870749996047186, 'sigma_multiplier': 1.2342098067840657, 'num_layers': 2, 'initialization_multiplier': 0.44779147988055623}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 230 final loss: 0.00104556\n",
      "Trial 231:\n",
      "  Learning Rate: 0.005986049238021355\n",
      "  Sigma Multiplier: 1.1053705641919385\n",
      "  Initialization Multiplier: 0.6071498295522044\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.63it/s, loss=-0.000375, elapsed time=0.09, total time=10.5]\n",
      "[I 2025-06-07 13:22:12,293] Trial 231 finished with value: -0.0003746464019260158 and parameters: {'learning_rate': 0.005986049238021355, 'sigma_multiplier': 1.1053705641919385, 'num_layers': 2, 'initialization_multiplier': 0.6071498295522044}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 231 final loss: -0.00037465\n",
      "Trial 232:\n",
      "  Learning Rate: 0.005348784232810031\n",
      "  Sigma Multiplier: 1.024920544726456\n",
      "  Initialization Multiplier: 0.5834954696566619\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.32it/s, loss=-0.000399, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 13:22:23,111] Trial 232 finished with value: -0.0003994558979765931 and parameters: {'learning_rate': 0.005348784232810031, 'sigma_multiplier': 1.024920544726456, 'num_layers': 2, 'initialization_multiplier': 0.5834954696566619}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 232 final loss: -0.00039946\n",
      "Trial 233:\n",
      "  Learning Rate: 0.004256107704759759\n",
      "  Sigma Multiplier: 1.0259863643929723\n",
      "  Initialization Multiplier: 0.5648051683758875\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000341, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 13:22:33,896] Trial 233 finished with value: -0.000340506072787678 and parameters: {'learning_rate': 0.004256107704759759, 'sigma_multiplier': 1.0259863643929723, 'num_layers': 2, 'initialization_multiplier': 0.5648051683758875}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 233 final loss: -0.00034051\n",
      "Trial 234:\n",
      "  Learning Rate: 0.005122987341041256\n",
      "  Sigma Multiplier: 0.950593573354374\n",
      "  Initialization Multiplier: 0.48990549137878603\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.90it/s, loss=-0.000180, elapsed time=0.12, total time=15.5]\n",
      "[I 2025-06-07 13:22:49,417] Trial 234 finished with value: -0.00018024195836010884 and parameters: {'learning_rate': 0.005122987341041256, 'sigma_multiplier': 0.950593573354374, 'num_layers': 4, 'initialization_multiplier': 0.48990549137878603}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 234 final loss: -0.00018024\n",
      "Trial 235:\n",
      "  Learning Rate: 0.006873157650005984\n",
      "  Sigma Multiplier: 1.0129778634837194\n",
      "  Initialization Multiplier: 0.5906780061308203\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.84it/s, loss=-0.000454, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 13:23:00,639] Trial 235 finished with value: -0.00045390477909667073 and parameters: {'learning_rate': 0.006873157650005984, 'sigma_multiplier': 1.0129778634837194, 'num_layers': 2, 'initialization_multiplier': 0.5906780061308203}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 235 final loss: -0.00045390\n",
      "Trial 236:\n",
      "  Learning Rate: 0.00651697994728767\n",
      "  Sigma Multiplier: 1.0465996198972625\n",
      "  Initialization Multiplier: 0.5257236770531876\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.27it/s, loss=-0.000299, elapsed time=0.07, total time=10.8]\n",
      "[I 2025-06-07 13:23:11,469] Trial 236 finished with value: -0.000299129213226956 and parameters: {'learning_rate': 0.00651697994728767, 'sigma_multiplier': 1.0465996198972625, 'num_layers': 2, 'initialization_multiplier': 0.5257236770531876}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 236 final loss: -0.00029913\n",
      "Trial 237:\n",
      "  Learning Rate: 0.005095704297765655\n",
      "  Sigma Multiplier: 1.019142041647709\n",
      "  Initialization Multiplier: 0.5797367983798287\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.99it/s, loss=-0.000323, elapsed time=0.07, total time=11]  \n",
      "[I 2025-06-07 13:23:22,530] Trial 237 finished with value: -0.00032301255057094405 and parameters: {'learning_rate': 0.005095704297765655, 'sigma_multiplier': 1.019142041647709, 'num_layers': 2, 'initialization_multiplier': 0.5797367983798287}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 237 final loss: -0.00032301\n",
      "Trial 238:\n",
      "  Learning Rate: 0.007529491572762352\n",
      "  Sigma Multiplier: 1.1506871838378898\n",
      "  Initialization Multiplier: 0.47932838261864874\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.65it/s, loss=-0.000349, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 13:23:33,123] Trial 238 finished with value: -0.00034865623782749644 and parameters: {'learning_rate': 0.007529491572762352, 'sigma_multiplier': 1.1506871838378898, 'num_layers': 2, 'initialization_multiplier': 0.47932838261864874}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 238 final loss: -0.00034866\n",
      "Trial 239:\n",
      "  Learning Rate: 0.003189724377238389\n",
      "  Sigma Multiplier: 1.0753734044195282\n",
      "  Initialization Multiplier: 0.5409869878097376\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.30it/s, loss=-0.000333, elapsed time=0.08, total time=10.7]\n",
      "[I 2025-06-07 13:23:43,905] Trial 239 finished with value: -0.0003333460644663744 and parameters: {'learning_rate': 0.003189724377238389, 'sigma_multiplier': 1.0753734044195282, 'num_layers': 2, 'initialization_multiplier': 0.5409869878097376}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 239 final loss: -0.00033335\n",
      "Trial 240:\n",
      "  Learning Rate: 0.005777990608041618\n",
      "  Sigma Multiplier: 0.9995331829771734\n",
      "  Initialization Multiplier: 0.5852970388101252\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.93it/s, loss=-0.000397, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:23:55,030] Trial 240 finished with value: -0.00039724166568028124 and parameters: {'learning_rate': 0.005777990608041618, 'sigma_multiplier': 0.9995331829771734, 'num_layers': 2, 'initialization_multiplier': 0.5852970388101252}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 240 final loss: -0.00039724\n",
      "Trial 241:\n",
      "  Learning Rate: 0.0058217521968834665\n",
      "  Sigma Multiplier: 1.0142481747022651\n",
      "  Initialization Multiplier: 0.6137793893910904\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.63it/s, loss=-0.000383, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:24:06,366] Trial 241 finished with value: -0.00038265231202042706 and parameters: {'learning_rate': 0.0058217521968834665, 'sigma_multiplier': 1.0142481747022651, 'num_layers': 2, 'initialization_multiplier': 0.6137793893910904}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 241 final loss: -0.00038265\n",
      "Trial 242:\n",
      "  Learning Rate: 0.006737410101083146\n",
      "  Sigma Multiplier: 0.9791871007641735\n",
      "  Initialization Multiplier: 0.5878082358110831\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000418, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:24:17,749] Trial 242 finished with value: -0.000418100105615412 and parameters: {'learning_rate': 0.006737410101083146, 'sigma_multiplier': 0.9791871007641735, 'num_layers': 2, 'initialization_multiplier': 0.5878082358110831}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 242 final loss: -0.00041810\n",
      "Trial 243:\n",
      "  Learning Rate: 0.007035835655807569\n",
      "  Sigma Multiplier: 0.9847343790281882\n",
      "  Initialization Multiplier: 0.559262418849808\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.24it/s, loss=-0.000399, elapsed time=0.07, total time=10.9]\n",
      "[I 2025-06-07 13:24:28,688] Trial 243 finished with value: -0.0003991283913807845 and parameters: {'learning_rate': 0.007035835655807569, 'sigma_multiplier': 0.9847343790281882, 'num_layers': 2, 'initialization_multiplier': 0.559262418849808}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 243 final loss: -0.00039913\n",
      "Trial 244:\n",
      "  Learning Rate: 0.0065794599669950484\n",
      "  Sigma Multiplier: 0.910534413361954\n",
      "  Initialization Multiplier: 0.5800003033641263\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.13it/s, loss=-0.000381, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 13:24:39,670] Trial 244 finished with value: -0.00038068454275010316 and parameters: {'learning_rate': 0.0065794599669950484, 'sigma_multiplier': 0.910534413361954, 'num_layers': 2, 'initialization_multiplier': 0.5800003033641263}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 244 final loss: -0.00038068\n",
      "Trial 245:\n",
      "  Learning Rate: 0.007641561190867256\n",
      "  Sigma Multiplier: 0.9803756807474611\n",
      "  Initialization Multiplier: 0.5760341801254858\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.99it/s, loss=-0.000372, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 13:24:50,851] Trial 245 finished with value: -0.0003715268544496445 and parameters: {'learning_rate': 0.007641561190867256, 'sigma_multiplier': 0.9803756807474611, 'num_layers': 2, 'initialization_multiplier': 0.5760341801254858}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 245 final loss: -0.00037153\n",
      "Trial 246:\n",
      "  Learning Rate: 0.006660243633033271\n",
      "  Sigma Multiplier: 0.9396286809284574\n",
      "  Initialization Multiplier: 1.2150659340792045\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.74it/s, loss=0.000444, elapsed time=0.05, total time=11.2] \n",
      "[I 2025-06-07 13:25:02,094] Trial 246 finished with value: 0.0004435035949501502 and parameters: {'learning_rate': 0.006660243633033271, 'sigma_multiplier': 0.9396286809284574, 'num_layers': 2, 'initialization_multiplier': 1.2150659340792045}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 246 final loss: 0.00044350\n",
      "Trial 247:\n",
      "  Learning Rate: 0.008423976674902287\n",
      "  Sigma Multiplier: 0.9876375960234558\n",
      "  Initialization Multiplier: 0.5413194661821406\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.92it/s, loss=-0.000280, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:25:13,296] Trial 247 finished with value: -0.0002797478572675277 and parameters: {'learning_rate': 0.008423976674902287, 'sigma_multiplier': 0.9876375960234558, 'num_layers': 2, 'initialization_multiplier': 0.5413194661821406}. Best is trial 144 with value: -0.0004832216293692365.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 247 final loss: -0.00027975\n",
      "Trial 248:\n",
      "  Learning Rate: 0.006115521401940773\n",
      "  Sigma Multiplier: 1.0372657813112909\n",
      "  Initialization Multiplier: 0.6303388864180629\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.43it/s, loss=-0.000488, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 13:25:24,059] Trial 248 finished with value: -0.00048807768206494604 and parameters: {'learning_rate': 0.006115521401940773, 'sigma_multiplier': 1.0372657813112909, 'num_layers': 2, 'initialization_multiplier': 0.6303388864180629}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 248 final loss: -0.00048808\n",
      "Trial 249:\n",
      "  Learning Rate: 0.005669119829837811\n",
      "  Sigma Multiplier: 1.0399595149107632\n",
      "  Initialization Multiplier: 0.6246829541028147\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.61it/s, loss=-0.000277, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 13:25:34,653] Trial 249 finished with value: -0.0002773894884644938 and parameters: {'learning_rate': 0.005669119829837811, 'sigma_multiplier': 1.0399595149107632, 'num_layers': 2, 'initialization_multiplier': 0.6246829541028147}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 249 final loss: -0.00027739\n",
      "Trial 250:\n",
      "  Learning Rate: 0.007767705644383626\n",
      "  Sigma Multiplier: 0.9607634297131635\n",
      "  Initialization Multiplier: 0.5058929897175716\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.92it/s, loss=-0.000329, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 13:25:45,714] Trial 250 finished with value: -0.0003286362539927799 and parameters: {'learning_rate': 0.007767705644383626, 'sigma_multiplier': 0.9607634297131635, 'num_layers': 2, 'initialization_multiplier': 0.5058929897175716}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 250 final loss: -0.00032864\n",
      "Trial 251:\n",
      "  Learning Rate: 0.004564876069118525\n",
      "  Sigma Multiplier: 0.8837442597286553\n",
      "  Initialization Multiplier: 0.6124394191832504\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000290, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:25:57,003] Trial 251 finished with value: -0.00029001275263896014 and parameters: {'learning_rate': 0.004564876069118525, 'sigma_multiplier': 0.8837442597286553, 'num_layers': 2, 'initialization_multiplier': 0.6124394191832504}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 251 final loss: -0.00029001\n",
      "Trial 252:\n",
      "  Learning Rate: 0.005721130293227835\n",
      "  Sigma Multiplier: 1.0028802960230374\n",
      "  Initialization Multiplier: 0.5625438760186096\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.82it/s, loss=-0.000389, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:26:08,185] Trial 252 finished with value: -0.0003886095663439726 and parameters: {'learning_rate': 0.005721130293227835, 'sigma_multiplier': 1.0028802960230374, 'num_layers': 2, 'initialization_multiplier': 0.5625438760186096}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 252 final loss: -0.00038861\n",
      "Trial 253:\n",
      "  Learning Rate: 0.008462646349191985\n",
      "  Sigma Multiplier: 1.0613766205175914\n",
      "  Initialization Multiplier: 0.5132901066851221\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.34it/s, loss=-0.000351, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 13:26:18,942] Trial 253 finished with value: -0.0003510977216997988 and parameters: {'learning_rate': 0.008462646349191985, 'sigma_multiplier': 1.0613766205175914, 'num_layers': 2, 'initialization_multiplier': 0.5132901066851221}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 253 final loss: -0.00035110\n",
      "Trial 254:\n",
      "  Learning Rate: 0.0070183727478094985\n",
      "  Sigma Multiplier: 0.9256855799836837\n",
      "  Initialization Multiplier: 0.6618419649871392\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000253, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:26:30,366] Trial 254 finished with value: -0.0002532434599608375 and parameters: {'learning_rate': 0.0070183727478094985, 'sigma_multiplier': 0.9256855799836837, 'num_layers': 2, 'initialization_multiplier': 0.6618419649871392}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 254 final loss: -0.00025324\n",
      "Trial 255:\n",
      "  Learning Rate: 0.00427874702167369\n",
      "  Sigma Multiplier: 0.9841030632353156\n",
      "  Initialization Multiplier: 0.5906512941786298\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.02it/s, loss=-0.000435, elapsed time=0.08, total time=11]  \n",
      "[I 2025-06-07 13:26:41,428] Trial 255 finished with value: -0.00043542575235684216 and parameters: {'learning_rate': 0.00427874702167369, 'sigma_multiplier': 0.9841030632353156, 'num_layers': 2, 'initialization_multiplier': 0.5906512941786298}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 255 final loss: -0.00043543\n",
      "Trial 256:\n",
      "  Learning Rate: 0.0037240818106825738\n",
      "  Sigma Multiplier: 0.9773307943739642\n",
      "  Initialization Multiplier: 0.5918904898331159\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.96it/s, loss=-0.000385, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:26:52,570] Trial 256 finished with value: -0.00038525618440658446 and parameters: {'learning_rate': 0.0037240818106825738, 'sigma_multiplier': 0.9773307943739642, 'num_layers': 2, 'initialization_multiplier': 0.5918904898331159}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 256 final loss: -0.00038526\n",
      "Trial 257:\n",
      "  Learning Rate: 0.004200251453838286\n",
      "  Sigma Multiplier: 1.0321112265125987\n",
      "  Initialization Multiplier: 0.5328963977556822\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.82it/s, loss=-0.000328, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:27:03,763] Trial 257 finished with value: -0.000327580343279115 and parameters: {'learning_rate': 0.004200251453838286, 'sigma_multiplier': 1.0321112265125987, 'num_layers': 2, 'initialization_multiplier': 0.5328963977556822}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 257 final loss: -0.00032758\n",
      "Trial 258:\n",
      "  Learning Rate: 0.0024509382390352414\n",
      "  Sigma Multiplier: 0.9262303901576227\n",
      "  Initialization Multiplier: 0.4753499438054207\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.88it/s, loss=-0.000311, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 13:27:14,929] Trial 258 finished with value: -0.0003107603051073278 and parameters: {'learning_rate': 0.0024509382390352414, 'sigma_multiplier': 0.9262303901576227, 'num_layers': 2, 'initialization_multiplier': 0.4753499438054207}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 258 final loss: -0.00031076\n",
      "Trial 259:\n",
      "  Learning Rate: 0.004342949145779358\n",
      "  Sigma Multiplier: 0.9955944441843484\n",
      "  Initialization Multiplier: 0.5781255736705601\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.65it/s, loss=-0.000278, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 13:27:25,535] Trial 259 finished with value: -0.00027834886209842345 and parameters: {'learning_rate': 0.004342949145779358, 'sigma_multiplier': 0.9955944441843484, 'num_layers': 2, 'initialization_multiplier': 0.5781255736705601}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 259 final loss: -0.00027835\n",
      "Trial 260:\n",
      "  Learning Rate: 0.005270852344448388\n",
      "  Sigma Multiplier: 1.076965287454277\n",
      "  Initialization Multiplier: 0.5410191937305875\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.26it/s, loss=-0.000406, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 13:27:36,378] Trial 260 finished with value: -0.0004056636938531413 and parameters: {'learning_rate': 0.005270852344448388, 'sigma_multiplier': 1.076965287454277, 'num_layers': 2, 'initialization_multiplier': 0.5410191937305875}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 260 final loss: -0.00040566\n",
      "Trial 261:\n",
      "  Learning Rate: 0.005479509468431397\n",
      "  Sigma Multiplier: 1.0642528381651901\n",
      "  Initialization Multiplier: 0.1706137341538726\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.67it/s, loss=-0.000197, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 13:27:47,773] Trial 261 finished with value: -0.00019676519405722838 and parameters: {'learning_rate': 0.005479509468431397, 'sigma_multiplier': 1.0642528381651901, 'num_layers': 2, 'initialization_multiplier': 0.1706137341538726}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 261 final loss: -0.00019677\n",
      "Trial 262:\n",
      "  Learning Rate: 0.009628995475985192\n",
      "  Sigma Multiplier: 1.0237632078957208\n",
      "  Initialization Multiplier: 0.541964047821514\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000378, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 13:27:59,037] Trial 262 finished with value: -0.00037825118159163785 and parameters: {'learning_rate': 0.009628995475985192, 'sigma_multiplier': 1.0237632078957208, 'num_layers': 2, 'initialization_multiplier': 0.541964047821514}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 262 final loss: -0.00037825\n",
      "Trial 263:\n",
      "  Learning Rate: 0.004835365054533338\n",
      "  Sigma Multiplier: 0.9620657254526711\n",
      "  Initialization Multiplier: 0.4513771854899191\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.12it/s, loss=-0.000185, elapsed time=0.06, total time=12.7]\n",
      "[I 2025-06-07 13:28:11,739] Trial 263 finished with value: -0.0001854557760886044 and parameters: {'learning_rate': 0.004835365054533338, 'sigma_multiplier': 0.9620657254526711, 'num_layers': 2, 'initialization_multiplier': 0.4513771854899191}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 263 final loss: -0.00018546\n",
      "Trial 264:\n",
      "  Learning Rate: 0.015173325254846437\n",
      "  Sigma Multiplier: 1.0808639348730085\n",
      "  Initialization Multiplier: 0.508233492537115\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.17it/s, loss=-0.000341, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 13:28:22,695] Trial 264 finished with value: -0.0003409178490082463 and parameters: {'learning_rate': 0.015173325254846437, 'sigma_multiplier': 1.0808639348730085, 'num_layers': 2, 'initialization_multiplier': 0.508233492537115}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 264 final loss: -0.00034092\n",
      "Trial 265:\n",
      "  Learning Rate: 0.003466345733719817\n",
      "  Sigma Multiplier: 1.040749941887684\n",
      "  Initialization Multiplier: 0.5786262368511889\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.25it/s, loss=-0.000158, elapsed time=0.09, total time=10.1]\n",
      "[I 2025-06-07 13:28:32,849] Trial 265 finished with value: -0.0001575962085643238 and parameters: {'learning_rate': 0.003466345733719817, 'sigma_multiplier': 1.040749941887684, 'num_layers': 1, 'initialization_multiplier': 0.5786262368511889}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 265 final loss: -0.00015760\n",
      "Trial 266:\n",
      "  Learning Rate: 0.006011573965309302\n",
      "  Sigma Multiplier: 1.0005887603754553\n",
      "  Initialization Multiplier: 0.49197443198397883\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.42it/s, loss=-0.000304, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 13:28:45,454] Trial 266 finished with value: -0.00030392933786873113 and parameters: {'learning_rate': 0.006011573965309302, 'sigma_multiplier': 1.0005887603754553, 'num_layers': 2, 'initialization_multiplier': 0.49197443198397883}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 266 final loss: -0.00030393\n",
      "Trial 267:\n",
      "  Learning Rate: 0.007899483867633844\n",
      "  Sigma Multiplier: 0.9050558561246669\n",
      "  Initialization Multiplier: 0.5471660322016412\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.95it/s, loss=-0.000347, elapsed time=0.08, total time=11.8]\n",
      "[I 2025-06-07 13:28:57,336] Trial 267 finished with value: -0.0003474931795089552 and parameters: {'learning_rate': 0.007899483867633844, 'sigma_multiplier': 0.9050558561246669, 'num_layers': 2, 'initialization_multiplier': 0.5471660322016412}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 267 final loss: -0.00034749\n",
      "Trial 268:\n",
      "  Learning Rate: 0.009095058270432606\n",
      "  Sigma Multiplier: 0.13416816713254454\n",
      "  Initialization Multiplier: 0.2628174748990039\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.26it/s, loss=0.000116, elapsed time=0.08, total time=14.9] \n",
      "[I 2025-06-07 13:29:12,254] Trial 268 finished with value: 0.00011611943379210081 and parameters: {'learning_rate': 0.009095058270432606, 'sigma_multiplier': 0.13416816713254454, 'num_layers': 2, 'initialization_multiplier': 0.2628174748990039}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 268 final loss: 0.00011612\n",
      "Trial 269:\n",
      "  Learning Rate: 0.011729767303117316\n",
      "  Sigma Multiplier: 1.0985005546471163\n",
      "  Initialization Multiplier: 0.6064166029936988\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.23it/s, loss=-0.000342, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 13:29:23,126] Trial 269 finished with value: -0.00034199222201224014 and parameters: {'learning_rate': 0.011729767303117316, 'sigma_multiplier': 1.0985005546471163, 'num_layers': 2, 'initialization_multiplier': 0.6064166029936988}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 269 final loss: -0.00034199\n",
      "Trial 270:\n",
      "  Learning Rate: 0.004122197309750497\n",
      "  Sigma Multiplier: 0.9848116657385433\n",
      "  Initialization Multiplier: 0.4428914529228196\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000351, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:29:34,668] Trial 270 finished with value: -0.0003509210185259587 and parameters: {'learning_rate': 0.004122197309750497, 'sigma_multiplier': 0.9848116657385433, 'num_layers': 2, 'initialization_multiplier': 0.4428914529228196}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 270 final loss: -0.00035092\n",
      "Trial 271:\n",
      "  Learning Rate: 0.0064395671663778405\n",
      "  Sigma Multiplier: 0.8577146256837176\n",
      "  Initialization Multiplier: 0.5197209075693829\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.17it/s, loss=-0.000279, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:29:46,366] Trial 271 finished with value: -0.00027918755845849675 and parameters: {'learning_rate': 0.0064395671663778405, 'sigma_multiplier': 0.8577146256837176, 'num_layers': 2, 'initialization_multiplier': 0.5197209075693829}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 271 final loss: -0.00027919\n",
      "Trial 272:\n",
      "  Learning Rate: 0.007133460455485789\n",
      "  Sigma Multiplier: 1.0497766107453925\n",
      "  Initialization Multiplier: 0.645374551949813\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.70it/s, loss=-0.000409, elapsed time=0.09, total time=11.3]\n",
      "[I 2025-06-07 13:29:57,676] Trial 272 finished with value: -0.00040926560622334184 and parameters: {'learning_rate': 0.007133460455485789, 'sigma_multiplier': 1.0497766107453925, 'num_layers': 2, 'initialization_multiplier': 0.645374551949813}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 272 final loss: -0.00040927\n",
      "Trial 273:\n",
      "  Learning Rate: 0.007535403603639828\n",
      "  Sigma Multiplier: 0.32126387120095834\n",
      "  Initialization Multiplier: 0.645572906932239\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.64it/s, loss=0.000481, elapsed time=0.1, total time=14.4] \n",
      "[I 2025-06-07 13:30:12,086] Trial 273 finished with value: 0.0004810752605033364 and parameters: {'learning_rate': 0.007535403603639828, 'sigma_multiplier': 0.32126387120095834, 'num_layers': 2, 'initialization_multiplier': 0.645572906932239}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 273 final loss: 0.00048108\n",
      "Trial 274:\n",
      "  Learning Rate: 0.010015271230193102\n",
      "  Sigma Multiplier: 1.052381800715164\n",
      "  Initialization Multiplier: 1.4548165206992127\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.47it/s, loss=0.000116, elapsed time=0.07, total time=11.4] \n",
      "[I 2025-06-07 13:30:23,528] Trial 274 finished with value: 0.00011597626416880924 and parameters: {'learning_rate': 0.010015271230193102, 'sigma_multiplier': 1.052381800715164, 'num_layers': 2, 'initialization_multiplier': 1.4548165206992127}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 274 final loss: 0.00011598\n",
      "Trial 275:\n",
      "  Learning Rate: 0.008697940038364037\n",
      "  Sigma Multiplier: 1.1005291434295474\n",
      "  Initialization Multiplier: 0.6269474913888212\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.87it/s, loss=-0.000401, elapsed time=0.09, total time=11.2]\n",
      "[I 2025-06-07 13:30:34,797] Trial 275 finished with value: -0.00040070291860027106 and parameters: {'learning_rate': 0.008697940038364037, 'sigma_multiplier': 1.1005291434295474, 'num_layers': 2, 'initialization_multiplier': 0.6269474913888212}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 275 final loss: -0.00040070\n",
      "Trial 276:\n",
      "  Learning Rate: 0.008989755151763403\n",
      "  Sigma Multiplier: 1.1065682190368606\n",
      "  Initialization Multiplier: 0.6729325915480694\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.66it/s, loss=-0.000330, elapsed time=0.12, total time=12.1]\n",
      "[I 2025-06-07 13:30:46,980] Trial 276 finished with value: -0.00033003602046145146 and parameters: {'learning_rate': 0.008989755151763403, 'sigma_multiplier': 1.1065682190368606, 'num_layers': 2, 'initialization_multiplier': 0.6729325915480694}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 276 final loss: -0.00033004\n",
      "Trial 277:\n",
      "  Learning Rate: 0.012744261381741203\n",
      "  Sigma Multiplier: 1.0743874333617085\n",
      "  Initialization Multiplier: 0.6076254689500247\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000318, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:30:58,444] Trial 277 finished with value: -0.00031776079540315636 and parameters: {'learning_rate': 0.012744261381741203, 'sigma_multiplier': 1.0743874333617085, 'num_layers': 2, 'initialization_multiplier': 0.6076254689500247}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 277 final loss: -0.00031776\n",
      "Trial 278:\n",
      "  Learning Rate: 0.010391303269592802\n",
      "  Sigma Multiplier: 1.1068275583877996\n",
      "  Initialization Multiplier: 0.19748122865038314\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.21it/s, loss=-0.000212, elapsed time=0.07, total time=12.7]\n",
      "[I 2025-06-07 13:31:11,181] Trial 278 finished with value: -0.00021245488182165302 and parameters: {'learning_rate': 0.010391303269592802, 'sigma_multiplier': 1.1068275583877996, 'num_layers': 2, 'initialization_multiplier': 0.19748122865038314}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 278 final loss: -0.00021245\n",
      "Trial 279:\n",
      "  Learning Rate: 0.008535205679487864\n",
      "  Sigma Multiplier: 1.0346410487267539\n",
      "  Initialization Multiplier: 0.64269569803745\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.85it/s, loss=-0.000347, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 13:31:23,260] Trial 279 finished with value: -0.0003472015630057818 and parameters: {'learning_rate': 0.008535205679487864, 'sigma_multiplier': 1.0346410487267539, 'num_layers': 2, 'initialization_multiplier': 0.64269569803745}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 279 final loss: -0.00034720\n",
      "Trial 280:\n",
      "  Learning Rate: 0.0028550745395191307\n",
      "  Sigma Multiplier: 1.073104640062073\n",
      "  Initialization Multiplier: 0.6763293826610031\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.10it/s, loss=-0.000180, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 13:31:35,093] Trial 280 finished with value: -0.00017969264853632709 and parameters: {'learning_rate': 0.0028550745395191307, 'sigma_multiplier': 1.073104640062073, 'num_layers': 2, 'initialization_multiplier': 0.6763293826610031}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 280 final loss: -0.00017969\n",
      "Trial 281:\n",
      "  Learning Rate: 0.01126288340287288\n",
      "  Sigma Multiplier: 1.1140763021263977\n",
      "  Initialization Multiplier: 0.47359308217528395\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000323, elapsed time=0.08, total time=11.5]\n",
      "[I 2025-06-07 13:31:46,625] Trial 281 finished with value: -0.0003228213371616905 and parameters: {'learning_rate': 0.01126288340287288, 'sigma_multiplier': 1.1140763021263977, 'num_layers': 2, 'initialization_multiplier': 0.47359308217528395}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 281 final loss: -0.00032282\n",
      "Trial 282:\n",
      "  Learning Rate: 0.01823584578446739\n",
      "  Sigma Multiplier: 1.0323568285854572\n",
      "  Initialization Multiplier: 0.6205749572328957\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.60it/s, loss=-0.000265, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 13:31:57,997] Trial 282 finished with value: -0.0002648605274040484 and parameters: {'learning_rate': 0.01823584578446739, 'sigma_multiplier': 1.0323568285854572, 'num_layers': 2, 'initialization_multiplier': 0.6205749572328957}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 282 final loss: -0.00026486\n",
      "Trial 283:\n",
      "  Learning Rate: 0.004979461643409642\n",
      "  Sigma Multiplier: 0.9357952042882323\n",
      "  Initialization Multiplier: 0.5465263350788888\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.07it/s, loss=-0.000338, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 13:32:09,805] Trial 283 finished with value: -0.0003375839820147154 and parameters: {'learning_rate': 0.004979461643409642, 'sigma_multiplier': 0.9357952042882323, 'num_layers': 2, 'initialization_multiplier': 0.5465263350788888}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 283 final loss: -0.00033758\n",
      "Trial 284:\n",
      "  Learning Rate: 0.014401310116860602\n",
      "  Sigma Multiplier: 1.0550354166106366\n",
      "  Initialization Multiplier: 1.0679307482188223\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.56it/s, loss=-0.000066, elapsed time=0.07, total time=13.3]\n",
      "[I 2025-06-07 13:32:23,146] Trial 284 finished with value: -6.637424406287772e-05 and parameters: {'learning_rate': 0.014401310116860602, 'sigma_multiplier': 1.0550354166106366, 'num_layers': 2, 'initialization_multiplier': 1.0679307482188223}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 284 final loss: -0.00006637\n",
      "Trial 285:\n",
      "  Learning Rate: 0.007058333910771692\n",
      "  Sigma Multiplier: 0.9564904215393485\n",
      "  Initialization Multiplier: 0.5847152641729475\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.53it/s, loss=-0.000427, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:32:34,766] Trial 285 finished with value: -0.00042732670330889355 and parameters: {'learning_rate': 0.007058333910771692, 'sigma_multiplier': 0.9564904215393485, 'num_layers': 2, 'initialization_multiplier': 0.5847152641729475}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 285 final loss: -0.00042733\n",
      "Trial 286:\n",
      "  Learning Rate: 0.007578558394816807\n",
      "  Sigma Multiplier: 0.9632788591772856\n",
      "  Initialization Multiplier: 0.42179627508868056\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000421, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:32:46,188] Trial 286 finished with value: -0.0004210350023320765 and parameters: {'learning_rate': 0.007578558394816807, 'sigma_multiplier': 0.9632788591772856, 'num_layers': 2, 'initialization_multiplier': 0.42179627508868056}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 286 final loss: -0.00042104\n",
      "Trial 287:\n",
      "  Learning Rate: 0.007027314427428624\n",
      "  Sigma Multiplier: 0.9601282226743288\n",
      "  Initialization Multiplier: 0.3999773409940845\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.47it/s, loss=-0.000350, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:32:57,603] Trial 287 finished with value: -0.0003500393163850719 and parameters: {'learning_rate': 0.007027314427428624, 'sigma_multiplier': 0.9601282226743288, 'num_layers': 2, 'initialization_multiplier': 0.3999773409940845}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 287 final loss: -0.00035004\n",
      "Trial 288:\n",
      "  Learning Rate: 0.0074258339040369145\n",
      "  Sigma Multiplier: 0.8953002785185867\n",
      "  Initialization Multiplier: 0.4213969497044418\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.48it/s, loss=-0.000258, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 13:33:10,009] Trial 288 finished with value: -0.0002582959612474964 and parameters: {'learning_rate': 0.0074258339040369145, 'sigma_multiplier': 0.8953002785185867, 'num_layers': 2, 'initialization_multiplier': 0.4213969497044418}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 288 final loss: -0.00025830\n",
      "Trial 289:\n",
      "  Learning Rate: 0.006143674355023329\n",
      "  Sigma Multiplier: 0.9453893784493637\n",
      "  Initialization Multiplier: 0.45875106538426436\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.04it/s, loss=-0.000313, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 13:33:21,907] Trial 289 finished with value: -0.00031275822780035643 and parameters: {'learning_rate': 0.006143674355023329, 'sigma_multiplier': 0.9453893784493637, 'num_layers': 2, 'initialization_multiplier': 0.45875106538426436}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 289 final loss: -0.00031276\n",
      "Trial 290:\n",
      "  Learning Rate: 0.007951386010357994\n",
      "  Sigma Multiplier: 0.9598157407569533\n",
      "  Initialization Multiplier: 0.3670418780008896\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.00it/s, loss=-0.000327, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 13:33:33,845] Trial 290 finished with value: -0.0003267919861592918 and parameters: {'learning_rate': 0.007951386010357994, 'sigma_multiplier': 0.9598157407569533, 'num_layers': 2, 'initialization_multiplier': 0.3670418780008896}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 290 final loss: -0.00032679\n",
      "Trial 291:\n",
      "  Learning Rate: 0.00919390249294439\n",
      "  Sigma Multiplier: 0.875587035982166\n",
      "  Initialization Multiplier: 0.500292688686815\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000277, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:33:45,632] Trial 291 finished with value: -0.0002773412015374831 and parameters: {'learning_rate': 0.00919390249294439, 'sigma_multiplier': 0.875587035982166, 'num_layers': 2, 'initialization_multiplier': 0.500292688686815}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 291 final loss: -0.00027734\n",
      "Trial 292:\n",
      "  Learning Rate: 0.0012735977364647984\n",
      "  Sigma Multiplier: 0.927816368238661\n",
      "  Initialization Multiplier: 0.3301525957834854\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.53it/s, loss=0.000086, elapsed time=0.13, total time=16.1]\n",
      "[I 2025-06-07 13:34:01,814] Trial 292 finished with value: 8.612956465319368e-05 and parameters: {'learning_rate': 0.0012735977364647984, 'sigma_multiplier': 0.927816368238661, 'num_layers': 4, 'initialization_multiplier': 0.3301525957834854}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 292 final loss: 0.00008613\n",
      "Trial 293:\n",
      "  Learning Rate: 0.0067025897588059765\n",
      "  Sigma Multiplier: 0.9993070021844712\n",
      "  Initialization Multiplier: 0.4349364187954886\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.40it/s, loss=-0.000359, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:34:13,353] Trial 293 finished with value: -0.0003591944693695058 and parameters: {'learning_rate': 0.0067025897588059765, 'sigma_multiplier': 0.9993070021844712, 'num_layers': 2, 'initialization_multiplier': 0.4349364187954886}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 293 final loss: -0.00035919\n",
      "Trial 294:\n",
      "  Learning Rate: 0.010955521458798304\n",
      "  Sigma Multiplier: 1.0142549159294025\n",
      "  Initialization Multiplier: 0.5154541381142672\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.57it/s, loss=-0.000371, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 13:34:24,760] Trial 294 finished with value: -0.0003708633981052179 and parameters: {'learning_rate': 0.010955521458798304, 'sigma_multiplier': 1.0142549159294025, 'num_layers': 2, 'initialization_multiplier': 0.5154541381142672}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 294 final loss: -0.00037086\n",
      "Trial 295:\n",
      "  Learning Rate: 0.007903365144512245\n",
      "  Sigma Multiplier: 0.9112612033633528\n",
      "  Initialization Multiplier: 0.5514366632989167\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000360, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:34:36,344] Trial 295 finished with value: -0.00036011052211775297 and parameters: {'learning_rate': 0.007903365144512245, 'sigma_multiplier': 0.9112612033633528, 'num_layers': 2, 'initialization_multiplier': 0.5514366632989167}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 295 final loss: -0.00036011\n",
      "Trial 296:\n",
      "  Learning Rate: 0.005810301695970961\n",
      "  Sigma Multiplier: 0.9648126144015836\n",
      "  Initialization Multiplier: 0.296337024129503\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.56it/s, loss=-0.000258, elapsed time=0.08, total time=11.3]\n",
      "[I 2025-06-07 13:34:47,732] Trial 296 finished with value: -0.00025834131922261003 and parameters: {'learning_rate': 0.005810301695970961, 'sigma_multiplier': 0.9648126144015836, 'num_layers': 2, 'initialization_multiplier': 0.296337024129503}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 296 final loss: -0.00025834\n",
      "Trial 297:\n",
      "  Learning Rate: 0.00992384815027789\n",
      "  Sigma Multiplier: 1.0593073642786088\n",
      "  Initialization Multiplier: 0.5034441420638827\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.33it/s, loss=-0.000465, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 13:34:58,563] Trial 297 finished with value: -0.0004648991308180689 and parameters: {'learning_rate': 0.00992384815027789, 'sigma_multiplier': 1.0593073642786088, 'num_layers': 2, 'initialization_multiplier': 0.5034441420638827}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 297 final loss: -0.00046490\n",
      "Trial 298:\n",
      "  Learning Rate: 0.012264561640985794\n",
      "  Sigma Multiplier: 1.0647527205143743\n",
      "  Initialization Multiplier: 0.4911606932305769\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.82it/s, loss=-0.000372, elapsed time=0.05, total time=9.7] \n",
      "[I 2025-06-07 13:35:08,324] Trial 298 finished with value: -0.0003715966860574619 and parameters: {'learning_rate': 0.012264561640985794, 'sigma_multiplier': 1.0647527205143743, 'num_layers': 2, 'initialization_multiplier': 0.4911606932305769}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 298 final loss: -0.00037160\n",
      "Trial 299:\n",
      "  Learning Rate: 0.010209544633286742\n",
      "  Sigma Multiplier: 1.0235854921836087\n",
      "  Initialization Multiplier: 0.5609218878736002\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000362, elapsed time=0.1, total time=11.5] \n",
      "[I 2025-06-07 13:35:19,943] Trial 299 finished with value: -0.00036172909453005607 and parameters: {'learning_rate': 0.010209544633286742, 'sigma_multiplier': 1.0235854921836087, 'num_layers': 2, 'initialization_multiplier': 0.5609218878736002}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 299 final loss: -0.00036173\n",
      "Trial 300:\n",
      "  Learning Rate: 0.013397914611971784\n",
      "  Sigma Multiplier: 1.0795824372108944\n",
      "  Initialization Multiplier: 0.5981086213417758\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.34it/s, loss=-0.000374, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:35:31,631] Trial 300 finished with value: -0.00037364156509781123 and parameters: {'learning_rate': 0.013397914611971784, 'sigma_multiplier': 1.0795824372108944, 'num_layers': 2, 'initialization_multiplier': 0.5981086213417758}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 300 final loss: -0.00037364\n",
      "Trial 301:\n",
      "  Learning Rate: 0.00953416138878224\n",
      "  Sigma Multiplier: 0.9869456268098655\n",
      "  Initialization Multiplier: 0.5133909259375696\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000443, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 13:35:43,118] Trial 301 finished with value: -0.0004431342484658023 and parameters: {'learning_rate': 0.00953416138878224, 'sigma_multiplier': 0.9869456268098655, 'num_layers': 2, 'initialization_multiplier': 0.5133909259375696}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 301 final loss: -0.00044313\n",
      "Trial 302:\n",
      "  Learning Rate: 0.016339844485832006\n",
      "  Sigma Multiplier: 1.0476200862105154\n",
      "  Initialization Multiplier: 0.13199765127993196\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.55it/s, loss=-0.000238, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:35:54,544] Trial 302 finished with value: -0.0002378103180243174 and parameters: {'learning_rate': 0.016339844485832006, 'sigma_multiplier': 1.0476200862105154, 'num_layers': 2, 'initialization_multiplier': 0.13199765127993196}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 302 final loss: -0.00023781\n",
      "Trial 303:\n",
      "  Learning Rate: 0.00972950334847049\n",
      "  Sigma Multiplier: 0.9938778409683705\n",
      "  Initialization Multiplier: 0.0742267849362262\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.13it/s, loss=-0.000136, elapsed time=0.07, total time=15.2]\n",
      "[I 2025-06-07 13:36:09,828] Trial 303 finished with value: -0.0001363500317835849 and parameters: {'learning_rate': 0.00972950334847049, 'sigma_multiplier': 0.9938778409683705, 'num_layers': 2, 'initialization_multiplier': 0.0742267849362262}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 303 final loss: -0.00013635\n",
      "Trial 304:\n",
      "  Learning Rate: 0.010569097537611812\n",
      "  Sigma Multiplier: 1.1238705362863683\n",
      "  Initialization Multiplier: 0.5282161917978242\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.57it/s, loss=-0.000336, elapsed time=0.05, total time=12.5]\n",
      "[I 2025-06-07 13:36:22,416] Trial 304 finished with value: -0.0003358319733781941 and parameters: {'learning_rate': 0.010569097537611812, 'sigma_multiplier': 1.1238705362863683, 'num_layers': 2, 'initialization_multiplier': 0.5282161917978242}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 304 final loss: -0.00033583\n",
      "Trial 305:\n",
      "  Learning Rate: 0.009024345929083586\n",
      "  Sigma Multiplier: 1.0213848122381646\n",
      "  Initialization Multiplier: 0.5877182761644213\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000427, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:36:33,904] Trial 305 finished with value: -0.0004266511617395637 and parameters: {'learning_rate': 0.009024345929083586, 'sigma_multiplier': 1.0213848122381646, 'num_layers': 2, 'initialization_multiplier': 0.5877182761644213}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 305 final loss: -0.00042665\n",
      "Trial 306:\n",
      "  Learning Rate: 0.008532133086660917\n",
      "  Sigma Multiplier: 0.9921960938278469\n",
      "  Initialization Multiplier: 0.6403288707653452\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.56it/s, loss=-0.000386, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:36:45,297] Trial 306 finished with value: -0.00038630184126160305 and parameters: {'learning_rate': 0.008532133086660917, 'sigma_multiplier': 0.9921960938278469, 'num_layers': 2, 'initialization_multiplier': 0.6403288707653452}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 306 final loss: -0.00038630\n",
      "Trial 307:\n",
      "  Learning Rate: 0.012492892934484513\n",
      "  Sigma Multiplier: 1.0242066632465907\n",
      "  Initialization Multiplier: 0.5999113094114077\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.49it/s, loss=-0.000398, elapsed time=0.15, total time=11.4]\n",
      "[I 2025-06-07 13:36:56,749] Trial 307 finished with value: -0.0003981927758016691 and parameters: {'learning_rate': 0.012492892934484513, 'sigma_multiplier': 1.0242066632465907, 'num_layers': 2, 'initialization_multiplier': 0.5999113094114077}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 307 final loss: -0.00039819\n",
      "Trial 308:\n",
      "  Learning Rate: 0.009353760196839112\n",
      "  Sigma Multiplier: 0.9720598999751311\n",
      "  Initialization Multiplier: 0.22335497187135855\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000325, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:37:08,203] Trial 308 finished with value: -0.0003245499917600974 and parameters: {'learning_rate': 0.009353760196839112, 'sigma_multiplier': 0.9720598999751311, 'num_layers': 2, 'initialization_multiplier': 0.22335497187135855}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 308 final loss: -0.00032455\n",
      "Trial 309:\n",
      "  Learning Rate: 0.014252198542446292\n",
      "  Sigma Multiplier: 1.8841935026188361\n",
      "  Initialization Multiplier: 0.5784177822041873\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.62it/s, loss=-0.000240, elapsed time=0.05, total time=9.31]\n",
      "[I 2025-06-07 13:37:17,554] Trial 309 finished with value: -0.0002404160154920432 and parameters: {'learning_rate': 0.014252198542446292, 'sigma_multiplier': 1.8841935026188361, 'num_layers': 2, 'initialization_multiplier': 0.5784177822041873}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 309 final loss: -0.00024042\n",
      "Trial 310:\n",
      "  Learning Rate: 0.011528460315734896\n",
      "  Sigma Multiplier: 1.0289800954502422\n",
      "  Initialization Multiplier: 0.680622729544399\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.23it/s, loss=-0.000254, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:37:29,274] Trial 310 finished with value: -0.00025413497108284146 and parameters: {'learning_rate': 0.011528460315734896, 'sigma_multiplier': 1.0289800954502422, 'num_layers': 2, 'initialization_multiplier': 0.680622729544399}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 310 final loss: -0.00025413\n",
      "Trial 311:\n",
      "  Learning Rate: 0.008122525308807887\n",
      "  Sigma Multiplier: 0.9368442269672159\n",
      "  Initialization Multiplier: 0.6285936135952026\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.53it/s, loss=-0.000435, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:37:40,720] Trial 311 finished with value: -0.00043491730275589576 and parameters: {'learning_rate': 0.008122525308807887, 'sigma_multiplier': 0.9368442269672159, 'num_layers': 2, 'initialization_multiplier': 0.6285936135952026}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 311 final loss: -0.00043492\n",
      "Trial 312:\n",
      "  Learning Rate: 0.009473183931577039\n",
      "  Sigma Multiplier: 0.9120786655032728\n",
      "  Initialization Multiplier: 0.5129950412645083\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.95it/s, loss=-0.000380, elapsed time=0.08, total time=11]  \n",
      "[I 2025-06-07 13:37:51,817] Trial 312 finished with value: -0.0003801141729423127 and parameters: {'learning_rate': 0.009473183931577039, 'sigma_multiplier': 0.9120786655032728, 'num_layers': 2, 'initialization_multiplier': 0.5129950412645083}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 312 final loss: -0.00038011\n",
      "Trial 313:\n",
      "  Learning Rate: 0.008293047416018853\n",
      "  Sigma Multiplier: 0.8335499143039835\n",
      "  Initialization Multiplier: 0.5761798579467778\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.73it/s, loss=-0.000179, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 13:38:03,974] Trial 313 finished with value: -0.0001787425577664057 and parameters: {'learning_rate': 0.008293047416018853, 'sigma_multiplier': 0.8335499143039835, 'num_layers': 2, 'initialization_multiplier': 0.5761798579467778}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 313 final loss: -0.00017874\n",
      "Trial 314:\n",
      "  Learning Rate: 0.011164399443958539\n",
      "  Sigma Multiplier: 0.9489793445173133\n",
      "  Initialization Multiplier: 0.6152646585295767\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000362, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:38:15,571] Trial 314 finished with value: -0.00036192561564884384 and parameters: {'learning_rate': 0.011164399443958539, 'sigma_multiplier': 0.9489793445173133, 'num_layers': 2, 'initialization_multiplier': 0.6152646585295767}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 314 final loss: -0.00036193\n",
      "Trial 315:\n",
      "  Learning Rate: 0.009473246235938043\n",
      "  Sigma Multiplier: 0.8748802693196355\n",
      "  Initialization Multiplier: 0.4786228453457735\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.19it/s, loss=-0.000346, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:38:27,262] Trial 315 finished with value: -0.00034616961565508075 and parameters: {'learning_rate': 0.009473246235938043, 'sigma_multiplier': 0.8748802693196355, 'num_layers': 2, 'initialization_multiplier': 0.4786228453457735}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 315 final loss: -0.00034617\n",
      "Trial 316:\n",
      "  Learning Rate: 0.007751785919894038\n",
      "  Sigma Multiplier: 0.9672919538925907\n",
      "  Initialization Multiplier: 0.5501847637785893\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.93it/s, loss=-0.000483, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:38:38,371] Trial 316 finished with value: -0.00048303365917926343 and parameters: {'learning_rate': 0.007751785919894038, 'sigma_multiplier': 0.9672919538925907, 'num_layers': 2, 'initialization_multiplier': 0.5501847637785893}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 316 final loss: -0.00048303\n",
      "Trial 317:\n",
      "  Learning Rate: 0.00014934273201576366\n",
      "  Sigma Multiplier: 0.9237302507119836\n",
      "  Initialization Multiplier: 0.5483070506845704\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.46it/s, loss=0.041183, elapsed time=0.05, total time=9.4] \n",
      "[I 2025-06-07 13:38:47,804] Trial 317 finished with value: 0.04118272002745469 and parameters: {'learning_rate': 0.00014934273201576366, 'sigma_multiplier': 0.9237302507119836, 'num_layers': 1, 'initialization_multiplier': 0.5483070506845704}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 317 final loss: 0.04118272\n",
      "Trial 318:\n",
      "  Learning Rate: 0.007731570080051329\n",
      "  Sigma Multiplier: 0.9639042606626481\n",
      "  Initialization Multiplier: 0.7009685807127635\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.97it/s, loss=-0.000361, elapsed time=0.06, total time=12.9]\n",
      "[I 2025-06-07 13:39:00,744] Trial 318 finished with value: -0.000360729930282453 and parameters: {'learning_rate': 0.007731570080051329, 'sigma_multiplier': 0.9639042606626481, 'num_layers': 2, 'initialization_multiplier': 0.7009685807127635}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 318 final loss: -0.00036073\n",
      "Trial 319:\n",
      "  Learning Rate: 0.007887892697799945\n",
      "  Sigma Multiplier: 0.9885044497003503\n",
      "  Initialization Multiplier: 0.5882318024169759\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.84it/s, loss=-0.000344, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 13:39:11,939] Trial 319 finished with value: -0.00034365480925688756 and parameters: {'learning_rate': 0.007887892697799945, 'sigma_multiplier': 0.9885044497003503, 'num_layers': 2, 'initialization_multiplier': 0.5882318024169759}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 319 final loss: -0.00034365\n",
      "Trial 320:\n",
      "  Learning Rate: 0.007140735871785507\n",
      "  Sigma Multiplier: 0.8850516377126307\n",
      "  Initialization Multiplier: 0.5424590869562312\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.63it/s, loss=-0.000312, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 13:39:23,384] Trial 320 finished with value: -0.0003122606287651312 and parameters: {'learning_rate': 0.007140735871785507, 'sigma_multiplier': 0.8850516377126307, 'num_layers': 2, 'initialization_multiplier': 0.5424590869562312}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 320 final loss: -0.00031226\n",
      "Trial 321:\n",
      "  Learning Rate: 0.01996719213218704\n",
      "  Sigma Multiplier: 0.9534646015376281\n",
      "  Initialization Multiplier: 0.6559363980088305\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.20it/s, loss=-0.000322, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:39:35,035] Trial 321 finished with value: -0.00032227274057320386 and parameters: {'learning_rate': 0.01996719213218704, 'sigma_multiplier': 0.9534646015376281, 'num_layers': 2, 'initialization_multiplier': 0.6559363980088305}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 321 final loss: -0.00032227\n",
      "Trial 322:\n",
      "  Learning Rate: 0.0020104078854299434\n",
      "  Sigma Multiplier: 0.9210669237482356\n",
      "  Initialization Multiplier: 0.5080627282616949\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.77it/s, loss=-0.000333, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:39:46,298] Trial 322 finished with value: -0.00033281643183680275 and parameters: {'learning_rate': 0.0020104078854299434, 'sigma_multiplier': 0.9210669237482356, 'num_layers': 2, 'initialization_multiplier': 0.5080627282616949}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 322 final loss: -0.00033282\n",
      "Trial 323:\n",
      "  Learning Rate: 0.008378552394907422\n",
      "  Sigma Multiplier: 1.0000441358124117\n",
      "  Initialization Multiplier: 0.5823285346662951\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.79it/s, loss=-0.000353, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:39:57,596] Trial 323 finished with value: -0.00035324470665783626 and parameters: {'learning_rate': 0.008378552394907422, 'sigma_multiplier': 1.0000441358124117, 'num_layers': 2, 'initialization_multiplier': 0.5823285346662951}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 323 final loss: -0.00035324\n",
      "Trial 324:\n",
      "  Learning Rate: 0.010602983499846005\n",
      "  Sigma Multiplier: 0.9840739421764394\n",
      "  Initialization Multiplier: 0.6297102183829841\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.82it/s, loss=-0.000484, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:40:08,781] Trial 324 finished with value: -0.0004843265999481983 and parameters: {'learning_rate': 0.010602983499846005, 'sigma_multiplier': 0.9840739421764394, 'num_layers': 2, 'initialization_multiplier': 0.6297102183829841}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 324 final loss: -0.00048433\n",
      "Trial 325:\n",
      "  Learning Rate: 0.012142476011153876\n",
      "  Sigma Multiplier: 0.9594079678820383\n",
      "  Initialization Multiplier: 0.6225234737133619\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.56it/s, loss=-0.000277, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 13:40:20,241] Trial 325 finished with value: -0.0002771389131656485 and parameters: {'learning_rate': 0.012142476011153876, 'sigma_multiplier': 0.9594079678820383, 'num_layers': 2, 'initialization_multiplier': 0.6225234737133619}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 325 final loss: -0.00027714\n",
      "Trial 326:\n",
      "  Learning Rate: 0.01043311062697599\n",
      "  Sigma Multiplier: 1.0051272325233918\n",
      "  Initialization Multiplier: 0.4547823064576857\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000358, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 13:40:31,411] Trial 326 finished with value: -0.0003576798371177507 and parameters: {'learning_rate': 0.01043311062697599, 'sigma_multiplier': 1.0051272325233918, 'num_layers': 2, 'initialization_multiplier': 0.4547823064576857}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 326 final loss: -0.00035768\n",
      "Trial 327:\n",
      "  Learning Rate: 0.008940319346660524\n",
      "  Sigma Multiplier: 0.930564910649159\n",
      "  Initialization Multiplier: 0.5153756807922253\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.36it/s, loss=-0.000277, elapsed time=0.05, total time=11.5]\n",
      "[I 2025-06-07 13:40:42,985] Trial 327 finished with value: -0.00027678186623731325 and parameters: {'learning_rate': 0.008940319346660524, 'sigma_multiplier': 0.930564910649159, 'num_layers': 2, 'initialization_multiplier': 0.5153756807922253}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 327 final loss: -0.00027678\n",
      "Trial 328:\n",
      "  Learning Rate: 0.013219888178787779\n",
      "  Sigma Multiplier: 0.9786013091540366\n",
      "  Initialization Multiplier: 0.6710938179111361\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000273, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:40:54,450] Trial 328 finished with value: -0.00027273909518813947 and parameters: {'learning_rate': 0.013219888178787779, 'sigma_multiplier': 0.9786013091540366, 'num_layers': 2, 'initialization_multiplier': 0.6710938179111361}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 328 final loss: -0.00027274\n",
      "Trial 329:\n",
      "  Learning Rate: 0.01593263281567266\n",
      "  Sigma Multiplier: 1.0160720243709371\n",
      "  Initialization Multiplier: 0.5712974680803125\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.58it/s, loss=-0.000436, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 13:41:05,869] Trial 329 finished with value: -0.00043632862523614095 and parameters: {'learning_rate': 0.01593263281567266, 'sigma_multiplier': 1.0160720243709371, 'num_layers': 2, 'initialization_multiplier': 0.5712974680803125}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 329 final loss: -0.00043633\n",
      "Trial 330:\n",
      "  Learning Rate: 0.016486634116140358\n",
      "  Sigma Multiplier: 0.8961374380075133\n",
      "  Initialization Multiplier: 0.5566600870610087\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.04it/s, loss=-0.000359, elapsed time=0.05, total time=11.8]\n",
      "[I 2025-06-07 13:41:17,733] Trial 330 finished with value: -0.00035947871520618013 and parameters: {'learning_rate': 0.016486634116140358, 'sigma_multiplier': 0.8961374380075133, 'num_layers': 2, 'initialization_multiplier': 0.5566600870610087}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 330 final loss: -0.00035948\n",
      "Trial 331:\n",
      "  Learning Rate: 0.014862822627143783\n",
      "  Sigma Multiplier: 0.9667433612305483\n",
      "  Initialization Multiplier: 0.4152177970928265\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.23it/s, loss=-0.000310, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:41:29,362] Trial 331 finished with value: -0.0003100634406238494 and parameters: {'learning_rate': 0.014862822627143783, 'sigma_multiplier': 0.9667433612305483, 'num_layers': 2, 'initialization_multiplier': 0.4152177970928265}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 331 final loss: -0.00031006\n",
      "Trial 332:\n",
      "  Learning Rate: 0.023870706277395043\n",
      "  Sigma Multiplier: 1.0121531616680128\n",
      "  Initialization Multiplier: 0.4710051158959646\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000304, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 13:41:40,522] Trial 332 finished with value: -0.0003038573665414141 and parameters: {'learning_rate': 0.023870706277395043, 'sigma_multiplier': 1.0121531616680128, 'num_layers': 2, 'initialization_multiplier': 0.4710051158959646}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 332 final loss: -0.00030386\n",
      "Trial 333:\n",
      "  Learning Rate: 0.020387307481222656\n",
      "  Sigma Multiplier: 0.9295965171703289\n",
      "  Initialization Multiplier: 0.5178597649028104\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.18it/s, loss=-0.000341, elapsed time=0.05, total time=11.7]\n",
      "[I 2025-06-07 13:41:52,280] Trial 333 finished with value: -0.00034090628755732477 and parameters: {'learning_rate': 0.020387307481222656, 'sigma_multiplier': 0.9295965171703289, 'num_layers': 2, 'initialization_multiplier': 0.5178597649028104}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 333 final loss: -0.00034091\n",
      "Trial 334:\n",
      "  Learning Rate: 0.010760065598935402\n",
      "  Sigma Multiplier: 1.0182279808644574\n",
      "  Initialization Multiplier: 0.5647405943363557\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000434, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:42:03,707] Trial 334 finished with value: -0.00043422319266050123 and parameters: {'learning_rate': 0.010760065598935402, 'sigma_multiplier': 1.0182279808644574, 'num_layers': 2, 'initialization_multiplier': 0.5647405943363557}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 334 final loss: -0.00043422\n",
      "Trial 335:\n",
      "  Learning Rate: 0.01318789745981863\n",
      "  Sigma Multiplier: 0.9869210771567581\n",
      "  Initialization Multiplier: 0.5730180491458366\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000452, elapsed time=0.05, total time=11.5]\n",
      "[I 2025-06-07 13:42:15,251] Trial 335 finished with value: -0.00045239598447024146 and parameters: {'learning_rate': 0.01318789745981863, 'sigma_multiplier': 0.9869210771567581, 'num_layers': 2, 'initialization_multiplier': 0.5730180491458366}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 335 final loss: -0.00045240\n",
      "Trial 336:\n",
      "  Learning Rate: 0.01751934963930545\n",
      "  Sigma Multiplier: 1.0163714497145562\n",
      "  Initialization Multiplier: 0.5866222462764779\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.91it/s, loss=-0.000352, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:42:26,399] Trial 336 finished with value: -0.0003522665475028198 and parameters: {'learning_rate': 0.01751934963930545, 'sigma_multiplier': 1.0163714497145562, 'num_layers': 2, 'initialization_multiplier': 0.5866222462764779}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 336 final loss: -0.00035227\n",
      "Trial 337:\n",
      "  Learning Rate: 0.014761680588941662\n",
      "  Sigma Multiplier: 0.9800514395235606\n",
      "  Initialization Multiplier: 0.6270728516359627\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.20it/s, loss=-0.000325, elapsed time=0.1, total time=11.7] \n",
      "[I 2025-06-07 13:42:38,098] Trial 337 finished with value: -0.00032488656078437275 and parameters: {'learning_rate': 0.014761680588941662, 'sigma_multiplier': 0.9800514395235606, 'num_layers': 2, 'initialization_multiplier': 0.6270728516359627}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 337 final loss: -0.00032489\n",
      "Trial 338:\n",
      "  Learning Rate: 0.02924130946856554\n",
      "  Sigma Multiplier: 1.0298193589359104\n",
      "  Initialization Multiplier: 0.5733071805663303\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.41it/s, loss=-0.000318, elapsed time=0.15, total time=11.4]\n",
      "[I 2025-06-07 13:42:49,598] Trial 338 finished with value: -0.00031783909665558576 and parameters: {'learning_rate': 0.02924130946856554, 'sigma_multiplier': 1.0298193589359104, 'num_layers': 2, 'initialization_multiplier': 0.5733071805663303}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 338 final loss: -0.00031784\n",
      "Trial 339:\n",
      "  Learning Rate: 0.012911416411929376\n",
      "  Sigma Multiplier: 0.851314065187591\n",
      "  Initialization Multiplier: 0.6050338872405147\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:18<00:00,  8.05it/s, loss=0.000000, elapsed time=0.14, total time=19]   \n",
      "[I 2025-06-07 13:43:08,674] Trial 339 finished with value: 1.0157213419028852e-07 and parameters: {'learning_rate': 0.012911416411929376, 'sigma_multiplier': 0.851314065187591, 'num_layers': 5, 'initialization_multiplier': 0.6050338872405147}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 339 final loss: 0.00000010\n",
      "Trial 340:\n",
      "  Learning Rate: 0.01139641721494189\n",
      "  Sigma Multiplier: 0.9804203235316894\n",
      "  Initialization Multiplier: 0.6600873712287847\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.14it/s, loss=-0.000266, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:43:20,406] Trial 340 finished with value: -0.00026569474292353966 and parameters: {'learning_rate': 0.01139641721494189, 'sigma_multiplier': 0.9804203235316894, 'num_layers': 2, 'initialization_multiplier': 0.6600873712287847}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 340 final loss: -0.00026569\n",
      "Trial 341:\n",
      "  Learning Rate: 0.015911980728161062\n",
      "  Sigma Multiplier: 1.0450574083000166\n",
      "  Initialization Multiplier: 0.5588648364102206\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.84it/s, loss=-0.000364, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:43:31,654] Trial 341 finished with value: -0.00036427287559286727 and parameters: {'learning_rate': 0.015911980728161062, 'sigma_multiplier': 1.0450574083000166, 'num_layers': 2, 'initialization_multiplier': 0.5588648364102206}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 341 final loss: -0.00036427\n",
      "Trial 342:\n",
      "  Learning Rate: 0.011171462190843112\n",
      "  Sigma Multiplier: 1.012244864282694\n",
      "  Initialization Multiplier: 0.70442783177322\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000248, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:43:43,222] Trial 342 finished with value: -0.00024767933231453727 and parameters: {'learning_rate': 0.011171462190843112, 'sigma_multiplier': 1.012244864282694, 'num_layers': 2, 'initialization_multiplier': 0.70442783177322}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 342 final loss: -0.00024768\n",
      "Trial 343:\n",
      "  Learning Rate: 0.013999490729445776\n",
      "  Sigma Multiplier: 0.9465576213480408\n",
      "  Initialization Multiplier: 0.5489260703730489\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000323, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:43:54,970] Trial 343 finished with value: -0.0003229735909947625 and parameters: {'learning_rate': 0.013999490729445776, 'sigma_multiplier': 0.9465576213480408, 'num_layers': 2, 'initialization_multiplier': 0.5489260703730489}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 343 final loss: -0.00032297\n",
      "Trial 344:\n",
      "  Learning Rate: 0.010028902630666225\n",
      "  Sigma Multiplier: 0.9793628493239185\n",
      "  Initialization Multiplier: 0.6058639461356923\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000369, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 13:44:06,429] Trial 344 finished with value: -0.0003694137466261701 and parameters: {'learning_rate': 0.010028902630666225, 'sigma_multiplier': 0.9793628493239185, 'num_layers': 2, 'initialization_multiplier': 0.6058639461356923}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 344 final loss: -0.00036941\n",
      "Trial 345:\n",
      "  Learning Rate: 0.012342231660895467\n",
      "  Sigma Multiplier: 0.8908148702293572\n",
      "  Initialization Multiplier: 0.6544992342364971\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000304, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 13:44:18,548] Trial 345 finished with value: -0.0003038506040521297 and parameters: {'learning_rate': 0.012342231660895467, 'sigma_multiplier': 0.8908148702293572, 'num_layers': 2, 'initialization_multiplier': 0.6544992342364971}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 345 final loss: -0.00030385\n",
      "Trial 346:\n",
      "  Learning Rate: 0.010356760763413951\n",
      "  Sigma Multiplier: 1.0430921216175106\n",
      "  Initialization Multiplier: 0.49456909240599656\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000330, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:44:29,972] Trial 346 finished with value: -0.0003296534572332559 and parameters: {'learning_rate': 0.010356760763413951, 'sigma_multiplier': 1.0430921216175106, 'num_layers': 2, 'initialization_multiplier': 0.49456909240599656}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 346 final loss: -0.00032965\n",
      "Trial 347:\n",
      "  Learning Rate: 0.019130694447160174\n",
      "  Sigma Multiplier: 1.0006231344391354\n",
      "  Initialization Multiplier: 0.5682486672294912\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.73it/s, loss=-0.000399, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 13:44:41,256] Trial 347 finished with value: -0.00039888321752278537 and parameters: {'learning_rate': 0.019130694447160174, 'sigma_multiplier': 1.0006231344391354, 'num_layers': 2, 'initialization_multiplier': 0.5682486672294912}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 347 final loss: -0.00039888\n",
      "Trial 348:\n",
      "  Learning Rate: 0.013101245188614998\n",
      "  Sigma Multiplier: 0.9322928444801382\n",
      "  Initialization Multiplier: 0.6150948812126049\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.18it/s, loss=-0.000348, elapsed time=0.09, total time=11.7]\n",
      "[I 2025-06-07 13:44:52,981] Trial 348 finished with value: -0.000347742638076908 and parameters: {'learning_rate': 0.013101245188614998, 'sigma_multiplier': 0.9322928444801382, 'num_layers': 2, 'initialization_multiplier': 0.6150948812126049}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 348 final loss: -0.00034774\n",
      "Trial 349:\n",
      "  Learning Rate: 0.009399421024465136\n",
      "  Sigma Multiplier: 1.055072048871443\n",
      "  Initialization Multiplier: 0.5337209091800076\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.70it/s, loss=-0.000267, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 13:45:04,263] Trial 349 finished with value: -0.00026668104536281366 and parameters: {'learning_rate': 0.009399421024465136, 'sigma_multiplier': 1.055072048871443, 'num_layers': 2, 'initialization_multiplier': 0.5337209091800076}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 349 final loss: -0.00026668\n",
      "Trial 350:\n",
      "  Learning Rate: 0.011545374471622608\n",
      "  Sigma Multiplier: 0.9679410872232712\n",
      "  Initialization Multiplier: 0.5793139756500018\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.23it/s, loss=-0.000312, elapsed time=0.08, total time=11.7]\n",
      "[I 2025-06-07 13:45:15,972] Trial 350 finished with value: -0.00031224482372308246 and parameters: {'learning_rate': 0.011545374471622608, 'sigma_multiplier': 0.9679410872232712, 'num_layers': 2, 'initialization_multiplier': 0.5793139756500018}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 350 final loss: -0.00031224\n",
      "Trial 351:\n",
      "  Learning Rate: 0.009044093848257545\n",
      "  Sigma Multiplier: 1.0080560052664902\n",
      "  Initialization Multiplier: 0.026673229657901865\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.12it/s, loss=-0.000141, elapsed time=0.09, total time=11.8]\n",
      "[I 2025-06-07 13:45:27,788] Trial 351 finished with value: -0.00014093869946300397 and parameters: {'learning_rate': 0.009044093848257545, 'sigma_multiplier': 1.0080560052664902, 'num_layers': 2, 'initialization_multiplier': 0.026673229657901865}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 351 final loss: -0.00014094\n",
      "Trial 352:\n",
      "  Learning Rate: 0.014791950614073488\n",
      "  Sigma Multiplier: 0.9085068184227252\n",
      "  Initialization Multiplier: 0.4906796894935286\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.17it/s, loss=-0.000374, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:45:39,522] Trial 352 finished with value: -0.0003736325410429506 and parameters: {'learning_rate': 0.014791950614073488, 'sigma_multiplier': 0.9085068184227252, 'num_layers': 2, 'initialization_multiplier': 0.4906796894935286}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 352 final loss: -0.00037363\n",
      "Trial 353:\n",
      "  Learning Rate: 0.010511900479324201\n",
      "  Sigma Multiplier: 1.0471834593797984\n",
      "  Initialization Multiplier: 0.6366884630709785\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.71it/s, loss=-0.000288, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:45:50,805] Trial 353 finished with value: -0.00028832737795004616 and parameters: {'learning_rate': 0.010511900479324201, 'sigma_multiplier': 1.0471834593797984, 'num_layers': 2, 'initialization_multiplier': 0.6366884630709785}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 353 final loss: -0.00028833\n",
      "Trial 354:\n",
      "  Learning Rate: 0.008319375969357065\n",
      "  Sigma Multiplier: 0.9533396875938325\n",
      "  Initialization Multiplier: 0.527167187255273\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.19it/s, loss=-0.000333, elapsed time=0.08, total time=11.7]\n",
      "[I 2025-06-07 13:46:02,527] Trial 354 finished with value: -0.00033272245796299037 and parameters: {'learning_rate': 0.008319375969357065, 'sigma_multiplier': 0.9533396875938325, 'num_layers': 2, 'initialization_multiplier': 0.527167187255273}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 354 final loss: -0.00033272\n",
      "Trial 355:\n",
      "  Learning Rate: 0.01736595963095857\n",
      "  Sigma Multiplier: 1.014178056570057\n",
      "  Initialization Multiplier: 0.6965876639147877\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.19it/s, loss=-0.000218, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 13:46:14,333] Trial 355 finished with value: -0.00021756757458057913 and parameters: {'learning_rate': 0.01736595963095857, 'sigma_multiplier': 1.014178056570057, 'num_layers': 2, 'initialization_multiplier': 0.6965876639147877}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 355 final loss: -0.00021757\n",
      "Trial 356:\n",
      "  Learning Rate: 0.01275676664015567\n",
      "  Sigma Multiplier: 1.0796920071210088\n",
      "  Initialization Multiplier: 0.5932100499762977\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.77it/s, loss=-0.000353, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:46:25,541] Trial 356 finished with value: -0.0003529173170798632 and parameters: {'learning_rate': 0.01275676664015567, 'sigma_multiplier': 1.0796920071210088, 'num_layers': 2, 'initialization_multiplier': 0.5932100499762977}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 356 final loss: -0.00035292\n",
      "Trial 357:\n",
      "  Learning Rate: 0.009473630068323396\n",
      "  Sigma Multiplier: 0.9883455703878964\n",
      "  Initialization Multiplier: 0.4474477327653162\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.36it/s, loss=-0.000330, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 13:46:37,226] Trial 357 finished with value: -0.00032971016458203153 and parameters: {'learning_rate': 0.009473630068323396, 'sigma_multiplier': 0.9883455703878964, 'num_layers': 2, 'initialization_multiplier': 0.4474477327653162}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 357 final loss: -0.00032971\n",
      "Trial 358:\n",
      "  Learning Rate: 0.00786559674275969\n",
      "  Sigma Multiplier: 0.9400068780553908\n",
      "  Initialization Multiplier: 0.5479112834747755\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.03it/s, loss=-0.000335, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 13:46:49,102] Trial 358 finished with value: -0.0003348013642479969 and parameters: {'learning_rate': 0.00786559674275969, 'sigma_multiplier': 0.9400068780553908, 'num_layers': 2, 'initialization_multiplier': 0.5479112834747755}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 358 final loss: -0.00033480\n",
      "Trial 359:\n",
      "  Learning Rate: 0.010612732360648561\n",
      "  Sigma Multiplier: 1.036443575499903\n",
      "  Initialization Multiplier: 0.6324532146006682\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.63it/s, loss=-0.000349, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 13:47:00,415] Trial 359 finished with value: -0.00034912321333094965 and parameters: {'learning_rate': 0.010612732360648561, 'sigma_multiplier': 1.036443575499903, 'num_layers': 2, 'initialization_multiplier': 0.6324532146006682}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 359 final loss: -0.00034912\n",
      "Trial 360:\n",
      "  Learning Rate: 0.007146637219748936\n",
      "  Sigma Multiplier: 0.9789024103632082\n",
      "  Initialization Multiplier: 0.49670538556005384\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.01it/s, loss=-0.000293, elapsed time=0.05, total time=11.9]\n",
      "[I 2025-06-07 13:47:12,397] Trial 360 finished with value: -0.000292926026851976 and parameters: {'learning_rate': 0.007146637219748936, 'sigma_multiplier': 0.9789024103632082, 'num_layers': 2, 'initialization_multiplier': 0.49670538556005384}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 360 final loss: -0.00029293\n",
      "Trial 361:\n",
      "  Learning Rate: 0.008882317496736096\n",
      "  Sigma Multiplier: 0.9028056265228428\n",
      "  Initialization Multiplier: 0.5721467243870901\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.76it/s, loss=-0.000387, elapsed time=0.09, total time=13.1]\n",
      "[I 2025-06-07 13:47:25,540] Trial 361 finished with value: -0.000387333341801373 and parameters: {'learning_rate': 0.008882317496736096, 'sigma_multiplier': 0.9028056265228428, 'num_layers': 2, 'initialization_multiplier': 0.5721467243870901}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 361 final loss: -0.00038733\n",
      "Trial 362:\n",
      "  Learning Rate: 0.012229405525802968\n",
      "  Sigma Multiplier: 0.8547924948985265\n",
      "  Initialization Multiplier: 0.5318188233395732\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.67it/s, loss=-0.000354, elapsed time=0.09, total time=13.2]\n",
      "[I 2025-06-07 13:47:38,766] Trial 362 finished with value: -0.0003537348416046371 and parameters: {'learning_rate': 0.012229405525802968, 'sigma_multiplier': 0.8547924948985265, 'num_layers': 2, 'initialization_multiplier': 0.5318188233395732}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 362 final loss: -0.00035373\n",
      "Trial 363:\n",
      "  Learning Rate: 0.016076104840365167\n",
      "  Sigma Multiplier: 1.1023285355941013\n",
      "  Initialization Multiplier: 0.6649527993861526\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.84it/s, loss=-0.000309, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 13:47:50,811] Trial 363 finished with value: -0.00030936646929496925 and parameters: {'learning_rate': 0.016076104840365167, 'sigma_multiplier': 1.1023285355941013, 'num_layers': 2, 'initialization_multiplier': 0.6649527993861526}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 363 final loss: -0.00030937\n",
      "Trial 364:\n",
      "  Learning Rate: 0.000426637457723328\n",
      "  Sigma Multiplier: 1.052798007803345\n",
      "  Initialization Multiplier: 0.3930168157734303\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.90it/s, loss=0.002729, elapsed time=0.06, total time=13.3]\n",
      "[I 2025-06-07 13:48:04,141] Trial 364 finished with value: 0.002729260333057728 and parameters: {'learning_rate': 0.000426637457723328, 'sigma_multiplier': 1.052798007803345, 'num_layers': 2, 'initialization_multiplier': 0.3930168157734303}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 364 final loss: 0.00272926\n",
      "Trial 365:\n",
      "  Learning Rate: 0.007624720283315056\n",
      "  Sigma Multiplier: 1.0080114901940795\n",
      "  Initialization Multiplier: 0.6085118004514811\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.12it/s, loss=-0.000349, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 13:48:16,028] Trial 365 finished with value: -0.00034884592736282496 and parameters: {'learning_rate': 0.007624720283315056, 'sigma_multiplier': 1.0080114901940795, 'num_layers': 2, 'initialization_multiplier': 0.6085118004514811}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 365 final loss: -0.00034885\n",
      "Trial 366:\n",
      "  Learning Rate: 0.010245831856861539\n",
      "  Sigma Multiplier: 0.9456247202137482\n",
      "  Initialization Multiplier: 0.4577563845214711\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.19it/s, loss=-0.000439, elapsed time=0.06, total time=12.6]\n",
      "[I 2025-06-07 13:48:28,668] Trial 366 finished with value: -0.0004394372720584836 and parameters: {'learning_rate': 0.010245831856861539, 'sigma_multiplier': 0.9456247202137482, 'num_layers': 2, 'initialization_multiplier': 0.4577563845214711}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 366 final loss: -0.00043944\n",
      "Trial 367:\n",
      "  Learning Rate: 0.011396846003117776\n",
      "  Sigma Multiplier: 0.9283400576663557\n",
      "  Initialization Multiplier: 0.44301835523357397\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.37it/s, loss=-0.000379, elapsed time=0.09, total time=14.9]\n",
      "[I 2025-06-07 13:48:43,598] Trial 367 finished with value: -0.00037860407769752 and parameters: {'learning_rate': 0.011396846003117776, 'sigma_multiplier': 0.9283400576663557, 'num_layers': 2, 'initialization_multiplier': 0.44301835523357397}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 367 final loss: -0.00037860\n",
      "Trial 368:\n",
      "  Learning Rate: 0.08189348048220246\n",
      "  Sigma Multiplier: 0.5819342400910708\n",
      "  Initialization Multiplier: 0.3703959687074022\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.81it/s, loss=0.000026, elapsed time=0.05, total time=12.1]\n",
      "[I 2025-06-07 13:48:55,783] Trial 368 finished with value: 2.6279898592461928e-05 and parameters: {'learning_rate': 0.08189348048220246, 'sigma_multiplier': 0.5819342400910708, 'num_layers': 1, 'initialization_multiplier': 0.3703959687074022}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 368 final loss: 0.00002628\n",
      "Trial 369:\n",
      "  Learning Rate: 0.013595419338834543\n",
      "  Sigma Multiplier: 0.8707688416380139\n",
      "  Initialization Multiplier: 0.4347975220264313\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.84it/s, loss=-0.000453, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 13:49:07,792] Trial 369 finished with value: -0.0004533337065936015 and parameters: {'learning_rate': 0.013595419338834543, 'sigma_multiplier': 0.8707688416380139, 'num_layers': 2, 'initialization_multiplier': 0.4347975220264313}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 369 final loss: -0.00045333\n",
      "Trial 370:\n",
      "  Learning Rate: 0.01021258984210763\n",
      "  Sigma Multiplier: 0.7950040321144848\n",
      "  Initialization Multiplier: 0.34620477113953807\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.64it/s, loss=-0.000200, elapsed time=0.05, total time=13.2]\n",
      "[I 2025-06-07 13:49:21,076] Trial 370 finished with value: -0.00020049318279737489 and parameters: {'learning_rate': 0.01021258984210763, 'sigma_multiplier': 0.7950040321144848, 'num_layers': 2, 'initialization_multiplier': 0.34620477113953807}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 370 final loss: -0.00020049\n",
      "Trial 371:\n",
      "  Learning Rate: 0.013353118508103175\n",
      "  Sigma Multiplier: 0.8751433794896558\n",
      "  Initialization Multiplier: 0.41426514003550047\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000366, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 13:49:33,161] Trial 371 finished with value: -0.00036603255454578513 and parameters: {'learning_rate': 0.013353118508103175, 'sigma_multiplier': 0.8751433794896558, 'num_layers': 2, 'initialization_multiplier': 0.41426514003550047}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 371 final loss: -0.00036603\n",
      "Trial 372:\n",
      "  Learning Rate: 0.008983112109570623\n",
      "  Sigma Multiplier: 0.8037881497406307\n",
      "  Initialization Multiplier: 0.45544697223150654\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.07it/s, loss=-0.000280, elapsed time=0.05, total time=13.8]\n",
      "[I 2025-06-07 13:49:47,048] Trial 372 finished with value: -0.0002797455119928876 and parameters: {'learning_rate': 0.008983112109570623, 'sigma_multiplier': 0.8037881497406307, 'num_layers': 2, 'initialization_multiplier': 0.45544697223150654}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 372 final loss: -0.00027975\n",
      "Trial 373:\n",
      "  Learning Rate: 0.010983256565369068\n",
      "  Sigma Multiplier: 0.8834277709440082\n",
      "  Initialization Multiplier: 0.40445936836067276\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.48it/s, loss=-0.000323, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 13:49:59,636] Trial 373 finished with value: -0.00032284369670185876 and parameters: {'learning_rate': 0.010983256565369068, 'sigma_multiplier': 0.8834277709440082, 'num_layers': 2, 'initialization_multiplier': 0.40445936836067276}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 373 final loss: -0.00032284\n",
      "Trial 374:\n",
      "  Learning Rate: 0.009232179328353242\n",
      "  Sigma Multiplier: 0.8360796261628496\n",
      "  Initialization Multiplier: 0.47801259685889225\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.83it/s, loss=-0.000367, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 13:50:11,697] Trial 374 finished with value: -0.0003672887073379421 and parameters: {'learning_rate': 0.009232179328353242, 'sigma_multiplier': 0.8360796261628496, 'num_layers': 2, 'initialization_multiplier': 0.47801259685889225}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 374 final loss: -0.00036729\n",
      "Trial 375:\n",
      "  Learning Rate: 0.013322588831890664\n",
      "  Sigma Multiplier: 0.942130156814893\n",
      "  Initialization Multiplier: 0.43238439194271644\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000346, elapsed time=0.05, total time=11.7]\n",
      "[I 2025-06-07 13:50:23,393] Trial 375 finished with value: -0.0003460255734562812 and parameters: {'learning_rate': 0.013322588831890664, 'sigma_multiplier': 0.942130156814893, 'num_layers': 2, 'initialization_multiplier': 0.43238439194271644}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 375 final loss: -0.00034603\n",
      "Trial 376:\n",
      "  Learning Rate: 0.008349342319093381\n",
      "  Sigma Multiplier: 0.9100882284383266\n",
      "  Initialization Multiplier: 0.47976740872892265\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000288, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 13:50:35,012] Trial 376 finished with value: -0.0002879798267020585 and parameters: {'learning_rate': 0.008349342319093381, 'sigma_multiplier': 0.9100882284383266, 'num_layers': 2, 'initialization_multiplier': 0.47976740872892265}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 376 final loss: -0.00028798\n",
      "Trial 377:\n",
      "  Learning Rate: 0.010823788510080427\n",
      "  Sigma Multiplier: 0.9436274795228711\n",
      "  Initialization Multiplier: 0.37396460546304555\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000313, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 13:50:46,701] Trial 377 finished with value: -0.0003134748954959076 and parameters: {'learning_rate': 0.010823788510080427, 'sigma_multiplier': 0.9436274795228711, 'num_layers': 2, 'initialization_multiplier': 0.37396460546304555}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 377 final loss: -0.00031347\n",
      "Trial 378:\n",
      "  Learning Rate: 0.014634376025346188\n",
      "  Sigma Multiplier: 0.9727122878686566\n",
      "  Initialization Multiplier: 1.8974998073256084\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.60it/s, loss=-0.000146, elapsed time=0.08, total time=12.2]\n",
      "[I 2025-06-07 13:50:58,927] Trial 378 finished with value: -0.00014638174235467232 and parameters: {'learning_rate': 0.014634376025346188, 'sigma_multiplier': 0.9727122878686566, 'num_layers': 2, 'initialization_multiplier': 1.8974998073256084}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 378 final loss: -0.00014638\n",
      "Trial 379:\n",
      "  Learning Rate: 0.007852601068627767\n",
      "  Sigma Multiplier: 1.025332684108601\n",
      "  Initialization Multiplier: 0.5160246532081127\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.69it/s, loss=-0.000351, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:51:10,208] Trial 379 finished with value: -0.00035088263454337434 and parameters: {'learning_rate': 0.007852601068627767, 'sigma_multiplier': 1.025332684108601, 'num_layers': 2, 'initialization_multiplier': 0.5160246532081127}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 379 final loss: -0.00035088\n",
      "Trial 380:\n",
      "  Learning Rate: 0.009686687975021696\n",
      "  Sigma Multiplier: 0.7409507624574058\n",
      "  Initialization Multiplier: 0.4224275505646244\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.43it/s, loss=-0.000104, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 13:51:22,654] Trial 380 finished with value: -0.00010363169122604206 and parameters: {'learning_rate': 0.009686687975021696, 'sigma_multiplier': 0.7409507624574058, 'num_layers': 2, 'initialization_multiplier': 0.4224275505646244}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 380 final loss: -0.00010363\n",
      "Trial 381:\n",
      "  Learning Rate: 0.006713441196332713\n",
      "  Sigma Multiplier: 0.8700860274821941\n",
      "  Initialization Multiplier: 0.4693291959839524\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.09it/s, loss=-0.000338, elapsed time=0.08, total time=13.8]\n",
      "[I 2025-06-07 13:51:36,509] Trial 381 finished with value: -0.00033814118580620465 and parameters: {'learning_rate': 0.006713441196332713, 'sigma_multiplier': 0.8700860274821941, 'num_layers': 2, 'initialization_multiplier': 0.4693291959839524}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 381 final loss: -0.00033814\n",
      "Trial 382:\n",
      "  Learning Rate: 0.012124965332493295\n",
      "  Sigma Multiplier: 0.989551430172681\n",
      "  Initialization Multiplier: 0.5117301154908607\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.47it/s, loss=-0.000461, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:51:48,085] Trial 382 finished with value: -0.00046105848822476024 and parameters: {'learning_rate': 0.012124965332493295, 'sigma_multiplier': 0.989551430172681, 'num_layers': 2, 'initialization_multiplier': 0.5117301154908607}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 382 final loss: -0.00046106\n",
      "Trial 383:\n",
      "  Learning Rate: 0.012157391314678934\n",
      "  Sigma Multiplier: 0.9953711895615042\n",
      "  Initialization Multiplier: 0.5353810755209452\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000419, elapsed time=0.05, total time=11.5]\n",
      "[I 2025-06-07 13:51:59,590] Trial 383 finished with value: -0.0004193054633400065 and parameters: {'learning_rate': 0.012157391314678934, 'sigma_multiplier': 0.9953711895615042, 'num_layers': 2, 'initialization_multiplier': 0.5353810755209452}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 383 final loss: -0.00041931\n",
      "Trial 384:\n",
      "  Learning Rate: 0.017344228131383074\n",
      "  Sigma Multiplier: 1.0681815648470345\n",
      "  Initialization Multiplier: 0.5167204976496144\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.63it/s, loss=-0.000333, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:52:10,898] Trial 384 finished with value: -0.0003332161570543687 and parameters: {'learning_rate': 0.017344228131383074, 'sigma_multiplier': 1.0681815648470345, 'num_layers': 2, 'initialization_multiplier': 0.5167204976496144}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 384 final loss: -0.00033322\n",
      "Trial 385:\n",
      "  Learning Rate: 0.013774267477655085\n",
      "  Sigma Multiplier: 1.0236975630429475\n",
      "  Initialization Multiplier: 0.56061062869944\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000425, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 13:52:22,807] Trial 385 finished with value: -0.00042461348594818285 and parameters: {'learning_rate': 0.013774267477655085, 'sigma_multiplier': 1.0236975630429475, 'num_layers': 2, 'initialization_multiplier': 0.56061062869944}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 385 final loss: -0.00042461\n",
      "Trial 386:\n",
      "  Learning Rate: 0.023048095807898822\n",
      "  Sigma Multiplier: 1.032608795380142\n",
      "  Initialization Multiplier: 0.5674822144462479\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.02it/s, loss=-0.000345, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 13:52:34,691] Trial 386 finished with value: -0.0003452695596912014 and parameters: {'learning_rate': 0.023048095807898822, 'sigma_multiplier': 1.032608795380142, 'num_layers': 2, 'initialization_multiplier': 0.5674822144462479}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 386 final loss: -0.00034527\n",
      "Trial 387:\n",
      "  Learning Rate: 0.013566117708313032\n",
      "  Sigma Multiplier: 1.0684447225708165\n",
      "  Initialization Multiplier: 0.5593456932040628\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.82it/s, loss=-0.000311, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:52:45,963] Trial 387 finished with value: -0.0003107456587468006 and parameters: {'learning_rate': 0.013566117708313032, 'sigma_multiplier': 1.0684447225708165, 'num_layers': 2, 'initialization_multiplier': 0.5593456932040628}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 387 final loss: -0.00031075\n",
      "Trial 388:\n",
      "  Learning Rate: 0.01606768493970034\n",
      "  Sigma Multiplier: 1.0132290704179299\n",
      "  Initialization Multiplier: 0.5010704745233482\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.25it/s, loss=-0.000295, elapsed time=0.05, total time=11.6]\n",
      "[I 2025-06-07 13:52:57,647] Trial 388 finished with value: -0.0002945787980804746 and parameters: {'learning_rate': 0.01606768493970034, 'sigma_multiplier': 1.0132290704179299, 'num_layers': 2, 'initialization_multiplier': 0.5010704745233482}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 388 final loss: -0.00029458\n",
      "Trial 389:\n",
      "  Learning Rate: 0.014873853235434735\n",
      "  Sigma Multiplier: 1.0407385727897676\n",
      "  Initialization Multiplier: 0.6151803318173684\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.58it/s, loss=-0.000392, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:53:09,061] Trial 389 finished with value: -0.0003915657793271685 and parameters: {'learning_rate': 0.014873853235434735, 'sigma_multiplier': 1.0407385727897676, 'num_layers': 2, 'initialization_multiplier': 0.6151803318173684}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 389 final loss: -0.00039157\n",
      "Trial 390:\n",
      "  Learning Rate: 0.011816937512862008\n",
      "  Sigma Multiplier: 1.0843649982234398\n",
      "  Initialization Multiplier: 0.5491414340325708\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.91it/s, loss=-0.000406, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 13:53:20,128] Trial 390 finished with value: -0.0004057972372883846 and parameters: {'learning_rate': 0.011816937512862008, 'sigma_multiplier': 1.0843649982234398, 'num_layers': 2, 'initialization_multiplier': 0.5491414340325708}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 390 final loss: -0.00040580\n",
      "Trial 391:\n",
      "  Learning Rate: 0.017969160820845632\n",
      "  Sigma Multiplier: 0.9924705219675228\n",
      "  Initialization Multiplier: 0.5947429966583879\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000419, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:53:31,347] Trial 391 finished with value: -0.0004186548185493868 and parameters: {'learning_rate': 0.017969160820845632, 'sigma_multiplier': 0.9924705219675228, 'num_layers': 2, 'initialization_multiplier': 0.5947429966583879}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 391 final loss: -0.00041865\n",
      "Trial 392:\n",
      "  Learning Rate: 0.013527226073781488\n",
      "  Sigma Multiplier: 1.0157654806584886\n",
      "  Initialization Multiplier: 0.643672587517269\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.55it/s, loss=-0.000433, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:53:42,816] Trial 392 finished with value: -0.0004328650560029893 and parameters: {'learning_rate': 0.013527226073781488, 'sigma_multiplier': 1.0157654806584886, 'num_layers': 2, 'initialization_multiplier': 0.643672587517269}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 392 final loss: -0.00043287\n",
      "Trial 393:\n",
      "  Learning Rate: 0.014126560850859211\n",
      "  Sigma Multiplier: 0.972223814991584\n",
      "  Initialization Multiplier: 0.6505373906710866\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000303, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 13:53:54,013] Trial 393 finished with value: -0.00030341872404349136 and parameters: {'learning_rate': 0.014126560850859211, 'sigma_multiplier': 0.972223814991584, 'num_layers': 2, 'initialization_multiplier': 0.6505373906710866}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 393 final loss: -0.00030342\n",
      "Trial 394:\n",
      "  Learning Rate: 0.011931059818243462\n",
      "  Sigma Multiplier: 1.016493403525563\n",
      "  Initialization Multiplier: 0.7220065151888662\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000178, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 13:54:05,798] Trial 394 finished with value: -0.00017775632429954598 and parameters: {'learning_rate': 0.011931059818243462, 'sigma_multiplier': 1.016493403525563, 'num_layers': 2, 'initialization_multiplier': 0.7220065151888662}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 394 final loss: -0.00017776\n",
      "Trial 395:\n",
      "  Learning Rate: 0.02010557023192252\n",
      "  Sigma Multiplier: 0.9211867273593387\n",
      "  Initialization Multiplier: 0.6814399583894639\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.79it/s, loss=-0.000299, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 13:54:17,934] Trial 395 finished with value: -0.00029914212468170085 and parameters: {'learning_rate': 0.02010557023192252, 'sigma_multiplier': 0.9211867273593387, 'num_layers': 2, 'initialization_multiplier': 0.6814399583894639}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 395 final loss: -0.00029914\n",
      "Trial 396:\n",
      "  Learning Rate: 0.014738908250768663\n",
      "  Sigma Multiplier: 0.9604708845145886\n",
      "  Initialization Multiplier: 0.5129435376286496\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.23it/s, loss=-0.000363, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 13:54:29,620] Trial 396 finished with value: -0.0003626191291258848 and parameters: {'learning_rate': 0.014738908250768663, 'sigma_multiplier': 0.9604708845145886, 'num_layers': 2, 'initialization_multiplier': 0.5129435376286496}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 396 final loss: -0.00036262\n",
      "Trial 397:\n",
      "  Learning Rate: 0.011532201219062094\n",
      "  Sigma Multiplier: 1.009405282333681\n",
      "  Initialization Multiplier: 0.5528777522520807\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.51it/s, loss=-0.000355, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:54:41,056] Trial 397 finished with value: -0.0003548732367303542 and parameters: {'learning_rate': 0.011532201219062094, 'sigma_multiplier': 1.009405282333681, 'num_layers': 2, 'initialization_multiplier': 0.5528777522520807}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 397 final loss: -0.00035487\n",
      "Trial 398:\n",
      "  Learning Rate: 0.010457766303668094\n",
      "  Sigma Multiplier: 1.0470453748026685\n",
      "  Initialization Multiplier: 0.48282560249284057\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.81it/s, loss=-0.000333, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 13:54:52,241] Trial 398 finished with value: -0.00033253636607557526 and parameters: {'learning_rate': 0.010457766303668094, 'sigma_multiplier': 1.0470453748026685, 'num_layers': 2, 'initialization_multiplier': 0.48282560249284057}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 398 final loss: -0.00033254\n",
      "Trial 399:\n",
      "  Learning Rate: 0.013626369285840899\n",
      "  Sigma Multiplier: 0.9870167877935084\n",
      "  Initialization Multiplier: 0.6263468620692086\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000450, elapsed time=0.05, total time=11.6]\n",
      "[I 2025-06-07 13:55:03,878] Trial 399 finished with value: -0.00044953263487591957 and parameters: {'learning_rate': 0.013626369285840899, 'sigma_multiplier': 0.9870167877935084, 'num_layers': 2, 'initialization_multiplier': 0.6263468620692086}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 399 final loss: -0.00044953\n",
      "Trial 400:\n",
      "  Learning Rate: 0.016543438166205522\n",
      "  Sigma Multiplier: 0.9083099106902198\n",
      "  Initialization Multiplier: 0.6524989316144486\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.75it/s, loss=-0.000209, elapsed time=0.09, total time=12.1]\n",
      "[I 2025-06-07 13:55:16,042] Trial 400 finished with value: -0.00020901838222892722 and parameters: {'learning_rate': 0.016543438166205522, 'sigma_multiplier': 0.9083099106902198, 'num_layers': 2, 'initialization_multiplier': 0.6524989316144486}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 400 final loss: -0.00020902\n",
      "Trial 401:\n",
      "  Learning Rate: 0.012677520716116705\n",
      "  Sigma Multiplier: 0.9695850367109096\n",
      "  Initialization Multiplier: 0.6273615515983602\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.83it/s, loss=-0.000406, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 13:55:27,294] Trial 401 finished with value: -0.0004064134438965087 and parameters: {'learning_rate': 0.012677520716116705, 'sigma_multiplier': 0.9695850367109096, 'num_layers': 2, 'initialization_multiplier': 0.6273615515983602}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 401 final loss: -0.00040641\n",
      "Trial 402:\n",
      "  Learning Rate: 0.010236962631844159\n",
      "  Sigma Multiplier: 0.9479981242119498\n",
      "  Initialization Multiplier: 0.7075851529789869\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000319, elapsed time=0.08, total time=11.8]\n",
      "[I 2025-06-07 13:55:39,138] Trial 402 finished with value: -0.0003189816640962181 and parameters: {'learning_rate': 0.010236962631844159, 'sigma_multiplier': 0.9479981242119498, 'num_layers': 2, 'initialization_multiplier': 0.7075851529789869}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 402 final loss: -0.00031898\n",
      "Trial 403:\n",
      "  Learning Rate: 0.009899015745434822\n",
      "  Sigma Multiplier: 0.9910193815331841\n",
      "  Initialization Multiplier: 0.5904280974196418\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000378, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:55:50,884] Trial 403 finished with value: -0.00037808901085174 and parameters: {'learning_rate': 0.009899015745434822, 'sigma_multiplier': 0.9910193815331841, 'num_layers': 2, 'initialization_multiplier': 0.5904280974196418}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 403 final loss: -0.00037809\n",
      "Trial 404:\n",
      "  Learning Rate: 0.018749183562091997\n",
      "  Sigma Multiplier: 0.9218068749557908\n",
      "  Initialization Multiplier: 0.7649752911584908\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.66it/s, loss=-0.000093, elapsed time=0.08, total time=12.2]\n",
      "[I 2025-06-07 13:56:03,090] Trial 404 finished with value: -9.330640590782535e-05 and parameters: {'learning_rate': 0.018749183562091997, 'sigma_multiplier': 0.9218068749557908, 'num_layers': 2, 'initialization_multiplier': 0.7649752911584908}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 404 final loss: -0.00009331\n",
      "Trial 405:\n",
      "  Learning Rate: 0.011829416356346925\n",
      "  Sigma Multiplier: 0.9909592019861571\n",
      "  Initialization Multiplier: 0.6762692089581779\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.45it/s, loss=-0.000339, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 13:56:14,542] Trial 405 finished with value: -0.000339007759370086 and parameters: {'learning_rate': 0.011829416356346925, 'sigma_multiplier': 0.9909592019861571, 'num_layers': 2, 'initialization_multiplier': 0.6762692089581779}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 405 final loss: -0.00033901\n",
      "Trial 406:\n",
      "  Learning Rate: 0.01321390548861559\n",
      "  Sigma Multiplier: 1.0390835420108548\n",
      "  Initialization Multiplier: 0.6214960941156659\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.06it/s, loss=-0.000205, elapsed time=0.08, total time=13.9]\n",
      "[I 2025-06-07 13:56:28,474] Trial 406 finished with value: -0.00020486393777374086 and parameters: {'learning_rate': 0.01321390548861559, 'sigma_multiplier': 1.0390835420108548, 'num_layers': 3, 'initialization_multiplier': 0.6214960941156659}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 406 final loss: -0.00020486\n",
      "Trial 407:\n",
      "  Learning Rate: 0.009106009406448\n",
      "  Sigma Multiplier: 0.9582595333507197\n",
      "  Initialization Multiplier: 0.520674892391154\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.31it/s, loss=-0.000316, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 13:56:40,062] Trial 407 finished with value: -0.00031600362831886984 and parameters: {'learning_rate': 0.009106009406448, 'sigma_multiplier': 0.9582595333507197, 'num_layers': 2, 'initialization_multiplier': 0.520674892391154}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 407 final loss: -0.00031600\n",
      "Trial 408:\n",
      "  Learning Rate: 0.01024931339310504\n",
      "  Sigma Multiplier: 0.864896840211394\n",
      "  Initialization Multiplier: 0.5788756406650497\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000311, elapsed time=0.1, total time=11.7] \n",
      "[I 2025-06-07 13:56:51,773] Trial 408 finished with value: -0.00031138586795091596 and parameters: {'learning_rate': 0.01024931339310504, 'sigma_multiplier': 0.864896840211394, 'num_layers': 2, 'initialization_multiplier': 0.5788756406650497}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 408 final loss: -0.00031139\n",
      "Trial 409:\n",
      "  Learning Rate: 0.015577908784627665\n",
      "  Sigma Multiplier: 1.0643687393165178\n",
      "  Initialization Multiplier: 0.6306253337911055\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000409, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 13:57:02,528] Trial 409 finished with value: -0.000408935033625929 and parameters: {'learning_rate': 0.015577908784627665, 'sigma_multiplier': 1.0643687393165178, 'num_layers': 2, 'initialization_multiplier': 0.6306253337911055}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 409 final loss: -0.00040894\n",
      "Trial 410:\n",
      "  Learning Rate: 0.011339216863054112\n",
      "  Sigma Multiplier: 0.9980463074452464\n",
      "  Initialization Multiplier: 0.4777201202450139\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.67it/s, loss=-0.000274, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 13:57:13,795] Trial 410 finished with value: -0.0002739373772632759 and parameters: {'learning_rate': 0.011339216863054112, 'sigma_multiplier': 0.9980463074452464, 'num_layers': 2, 'initialization_multiplier': 0.4777201202450139}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 410 final loss: -0.00027394\n",
      "Trial 411:\n",
      "  Learning Rate: 0.008824643352397113\n",
      "  Sigma Multiplier: 0.9375127205952815\n",
      "  Initialization Multiplier: 0.5442740030815376\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000332, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 13:57:25,336] Trial 411 finished with value: -0.00033235180696624376 and parameters: {'learning_rate': 0.008824643352397113, 'sigma_multiplier': 0.9375127205952815, 'num_layers': 2, 'initialization_multiplier': 0.5442740030815376}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 411 final loss: -0.00033235\n",
      "Trial 412:\n",
      "  Learning Rate: 0.013356889908595217\n",
      "  Sigma Multiplier: 1.1067399563853664\n",
      "  Initialization Multiplier: 0.5970723885148368\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.69it/s, loss=-0.000331, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 13:57:36,732] Trial 412 finished with value: -0.00033142977193884715 and parameters: {'learning_rate': 0.013356889908595217, 'sigma_multiplier': 1.1067399563853664, 'num_layers': 2, 'initialization_multiplier': 0.5970723885148368}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 412 final loss: -0.00033143\n",
      "Trial 413:\n",
      "  Learning Rate: 0.011267189604325678\n",
      "  Sigma Multiplier: 0.9080891008387567\n",
      "  Initialization Multiplier: 0.6657770908305733\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.79it/s, loss=-0.000178, elapsed time=0.08, total time=12.1]\n",
      "[I 2025-06-07 13:57:48,870] Trial 413 finished with value: -0.00017783940223409152 and parameters: {'learning_rate': 0.011267189604325678, 'sigma_multiplier': 0.9080891008387567, 'num_layers': 2, 'initialization_multiplier': 0.6657770908305733}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 413 final loss: -0.00017784\n",
      "Trial 414:\n",
      "  Learning Rate: 0.020417819842008748\n",
      "  Sigma Multiplier: 0.46485966796259537\n",
      "  Initialization Multiplier: 0.5141842244586061\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.83it/s, loss=0.000376, elapsed time=0.15, total time=14.1]\n",
      "[I 2025-06-07 13:58:03,067] Trial 414 finished with value: 0.0003756003663420788 and parameters: {'learning_rate': 0.020417819842008748, 'sigma_multiplier': 0.46485966796259537, 'num_layers': 2, 'initialization_multiplier': 0.5141842244586061}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 414 final loss: 0.00037560\n",
      "Trial 415:\n",
      "  Learning Rate: 0.0016248170621675178\n",
      "  Sigma Multiplier: 1.025391922666261\n",
      "  Initialization Multiplier: 0.5628357117617759\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.58it/s, loss=-0.000032, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 13:58:14,491] Trial 415 finished with value: -3.152490229675406e-05 and parameters: {'learning_rate': 0.0016248170621675178, 'sigma_multiplier': 1.025391922666261, 'num_layers': 2, 'initialization_multiplier': 0.5628357117617759}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 415 final loss: -0.00003152\n",
      "Trial 416:\n",
      "  Learning Rate: 0.009038125975440679\n",
      "  Sigma Multiplier: 1.7565101805303396\n",
      "  Initialization Multiplier: 1.471358637895218\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.72it/s, loss=-0.000188, elapsed time=0.06, total time=10.5]\n",
      "[I 2025-06-07 13:58:25,050] Trial 416 finished with value: -0.00018791507889117146 and parameters: {'learning_rate': 0.009038125975440679, 'sigma_multiplier': 1.7565101805303396, 'num_layers': 2, 'initialization_multiplier': 1.471358637895218}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 416 final loss: -0.00018792\n",
      "Trial 417:\n",
      "  Learning Rate: 0.01646749605605015\n",
      "  Sigma Multiplier: 0.9723818743405845\n",
      "  Initialization Multiplier: 0.45914235248486035\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000380, elapsed time=0.1, total time=11.6] \n",
      "[I 2025-06-07 13:58:36,670] Trial 417 finished with value: -0.0003799681562428705 and parameters: {'learning_rate': 0.01646749605605015, 'sigma_multiplier': 0.9723818743405845, 'num_layers': 2, 'initialization_multiplier': 0.45914235248486035}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 417 final loss: -0.00037997\n",
      "Trial 418:\n",
      "  Learning Rate: 0.010374882817128442\n",
      "  Sigma Multiplier: 1.0657634096828847\n",
      "  Initialization Multiplier: 0.5840636039931794\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.49it/s, loss=-0.000353, elapsed time=0.05, total time=11.5]\n",
      "[I 2025-06-07 13:58:48,220] Trial 418 finished with value: -0.0003532305079582724 and parameters: {'learning_rate': 0.010374882817128442, 'sigma_multiplier': 1.0657634096828847, 'num_layers': 2, 'initialization_multiplier': 0.5840636039931794}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 418 final loss: -0.00035323\n",
      "Trial 419:\n",
      "  Learning Rate: 5.278892739073629e-05\n",
      "  Sigma Multiplier: 0.8246761890516148\n",
      "  Initialization Multiplier: 0.6339908103963784\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.31it/s, loss=0.095999, elapsed time=0.06, total time=12.6]\n",
      "[I 2025-06-07 13:59:00,827] Trial 419 finished with value: 0.09599914298398492 and parameters: {'learning_rate': 5.278892739073629e-05, 'sigma_multiplier': 0.8246761890516148, 'num_layers': 2, 'initialization_multiplier': 0.6339908103963784}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 419 final loss: 0.09599914\n",
      "Trial 420:\n",
      "  Learning Rate: 0.01356857926363592\n",
      "  Sigma Multiplier: 1.0034675763987706\n",
      "  Initialization Multiplier: 1.9746507947490524\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.12it/s, loss=-0.000047, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 13:59:12,610] Trial 420 finished with value: -4.681282998531291e-05 and parameters: {'learning_rate': 0.01356857926363592, 'sigma_multiplier': 1.0034675763987706, 'num_layers': 2, 'initialization_multiplier': 1.9746507947490524}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 420 final loss: -0.00004681\n",
      "Trial 421:\n",
      "  Learning Rate: 0.008329399925550677\n",
      "  Sigma Multiplier: 0.9478382087493603\n",
      "  Initialization Multiplier: 0.7007911160389813\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.10it/s, loss=-0.000271, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 13:59:24,529] Trial 421 finished with value: -0.0002711028547024553 and parameters: {'learning_rate': 0.008329399925550677, 'sigma_multiplier': 0.9478382087493603, 'num_layers': 2, 'initialization_multiplier': 0.7007911160389813}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 421 final loss: -0.00027110\n",
      "Trial 422:\n",
      "  Learning Rate: 0.0097517038534069\n",
      "  Sigma Multiplier: 1.041245046851373\n",
      "  Initialization Multiplier: 0.529703379592389\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.91it/s, loss=-0.000391, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 13:59:36,533] Trial 422 finished with value: -0.0003908594651854549 and parameters: {'learning_rate': 0.0097517038534069, 'sigma_multiplier': 1.041245046851373, 'num_layers': 2, 'initialization_multiplier': 0.529703379592389}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 422 final loss: -0.00039086\n",
      "Trial 423:\n",
      "  Learning Rate: 0.01184056165882762\n",
      "  Sigma Multiplier: 0.8924443396672987\n",
      "  Initialization Multiplier: 0.5047295068734352\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.75it/s, loss=-0.000315, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 13:59:48,680] Trial 423 finished with value: -0.00031512161515623614 and parameters: {'learning_rate': 0.01184056165882762, 'sigma_multiplier': 0.8924443396672987, 'num_layers': 2, 'initialization_multiplier': 0.5047295068734352}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 423 final loss: -0.00031512\n",
      "Trial 424:\n",
      "  Learning Rate: 0.014672861505758767\n",
      "  Sigma Multiplier: 0.9972690311787696\n",
      "  Initialization Multiplier: 0.6112982363802385\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.11it/s, loss=-0.000312, elapsed time=0.09, total time=11.7]\n",
      "[I 2025-06-07 14:00:00,457] Trial 424 finished with value: -0.00031163610792430964 and parameters: {'learning_rate': 0.014672861505758767, 'sigma_multiplier': 0.9972690311787696, 'num_layers': 2, 'initialization_multiplier': 0.6112982363802385}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 424 final loss: -0.00031164\n",
      "Trial 425:\n",
      "  Learning Rate: 0.00849409133538556\n",
      "  Sigma Multiplier: 1.0835454268969946\n",
      "  Initialization Multiplier: 0.5550717376621254\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.61it/s, loss=-0.000376, elapsed time=0.04, total time=9.34]\n",
      "[I 2025-06-07 14:00:09,838] Trial 425 finished with value: -0.00037593280480041435 and parameters: {'learning_rate': 0.00849409133538556, 'sigma_multiplier': 1.0835454268969946, 'num_layers': 1, 'initialization_multiplier': 0.5550717376621254}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 425 final loss: -0.00037593\n",
      "Trial 426:\n",
      "  Learning Rate: 0.025781325688460883\n",
      "  Sigma Multiplier: 0.964878912503448\n",
      "  Initialization Multiplier: 0.466892534023612\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.72it/s, loss=-0.000237, elapsed time=0.08, total time=12.1]\n",
      "[I 2025-06-07 14:00:22,034] Trial 426 finished with value: -0.00023658288306308996 and parameters: {'learning_rate': 0.025781325688460883, 'sigma_multiplier': 0.964878912503448, 'num_layers': 2, 'initialization_multiplier': 0.466892534023612}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 426 final loss: -0.00023658\n",
      "Trial 427:\n",
      "  Learning Rate: 0.012046086170968175\n",
      "  Sigma Multiplier: 1.0312691921383956\n",
      "  Initialization Multiplier: 0.6578352898360017\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.27it/s, loss=-0.000379, elapsed time=0.09, total time=11.7]\n",
      "[I 2025-06-07 14:00:33,728] Trial 427 finished with value: -0.0003790839745284193 and parameters: {'learning_rate': 0.012046086170968175, 'sigma_multiplier': 1.0312691921383956, 'num_layers': 2, 'initialization_multiplier': 0.6578352898360017}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 427 final loss: -0.00037908\n",
      "Trial 428:\n",
      "  Learning Rate: 0.0076283705479538305\n",
      "  Sigma Multiplier: 1.1339501701503976\n",
      "  Initialization Multiplier: 0.6032913686677991\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.28it/s, loss=-0.000385, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 14:00:44,625] Trial 428 finished with value: -0.00038528260407467654 and parameters: {'learning_rate': 0.0076283705479538305, 'sigma_multiplier': 1.1339501701503976, 'num_layers': 2, 'initialization_multiplier': 0.6032913686677991}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 428 final loss: -0.00038528\n",
      "Trial 429:\n",
      "  Learning Rate: 0.009989152199868269\n",
      "  Sigma Multiplier: 0.9264925324263806\n",
      "  Initialization Multiplier: 0.535399477217125\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.16it/s, loss=-0.000388, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:00:56,385] Trial 429 finished with value: -0.00038799545869294173 and parameters: {'learning_rate': 0.009989152199868269, 'sigma_multiplier': 0.9264925324263806, 'num_layers': 2, 'initialization_multiplier': 0.535399477217125}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 429 final loss: -0.00038800\n",
      "Trial 430:\n",
      "  Learning Rate: 0.015546837484028964\n",
      "  Sigma Multiplier: 0.9980602019143109\n",
      "  Initialization Multiplier: 0.7372303820801657\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.74it/s, loss=-0.000087, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:01:08,489] Trial 430 finished with value: -8.66818366709186e-05 and parameters: {'learning_rate': 0.015546837484028964, 'sigma_multiplier': 0.9980602019143109, 'num_layers': 2, 'initialization_multiplier': 0.7372303820801657}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 430 final loss: -0.00008668\n",
      "Trial 431:\n",
      "  Learning Rate: 0.011185085133284778\n",
      "  Sigma Multiplier: 1.0503128018130088\n",
      "  Initialization Multiplier: 0.49463226437880314\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.00it/s, loss=-0.000365, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 14:01:19,536] Trial 431 finished with value: -0.00036484623129045884 and parameters: {'learning_rate': 0.011185085133284778, 'sigma_multiplier': 1.0503128018130088, 'num_layers': 2, 'initialization_multiplier': 0.49463226437880314}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 431 final loss: -0.00036485\n",
      "Trial 432:\n",
      "  Learning Rate: 0.008964184082814502\n",
      "  Sigma Multiplier: 0.9580192141564436\n",
      "  Initialization Multiplier: 0.585671580127659\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000368, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:01:31,008] Trial 432 finished with value: -0.00036824393119154643 and parameters: {'learning_rate': 0.008964184082814502, 'sigma_multiplier': 0.9580192141564436, 'num_layers': 2, 'initialization_multiplier': 0.585671580127659}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 432 final loss: -0.00036824\n",
      "Trial 433:\n",
      "  Learning Rate: 0.018102268064266052\n",
      "  Sigma Multiplier: 1.4761237582609554\n",
      "  Initialization Multiplier: 0.6476236077688493\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.24it/s, loss=-0.000215, elapsed time=0.08, total time=12.6]\n",
      "[I 2025-06-07 14:01:43,626] Trial 433 finished with value: -0.00021516912612768363 and parameters: {'learning_rate': 0.018102268064266052, 'sigma_multiplier': 1.4761237582609554, 'num_layers': 3, 'initialization_multiplier': 0.6476236077688493}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 433 final loss: -0.00021517\n",
      "Trial 434:\n",
      "  Learning Rate: 0.007501327158707412\n",
      "  Sigma Multiplier: 1.1072640483609215\n",
      "  Initialization Multiplier: 0.5645783429989081\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000325, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:01:54,874] Trial 434 finished with value: -0.00032548099030327293 and parameters: {'learning_rate': 0.007501327158707412, 'sigma_multiplier': 1.1072640483609215, 'num_layers': 2, 'initialization_multiplier': 0.5645783429989081}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 434 final loss: -0.00032548\n",
      "Trial 435:\n",
      "  Learning Rate: 0.012702943780243134\n",
      "  Sigma Multiplier: 0.8511043840309128\n",
      "  Initialization Multiplier: 0.5015447758898913\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.31it/s, loss=-0.000309, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 14:02:07,406] Trial 435 finished with value: -0.0003090226148845086 and parameters: {'learning_rate': 0.012702943780243134, 'sigma_multiplier': 0.8511043840309128, 'num_layers': 2, 'initialization_multiplier': 0.5015447758898913}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 435 final loss: -0.00030902\n",
      "Trial 436:\n",
      "  Learning Rate: 0.010021130637133264\n",
      "  Sigma Multiplier: 1.0092309109181008\n",
      "  Initialization Multiplier: 0.44691937911278345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.45it/s, loss=-0.000365, elapsed time=0.09, total time=11.5]\n",
      "[I 2025-06-07 14:02:18,908] Trial 436 finished with value: -0.00036456123774823327 and parameters: {'learning_rate': 0.010021130637133264, 'sigma_multiplier': 1.0092309109181008, 'num_layers': 2, 'initialization_multiplier': 0.44691937911278345}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 436 final loss: -0.00036456\n",
      "Trial 437:\n",
      "  Learning Rate: 0.007949954599579572\n",
      "  Sigma Multiplier: 0.9094233216299208\n",
      "  Initialization Multiplier: 0.6243308282605055\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.98it/s, loss=-0.000362, elapsed time=0.05, total time=11.8]\n",
      "[I 2025-06-07 14:02:30,795] Trial 437 finished with value: -0.00036156656132460774 and parameters: {'learning_rate': 0.007949954599579572, 'sigma_multiplier': 0.9094233216299208, 'num_layers': 2, 'initialization_multiplier': 0.6243308282605055}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 437 final loss: -0.00036157\n",
      "Trial 438:\n",
      "  Learning Rate: 0.013579572838438381\n",
      "  Sigma Multiplier: 0.9719562927532187\n",
      "  Initialization Multiplier: 1.2335916332900836\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.88it/s, loss=-0.000192, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 14:02:42,821] Trial 438 finished with value: -0.00019155539335002266 and parameters: {'learning_rate': 0.013579572838438381, 'sigma_multiplier': 0.9719562927532187, 'num_layers': 2, 'initialization_multiplier': 1.2335916332900836}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 438 final loss: -0.00019156\n",
      "Trial 439:\n",
      "  Learning Rate: 0.0066139460134675915\n",
      "  Sigma Multiplier: 1.0697710939633793\n",
      "  Initialization Multiplier: 0.5371189723103497\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000362, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:02:54,276] Trial 439 finished with value: -0.0003615502164425759 and parameters: {'learning_rate': 0.0066139460134675915, 'sigma_multiplier': 1.0697710939633793, 'num_layers': 2, 'initialization_multiplier': 0.5371189723103497}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 439 final loss: -0.00036155\n",
      "Trial 440:\n",
      "  Learning Rate: 0.010705512433578184\n",
      "  Sigma Multiplier: 1.023693807247729\n",
      "  Initialization Multiplier: 0.6866159127633044\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.60it/s, loss=-0.000402, elapsed time=0.06, total time=12.3]\n",
      "[I 2025-06-07 14:03:06,611] Trial 440 finished with value: -0.00040178205349216555 and parameters: {'learning_rate': 0.010705512433578184, 'sigma_multiplier': 1.023693807247729, 'num_layers': 2, 'initialization_multiplier': 0.6866159127633044}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 440 final loss: -0.00040178\n",
      "Trial 441:\n",
      "  Learning Rate: 0.021389215410853788\n",
      "  Sigma Multiplier: 0.9353218033473227\n",
      "  Initialization Multiplier: 0.9130648305629422\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.44it/s, loss=-0.000185, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 14:03:19,046] Trial 441 finished with value: -0.00018500968395823678 and parameters: {'learning_rate': 0.021389215410853788, 'sigma_multiplier': 0.9353218033473227, 'num_layers': 2, 'initialization_multiplier': 0.9130648305629422}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 441 final loss: -0.00018501\n",
      "Trial 442:\n",
      "  Learning Rate: 0.009351698384392359\n",
      "  Sigma Multiplier: 0.9849459068279064\n",
      "  Initialization Multiplier: 0.5900902903771736\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000386, elapsed time=0.08, total time=11.5]\n",
      "[I 2025-06-07 14:03:30,567] Trial 442 finished with value: -0.000386126534409909 and parameters: {'learning_rate': 0.009351698384392359, 'sigma_multiplier': 0.9849459068279064, 'num_layers': 2, 'initialization_multiplier': 0.5900902903771736}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 442 final loss: -0.00038613\n",
      "Trial 443:\n",
      "  Learning Rate: 0.012893860999810821\n",
      "  Sigma Multiplier: 1.0602160914638379\n",
      "  Initialization Multiplier: 0.5565165911310748\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.55it/s, loss=-0.000307, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:03:41,975] Trial 443 finished with value: -0.0003069411248841213 and parameters: {'learning_rate': 0.012893860999810821, 'sigma_multiplier': 1.0602160914638379, 'num_layers': 2, 'initialization_multiplier': 0.5565165911310748}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 443 final loss: -0.00030694\n",
      "Trial 444:\n",
      "  Learning Rate: 0.01613421338265001\n",
      "  Sigma Multiplier: 0.8998220406454841\n",
      "  Initialization Multiplier: 0.48548145161696926\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.99it/s, loss=-0.000276, elapsed time=0.07, total time=11.9]\n",
      "[I 2025-06-07 14:03:53,899] Trial 444 finished with value: -0.00027600521213225963 and parameters: {'learning_rate': 0.01613421338265001, 'sigma_multiplier': 0.8998220406454841, 'num_layers': 2, 'initialization_multiplier': 0.48548145161696926}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 444 final loss: -0.00027601\n",
      "Trial 445:\n",
      "  Learning Rate: 0.0025691842673659817\n",
      "  Sigma Multiplier: 0.27169319455842955\n",
      "  Initialization Multiplier: 0.6241053031825108\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.04it/s, loss=0.000098, elapsed time=0.09, total time=15.2] \n",
      "[I 2025-06-07 14:04:09,197] Trial 445 finished with value: 9.808787133069787e-05 and parameters: {'learning_rate': 0.0025691842673659817, 'sigma_multiplier': 0.27169319455842955, 'num_layers': 2, 'initialization_multiplier': 0.6241053031825108}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 445 final loss: 0.00009809\n",
      "Trial 446:\n",
      "  Learning Rate: 0.008079094387805717\n",
      "  Sigma Multiplier: 0.7678448493990808\n",
      "  Initialization Multiplier: 0.5187114142630018\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.09it/s, loss=-0.000251, elapsed time=0.06, total time=12.7]\n",
      "[I 2025-06-07 14:04:21,950] Trial 446 finished with value: -0.0002513741369903367 and parameters: {'learning_rate': 0.008079094387805717, 'sigma_multiplier': 0.7678448493990808, 'num_layers': 2, 'initialization_multiplier': 0.5187114142630018}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 446 final loss: -0.00025137\n",
      "Trial 447:\n",
      "  Learning Rate: 0.0008910757044518747\n",
      "  Sigma Multiplier: 1.0229729374381866\n",
      "  Initialization Multiplier: 0.5887623531930465\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.71it/s, loss=0.007102, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:04:33,235] Trial 447 finished with value: 0.007102440013395235 and parameters: {'learning_rate': 0.0008910757044518747, 'sigma_multiplier': 1.0229729374381866, 'num_layers': 2, 'initialization_multiplier': 0.5887623531930465}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 447 final loss: 0.00710244\n",
      "Trial 448:\n",
      "  Learning Rate: 0.011267245033664214\n",
      "  Sigma Multiplier: 0.9569709821480505\n",
      "  Initialization Multiplier: 0.45914860693046794\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.40it/s, loss=-0.000329, elapsed time=0.08, total time=11.5]\n",
      "[I 2025-06-07 14:04:44,801] Trial 448 finished with value: -0.0003289364868404477 and parameters: {'learning_rate': 0.011267245033664214, 'sigma_multiplier': 0.9569709821480505, 'num_layers': 2, 'initialization_multiplier': 0.45914860693046794}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 448 final loss: -0.00032894\n",
      "Trial 449:\n",
      "  Learning Rate: 0.006578094883532394\n",
      "  Sigma Multiplier: 1.1085153935881358\n",
      "  Initialization Multiplier: 0.6727298450804675\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.87it/s, loss=-0.000413, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 14:04:56,030] Trial 449 finished with value: -0.00041251974614338343 and parameters: {'learning_rate': 0.006578094883532394, 'sigma_multiplier': 1.1085153935881358, 'num_layers': 2, 'initialization_multiplier': 0.6727298450804675}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 449 final loss: -0.00041252\n",
      "Trial 450:\n",
      "  Learning Rate: 0.009319625106856766\n",
      "  Sigma Multiplier: 0.9866453567256805\n",
      "  Initialization Multiplier: 0.5461355746377008\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000439, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:05:07,508] Trial 450 finished with value: -0.0004391191814192027 and parameters: {'learning_rate': 0.009319625106856766, 'sigma_multiplier': 0.9866453567256805, 'num_layers': 2, 'initialization_multiplier': 0.5461355746377008}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 450 final loss: -0.00043912\n",
      "Trial 451:\n",
      "  Learning Rate: 0.00860473469079008\n",
      "  Sigma Multiplier: 0.8830744407247145\n",
      "  Initialization Multiplier: 0.5204380802928427\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.94it/s, loss=-0.000323, elapsed time=0.14, total time=14.1]\n",
      "[I 2025-06-07 14:05:21,637] Trial 451 finished with value: -0.0003225242708302908 and parameters: {'learning_rate': 0.00860473469079008, 'sigma_multiplier': 0.8830744407247145, 'num_layers': 2, 'initialization_multiplier': 0.5204380802928427}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 451 final loss: -0.00032252\n",
      "Trial 452:\n",
      "  Learning Rate: 0.007179988964863914\n",
      "  Sigma Multiplier: 0.9854505205746404\n",
      "  Initialization Multiplier: 0.43388569557597356\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.78it/s, loss=-0.000376, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 14:05:33,753] Trial 452 finished with value: -0.0003761339184613912 and parameters: {'learning_rate': 0.007179988964863914, 'sigma_multiplier': 0.9854505205746404, 'num_layers': 2, 'initialization_multiplier': 0.43388569557597356}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 452 final loss: -0.00037613\n",
      "Trial 453:\n",
      "  Learning Rate: 0.008925449661432237\n",
      "  Sigma Multiplier: 0.937599172227213\n",
      "  Initialization Multiplier: 0.6233611076301312\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.86it/s, loss=-0.000319, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 14:05:45,761] Trial 453 finished with value: -0.0003191429402938989 and parameters: {'learning_rate': 0.008925449661432237, 'sigma_multiplier': 0.937599172227213, 'num_layers': 2, 'initialization_multiplier': 0.6233611076301312}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 453 final loss: -0.00031914\n",
      "Trial 454:\n",
      "  Learning Rate: 0.009805794026480854\n",
      "  Sigma Multiplier: 1.0480689759917197\n",
      "  Initialization Multiplier: 0.5749814551222553\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.40it/s, loss=-0.000424, elapsed time=0.09, total time=11.5]\n",
      "[I 2025-06-07 14:05:57,350] Trial 454 finished with value: -0.0004237234345419606 and parameters: {'learning_rate': 0.009805794026480854, 'sigma_multiplier': 1.0480689759917197, 'num_layers': 2, 'initialization_multiplier': 0.5749814551222553}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 454 final loss: -0.00042372\n",
      "Trial 455:\n",
      "  Learning Rate: 0.00637890004248206\n",
      "  Sigma Multiplier: 0.9811949415842308\n",
      "  Initialization Multiplier: 0.7152368064859743\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.87it/s, loss=-0.000265, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:06:09,486] Trial 455 finished with value: -0.000264736558225541 and parameters: {'learning_rate': 0.00637890004248206, 'sigma_multiplier': 0.9811949415842308, 'num_layers': 2, 'initialization_multiplier': 0.7152368064859743}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 455 final loss: -0.00026474\n",
      "Trial 456:\n",
      "  Learning Rate: 0.0081934682988772\n",
      "  Sigma Multiplier: 1.0814788183044752\n",
      "  Initialization Multiplier: 0.4879490207454491\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000350, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:06:20,984] Trial 456 finished with value: -0.00035025580099906205 and parameters: {'learning_rate': 0.0081934682988772, 'sigma_multiplier': 1.0814788183044752, 'num_layers': 2, 'initialization_multiplier': 0.4879490207454491}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 456 final loss: -0.00035026\n",
      "Trial 457:\n",
      "  Learning Rate: 0.010300685660775195\n",
      "  Sigma Multiplier: 1.0192964825902788\n",
      "  Initialization Multiplier: 0.5451409405435107\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.60it/s, loss=-0.000394, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:06:33,324] Trial 457 finished with value: -0.0003936957760613875 and parameters: {'learning_rate': 0.010300685660775195, 'sigma_multiplier': 1.0192964825902788, 'num_layers': 2, 'initialization_multiplier': 0.5451409405435107}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 457 final loss: -0.00039370\n",
      "Trial 458:\n",
      "  Learning Rate: 0.0074660060032102245\n",
      "  Sigma Multiplier: 0.932765489661106\n",
      "  Initialization Multiplier: 0.6566899458086729\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.53it/s, loss=-0.000261, elapsed time=0.05, total time=12.2]\n",
      "[I 2025-06-07 14:06:45,618] Trial 458 finished with value: -0.00026112003005358353 and parameters: {'learning_rate': 0.0074660060032102245, 'sigma_multiplier': 0.932765489661106, 'num_layers': 2, 'initialization_multiplier': 0.6566899458086729}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 458 final loss: -0.00026112\n",
      "Trial 459:\n",
      "  Learning Rate: 0.0005084193541020148\n",
      "  Sigma Multiplier: 0.9732363592797088\n",
      "  Initialization Multiplier: 0.5870585304791867\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.18it/s, loss=0.023696, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 14:06:57,370] Trial 459 finished with value: 0.023696212657234043 and parameters: {'learning_rate': 0.0005084193541020148, 'sigma_multiplier': 0.9732363592797088, 'num_layers': 2, 'initialization_multiplier': 0.5870585304791867}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 459 final loss: 0.02369621\n",
      "Trial 460:\n",
      "  Learning Rate: 0.0013876908406211992\n",
      "  Sigma Multiplier: 1.5749442216001903\n",
      "  Initialization Multiplier: 1.7424614539857\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.31it/s, loss=0.039156, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 14:07:08,254] Trial 460 finished with value: 0.03915582696489354 and parameters: {'learning_rate': 0.0013876908406211992, 'sigma_multiplier': 1.5749442216001903, 'num_layers': 2, 'initialization_multiplier': 1.7424614539857}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 460 final loss: 0.03915583\n",
      "Trial 461:\n",
      "  Learning Rate: 0.011875958330595437\n",
      "  Sigma Multiplier: 0.8273788084148306\n",
      "  Initialization Multiplier: 1.3313776273921802\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.09it/s, loss=0.000140, elapsed time=0.08, total time=12.7] \n",
      "[I 2025-06-07 14:07:20,979] Trial 461 finished with value: 0.00013997048519073568 and parameters: {'learning_rate': 0.011875958330595437, 'sigma_multiplier': 0.8273788084148306, 'num_layers': 2, 'initialization_multiplier': 1.3313776273921802}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 461 final loss: 0.00013997\n",
      "Trial 462:\n",
      "  Learning Rate: 0.005612047433197327\n",
      "  Sigma Multiplier: 1.040245539068071\n",
      "  Initialization Multiplier: 0.6171338123062193\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:16<00:00,  9.13it/s, loss=-0.000050, elapsed time=0.1, total time=16.8] \n",
      "[I 2025-06-07 14:07:37,819] Trial 462 finished with value: -5.045451800570083e-05 and parameters: {'learning_rate': 0.005612047433197327, 'sigma_multiplier': 1.040245539068071, 'num_layers': 4, 'initialization_multiplier': 0.6171338123062193}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 462 final loss: -0.00005045\n",
      "Trial 463:\n",
      "  Learning Rate: 0.009355603492889785\n",
      "  Sigma Multiplier: 0.8857036952210808\n",
      "  Initialization Multiplier: 0.5300040736706151\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.61it/s, loss=-0.000338, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 14:07:50,267] Trial 463 finished with value: -0.00033806090837325774 and parameters: {'learning_rate': 0.009355603492889785, 'sigma_multiplier': 0.8857036952210808, 'num_layers': 2, 'initialization_multiplier': 0.5300040736706151}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 463 final loss: -0.00033806\n",
      "Trial 464:\n",
      "  Learning Rate: 0.014323131624548626\n",
      "  Sigma Multiplier: 1.1289224371423683\n",
      "  Initialization Multiplier: 0.9851872757377852\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.81it/s, loss=-0.000313, elapsed time=0.08, total time=12.1]\n",
      "[I 2025-06-07 14:08:02,446] Trial 464 finished with value: -0.0003131223603096801 and parameters: {'learning_rate': 0.014323131624548626, 'sigma_multiplier': 1.1289224371423683, 'num_layers': 2, 'initialization_multiplier': 0.9851872757377852}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 464 final loss: -0.00031312\n",
      "Trial 465:\n",
      "  Learning Rate: 0.0022256427612357896\n",
      "  Sigma Multiplier: 1.0003143090849136\n",
      "  Initialization Multiplier: 0.4850697041067369\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.69it/s, loss=-0.000399, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:08:14,620] Trial 465 finished with value: -0.0003993494842876193 and parameters: {'learning_rate': 0.0022256427612357896, 'sigma_multiplier': 1.0003143090849136, 'num_layers': 2, 'initialization_multiplier': 0.4850697041067369}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 465 final loss: -0.00039935\n",
      "Trial 466:\n",
      "  Learning Rate: 0.007119880657106015\n",
      "  Sigma Multiplier: 0.9409829600208847\n",
      "  Initialization Multiplier: 0.5618287845354375\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.76it/s, loss=-0.000316, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 14:08:26,782] Trial 466 finished with value: -0.00031583697994024153 and parameters: {'learning_rate': 0.007119880657106015, 'sigma_multiplier': 0.9409829600208847, 'num_layers': 2, 'initialization_multiplier': 0.5618287845354375}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 466 final loss: -0.00031584\n",
      "Trial 467:\n",
      "  Learning Rate: 0.01067696365989676\n",
      "  Sigma Multiplier: 1.0849607442037452\n",
      "  Initialization Multiplier: 0.6536421397824745\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.70it/s, loss=-0.000341, elapsed time=0.15, total time=11.4]\n",
      "[I 2025-06-07 14:08:38,199] Trial 467 finished with value: -0.00034063343930049205 and parameters: {'learning_rate': 0.01067696365989676, 'sigma_multiplier': 1.0849607442037452, 'num_layers': 2, 'initialization_multiplier': 0.6536421397824745}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 467 final loss: -0.00034063\n",
      "Trial 468:\n",
      "  Learning Rate: 0.008439634398777133\n",
      "  Sigma Multiplier: 1.016739142116299\n",
      "  Initialization Multiplier: 0.5969642821104767\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.45it/s, loss=-0.000351, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:08:49,653] Trial 468 finished with value: -0.0003512849297464029 and parameters: {'learning_rate': 0.008439634398777133, 'sigma_multiplier': 1.016739142116299, 'num_layers': 2, 'initialization_multiplier': 0.5969642821104767}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 468 final loss: -0.00035128\n",
      "Trial 469:\n",
      "  Learning Rate: 0.018149055672037676\n",
      "  Sigma Multiplier: 0.9618122102491936\n",
      "  Initialization Multiplier: 0.4459655428230778\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000301, elapsed time=0.1, total time=11.9] \n",
      "[I 2025-06-07 14:09:01,588] Trial 469 finished with value: -0.00030117001452236 and parameters: {'learning_rate': 0.018149055672037676, 'sigma_multiplier': 0.9618122102491936, 'num_layers': 2, 'initialization_multiplier': 0.4459655428230778}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 469 final loss: -0.00030117\n",
      "Trial 470:\n",
      "  Learning Rate: 0.012828145158466092\n",
      "  Sigma Multiplier: 1.0551876278650762\n",
      "  Initialization Multiplier: 0.5206686632591719\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:18<00:00,  8.28it/s, loss=-0.000094, elapsed time=0.12, total time=18.5]\n",
      "[I 2025-06-07 14:09:20,205] Trial 470 finished with value: -9.353888397926756e-05 and parameters: {'learning_rate': 0.012828145158466092, 'sigma_multiplier': 1.0551876278650762, 'num_layers': 5, 'initialization_multiplier': 0.5206686632591719}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 470 final loss: -0.00009354\n",
      "Trial 471:\n",
      "  Learning Rate: 0.003259733190918939\n",
      "  Sigma Multiplier: 0.9265908957421362\n",
      "  Initialization Multiplier: 0.5663693508860983\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.96it/s, loss=-0.000266, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 14:09:32,213] Trial 471 finished with value: -0.00026563182680414664 and parameters: {'learning_rate': 0.003259733190918939, 'sigma_multiplier': 0.9265908957421362, 'num_layers': 2, 'initialization_multiplier': 0.5663693508860983}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 471 final loss: -0.00026563\n",
      "Trial 472:\n",
      "  Learning Rate: 0.009843718450626909\n",
      "  Sigma Multiplier: 0.9896550970484164\n",
      "  Initialization Multiplier: 0.681752910904558\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.81it/s, loss=-0.000322, elapsed time=0.09, total time=12.1]\n",
      "[I 2025-06-07 14:09:44,346] Trial 472 finished with value: -0.000321554995531442 and parameters: {'learning_rate': 0.009843718450626909, 'sigma_multiplier': 0.9896550970484164, 'num_layers': 2, 'initialization_multiplier': 0.681752910904558}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 472 final loss: -0.00032155\n",
      "Trial 473:\n",
      "  Learning Rate: 0.006361001062140426\n",
      "  Sigma Multiplier: 0.8618053186718336\n",
      "  Initialization Multiplier: 0.636254088435876\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.38it/s, loss=-0.000361, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 14:09:56,901] Trial 473 finished with value: -0.0003611798152422055 and parameters: {'learning_rate': 0.006361001062140426, 'sigma_multiplier': 0.8618053186718336, 'num_layers': 2, 'initialization_multiplier': 0.636254088435876}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 473 final loss: -0.00036118\n",
      "Trial 474:\n",
      "  Learning Rate: 0.015491279404655507\n",
      "  Sigma Multiplier: 1.0312438939417106\n",
      "  Initialization Multiplier: 0.4225416881087153\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.12it/s, loss=-0.000409, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:10:08,750] Trial 474 finished with value: -0.0004093321759022802 and parameters: {'learning_rate': 0.015491279404655507, 'sigma_multiplier': 1.0312438939417106, 'num_layers': 2, 'initialization_multiplier': 0.4225416881087153}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 474 final loss: -0.00040933\n",
      "Trial 475:\n",
      "  Learning Rate: 0.00862940792343032\n",
      "  Sigma Multiplier: 0.8990808395790644\n",
      "  Initialization Multiplier: 0.5047447345810995\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.85it/s, loss=-0.000261, elapsed time=0.08, total time=11.9]\n",
      "[I 2025-06-07 14:10:20,751] Trial 475 finished with value: -0.0002611680387408477 and parameters: {'learning_rate': 0.00862940792343032, 'sigma_multiplier': 0.8990808395790644, 'num_layers': 2, 'initialization_multiplier': 0.5047447345810995}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 475 final loss: -0.00026117\n",
      "Trial 476:\n",
      "  Learning Rate: 0.011416818296322422\n",
      "  Sigma Multiplier: 1.093612823181493\n",
      "  Initialization Multiplier: 0.6110125756959717\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.45it/s, loss=-0.000360, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:10:32,272] Trial 476 finished with value: -0.0003604707603023599 and parameters: {'learning_rate': 0.011416818296322422, 'sigma_multiplier': 1.093612823181493, 'num_layers': 2, 'initialization_multiplier': 0.6110125756959717}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 476 final loss: -0.00036047\n",
      "Trial 477:\n",
      "  Learning Rate: 9.627939780973241e-05\n",
      "  Sigma Multiplier: 0.9920976159326036\n",
      "  Initialization Multiplier: 0.7479596703035272\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=0.113348, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:10:43,763] Trial 477 finished with value: 0.11334773040447617 and parameters: {'learning_rate': 9.627939780973241e-05, 'sigma_multiplier': 0.9920976159326036, 'num_layers': 2, 'initialization_multiplier': 0.7479596703035272}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 477 final loss: 0.11334773\n",
      "Trial 478:\n",
      "  Learning Rate: 0.004697136247185719\n",
      "  Sigma Multiplier: 1.0536900115711736\n",
      "  Initialization Multiplier: 0.5360600136634551\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.68it/s, loss=-0.000286, elapsed time=0.07, total time=9.87]\n",
      "[I 2025-06-07 14:10:53,669] Trial 478 finished with value: -0.00028625177127448667 and parameters: {'learning_rate': 0.004697136247185719, 'sigma_multiplier': 1.0536900115711736, 'num_layers': 1, 'initialization_multiplier': 0.5360600136634551}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 478 final loss: -0.00028625\n",
      "Trial 479:\n",
      "  Learning Rate: 0.04853941514014136\n",
      "  Sigma Multiplier: 0.9576483873328091\n",
      "  Initialization Multiplier: 0.5775530965477912\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.17it/s, loss=-0.000288, elapsed time=0.08, total time=11.7]\n",
      "[I 2025-06-07 14:11:05,438] Trial 479 finished with value: -0.00028756284439728326 and parameters: {'learning_rate': 0.04853941514014136, 'sigma_multiplier': 0.9576483873328091, 'num_layers': 2, 'initialization_multiplier': 0.5775530965477912}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 479 final loss: -0.00028756\n",
      "Trial 480:\n",
      "  Learning Rate: 0.007115039284996518\n",
      "  Sigma Multiplier: 1.0273779821428661\n",
      "  Initialization Multiplier: 0.46348225070511967\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000389, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:11:16,900] Trial 480 finished with value: -0.0003887184357222933 and parameters: {'learning_rate': 0.007115039284996518, 'sigma_multiplier': 1.0273779821428661, 'num_layers': 2, 'initialization_multiplier': 0.46348225070511967}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 480 final loss: -0.00038872\n",
      "Trial 481:\n",
      "  Learning Rate: 0.01337482595289105\n",
      "  Sigma Multiplier: 0.9216039653816525\n",
      "  Initialization Multiplier: 0.551267543109294\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.74it/s, loss=-0.000224, elapsed time=0.09, total time=12.1]\n",
      "[I 2025-06-07 14:11:29,050] Trial 481 finished with value: -0.00022371449010661005 and parameters: {'learning_rate': 0.01337482595289105, 'sigma_multiplier': 0.9216039653816525, 'num_layers': 2, 'initialization_multiplier': 0.551267543109294}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 481 final loss: -0.00022371\n",
      "Trial 482:\n",
      "  Learning Rate: 0.0059083451850969245\n",
      "  Sigma Multiplier: 1.1300056422161606\n",
      "  Initialization Multiplier: 0.4906920643471064\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.42it/s, loss=-0.000345, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 14:11:40,638] Trial 482 finished with value: -0.00034475661756339207 and parameters: {'learning_rate': 0.0059083451850969245, 'sigma_multiplier': 1.1300056422161606, 'num_layers': 2, 'initialization_multiplier': 0.4906920643471064}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 482 final loss: -0.00034476\n",
      "Trial 483:\n",
      "  Learning Rate: 0.010384736598365554\n",
      "  Sigma Multiplier: 0.9754278365243632\n",
      "  Initialization Multiplier: 0.7018930270523576\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000365, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:11:52,287] Trial 483 finished with value: -0.0003648255340056389 and parameters: {'learning_rate': 0.010384736598365554, 'sigma_multiplier': 0.9754278365243632, 'num_layers': 2, 'initialization_multiplier': 0.7018930270523576}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 483 final loss: -0.00036483\n",
      "Trial 484:\n",
      "  Learning Rate: 0.008807529777852052\n",
      "  Sigma Multiplier: 1.010833499770241\n",
      "  Initialization Multiplier: 0.6356151004671999\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000345, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:12:04,147] Trial 484 finished with value: -0.0003447157212471679 and parameters: {'learning_rate': 0.008807529777852052, 'sigma_multiplier': 1.010833499770241, 'num_layers': 2, 'initialization_multiplier': 0.6356151004671999}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 484 final loss: -0.00034472\n",
      "Trial 485:\n",
      "  Learning Rate: 0.007984667541756222\n",
      "  Sigma Multiplier: 1.0703366169214472\n",
      "  Initialization Multiplier: 0.593700525359195\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000284, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:12:16,037] Trial 485 finished with value: -0.0002836667643379795 and parameters: {'learning_rate': 0.007984667541756222, 'sigma_multiplier': 1.0703366169214472, 'num_layers': 2, 'initialization_multiplier': 0.593700525359195}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 485 final loss: -0.00028367\n",
      "Trial 486:\n",
      "  Learning Rate: 0.0119218374682121\n",
      "  Sigma Multiplier: 0.9509109704027444\n",
      "  Initialization Multiplier: 0.41176584613531325\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000340, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 14:12:27,888] Trial 486 finished with value: -0.0003399199819462771 and parameters: {'learning_rate': 0.0119218374682121, 'sigma_multiplier': 0.9509109704027444, 'num_layers': 2, 'initialization_multiplier': 0.41176584613531325}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 486 final loss: -0.00033992\n",
      "Trial 487:\n",
      "  Learning Rate: 0.015483594301279578\n",
      "  Sigma Multiplier: 0.9955617652551723\n",
      "  Initialization Multiplier: 0.5263325694662895\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000376, elapsed time=0.1, total time=12.1] \n",
      "[I 2025-06-07 14:12:40,145] Trial 487 finished with value: -0.0003755754006264699 and parameters: {'learning_rate': 0.015483594301279578, 'sigma_multiplier': 0.9955617652551723, 'num_layers': 2, 'initialization_multiplier': 0.5263325694662895}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 487 final loss: -0.00037558\n",
      "Trial 488:\n",
      "  Learning Rate: 0.009874002691611403\n",
      "  Sigma Multiplier: 0.9081284457158967\n",
      "  Initialization Multiplier: 0.6017633649650375\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.22it/s, loss=-0.000350, elapsed time=0.1, total time=12.7] \n",
      "[I 2025-06-07 14:12:52,867] Trial 488 finished with value: -0.0003496816113316241 and parameters: {'learning_rate': 0.009874002691611403, 'sigma_multiplier': 0.9081284457158967, 'num_layers': 2, 'initialization_multiplier': 0.6017633649650375}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 488 final loss: -0.00034968\n",
      "Trial 489:\n",
      "  Learning Rate: 0.0073567990530811755\n",
      "  Sigma Multiplier: 1.0518631032052372\n",
      "  Initialization Multiplier: 0.5564701655792373\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.43it/s, loss=-0.000313, elapsed time=0.07, total time=12.4]\n",
      "[I 2025-06-07 14:13:05,282] Trial 489 finished with value: -0.000312631661972128 and parameters: {'learning_rate': 0.0073567990530811755, 'sigma_multiplier': 1.0518631032052372, 'num_layers': 2, 'initialization_multiplier': 0.5564701655792373}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 489 final loss: -0.00031263\n",
      "Trial 490:\n",
      "  Learning Rate: 0.013645237885761248\n",
      "  Sigma Multiplier: 0.9531704391585383\n",
      "  Initialization Multiplier: 0.6576572072030507\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.44it/s, loss=-0.000312, elapsed time=0.07, total time=12.4]\n",
      "[I 2025-06-07 14:13:17,749] Trial 490 finished with value: -0.0003123802579643581 and parameters: {'learning_rate': 0.013645237885761248, 'sigma_multiplier': 0.9531704391585383, 'num_layers': 2, 'initialization_multiplier': 0.6576572072030507}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 490 final loss: -0.00031238\n",
      "Trial 491:\n",
      "  Learning Rate: 0.021692813154046548\n",
      "  Sigma Multiplier: 1.0908333718576435\n",
      "  Initialization Multiplier: 0.4764915717000764\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000369, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 14:13:29,381] Trial 491 finished with value: -0.00036929238419622075 and parameters: {'learning_rate': 0.021692813154046548, 'sigma_multiplier': 1.0908333718576435, 'num_layers': 2, 'initialization_multiplier': 0.4764915717000764}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 491 final loss: -0.00036929\n",
      "Trial 492:\n",
      "  Learning Rate: 0.003888456786561695\n",
      "  Sigma Multiplier: 1.1581571997111384\n",
      "  Initialization Multiplier: 0.520480607541187\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.91it/s, loss=-0.000380, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 14:13:40,550] Trial 492 finished with value: -0.0003795261646277838 and parameters: {'learning_rate': 0.003888456786561695, 'sigma_multiplier': 1.1581571997111384, 'num_layers': 2, 'initialization_multiplier': 0.520480607541187}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 492 final loss: -0.00037953\n",
      "Trial 493:\n",
      "  Learning Rate: 0.01119653383857233\n",
      "  Sigma Multiplier: 0.8613533029813968\n",
      "  Initialization Multiplier: 0.6161979818917298\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.16it/s, loss=0.000021, elapsed time=0.07, total time=15.1] \n",
      "[I 2025-06-07 14:13:55,710] Trial 493 finished with value: 2.060700623483235e-05 and parameters: {'learning_rate': 0.01119653383857233, 'sigma_multiplier': 0.8613533029813968, 'num_layers': 3, 'initialization_multiplier': 0.6161979818917298}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 493 final loss: 0.00002061\n",
      "Trial 494:\n",
      "  Learning Rate: 0.006048389520420699\n",
      "  Sigma Multiplier: 1.0178621820891802\n",
      "  Initialization Multiplier: 0.5633553533802768\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.66it/s, loss=-0.000341, elapsed time=0.05, total time=12.3]\n",
      "[I 2025-06-07 14:14:08,148] Trial 494 finished with value: -0.00034107404872689895 and parameters: {'learning_rate': 0.006048389520420699, 'sigma_multiplier': 1.0178621820891802, 'num_layers': 2, 'initialization_multiplier': 0.5633553533802768}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 494 final loss: -0.00034107\n",
      "Trial 495:\n",
      "  Learning Rate: 0.009207078440402337\n",
      "  Sigma Multiplier: 0.9839479655601798\n",
      "  Initialization Multiplier: 0.6845250344100686\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.55it/s, loss=-0.000354, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 14:14:20,447] Trial 495 finished with value: -0.00035445336250336534 and parameters: {'learning_rate': 0.009207078440402337, 'sigma_multiplier': 0.9839479655601798, 'num_layers': 2, 'initialization_multiplier': 0.6845250344100686}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 495 final loss: -0.00035445\n",
      "Trial 496:\n",
      "  Learning Rate: 0.007506746222903477\n",
      "  Sigma Multiplier: 1.0425424744780398\n",
      "  Initialization Multiplier: 0.45765511725631225\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.60it/s, loss=-0.000316, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 14:14:31,840] Trial 496 finished with value: -0.00031550318694471613 and parameters: {'learning_rate': 0.007506746222903477, 'sigma_multiplier': 1.0425424744780398, 'num_layers': 2, 'initialization_multiplier': 0.45765511725631225}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 496 final loss: -0.00031550\n",
      "Trial 497:\n",
      "  Learning Rate: 0.0053297802596021385\n",
      "  Sigma Multiplier: 0.9245472961620811\n",
      "  Initialization Multiplier: 0.5869823289270373\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.76it/s, loss=-0.000341, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 14:14:43,954] Trial 497 finished with value: -0.000340953840834266 and parameters: {'learning_rate': 0.0053297802596021385, 'sigma_multiplier': 0.9245472961620811, 'num_layers': 2, 'initialization_multiplier': 0.5869823289270373}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 497 final loss: -0.00034095\n",
      "Trial 498:\n",
      "  Learning Rate: 0.017468799931768877\n",
      "  Sigma Multiplier: 1.0020987250809035\n",
      "  Initialization Multiplier: 0.5027591715265085\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.72it/s, loss=-0.000297, elapsed time=0.08, total time=12.1]\n",
      "[I 2025-06-07 14:14:56,067] Trial 498 finished with value: -0.00029694082738688035 and parameters: {'learning_rate': 0.017468799931768877, 'sigma_multiplier': 1.0020987250809035, 'num_layers': 2, 'initialization_multiplier': 0.5027591715265085}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 498 final loss: -0.00029694\n",
      "Trial 499:\n",
      "  Learning Rate: 0.01201356281114738\n",
      "  Sigma Multiplier: 0.9616864294130012\n",
      "  Initialization Multiplier: 0.6490861444166702\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.58it/s, loss=-0.000291, elapsed time=0.06, total time=12.2]\n",
      "[I 2025-06-07 14:15:08,368] Trial 499 finished with value: -0.00029077650498218765 and parameters: {'learning_rate': 0.01201356281114738, 'sigma_multiplier': 0.9616864294130012, 'num_layers': 2, 'initialization_multiplier': 0.6490861444166702}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 499 final loss: -0.00029078\n",
      "Trial 500:\n",
      "  Learning Rate: 0.009941971327478859\n",
      "  Sigma Multiplier: 1.1065444889463432\n",
      "  Initialization Multiplier: 0.5470412906163082\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.29it/s, loss=-0.000337, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:15:20,058] Trial 500 finished with value: -0.0003370156065589178 and parameters: {'learning_rate': 0.009941971327478859, 'sigma_multiplier': 1.1065444889463432, 'num_layers': 2, 'initialization_multiplier': 0.5470412906163082}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 500 final loss: -0.00033702\n",
      "Trial 501:\n",
      "  Learning Rate: 0.008452743355418629\n",
      "  Sigma Multiplier: 1.0606379212262558\n",
      "  Initialization Multiplier: 0.39548474068131995\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000397, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 14:15:31,787] Trial 501 finished with value: -0.0003970409382123125 and parameters: {'learning_rate': 0.008452743355418629, 'sigma_multiplier': 1.0606379212262558, 'num_layers': 2, 'initialization_multiplier': 0.39548474068131995}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 501 final loss: -0.00039704\n",
      "Trial 502:\n",
      "  Learning Rate: 0.014163344899520234\n",
      "  Sigma Multiplier: 0.8997427363055674\n",
      "  Initialization Multiplier: 0.6142288000178151\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.01it/s, loss=-0.000217, elapsed time=0.07, total time=11.9]\n",
      "[I 2025-06-07 14:15:43,691] Trial 502 finished with value: -0.00021727165088652694 and parameters: {'learning_rate': 0.014163344899520234, 'sigma_multiplier': 0.8997427363055674, 'num_layers': 2, 'initialization_multiplier': 0.6142288000178151}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 502 final loss: -0.00021727\n",
      "Trial 503:\n",
      "  Learning Rate: 0.006857957485453881\n",
      "  Sigma Multiplier: 1.019889801880716\n",
      "  Initialization Multiplier: 0.5135655787648512\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=-0.000333, elapsed time=0.08, total time=11.3]\n",
      "[I 2025-06-07 14:15:55,080] Trial 503 finished with value: -0.00033336061587149366 and parameters: {'learning_rate': 0.006857957485453881, 'sigma_multiplier': 1.019889801880716, 'num_layers': 2, 'initialization_multiplier': 0.5135655787648512}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 503 final loss: -0.00033336\n",
      "Trial 504:\n",
      "  Learning Rate: 0.011245474150914647\n",
      "  Sigma Multiplier: 0.9711819697677573\n",
      "  Initialization Multiplier: 0.7250346403297798\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.14it/s, loss=-0.000317, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:16:06,859] Trial 504 finished with value: -0.00031696922658568056 and parameters: {'learning_rate': 0.011245474150914647, 'sigma_multiplier': 0.9711819697677573, 'num_layers': 2, 'initialization_multiplier': 0.7250346403297798}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 504 final loss: -0.00031697\n",
      "Trial 505:\n",
      "  Learning Rate: 0.008613140255386644\n",
      "  Sigma Multiplier: 0.936933631078302\n",
      "  Initialization Multiplier: 0.4488565967911635\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.75it/s, loss=-0.000414, elapsed time=0.08, total time=12]  \n",
      "[I 2025-06-07 14:16:18,949] Trial 505 finished with value: -0.0004144143848429123 and parameters: {'learning_rate': 0.008613140255386644, 'sigma_multiplier': 0.936933631078302, 'num_layers': 2, 'initialization_multiplier': 0.4488565967911635}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 505 final loss: -0.00041441\n",
      "Trial 506:\n",
      "  Learning Rate: 0.010044963288789352\n",
      "  Sigma Multiplier: 1.027880622308439\n",
      "  Initialization Multiplier: 0.5430347379790681\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.81it/s, loss=-0.000384, elapsed time=0.05, total time=12.1]\n",
      "[I 2025-06-07 14:16:31,066] Trial 506 finished with value: -0.00038432475712213865 and parameters: {'learning_rate': 0.010044963288789352, 'sigma_multiplier': 1.027880622308439, 'num_layers': 2, 'initialization_multiplier': 0.5430347379790681}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 506 final loss: -0.00038432\n",
      "Trial 507:\n",
      "  Learning Rate: 0.013289111204143696\n",
      "  Sigma Multiplier: 1.084969208870268\n",
      "  Initialization Multiplier: 0.5833019728760512\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.39it/s, loss=-0.000389, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:16:42,643] Trial 507 finished with value: -0.0003888086249064146 and parameters: {'learning_rate': 0.013289111204143696, 'sigma_multiplier': 1.084969208870268, 'num_layers': 2, 'initialization_multiplier': 0.5833019728760512}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 507 final loss: -0.00038881\n",
      "Trial 508:\n",
      "  Learning Rate: 0.006371659591646259\n",
      "  Sigma Multiplier: 0.9875374241015789\n",
      "  Initialization Multiplier: 0.6502295470528858\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.61it/s, loss=-0.000419, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 14:16:54,897] Trial 508 finished with value: -0.0004194867659945889 and parameters: {'learning_rate': 0.006371659591646259, 'sigma_multiplier': 0.9875374241015789, 'num_layers': 2, 'initialization_multiplier': 0.6502295470528858}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 508 final loss: -0.00041949\n",
      "Trial 509:\n",
      "  Learning Rate: 0.007816909993745144\n",
      "  Sigma Multiplier: 0.829580628446358\n",
      "  Initialization Multiplier: 0.49491146627843735\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.23it/s, loss=-0.000344, elapsed time=0.05, total time=12.6]\n",
      "[I 2025-06-07 14:17:07,531] Trial 509 finished with value: -0.00034399597539717545 and parameters: {'learning_rate': 0.007816909993745144, 'sigma_multiplier': 0.829580628446358, 'num_layers': 2, 'initialization_multiplier': 0.49491146627843735}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 509 final loss: -0.00034400\n",
      "Trial 510:\n",
      "  Learning Rate: 0.01745021019551438\n",
      "  Sigma Multiplier: 0.8843869600443814\n",
      "  Initialization Multiplier: 0.5764548471947352\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.47it/s, loss=-0.000392, elapsed time=0.07, total time=12.4]\n",
      "[I 2025-06-07 14:17:19,992] Trial 510 finished with value: -0.0003922034185626275 and parameters: {'learning_rate': 0.01745021019551438, 'sigma_multiplier': 0.8843869600443814, 'num_layers': 2, 'initialization_multiplier': 0.5764548471947352}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 510 final loss: -0.00039220\n",
      "Trial 511:\n",
      "  Learning Rate: 0.011183989005017242\n",
      "  Sigma Multiplier: 1.0432138124789503\n",
      "  Initialization Multiplier: 0.6217001528210259\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.91it/s, loss=-0.000373, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 14:17:32,037] Trial 511 finished with value: -0.00037289903984905336 and parameters: {'learning_rate': 0.011183989005017242, 'sigma_multiplier': 1.0432138124789503, 'num_layers': 2, 'initialization_multiplier': 0.6217001528210259}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 511 final loss: -0.00037290\n",
      "Trial 512:\n",
      "  Learning Rate: 0.005296703391566309\n",
      "  Sigma Multiplier: 0.9509851499185437\n",
      "  Initialization Multiplier: 0.5268485790846353\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.52it/s, loss=-0.000387, elapsed time=0.05, total time=12.3]\n",
      "[I 2025-06-07 14:17:44,409] Trial 512 finished with value: -0.0003873625636247893 and parameters: {'learning_rate': 0.005296703391566309, 'sigma_multiplier': 0.9509851499185437, 'num_layers': 2, 'initialization_multiplier': 0.5268485790846353}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 512 final loss: -0.00038736\n",
      "Trial 513:\n",
      "  Learning Rate: 0.0044024682646083505\n",
      "  Sigma Multiplier: 1.1230777025675294\n",
      "  Initialization Multiplier: 0.47407905620070345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000350, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 14:17:56,010] Trial 513 finished with value: -0.0003502967505445124 and parameters: {'learning_rate': 0.0044024682646083505, 'sigma_multiplier': 1.1230777025675294, 'num_layers': 2, 'initialization_multiplier': 0.47407905620070345}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 513 final loss: -0.00035030\n",
      "Trial 514:\n",
      "  Learning Rate: 0.009219837364748688\n",
      "  Sigma Multiplier: 1.0054277517859411\n",
      "  Initialization Multiplier: 0.6743318991429935\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.81it/s, loss=-0.000342, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:18:08,169] Trial 514 finished with value: -0.00034223901640914866 and parameters: {'learning_rate': 0.009219837364748688, 'sigma_multiplier': 1.0054277517859411, 'num_layers': 2, 'initialization_multiplier': 0.6743318991429935}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 514 final loss: -0.00034224\n",
      "Trial 515:\n",
      "  Learning Rate: 0.015274832091886471\n",
      "  Sigma Multiplier: 0.9784648790526589\n",
      "  Initialization Multiplier: 0.5649267695340082\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:16<00:00,  9.15it/s, loss=-0.000212, elapsed time=0.1, total time=16.8] \n",
      "[I 2025-06-07 14:18:25,029] Trial 515 finished with value: -0.0002123334889830425 and parameters: {'learning_rate': 0.015274832091886471, 'sigma_multiplier': 0.9784648790526589, 'num_layers': 4, 'initialization_multiplier': 0.5649267695340082}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 515 final loss: -0.00021233\n",
      "Trial 516:\n",
      "  Learning Rate: 0.01196790185357083\n",
      "  Sigma Multiplier: 1.0651736456243213\n",
      "  Initialization Multiplier: 0.6036623944121896\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.52it/s, loss=-0.000365, elapsed time=0.08, total time=12.3]\n",
      "[I 2025-06-07 14:18:37,396] Trial 516 finished with value: -0.00036488389908400607 and parameters: {'learning_rate': 0.01196790185357083, 'sigma_multiplier': 1.0651736456243213, 'num_layers': 2, 'initialization_multiplier': 0.6036623944121896}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 516 final loss: -0.00036488\n",
      "Trial 517:\n",
      "  Learning Rate: 0.007475106072709745\n",
      "  Sigma Multiplier: 0.9458937500099676\n",
      "  Initialization Multiplier: 0.4291406336399576\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.18it/s, loss=-0.000195, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 14:18:47,637] Trial 517 finished with value: -0.00019486075121033695 and parameters: {'learning_rate': 0.007475106072709745, 'sigma_multiplier': 0.9458937500099676, 'num_layers': 1, 'initialization_multiplier': 0.4291406336399576}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 517 final loss: -0.00019486\n",
      "Trial 518:\n",
      "  Learning Rate: 0.00979633092125363\n",
      "  Sigma Multiplier: 1.0236063592515785\n",
      "  Initialization Multiplier: 0.5444489757439587\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.60it/s, loss=-0.000313, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 14:18:59,013] Trial 518 finished with value: -0.0003134479445667379 and parameters: {'learning_rate': 0.00979633092125363, 'sigma_multiplier': 1.0236063592515785, 'num_layers': 2, 'initialization_multiplier': 0.5444489757439587}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 518 final loss: -0.00031345\n",
      "Trial 519:\n",
      "  Learning Rate: 0.00026864548076850105\n",
      "  Sigma Multiplier: 0.9311202012244634\n",
      "  Initialization Multiplier: 0.502247910126775\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.51it/s, loss=0.020919, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:19:11,390] Trial 519 finished with value: 0.020918750748957392 and parameters: {'learning_rate': 0.00026864548076850105, 'sigma_multiplier': 0.9311202012244634, 'num_layers': 2, 'initialization_multiplier': 0.502247910126775}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 519 final loss: 0.02091875\n",
      "Trial 520:\n",
      "  Learning Rate: 0.013198880075807306\n",
      "  Sigma Multiplier: 0.9863541344175837\n",
      "  Initialization Multiplier: 0.3637052313694774\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000336, elapsed time=0.1, total time=11.7] \n",
      "[I 2025-06-07 14:19:23,185] Trial 520 finished with value: -0.0003355764855871204 and parameters: {'learning_rate': 0.013198880075807306, 'sigma_multiplier': 0.9863541344175837, 'num_layers': 2, 'initialization_multiplier': 0.3637052313694774}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 520 final loss: -0.00033558\n",
      "Trial 521:\n",
      "  Learning Rate: 0.006226635375965414\n",
      "  Sigma Multiplier: 0.8983045958966619\n",
      "  Initialization Multiplier: 0.639912397015708\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.41it/s, loss=-0.000415, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:19:35,586] Trial 521 finished with value: -0.0004153750451419777 and parameters: {'learning_rate': 0.006226635375965414, 'sigma_multiplier': 0.8983045958966619, 'num_layers': 2, 'initialization_multiplier': 0.639912397015708}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 521 final loss: -0.00041538\n",
      "Trial 522:\n",
      "  Learning Rate: 0.008291850411793004\n",
      "  Sigma Multiplier: 1.0697407925461475\n",
      "  Initialization Multiplier: 0.589623222790543\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.15it/s, loss=-0.000342, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 14:19:47,400] Trial 522 finished with value: -0.0003419821224753935 and parameters: {'learning_rate': 0.008291850411793004, 'sigma_multiplier': 1.0697407925461475, 'num_layers': 2, 'initialization_multiplier': 0.589623222790543}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 522 final loss: -0.00034198\n",
      "Trial 523:\n",
      "  Learning Rate: 0.019381820090167725\n",
      "  Sigma Multiplier: 1.01398731383645\n",
      "  Initialization Multiplier: 0.7017245680358173\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.90it/s, loss=-0.000047, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 14:19:59,414] Trial 523 finished with value: -4.737273212263328e-05 and parameters: {'learning_rate': 0.019381820090167725, 'sigma_multiplier': 1.01398731383645, 'num_layers': 2, 'initialization_multiplier': 0.7017245680358173}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 523 final loss: -0.00004737\n",
      "Trial 524:\n",
      "  Learning Rate: 0.002927170616632618\n",
      "  Sigma Multiplier: 1.1571439863585269\n",
      "  Initialization Multiplier: 0.46669076657075353\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.49it/s, loss=-0.000397, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:20:10,925] Trial 524 finished with value: -0.0003969598280201449 and parameters: {'learning_rate': 0.002927170616632618, 'sigma_multiplier': 1.1571439863585269, 'num_layers': 2, 'initialization_multiplier': 0.46669076657075353}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 524 final loss: -0.00039696\n",
      "Trial 525:\n",
      "  Learning Rate: 0.010424619389391869\n",
      "  Sigma Multiplier: 0.9693423983890478\n",
      "  Initialization Multiplier: 0.5592470467103369\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.67it/s, loss=-0.000082, elapsed time=0.09, total time=14.4]\n",
      "[I 2025-06-07 14:20:25,420] Trial 525 finished with value: -8.159782236839585e-05 and parameters: {'learning_rate': 0.010424619389391869, 'sigma_multiplier': 0.9693423983890478, 'num_layers': 3, 'initialization_multiplier': 0.5592470467103369}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 525 final loss: -0.00008160\n",
      "Trial 526:\n",
      "  Learning Rate: 0.007021311687098382\n",
      "  Sigma Multiplier: 1.1064183633691977\n",
      "  Initialization Multiplier: 0.62250443986899\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000341, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 14:20:36,814] Trial 526 finished with value: -0.000341409226473938 and parameters: {'learning_rate': 0.007021311687098382, 'sigma_multiplier': 1.1064183633691977, 'num_layers': 2, 'initialization_multiplier': 0.62250443986899}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 526 final loss: -0.00034141\n",
      "Trial 527:\n",
      "  Learning Rate: 0.014932315244149189\n",
      "  Sigma Multiplier: 1.0453332028967914\n",
      "  Initialization Multiplier: 0.5022794391150878\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000400, elapsed time=0.05, total time=11.8]\n",
      "[I 2025-06-07 14:20:48,653] Trial 527 finished with value: -0.00040031612726635594 and parameters: {'learning_rate': 0.014932315244149189, 'sigma_multiplier': 1.0453332028967914, 'num_layers': 2, 'initialization_multiplier': 0.5022794391150878}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 527 final loss: -0.00040032\n",
      "Trial 528:\n",
      "  Learning Rate: 0.008801205011974171\n",
      "  Sigma Multiplier: 0.8599866491656303\n",
      "  Initialization Multiplier: 0.5429086713326593\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.23it/s, loss=-0.000359, elapsed time=0.06, total time=12.6]\n",
      "[I 2025-06-07 14:21:01,320] Trial 528 finished with value: -0.0003591570498848118 and parameters: {'learning_rate': 0.008801205011974171, 'sigma_multiplier': 0.8599866491656303, 'num_layers': 2, 'initialization_multiplier': 0.5429086713326593}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 528 final loss: -0.00035916\n",
      "Trial 529:\n",
      "  Learning Rate: 0.012131987056593442\n",
      "  Sigma Multiplier: 0.9986493641776997\n",
      "  Initialization Multiplier: 1.1532865943587927\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.50it/s, loss=-0.000156, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 14:21:13,757] Trial 529 finished with value: -0.00015596090243328575 and parameters: {'learning_rate': 0.012131987056593442, 'sigma_multiplier': 0.9986493641776997, 'num_layers': 2, 'initialization_multiplier': 1.1532865943587927}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 529 final loss: -0.00015596\n",
      "Trial 530:\n",
      "  Learning Rate: 0.010215617374269103\n",
      "  Sigma Multiplier: 0.9344925797963093\n",
      "  Initialization Multiplier: 0.588218632467665\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.92it/s, loss=-0.000328, elapsed time=0.09, total time=11.9]\n",
      "[I 2025-06-07 14:21:25,726] Trial 530 finished with value: -0.0003280276932690296 and parameters: {'learning_rate': 0.010215617374269103, 'sigma_multiplier': 0.9344925797963093, 'num_layers': 2, 'initialization_multiplier': 0.588218632467665}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 530 final loss: -0.00032803\n",
      "Trial 531:\n",
      "  Learning Rate: 0.0010933915700973762\n",
      "  Sigma Multiplier: 1.044884766028485\n",
      "  Initialization Multiplier: 0.6621532725365346\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.91it/s, loss=0.019121, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 14:21:37,721] Trial 531 finished with value: 0.019120936509475116 and parameters: {'learning_rate': 0.0010933915700973762, 'sigma_multiplier': 1.044884766028485, 'num_layers': 2, 'initialization_multiplier': 0.6621532725365346}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 531 final loss: 0.01912094\n",
      "Trial 532:\n",
      "  Learning Rate: 0.001841899009741934\n",
      "  Sigma Multiplier: 1.0863136678908352\n",
      "  Initialization Multiplier: 0.4435854543131784\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.91it/s, loss=-0.000384, elapsed time=0.05, total time=14.1]\n",
      "[I 2025-06-07 14:21:51,825] Trial 532 finished with value: -0.00038363840354590584 and parameters: {'learning_rate': 0.001841899009741934, 'sigma_multiplier': 1.0863136678908352, 'num_layers': 2, 'initialization_multiplier': 0.4435854543131784}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 532 final loss: -0.00038364\n",
      "Trial 533:\n",
      "  Learning Rate: 0.007862351698396613\n",
      "  Sigma Multiplier: 0.9124720495655532\n",
      "  Initialization Multiplier: 0.5262782980666532\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.96it/s, loss=-0.000374, elapsed time=0.07, total time=12.9]\n",
      "[I 2025-06-07 14:22:04,792] Trial 533 finished with value: -0.0003735808593610962 and parameters: {'learning_rate': 0.007862351698396613, 'sigma_multiplier': 0.9124720495655532, 'num_layers': 2, 'initialization_multiplier': 0.5262782980666532}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 533 final loss: -0.00037358\n",
      "Trial 534:\n",
      "  Learning Rate: 0.005671068542497572\n",
      "  Sigma Multiplier: 0.9714671349481387\n",
      "  Initialization Multiplier: 0.7612281981513376\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.17it/s, loss=-0.000064, elapsed time=0.05, total time=12.8]\n",
      "[I 2025-06-07 14:22:17,689] Trial 534 finished with value: -6.391584037220211e-05 and parameters: {'learning_rate': 0.005671068542497572, 'sigma_multiplier': 0.9714671349481387, 'num_layers': 2, 'initialization_multiplier': 0.7612281981513376}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 534 final loss: -0.00006392\n",
      "Trial 535:\n",
      "  Learning Rate: 0.013309892854161927\n",
      "  Sigma Multiplier: 1.0169806740095677\n",
      "  Initialization Multiplier: 0.6168717557428111\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.42it/s, loss=-0.000346, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 14:22:30,115] Trial 535 finished with value: -0.0003461357091604852 and parameters: {'learning_rate': 0.013309892854161927, 'sigma_multiplier': 1.0169806740095677, 'num_layers': 2, 'initialization_multiplier': 0.6168717557428111}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 535 final loss: -0.00034614\n",
      "Trial 536:\n",
      "  Learning Rate: 0.00922511457295934\n",
      "  Sigma Multiplier: 0.9666911302999031\n",
      "  Initialization Multiplier: 0.5710814474386768\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.16it/s, loss=-0.000280, elapsed time=0.1, total time=12.7] \n",
      "[I 2025-06-07 14:22:42,881] Trial 536 finished with value: -0.0002800244459803103 and parameters: {'learning_rate': 0.00922511457295934, 'sigma_multiplier': 0.9666911302999031, 'num_layers': 2, 'initialization_multiplier': 0.5710814474386768}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 536 final loss: -0.00028002\n",
      "Trial 537:\n",
      "  Learning Rate: 0.016354886945516664\n",
      "  Sigma Multiplier: 1.0519384183650222\n",
      "  Initialization Multiplier: 0.49315749540447473\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.67it/s, loss=-0.000326, elapsed time=0.05, total time=12.2]\n",
      "[I 2025-06-07 14:22:55,090] Trial 537 finished with value: -0.00032600451846422063 and parameters: {'learning_rate': 0.016354886945516664, 'sigma_multiplier': 1.0519384183650222, 'num_layers': 2, 'initialization_multiplier': 0.49315749540447473}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 537 final loss: -0.00032600\n",
      "Trial 538:\n",
      "  Learning Rate: 0.011659563194301767\n",
      "  Sigma Multiplier: 1.0030405005741334\n",
      "  Initialization Multiplier: 0.39716406720599196\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000385, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:23:07,004] Trial 538 finished with value: -0.00038478970643519226 and parameters: {'learning_rate': 0.011659563194301767, 'sigma_multiplier': 1.0030405005741334, 'num_layers': 2, 'initialization_multiplier': 0.39716406720599196}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 538 final loss: -0.00038479\n",
      "Trial 539:\n",
      "  Learning Rate: 0.004852306877319026\n",
      "  Sigma Multiplier: 0.7987242598466722\n",
      "  Initialization Multiplier: 0.6442410979925488\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.93it/s, loss=-0.000232, elapsed time=0.06, total time=12.9]\n",
      "[I 2025-06-07 14:23:19,928] Trial 539 finished with value: -0.00023155951416522756 and parameters: {'learning_rate': 0.004852306877319026, 'sigma_multiplier': 0.7987242598466722, 'num_layers': 2, 'initialization_multiplier': 0.6442410979925488}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 539 final loss: -0.00023156\n",
      "Trial 540:\n",
      "  Learning Rate: 0.0068889643175707015\n",
      "  Sigma Multiplier: 0.8954221621057544\n",
      "  Initialization Multiplier: 0.6980614399679058\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.52it/s, loss=-0.000296, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:23:32,242] Trial 540 finished with value: -0.00029596190265555015 and parameters: {'learning_rate': 0.0068889643175707015, 'sigma_multiplier': 0.8954221621057544, 'num_layers': 2, 'initialization_multiplier': 0.6980614399679058}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 540 final loss: -0.00029596\n",
      "Trial 541:\n",
      "  Learning Rate: 0.010879105370408159\n",
      "  Sigma Multiplier: 1.930608539245565\n",
      "  Initialization Multiplier: 0.5907389089563695\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.20it/s, loss=-0.000214, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 14:23:42,485] Trial 541 finished with value: -0.00021380631090761053 and parameters: {'learning_rate': 0.010879105370408159, 'sigma_multiplier': 1.930608539245565, 'num_layers': 2, 'initialization_multiplier': 0.5907389089563695}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 541 final loss: -0.00021381\n",
      "Trial 542:\n",
      "  Learning Rate: 0.008950143951180677\n",
      "  Sigma Multiplier: 0.9408700511017887\n",
      "  Initialization Multiplier: 0.8150185936366001\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.46it/s, loss=-0.000196, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 14:23:54,897] Trial 542 finished with value: -0.00019596140429883367 and parameters: {'learning_rate': 0.008950143951180677, 'sigma_multiplier': 0.9408700511017887, 'num_layers': 2, 'initialization_multiplier': 0.8150185936366001}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 542 final loss: -0.00019596\n",
      "Trial 543:\n",
      "  Learning Rate: 0.007895483142918863\n",
      "  Sigma Multiplier: 1.1230655151318278\n",
      "  Initialization Multiplier: 0.5323883262187499\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.35it/s, loss=-0.000323, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:24:06,509] Trial 543 finished with value: -0.00032266765395175387 and parameters: {'learning_rate': 0.007895483142918863, 'sigma_multiplier': 1.1230655151318278, 'num_layers': 2, 'initialization_multiplier': 0.5323883262187499}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 543 final loss: -0.00032267\n",
      "Trial 544:\n",
      "  Learning Rate: 0.014268527663130925\n",
      "  Sigma Multiplier: 1.079938316786168\n",
      "  Initialization Multiplier: 0.47295558235579677\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000440, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:24:18,004] Trial 544 finished with value: -0.000439963039844132 and parameters: {'learning_rate': 0.014268527663130925, 'sigma_multiplier': 1.079938316786168, 'num_layers': 2, 'initialization_multiplier': 0.47295558235579677}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 544 final loss: -0.00043996\n",
      "Trial 545:\n",
      "  Learning Rate: 0.02275045580341487\n",
      "  Sigma Multiplier: 1.148087992367468\n",
      "  Initialization Multiplier: 0.45330837291740345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.15it/s, loss=-0.000387, elapsed time=0.09, total time=11.7]\n",
      "[I 2025-06-07 14:24:29,754] Trial 545 finished with value: -0.0003870264795396437 and parameters: {'learning_rate': 0.02275045580341487, 'sigma_multiplier': 1.148087992367468, 'num_layers': 2, 'initialization_multiplier': 0.45330837291740345}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 545 final loss: -0.00038703\n",
      "Trial 546:\n",
      "  Learning Rate: 0.01433745818149204\n",
      "  Sigma Multiplier: 1.075194976439697\n",
      "  Initialization Multiplier: 0.39483010223594955\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.32it/s, loss=-0.000328, elapsed time=0.06, total time=11.7]\n",
      "[I 2025-06-07 14:24:41,454] Trial 546 finished with value: -0.0003276749628029848 and parameters: {'learning_rate': 0.01433745818149204, 'sigma_multiplier': 1.075194976439697, 'num_layers': 2, 'initialization_multiplier': 0.39483010223594955}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 546 final loss: -0.00032767\n",
      "Trial 547:\n",
      "  Learning Rate: 0.01781598675057018\n",
      "  Sigma Multiplier: 1.093627018438241\n",
      "  Initialization Multiplier: 0.4908260184503289\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.42it/s, loss=-0.000325, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:24:52,904] Trial 547 finished with value: -0.00032489712220825034 and parameters: {'learning_rate': 0.01781598675057018, 'sigma_multiplier': 1.093627018438241, 'num_layers': 2, 'initialization_multiplier': 0.4908260184503289}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 547 final loss: -0.00032490\n",
      "Trial 548:\n",
      "  Learning Rate: 0.01527889184597933\n",
      "  Sigma Multiplier: 1.6898127256508557\n",
      "  Initialization Multiplier: 0.4240047476715527\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.69it/s, loss=-0.000213, elapsed time=0.09, total time=10.5]\n",
      "[I 2025-06-07 14:25:03,475] Trial 548 finished with value: -0.0002130389331097889 and parameters: {'learning_rate': 0.01527889184597933, 'sigma_multiplier': 1.6898127256508557, 'num_layers': 2, 'initialization_multiplier': 0.4240047476715527}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 548 final loss: -0.00021304\n",
      "Trial 549:\n",
      "  Learning Rate: 0.01811843526388612\n",
      "  Sigma Multiplier: 1.1271087605730132\n",
      "  Initialization Multiplier: 1.0488767670568497\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.25it/s, loss=-0.000195, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 14:25:15,173] Trial 549 finished with value: -0.00019529034866671836 and parameters: {'learning_rate': 0.01811843526388612, 'sigma_multiplier': 1.1271087605730132, 'num_layers': 2, 'initialization_multiplier': 1.0488767670568497}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 549 final loss: -0.00019529\n",
      "Trial 550:\n",
      "  Learning Rate: 0.013280251823198915\n",
      "  Sigma Multiplier: 1.032516057211448\n",
      "  Initialization Multiplier: 0.46750394971544357\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.22it/s, loss=-0.000283, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:25:26,889] Trial 550 finished with value: -0.0002825360628522642 and parameters: {'learning_rate': 0.013280251823198915, 'sigma_multiplier': 1.032516057211448, 'num_layers': 2, 'initialization_multiplier': 0.46750394971544357}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 550 final loss: -0.00028254\n",
      "Trial 551:\n",
      "  Learning Rate: 0.026935995257920883\n",
      "  Sigma Multiplier: 0.8567900961951423\n",
      "  Initialization Multiplier: 0.5125206230743078\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.39it/s, loss=-0.000250, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 14:25:39,399] Trial 551 finished with value: -0.0002501364763686498 and parameters: {'learning_rate': 0.026935995257920883, 'sigma_multiplier': 0.8567900961951423, 'num_layers': 2, 'initialization_multiplier': 0.5125206230743078}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 551 final loss: -0.00025014\n",
      "Trial 552:\n",
      "  Learning Rate: 0.021156936203944456\n",
      "  Sigma Multiplier: 1.075002275853098\n",
      "  Initialization Multiplier: 0.35216919771741273\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.61it/s, loss=-0.000403, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 14:25:50,719] Trial 552 finished with value: -0.00040286363310300475 and parameters: {'learning_rate': 0.021156936203944456, 'sigma_multiplier': 1.075002275853098, 'num_layers': 2, 'initialization_multiplier': 0.35216919771741273}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 552 final loss: -0.00040286\n",
      "Trial 553:\n",
      "  Learning Rate: 0.01253597785137797\n",
      "  Sigma Multiplier: 0.9944422517456006\n",
      "  Initialization Multiplier: 0.4369913398688736\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.21it/s, loss=-0.000336, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:26:02,413] Trial 553 finished with value: -0.00033616378750120536 and parameters: {'learning_rate': 0.01253597785137797, 'sigma_multiplier': 0.9944422517456006, 'num_layers': 2, 'initialization_multiplier': 0.4369913398688736}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 553 final loss: -0.00033616\n",
      "Trial 554:\n",
      "  Learning Rate: 0.003701714673131165\n",
      "  Sigma Multiplier: 0.9567258708865047\n",
      "  Initialization Multiplier: 0.4764848849595965\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.05it/s, loss=-0.000351, elapsed time=0.05, total time=11.8]\n",
      "[I 2025-06-07 14:26:14,253] Trial 554 finished with value: -0.00035057708603674893 and parameters: {'learning_rate': 0.003701714673131165, 'sigma_multiplier': 0.9567258708865047, 'num_layers': 2, 'initialization_multiplier': 0.4764848849595965}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 554 final loss: -0.00035058\n",
      "Trial 555:\n",
      "  Learning Rate: 0.011193398089675599\n",
      "  Sigma Multiplier: 1.0485761834477105\n",
      "  Initialization Multiplier: 0.5408305835851653\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000296, elapsed time=0.08, total time=11.5]\n",
      "[I 2025-06-07 14:26:25,792] Trial 555 finished with value: -0.0002961530144086995 and parameters: {'learning_rate': 0.011193398089675599, 'sigma_multiplier': 1.0485761834477105, 'num_layers': 2, 'initialization_multiplier': 0.5408305835851653}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 555 final loss: -0.00029615\n",
      "Trial 556:\n",
      "  Learning Rate: 0.016427536025149167\n",
      "  Sigma Multiplier: 0.6713087239094702\n",
      "  Initialization Multiplier: 0.5582769929217895\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.39it/s, loss=-0.000250, elapsed time=0.07, total time=13.6]\n",
      "[I 2025-06-07 14:26:39,387] Trial 556 finished with value: -0.00024972857503566904 and parameters: {'learning_rate': 0.016427536025149167, 'sigma_multiplier': 0.6713087239094702, 'num_layers': 2, 'initialization_multiplier': 0.5582769929217895}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 556 final loss: -0.00024973\n",
      "Trial 557:\n",
      "  Learning Rate: 0.014667553542717898\n",
      "  Sigma Multiplier: 0.9203960830648054\n",
      "  Initialization Multiplier: 0.49746893987568436\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.24it/s, loss=-0.000389, elapsed time=0.05, total time=11.6]\n",
      "[I 2025-06-07 14:26:51,073] Trial 557 finished with value: -0.0003893209972493026 and parameters: {'learning_rate': 0.014667553542717898, 'sigma_multiplier': 0.9203960830648054, 'num_layers': 2, 'initialization_multiplier': 0.49746893987568436}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 557 final loss: -0.00038932\n",
      "Trial 558:\n",
      "  Learning Rate: 0.010545306771966636\n",
      "  Sigma Multiplier: 1.177997611451949\n",
      "  Initialization Multiplier: 0.42222706207861893\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.84it/s, loss=-0.000395, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:27:02,292] Trial 558 finished with value: -0.00039498233024595563 and parameters: {'learning_rate': 0.010545306771966636, 'sigma_multiplier': 1.177997611451949, 'num_layers': 2, 'initialization_multiplier': 0.42222706207861893}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 558 final loss: -0.00039498\n",
      "Trial 559:\n",
      "  Learning Rate: 0.012589834491758082\n",
      "  Sigma Multiplier: 1.0023343193841676\n",
      "  Initialization Multiplier: 0.6210049019188748\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000353, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:27:13,890] Trial 559 finished with value: -0.00035302923842647516 and parameters: {'learning_rate': 0.012589834491758082, 'sigma_multiplier': 1.0023343193841676, 'num_layers': 2, 'initialization_multiplier': 0.6210049019188748}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 559 final loss: -0.00035303\n",
      "Trial 560:\n",
      "  Learning Rate: 0.006710571157210018\n",
      "  Sigma Multiplier: 0.9729366148956016\n",
      "  Initialization Multiplier: 0.5260562843121317\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.66it/s, loss=-0.000356, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 14:27:25,255] Trial 560 finished with value: -0.00035627310906501125 and parameters: {'learning_rate': 0.006710571157210018, 'sigma_multiplier': 0.9729366148956016, 'num_layers': 2, 'initialization_multiplier': 0.5260562843121317}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 560 final loss: -0.00035627\n",
      "Trial 561:\n",
      "  Learning Rate: 0.010574839950748736\n",
      "  Sigma Multiplier: 1.0952063755559232\n",
      "  Initialization Multiplier: 0.5669101474481864\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.67it/s, loss=-0.000409, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:27:36,523] Trial 561 finished with value: -0.00040941861782524305 and parameters: {'learning_rate': 0.010574839950748736, 'sigma_multiplier': 1.0952063755559232, 'num_layers': 2, 'initialization_multiplier': 0.5669101474481864}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 561 final loss: -0.00040942\n",
      "Trial 562:\n",
      "  Learning Rate: 0.01977299921952762\n",
      "  Sigma Multiplier: 0.4562053757608675\n",
      "  Initialization Multiplier: 0.46379471834825975\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.33it/s, loss=0.000334, elapsed time=0.1, total time=14.8] \n",
      "[I 2025-06-07 14:27:51,407] Trial 562 finished with value: 0.00033440279887272034 and parameters: {'learning_rate': 0.01977299921952762, 'sigma_multiplier': 0.4562053757608675, 'num_layers': 2, 'initialization_multiplier': 0.46379471834825975}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 562 final loss: 0.00033440\n",
      "Trial 563:\n",
      "  Learning Rate: 0.013686082772880916\n",
      "  Sigma Multiplier: 1.0200070110527113\n",
      "  Initialization Multiplier: 0.6731013023247105\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.93it/s, loss=-0.000342, elapsed time=0.07, total time=11.9]\n",
      "[I 2025-06-07 14:28:03,362] Trial 563 finished with value: -0.00034233594479320253 and parameters: {'learning_rate': 0.013686082772880916, 'sigma_multiplier': 1.0200070110527113, 'num_layers': 2, 'initialization_multiplier': 0.6731013023247105}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 563 final loss: -0.00034234\n",
      "Trial 564:\n",
      "  Learning Rate: 0.009267819209260978\n",
      "  Sigma Multiplier: 0.9245152630478557\n",
      "  Initialization Multiplier: 0.5096080334519296\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.07it/s, loss=-0.000380, elapsed time=0.06, total time=12.8]\n",
      "[I 2025-06-07 14:28:16,210] Trial 564 finished with value: -0.0003803517620219168 and parameters: {'learning_rate': 0.009267819209260978, 'sigma_multiplier': 0.9245152630478557, 'num_layers': 2, 'initialization_multiplier': 0.5096080334519296}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 564 final loss: -0.00038035\n",
      "Trial 565:\n",
      "  Learning Rate: 0.005989299675026271\n",
      "  Sigma Multiplier: 1.0362047515445456\n",
      "  Initialization Multiplier: 0.603568007169099\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.47it/s, loss=-0.000488, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:28:27,822] Trial 565 finished with value: -0.0004876056830113411 and parameters: {'learning_rate': 0.005989299675026271, 'sigma_multiplier': 1.0362047515445456, 'num_layers': 2, 'initialization_multiplier': 0.603568007169099}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 565 final loss: -0.00048761\n",
      "Trial 566:\n",
      "  Learning Rate: 0.004226389590579168\n",
      "  Sigma Multiplier: 1.1075819288777582\n",
      "  Initialization Multiplier: 0.638067520600896\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.46it/s, loss=-0.000314, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:28:40,227] Trial 566 finished with value: -0.0003139658674043982 and parameters: {'learning_rate': 0.004226389590579168, 'sigma_multiplier': 1.1075819288777582, 'num_layers': 2, 'initialization_multiplier': 0.638067520600896}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 566 final loss: -0.00031397\n",
      "Trial 567:\n",
      "  Learning Rate: 0.005081364423397803\n",
      "  Sigma Multiplier: 1.0649461069154462\n",
      "  Initialization Multiplier: 0.7368324489986204\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.90it/s, loss=-0.000438, elapsed time=0.06, total time=9.8] \n",
      "[I 2025-06-07 14:28:50,068] Trial 567 finished with value: -0.00043849156553393153 and parameters: {'learning_rate': 0.005081364423397803, 'sigma_multiplier': 1.0649461069154462, 'num_layers': 1, 'initialization_multiplier': 0.7368324489986204}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 567 final loss: -0.00043849\n",
      "Trial 568:\n",
      "  Learning Rate: 0.005169005310204555\n",
      "  Sigma Multiplier: 1.1454321147402684\n",
      "  Initialization Multiplier: 0.8625158053651996\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.01it/s, loss=-0.000411, elapsed time=0.07, total time=9.7] \n",
      "[I 2025-06-07 14:28:59,824] Trial 568 finished with value: -0.0004106166862311109 and parameters: {'learning_rate': 0.005169005310204555, 'sigma_multiplier': 1.1454321147402684, 'num_layers': 1, 'initialization_multiplier': 0.8625158053651996}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 568 final loss: -0.00041062\n",
      "Trial 569:\n",
      "  Learning Rate: 0.004387928940891391\n",
      "  Sigma Multiplier: 1.0730300327701883\n",
      "  Initialization Multiplier: 0.7496669591984704\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.28it/s, loss=-0.000336, elapsed time=0.05, total time=9.57]\n",
      "[I 2025-06-07 14:29:09,437] Trial 569 finished with value: -0.0003363959909492522 and parameters: {'learning_rate': 0.004387928940891391, 'sigma_multiplier': 1.0730300327701883, 'num_layers': 1, 'initialization_multiplier': 0.7496669591984704}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 569 final loss: -0.00033640\n",
      "Trial 570:\n",
      "  Learning Rate: 0.005020496088935337\n",
      "  Sigma Multiplier: 1.1239864651378166\n",
      "  Initialization Multiplier: 0.5537594595199471\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.38it/s, loss=-0.000327, elapsed time=0.05, total time=9.46]\n",
      "[I 2025-06-07 14:29:18,933] Trial 570 finished with value: -0.00032739139231832714 and parameters: {'learning_rate': 0.005020496088935337, 'sigma_multiplier': 1.1239864651378166, 'num_layers': 1, 'initialization_multiplier': 0.5537594595199471}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 570 final loss: -0.00032739\n",
      "Trial 571:\n",
      "  Learning Rate: 0.003972572642090207\n",
      "  Sigma Multiplier: 1.0675442551820375\n",
      "  Initialization Multiplier: 0.46400574909431996\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.58it/s, loss=-0.000389, elapsed time=0.09, total time=13.3]\n",
      "[I 2025-06-07 14:29:32,288] Trial 571 finished with value: -0.0003887639672131855 and parameters: {'learning_rate': 0.003972572642090207, 'sigma_multiplier': 1.0675442551820375, 'num_layers': 3, 'initialization_multiplier': 0.46400574909431996}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 571 final loss: -0.00038876\n",
      "Trial 572:\n",
      "  Learning Rate: 0.003513901695652391\n",
      "  Sigma Multiplier: 1.0513472638675372\n",
      "  Initialization Multiplier: 0.7121914108216727\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.45it/s, loss=-0.000245, elapsed time=0.06, total time=9.49]\n",
      "[I 2025-06-07 14:29:41,844] Trial 572 finished with value: -0.00024546129621014456 and parameters: {'learning_rate': 0.003513901695652391, 'sigma_multiplier': 1.0513472638675372, 'num_layers': 1, 'initialization_multiplier': 0.7121914108216727}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 572 final loss: -0.00024546\n",
      "Trial 573:\n",
      "  Learning Rate: 3.027675952889044e-05\n",
      "  Sigma Multiplier: 1.096685773910027\n",
      "  Initialization Multiplier: 0.7817741907428135\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.12it/s, loss=0.016373, elapsed time=0.05, total time=9.62]\n",
      "[I 2025-06-07 14:29:51,496] Trial 573 finished with value: 0.01637320470020641 and parameters: {'learning_rate': 3.027675952889044e-05, 'sigma_multiplier': 1.096685773910027, 'num_layers': 1, 'initialization_multiplier': 0.7817741907428135}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 573 final loss: 0.01637320\n",
      "Trial 574:\n",
      "  Learning Rate: 0.005709141497031248\n",
      "  Sigma Multiplier: 1.0393011660820626\n",
      "  Initialization Multiplier: 0.5969151506972343\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.19it/s, loss=-0.000195, elapsed time=0.06, total time=9.62]\n",
      "[I 2025-06-07 14:30:01,163] Trial 574 finished with value: -0.00019537222439984118 and parameters: {'learning_rate': 0.005709141497031248, 'sigma_multiplier': 1.0393011660820626, 'num_layers': 1, 'initialization_multiplier': 0.5969151506972343}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 574 final loss: -0.00019537\n",
      "Trial 575:\n",
      "  Learning Rate: 0.005761524331366801\n",
      "  Sigma Multiplier: 1.0654042503021326\n",
      "  Initialization Multiplier: 0.38324720260915335\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.24it/s, loss=-0.000405, elapsed time=0.09, total time=13.7]\n",
      "[I 2025-06-07 14:30:14,972] Trial 575 finished with value: -0.00040470570796977134 and parameters: {'learning_rate': 0.005761524331366801, 'sigma_multiplier': 1.0654042503021326, 'num_layers': 3, 'initialization_multiplier': 0.38324720260915335}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 575 final loss: -0.00040471\n",
      "Trial 576:\n",
      "  Learning Rate: 0.037036281805768366\n",
      "  Sigma Multiplier: 1.028044793536628\n",
      "  Initialization Multiplier: 0.5280930801024858\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.14it/s, loss=-0.000274, elapsed time=0.06, total time=9.6]  \n",
      "[I 2025-06-07 14:30:24,611] Trial 576 finished with value: -0.000274024026828871 and parameters: {'learning_rate': 0.037036281805768366, 'sigma_multiplier': 1.028044793536628, 'num_layers': 1, 'initialization_multiplier': 0.5280930801024858}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 576 final loss: -0.00027402\n",
      "Trial 577:\n",
      "  Learning Rate: 0.004674320608631284\n",
      "  Sigma Multiplier: 1.123295909028293\n",
      "  Initialization Multiplier: 0.48769503150355725\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.27it/s, loss=-0.000232, elapsed time=0.06, total time=9.5] \n",
      "[I 2025-06-07 14:30:34,152] Trial 577 finished with value: -0.00023236475575689415 and parameters: {'learning_rate': 0.004674320608631284, 'sigma_multiplier': 1.123295909028293, 'num_layers': 1, 'initialization_multiplier': 0.48769503150355725}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 577 final loss: -0.00023236\n",
      "Trial 578:\n",
      "  Learning Rate: 0.005794645480029808\n",
      "  Sigma Multiplier: 1.1898627054033162\n",
      "  Initialization Multiplier: 0.4286372423653082\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.68it/s, loss=-0.000312, elapsed time=0.06, total time=13.2]\n",
      "[I 2025-06-07 14:30:47,420] Trial 578 finished with value: -0.0003118963715987502 and parameters: {'learning_rate': 0.005794645480029808, 'sigma_multiplier': 1.1898627054033162, 'num_layers': 3, 'initialization_multiplier': 0.4286372423653082}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 578 final loss: -0.00031190\n",
      "Trial 579:\n",
      "  Learning Rate: 0.005106663070031187\n",
      "  Sigma Multiplier: 0.9890281611944065\n",
      "  Initialization Multiplier: 0.6060521539235909\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.35it/s, loss=-0.000050, elapsed time=0.05, total time=9.39]\n",
      "[I 2025-06-07 14:30:56,863] Trial 579 finished with value: -4.998890558341012e-05 and parameters: {'learning_rate': 0.005106663070031187, 'sigma_multiplier': 0.9890281611944065, 'num_layers': 1, 'initialization_multiplier': 0.6060521539235909}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 579 final loss: -0.00004999\n",
      "Trial 580:\n",
      "  Learning Rate: 0.006529838785567829\n",
      "  Sigma Multiplier: 1.1570826782899115\n",
      "  Initialization Multiplier: 0.551364606673881\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.36it/s, loss=-0.000165, elapsed time=0.05, total time=13.5]\n",
      "[I 2025-06-07 14:31:10,429] Trial 580 finished with value: -0.00016513441673014645 and parameters: {'learning_rate': 0.006529838785567829, 'sigma_multiplier': 1.1570826782899115, 'num_layers': 3, 'initialization_multiplier': 0.551364606673881}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 580 final loss: -0.00016513\n",
      "Trial 581:\n",
      "  Learning Rate: 0.004351320744314017\n",
      "  Sigma Multiplier: 1.0893390362599067\n",
      "  Initialization Multiplier: 0.6871279340893868\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.22it/s, loss=-0.000332, elapsed time=0.06, total time=8.98]\n",
      "[I 2025-06-07 14:31:19,448] Trial 581 finished with value: -0.0003323838724699379 and parameters: {'learning_rate': 0.004351320744314017, 'sigma_multiplier': 1.0893390362599067, 'num_layers': 1, 'initialization_multiplier': 0.6871279340893868}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 581 final loss: -0.00033238\n",
      "Trial 582:\n",
      "  Learning Rate: 0.00621828439507321\n",
      "  Sigma Multiplier: 1.0370340768277175\n",
      "  Initialization Multiplier: 0.573122246566628\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.41it/s, loss=-0.000174, elapsed time=0.09, total time=13.4]\n",
      "[I 2025-06-07 14:31:32,921] Trial 582 finished with value: -0.00017409940707691467 and parameters: {'learning_rate': 0.00621828439507321, 'sigma_multiplier': 1.0370340768277175, 'num_layers': 3, 'initialization_multiplier': 0.573122246566628}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 582 final loss: -0.00017410\n",
      "Trial 583:\n",
      "  Learning Rate: 0.007863718953967215\n",
      "  Sigma Multiplier: 0.9966796621249847\n",
      "  Initialization Multiplier: 0.5116045000567276\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.97it/s, loss=-0.000131, elapsed time=0.1, total time=15.3] \n",
      "[I 2025-06-07 14:31:48,344] Trial 583 finished with value: -0.00013095315355297912 and parameters: {'learning_rate': 0.007863718953967215, 'sigma_multiplier': 0.9966796621249847, 'num_layers': 4, 'initialization_multiplier': 0.5116045000567276}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 583 final loss: -0.00013095\n",
      "Trial 584:\n",
      "  Learning Rate: 0.003285538442107553\n",
      "  Sigma Multiplier: 0.9766212859266665\n",
      "  Initialization Multiplier: 0.6294119393360736\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.12it/s, loss=-0.000279, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 14:31:59,362] Trial 584 finished with value: -0.0002790009601847465 and parameters: {'learning_rate': 0.003285538442107553, 'sigma_multiplier': 0.9766212859266665, 'num_layers': 2, 'initialization_multiplier': 0.6294119393360736}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 584 final loss: -0.00027900\n",
      "Trial 585:\n",
      "  Learning Rate: 0.007393522267474357\n",
      "  Sigma Multiplier: 1.0476599796830746\n",
      "  Initialization Multiplier: 0.46844034439627746\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.19it/s, loss=-0.000385, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 14:32:10,248] Trial 585 finished with value: -0.0003847056571960205 and parameters: {'learning_rate': 0.007393522267474357, 'sigma_multiplier': 1.0476599796830746, 'num_layers': 2, 'initialization_multiplier': 0.46844034439627746}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 585 final loss: -0.00038471\n",
      "Trial 586:\n",
      "  Learning Rate: 0.005456589814108792\n",
      "  Sigma Multiplier: 1.0864033809893894\n",
      "  Initialization Multiplier: 0.5516184221346051\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.19it/s, loss=-0.000370, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 14:32:21,161] Trial 586 finished with value: -0.0003697418525749576 and parameters: {'learning_rate': 0.005456589814108792, 'sigma_multiplier': 1.0864033809893894, 'num_layers': 2, 'initialization_multiplier': 0.5516184221346051}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 586 final loss: -0.00036974\n",
      "Trial 587:\n",
      "  Learning Rate: 0.008276695396012564\n",
      "  Sigma Multiplier: 1.0076325225614136\n",
      "  Initialization Multiplier: 0.5139990607714872\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.81it/s, loss=-0.000318, elapsed time=0.07, total time=11.1]\n",
      "[I 2025-06-07 14:32:32,338] Trial 587 finished with value: -0.0003175131004202259 and parameters: {'learning_rate': 0.008276695396012564, 'sigma_multiplier': 1.0076325225614136, 'num_layers': 2, 'initialization_multiplier': 0.5139990607714872}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 587 final loss: -0.00031751\n",
      "Trial 588:\n",
      "  Learning Rate: 0.00638385075999232\n",
      "  Sigma Multiplier: 0.8833397035911749\n",
      "  Initialization Multiplier: 0.6651835709207707\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.89it/s, loss=-0.000185, elapsed time=0.05, total time=11.9]\n",
      "[I 2025-06-07 14:32:44,345] Trial 588 finished with value: -0.00018516637369418815 and parameters: {'learning_rate': 0.00638385075999232, 'sigma_multiplier': 0.8833397035911749, 'num_layers': 2, 'initialization_multiplier': 0.6651835709207707}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 588 final loss: -0.00018517\n",
      "Trial 589:\n",
      "  Learning Rate: 0.00962228453168651\n",
      "  Sigma Multiplier: 0.947608129962642\n",
      "  Initialization Multiplier: 0.6018153849427126\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.65it/s, loss=0.000028, elapsed time=0.11, total time=17.9] \n",
      "[I 2025-06-07 14:33:02,333] Trial 589 finished with value: 2.7999819717085846e-05 and parameters: {'learning_rate': 0.00962228453168651, 'sigma_multiplier': 0.947608129962642, 'num_layers': 4, 'initialization_multiplier': 0.6018153849427126}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 589 final loss: 0.00002800\n",
      "Trial 590:\n",
      "  Learning Rate: 0.007244249772860417\n",
      "  Sigma Multiplier: 1.034509344493126\n",
      "  Initialization Multiplier: 0.31807628866075854\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.49it/s, loss=-0.000259, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:33:13,831] Trial 590 finished with value: -0.0002589836255772042 and parameters: {'learning_rate': 0.007244249772860417, 'sigma_multiplier': 1.034509344493126, 'num_layers': 2, 'initialization_multiplier': 0.31807628866075854}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 590 final loss: -0.00025898\n",
      "Trial 591:\n",
      "  Learning Rate: 0.010765017577743544\n",
      "  Sigma Multiplier: 0.9798436866799907\n",
      "  Initialization Multiplier: 0.4065271269335967\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000295, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:33:25,983] Trial 591 finished with value: -0.00029483144513362626 and parameters: {'learning_rate': 0.010765017577743544, 'sigma_multiplier': 0.9798436866799907, 'num_layers': 2, 'initialization_multiplier': 0.4065271269335967}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 591 final loss: -0.00029483\n",
      "Trial 592:\n",
      "  Learning Rate: 0.004815332835980337\n",
      "  Sigma Multiplier: 1.1118762991321265\n",
      "  Initialization Multiplier: 0.5730656615790708\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.73it/s, loss=-0.000340, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:33:37,287] Trial 592 finished with value: -0.0003396526219237529 and parameters: {'learning_rate': 0.004815332835980337, 'sigma_multiplier': 1.1118762991321265, 'num_layers': 2, 'initialization_multiplier': 0.5730656615790708}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 592 final loss: -0.00033965\n",
      "Trial 593:\n",
      "  Learning Rate: 0.008781320296979532\n",
      "  Sigma Multiplier: 1.0554303228439266\n",
      "  Initialization Multiplier: 0.9128438443491182\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.56it/s, loss=-0.000310, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 14:33:48,668] Trial 593 finished with value: -0.0003100838588393854 and parameters: {'learning_rate': 0.008781320296979532, 'sigma_multiplier': 1.0554303228439266, 'num_layers': 2, 'initialization_multiplier': 0.9128438443491182}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 593 final loss: -0.00031008\n",
      "Trial 594:\n",
      "  Learning Rate: 0.011839126726060654\n",
      "  Sigma Multiplier: 1.0089473810213057\n",
      "  Initialization Multiplier: 0.49296332887251476\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000427, elapsed time=0.15, total time=11.4]\n",
      "[I 2025-06-07 14:34:00,182] Trial 594 finished with value: -0.0004269195160284194 and parameters: {'learning_rate': 0.011839126726060654, 'sigma_multiplier': 1.0089473810213057, 'num_layers': 2, 'initialization_multiplier': 0.49296332887251476}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 594 final loss: -0.00042692\n",
      "Trial 595:\n",
      "  Learning Rate: 0.006234951987288581\n",
      "  Sigma Multiplier: 0.9440882406168218\n",
      "  Initialization Multiplier: 0.44385681051356296\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.57it/s, loss=-0.000402, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 14:34:11,635] Trial 595 finished with value: -0.00040249638422870014 and parameters: {'learning_rate': 0.006234951987288581, 'sigma_multiplier': 0.9440882406168218, 'num_layers': 2, 'initialization_multiplier': 0.44385681051356296}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 595 final loss: -0.00040250\n",
      "Trial 596:\n",
      "  Learning Rate: 0.003950858552039628\n",
      "  Sigma Multiplier: 0.902727095089606\n",
      "  Initialization Multiplier: 0.53602054972097\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.15it/s, loss=-0.000309, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:34:23,585] Trial 596 finished with value: -0.00030885056579880635 and parameters: {'learning_rate': 0.003950858552039628, 'sigma_multiplier': 0.902727095089606, 'num_layers': 2, 'initialization_multiplier': 0.53602054972097}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 596 final loss: -0.00030885\n",
      "Trial 597:\n",
      "  Learning Rate: 0.007944882371641617\n",
      "  Sigma Multiplier: 1.07295158980393\n",
      "  Initialization Multiplier: 1.0955164227401388\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000153, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 14:34:35,234] Trial 597 finished with value: -0.00015259337371621595 and parameters: {'learning_rate': 0.007944882371641617, 'sigma_multiplier': 1.07295158980393, 'num_layers': 2, 'initialization_multiplier': 1.0955164227401388}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 597 final loss: -0.00015259\n",
      "Trial 598:\n",
      "  Learning Rate: 0.009735471462545851\n",
      "  Sigma Multiplier: 0.9688993626959002\n",
      "  Initialization Multiplier: 0.6015005304281067\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=-0.000319, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:34:46,678] Trial 598 finished with value: -0.00031930313203858905 and parameters: {'learning_rate': 0.009735471462545851, 'sigma_multiplier': 0.9688993626959002, 'num_layers': 2, 'initialization_multiplier': 0.6015005304281067}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 598 final loss: -0.00031930\n",
      "Trial 599:\n",
      "  Learning Rate: 0.011781628968830478\n",
      "  Sigma Multiplier: 1.0118376966677969\n",
      "  Initialization Multiplier: 1.4991036626593002\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.59it/s, loss=-0.000285, elapsed time=0.05, total time=9.34]\n",
      "[I 2025-06-07 14:34:56,064] Trial 599 finished with value: -0.00028542982173748467 and parameters: {'learning_rate': 0.011781628968830478, 'sigma_multiplier': 1.0118376966677969, 'num_layers': 1, 'initialization_multiplier': 1.4991036626593002}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 599 final loss: -0.00028543\n",
      "Trial 600:\n",
      "  Learning Rate: 0.0070018766224903784\n",
      "  Sigma Multiplier: 0.8246926429157542\n",
      "  Initialization Multiplier: 0.6549477241412045\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.83it/s, loss=-0.000310, elapsed time=0.08, total time=11.9]\n",
      "[I 2025-06-07 14:35:08,033] Trial 600 finished with value: -0.00030976691294712795 and parameters: {'learning_rate': 0.0070018766224903784, 'sigma_multiplier': 0.8246926429157542, 'num_layers': 2, 'initialization_multiplier': 0.6549477241412045}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 600 final loss: -0.00030977\n",
      "Trial 601:\n",
      "  Learning Rate: 0.0001295823436835382\n",
      "  Sigma Multiplier: 1.14504552116955\n",
      "  Initialization Multiplier: 0.5286527514711594\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.27it/s, loss=0.034780, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 14:35:18,903] Trial 601 finished with value: 0.03477961185502359 and parameters: {'learning_rate': 0.0001295823436835382, 'sigma_multiplier': 1.14504552116955, 'num_layers': 2, 'initialization_multiplier': 0.5286527514711594}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 601 final loss: 0.03477961\n",
      "Trial 602:\n",
      "  Learning Rate: 0.015336774425065584\n",
      "  Sigma Multiplier: 1.0446919398103396\n",
      "  Initialization Multiplier: 0.5747535100386003\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000370, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:35:30,486] Trial 602 finished with value: -0.00036986310719914464 and parameters: {'learning_rate': 0.015336774425065584, 'sigma_multiplier': 1.0446919398103396, 'num_layers': 2, 'initialization_multiplier': 0.5747535100386003}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 602 final loss: -0.00036986\n",
      "Trial 603:\n",
      "  Learning Rate: 0.009217365412204652\n",
      "  Sigma Multiplier: 0.9285634330498803\n",
      "  Initialization Multiplier: 0.47882430297190176\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.56it/s, loss=-0.000407, elapsed time=0.08, total time=12.7]\n",
      "[I 2025-06-07 14:35:43,279] Trial 603 finished with value: -0.00040682993088020575 and parameters: {'learning_rate': 0.009217365412204652, 'sigma_multiplier': 0.9285634330498803, 'num_layers': 2, 'initialization_multiplier': 0.47882430297190176}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 603 final loss: -0.00040683\n",
      "Trial 604:\n",
      "  Learning Rate: 0.00533729096221635\n",
      "  Sigma Multiplier: 0.9850106985732044\n",
      "  Initialization Multiplier: 0.7066886386420745\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000257, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 14:35:54,905] Trial 604 finished with value: -0.00025651736704317265 and parameters: {'learning_rate': 0.00533729096221635, 'sigma_multiplier': 0.9850106985732044, 'num_layers': 2, 'initialization_multiplier': 0.7066886386420745}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 604 final loss: -0.00025652\n",
      "Trial 605:\n",
      "  Learning Rate: 0.010325438157005703\n",
      "  Sigma Multiplier: 1.1081554624655159\n",
      "  Initialization Multiplier: 0.615541324775656\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.41it/s, loss=-0.000347, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 14:36:05,648] Trial 605 finished with value: -0.00034693486434211787 and parameters: {'learning_rate': 0.010325438157005703, 'sigma_multiplier': 1.1081554624655159, 'num_layers': 2, 'initialization_multiplier': 0.615541324775656}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 605 final loss: -0.00034693\n",
      "Trial 606:\n",
      "  Learning Rate: 0.0028314840155877962\n",
      "  Sigma Multiplier: 1.0245605480278268\n",
      "  Initialization Multiplier: 0.5527320264221982\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.60it/s, loss=-0.000389, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:36:17,102] Trial 606 finished with value: -0.00038916190862004515 and parameters: {'learning_rate': 0.0028314840155877962, 'sigma_multiplier': 1.0245605480278268, 'num_layers': 2, 'initialization_multiplier': 0.5527320264221982}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 606 final loss: -0.00038916\n",
      "Trial 607:\n",
      "  Learning Rate: 0.008085245782995163\n",
      "  Sigma Multiplier: 1.0723360859065905\n",
      "  Initialization Multiplier: 0.633767850843298\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.48it/s, loss=-0.000403, elapsed time=0.09, total time=11.4]\n",
      "[I 2025-06-07 14:36:28,567] Trial 607 finished with value: -0.0004030570183643246 and parameters: {'learning_rate': 0.008085245782995163, 'sigma_multiplier': 1.0723360859065905, 'num_layers': 2, 'initialization_multiplier': 0.633767850843298}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 607 final loss: -0.00040306\n",
      "Trial 608:\n",
      "  Learning Rate: 0.012692762150963004\n",
      "  Sigma Multiplier: 0.9530193541857057\n",
      "  Initialization Multiplier: 0.5106140950197683\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000319, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 14:36:40,204] Trial 608 finished with value: -0.0003191733912274768 and parameters: {'learning_rate': 0.012692762150963004, 'sigma_multiplier': 0.9530193541857057, 'num_layers': 2, 'initialization_multiplier': 0.5106140950197683}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 608 final loss: -0.00031917\n",
      "Trial 609:\n",
      "  Learning Rate: 0.006143143911040651\n",
      "  Sigma Multiplier: 0.8618361052462137\n",
      "  Initialization Multiplier: 0.4412826428711163\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.77it/s, loss=-0.000308, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:36:51,424] Trial 609 finished with value: -0.0003080135522013076 and parameters: {'learning_rate': 0.006143143911040651, 'sigma_multiplier': 0.8618361052462137, 'num_layers': 2, 'initialization_multiplier': 0.4412826428711163}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 609 final loss: -0.00030801\n",
      "Trial 610:\n",
      "  Learning Rate: 0.017470963079564004\n",
      "  Sigma Multiplier: 0.9959166602298498\n",
      "  Initialization Multiplier: 0.7246677460598964\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.37it/s, loss=-0.000235, elapsed time=0.07, total time=11.6]\n",
      "[I 2025-06-07 14:37:03,064] Trial 610 finished with value: -0.00023511938781794182 and parameters: {'learning_rate': 0.017470963079564004, 'sigma_multiplier': 0.9959166602298498, 'num_layers': 2, 'initialization_multiplier': 0.7246677460598964}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 610 final loss: -0.00023512\n",
      "Trial 611:\n",
      "  Learning Rate: 0.010768000059927747\n",
      "  Sigma Multiplier: 1.038947074414477\n",
      "  Initialization Multiplier: 0.38319645287591775\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.11it/s, loss=-0.000225, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 14:37:14,002] Trial 611 finished with value: -0.0002251687549891661 and parameters: {'learning_rate': 0.010768000059927747, 'sigma_multiplier': 1.038947074414477, 'num_layers': 2, 'initialization_multiplier': 0.38319645287591775}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 611 final loss: -0.00022517\n",
      "Trial 612:\n",
      "  Learning Rate: 0.007579837631915513\n",
      "  Sigma Multiplier: 0.9035401018662292\n",
      "  Initialization Multiplier: 0.584672781641009\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.63it/s, loss=-0.000319, elapsed time=0.09, total time=12.2]\n",
      "[I 2025-06-07 14:37:26,253] Trial 612 finished with value: -0.00031861733645787723 and parameters: {'learning_rate': 0.007579837631915513, 'sigma_multiplier': 0.9035401018662292, 'num_layers': 2, 'initialization_multiplier': 0.584672781641009}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 612 final loss: -0.00031862\n",
      "Trial 613:\n",
      "  Learning Rate: 0.004685080383713583\n",
      "  Sigma Multiplier: 0.9655478938887984\n",
      "  Initialization Multiplier: 0.6688097929542626\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:19<00:00,  7.75it/s, loss=-0.000143, elapsed time=0.11, total time=20]  \n",
      "[I 2025-06-07 14:37:46,506] Trial 613 finished with value: -0.00014288024470549706 and parameters: {'learning_rate': 0.004685080383713583, 'sigma_multiplier': 0.9655478938887984, 'num_layers': 5, 'initialization_multiplier': 0.6688097929542626}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 613 final loss: -0.00014288\n",
      "Trial 614:\n",
      "  Learning Rate: 0.014937619475428697\n",
      "  Sigma Multiplier: 1.0099080235313893\n",
      "  Initialization Multiplier: 0.483915531853285\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.53it/s, loss=-0.000393, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:37:57,939] Trial 614 finished with value: -0.0003933708455163935 and parameters: {'learning_rate': 0.014937619475428697, 'sigma_multiplier': 1.0099080235313893, 'num_layers': 2, 'initialization_multiplier': 0.483915531853285}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 614 final loss: -0.00039337\n",
      "Trial 615:\n",
      "  Learning Rate: 0.00910889210402316\n",
      "  Sigma Multiplier: 1.0986545633641183\n",
      "  Initialization Multiplier: 0.5383712956601607\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.03it/s, loss=-0.000347, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:38:09,368] Trial 615 finished with value: -0.00034742552922571246 and parameters: {'learning_rate': 0.00910889210402316, 'sigma_multiplier': 1.0986545633641183, 'num_layers': 2, 'initialization_multiplier': 0.5383712956601607}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 615 final loss: -0.00034743\n",
      "Trial 616:\n",
      "  Learning Rate: 0.012212104201066276\n",
      "  Sigma Multiplier: 0.939447223502361\n",
      "  Initialization Multiplier: 0.6118365216741317\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.28it/s, loss=-0.000047, elapsed time=0.09, total time=13.7]\n",
      "[I 2025-06-07 14:38:23,080] Trial 616 finished with value: -4.733269173882921e-05 and parameters: {'learning_rate': 0.012212104201066276, 'sigma_multiplier': 0.939447223502361, 'num_layers': 3, 'initialization_multiplier': 0.6118365216741317}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 616 final loss: -0.00004733\n",
      "Trial 617:\n",
      "  Learning Rate: 0.007047120170221414\n",
      "  Sigma Multiplier: 1.0586739851778348\n",
      "  Initialization Multiplier: 0.5700934887575366\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.57it/s, loss=-0.000366, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:38:34,511] Trial 617 finished with value: -0.0003658000805133481 and parameters: {'learning_rate': 0.007047120170221414, 'sigma_multiplier': 1.0586739851778348, 'num_layers': 2, 'initialization_multiplier': 0.5700934887575366}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 617 final loss: -0.00036580\n",
      "Trial 618:\n",
      "  Learning Rate: 0.009737934705547008\n",
      "  Sigma Multiplier: 0.9910397980014953\n",
      "  Initialization Multiplier: 0.5126755355713029\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.57it/s, loss=-0.000359, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:38:45,956] Trial 618 finished with value: -0.00035924489506518315 and parameters: {'learning_rate': 0.009737934705547008, 'sigma_multiplier': 0.9910397980014953, 'num_layers': 2, 'initialization_multiplier': 0.5126755355713029}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 618 final loss: -0.00035924\n",
      "Trial 619:\n",
      "  Learning Rate: 0.005801301937445217\n",
      "  Sigma Multiplier: 1.0278335074256817\n",
      "  Initialization Multiplier: 0.4481397409286443\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.65it/s, loss=-0.000302, elapsed time=0.09, total time=11.3]\n",
      "[I 2025-06-07 14:38:57,351] Trial 619 finished with value: -0.00030165917618415306 and parameters: {'learning_rate': 0.005801301937445217, 'sigma_multiplier': 1.0278335074256817, 'num_layers': 2, 'initialization_multiplier': 0.4481397409286443}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 619 final loss: -0.00030166\n",
      "Trial 620:\n",
      "  Learning Rate: 0.013148658374368133\n",
      "  Sigma Multiplier: 1.1599980777464647\n",
      "  Initialization Multiplier: 0.6386091670666489\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.17it/s, loss=-0.000372, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 14:39:08,351] Trial 620 finished with value: -0.00037165220266897414 and parameters: {'learning_rate': 0.013148658374368133, 'sigma_multiplier': 1.1599980777464647, 'num_layers': 2, 'initialization_multiplier': 0.6386091670666489}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 620 final loss: -0.00037165\n",
      "Trial 621:\n",
      "  Learning Rate: 0.008197581636745143\n",
      "  Sigma Multiplier: 0.9208254974830136\n",
      "  Initialization Multiplier: 0.5821905488430912\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.43it/s, loss=-0.000400, elapsed time=0.1, total time=11.4] \n",
      "[I 2025-06-07 14:39:19,803] Trial 621 finished with value: -0.00040000974362347383 and parameters: {'learning_rate': 0.008197581636745143, 'sigma_multiplier': 0.9208254974830136, 'num_layers': 2, 'initialization_multiplier': 0.5821905488430912}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 621 final loss: -0.00040001\n",
      "Trial 622:\n",
      "  Learning Rate: 0.010908277423827287\n",
      "  Sigma Multiplier: 1.0776581998549755\n",
      "  Initialization Multiplier: 0.5295562514097393\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000337, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:39:31,059] Trial 622 finished with value: -0.0003368189759392556 and parameters: {'learning_rate': 0.010908277423827287, 'sigma_multiplier': 1.0776581998549755, 'num_layers': 2, 'initialization_multiplier': 0.5295562514097393}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 622 final loss: -0.00033682\n",
      "Trial 623:\n",
      "  Learning Rate: 0.016342689249994588\n",
      "  Sigma Multiplier: 0.9665144843735491\n",
      "  Initialization Multiplier: 0.47381380485167446\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.56it/s, loss=-0.000342, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:39:42,510] Trial 623 finished with value: -0.00034213474175504754 and parameters: {'learning_rate': 0.016342689249994588, 'sigma_multiplier': 0.9665144843735491, 'num_layers': 2, 'initialization_multiplier': 0.47381380485167446}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 623 final loss: -0.00034213\n",
      "Trial 624:\n",
      "  Learning Rate: 0.008941572693160777\n",
      "  Sigma Multiplier: 0.8760228423843527\n",
      "  Initialization Multiplier: 0.6114104523727857\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.43it/s, loss=-0.000361, elapsed time=0.07, total time=14.7]\n",
      "[I 2025-06-07 14:39:57,265] Trial 624 finished with value: -0.0003607748213465884 and parameters: {'learning_rate': 0.008941572693160777, 'sigma_multiplier': 0.8760228423843527, 'num_layers': 2, 'initialization_multiplier': 0.6114104523727857}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 624 final loss: -0.00036077\n",
      "Trial 625:\n",
      "  Learning Rate: 0.003703251174634949\n",
      "  Sigma Multiplier: 1.0108785466313845\n",
      "  Initialization Multiplier: 0.5548697797543212\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.18it/s, loss=-0.000362, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 14:40:08,228] Trial 625 finished with value: -0.0003618208111303256 and parameters: {'learning_rate': 0.003703251174634949, 'sigma_multiplier': 1.0108785466313845, 'num_layers': 2, 'initialization_multiplier': 0.5548697797543212}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 625 final loss: -0.00036182\n",
      "Trial 626:\n",
      "  Learning Rate: 0.006728051869328571\n",
      "  Sigma Multiplier: 1.0570200609376053\n",
      "  Initialization Multiplier: 0.6836743674102915\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.19it/s, loss=-0.000188, elapsed time=0.05, total time=9.02]\n",
      "[I 2025-06-07 14:40:17,285] Trial 626 finished with value: -0.0001881032008260887 and parameters: {'learning_rate': 0.006728051869328571, 'sigma_multiplier': 1.0570200609376053, 'num_layers': 1, 'initialization_multiplier': 0.6836743674102915}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 626 final loss: -0.00018810\n",
      "Trial 627:\n",
      "  Learning Rate: 0.0113535521063887\n",
      "  Sigma Multiplier: 1.1297073354744547\n",
      "  Initialization Multiplier: 0.4233060567497713\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.69it/s, loss=-0.000372, elapsed time=0.05, total time=10.4]\n",
      "[I 2025-06-07 14:40:27,799] Trial 627 finished with value: -0.00037166187539071393 and parameters: {'learning_rate': 0.0113535521063887, 'sigma_multiplier': 1.1297073354744547, 'num_layers': 2, 'initialization_multiplier': 0.4233060567497713}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 627 final loss: -0.00037166\n",
      "Trial 628:\n",
      "  Learning Rate: 0.00473572891195858\n",
      "  Sigma Multiplier: 0.9841031167162347\n",
      "  Initialization Multiplier: 0.5250068765681645\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.83it/s, loss=-0.000295, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 14:40:38,932] Trial 628 finished with value: -0.00029522531967256737 and parameters: {'learning_rate': 0.00473572891195858, 'sigma_multiplier': 0.9841031167162347, 'num_layers': 2, 'initialization_multiplier': 0.5250068765681645}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 628 final loss: -0.00029523\n",
      "Trial 629:\n",
      "  Learning Rate: 0.013796828327172802\n",
      "  Sigma Multiplier: 0.9501468865942123\n",
      "  Initialization Multiplier: 0.49219580904739646\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000292, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 14:40:50,264] Trial 629 finished with value: -0.0002918142194629011 and parameters: {'learning_rate': 0.013796828327172802, 'sigma_multiplier': 0.9501468865942123, 'num_layers': 2, 'initialization_multiplier': 0.49219580904739646}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 629 final loss: -0.00029181\n",
      "Trial 630:\n",
      "  Learning Rate: 0.009693922289990716\n",
      "  Sigma Multiplier: 1.0287745403191735\n",
      "  Initialization Multiplier: 0.639213127905069\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.11it/s, loss=-0.000403, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:41:02,024] Trial 630 finished with value: -0.000403174505483067 and parameters: {'learning_rate': 0.009693922289990716, 'sigma_multiplier': 1.0287745403191735, 'num_layers': 2, 'initialization_multiplier': 0.639213127905069}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 630 final loss: -0.00040317\n",
      "Trial 631:\n",
      "  Learning Rate: 0.01850254015869139\n",
      "  Sigma Multiplier: 1.626409412687503\n",
      "  Initialization Multiplier: 0.5882597956723223\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.59it/s, loss=-0.000273, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 14:41:12,261] Trial 631 finished with value: -0.00027309902820085036 and parameters: {'learning_rate': 0.01850254015869139, 'sigma_multiplier': 1.626409412687503, 'num_layers': 2, 'initialization_multiplier': 0.5882597956723223}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 631 final loss: -0.00027310\n",
      "Trial 632:\n",
      "  Learning Rate: 0.008243129086774426\n",
      "  Sigma Multiplier: 0.913770567387073\n",
      "  Initialization Multiplier: 0.554941211912409\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000337, elapsed time=0.06, total time=11.4]\n",
      "[I 2025-06-07 14:41:23,711] Trial 632 finished with value: -0.00033716141490924763 and parameters: {'learning_rate': 0.008243129086774426, 'sigma_multiplier': 0.913770567387073, 'num_layers': 2, 'initialization_multiplier': 0.554941211912409}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 632 final loss: -0.00033716\n",
      "Trial 633:\n",
      "  Learning Rate: 0.005661501259851788\n",
      "  Sigma Multiplier: 1.0930129804382283\n",
      "  Initialization Multiplier: 0.6727898269965402\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.65it/s, loss=-0.000328, elapsed time=0.12, total time=11.4]\n",
      "[I 2025-06-07 14:41:35,207] Trial 633 finished with value: -0.00032754985589513575 and parameters: {'learning_rate': 0.005661501259851788, 'sigma_multiplier': 1.0930129804382283, 'num_layers': 2, 'initialization_multiplier': 0.6727898269965402}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 633 final loss: -0.00032755\n",
      "Trial 634:\n",
      "  Learning Rate: 0.011603406308841399\n",
      "  Sigma Multiplier: 0.9837601480627233\n",
      "  Initialization Multiplier: 0.4744074916511464\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.98it/s, loss=-0.000334, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 14:41:46,257] Trial 634 finished with value: -0.0003338170898553326 and parameters: {'learning_rate': 0.011603406308841399, 'sigma_multiplier': 0.9837601480627233, 'num_layers': 2, 'initialization_multiplier': 0.4744074916511464}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 634 final loss: -0.00033382\n",
      "Trial 635:\n",
      "  Learning Rate: 0.007201152952386206\n",
      "  Sigma Multiplier: 1.0594466399948095\n",
      "  Initialization Multiplier: 0.36448202608589597\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.86it/s, loss=-0.000313, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:41:57,455] Trial 635 finished with value: -0.00031280998275834014 and parameters: {'learning_rate': 0.007201152952386206, 'sigma_multiplier': 1.0594466399948095, 'num_layers': 2, 'initialization_multiplier': 0.36448202608589597}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 635 final loss: -0.00031281\n",
      "Trial 636:\n",
      "  Learning Rate: 0.013914004548321859\n",
      "  Sigma Multiplier: 1.0188094015823626\n",
      "  Initialization Multiplier: 0.6147614526971189\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.69it/s, loss=-0.000267, elapsed time=0.05, total time=9.86]\n",
      "[I 2025-06-07 14:42:07,361] Trial 636 finished with value: -0.00026689749573398326 and parameters: {'learning_rate': 0.013914004548321859, 'sigma_multiplier': 1.0188094015823626, 'num_layers': 1, 'initialization_multiplier': 0.6147614526971189}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 636 final loss: -0.00026690\n",
      "Trial 637:\n",
      "  Learning Rate: 0.023257687235310166\n",
      "  Sigma Multiplier: 0.9439692066326345\n",
      "  Initialization Multiplier: 0.5080722612090458\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.54it/s, loss=-0.000267, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 14:42:18,748] Trial 637 finished with value: -0.0002669172517351403 and parameters: {'learning_rate': 0.023257687235310166, 'sigma_multiplier': 0.9439692066326345, 'num_layers': 2, 'initialization_multiplier': 0.5080722612090458}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 637 final loss: -0.00026692\n",
      "Trial 638:\n",
      "  Learning Rate: 0.01012755302053437\n",
      "  Sigma Multiplier: 0.7686131550127164\n",
      "  Initialization Multiplier: 0.5728950356238826\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.98it/s, loss=-0.000211, elapsed time=0.06, total time=11.8]\n",
      "[I 2025-06-07 14:42:30,667] Trial 638 finished with value: -0.0002111348392352972 and parameters: {'learning_rate': 0.01012755302053437, 'sigma_multiplier': 0.7686131550127164, 'num_layers': 2, 'initialization_multiplier': 0.5728950356238826}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 638 final loss: -0.00021113\n",
      "Trial 639:\n",
      "  Learning Rate: 0.006421380902545413\n",
      "  Sigma Multiplier: 1.1076304049760473\n",
      "  Initialization Multiplier: 0.7522483724600934\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.86it/s, loss=-0.000316, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 14:42:41,821] Trial 639 finished with value: -0.0003163430412215499 and parameters: {'learning_rate': 0.006421380902545413, 'sigma_multiplier': 1.1076304049760473, 'num_layers': 2, 'initialization_multiplier': 0.7522483724600934}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 639 final loss: -0.00031634\n",
      "Trial 640:\n",
      "  Learning Rate: 0.00867670451200758\n",
      "  Sigma Multiplier: 1.2007424881728104\n",
      "  Initialization Multiplier: 0.42778050317143945\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.25it/s, loss=-0.000321, elapsed time=0.07, total time=10.8]\n",
      "[I 2025-06-07 14:42:52,684] Trial 640 finished with value: -0.000320775126644034 and parameters: {'learning_rate': 0.00867670451200758, 'sigma_multiplier': 1.2007424881728104, 'num_layers': 2, 'initialization_multiplier': 0.42778050317143945}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 640 final loss: -0.00032078\n",
      "Trial 641:\n",
      "  Learning Rate: 0.00431038604559327\n",
      "  Sigma Multiplier: 0.880506213445359\n",
      "  Initialization Multiplier: 0.8033859826006691\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.01it/s, loss=-0.000198, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 14:43:04,582] Trial 641 finished with value: -0.00019760516419574137 and parameters: {'learning_rate': 0.00431038604559327, 'sigma_multiplier': 0.880506213445359, 'num_layers': 2, 'initialization_multiplier': 0.8033859826006691}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 641 final loss: -0.00019761\n",
      "Trial 642:\n",
      "  Learning Rate: 0.01230274645197267\n",
      "  Sigma Multiplier: 0.976741312224988\n",
      "  Initialization Multiplier: 0.5461270306643047\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.05it/s, loss=-0.000304, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 14:43:15,740] Trial 642 finished with value: -0.00030448097959248724 and parameters: {'learning_rate': 0.01230274645197267, 'sigma_multiplier': 0.976741312224988, 'num_layers': 2, 'initialization_multiplier': 0.5461270306643047}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 642 final loss: -0.00030448\n",
      "Trial 643:\n",
      "  Learning Rate: 0.015557248551441192\n",
      "  Sigma Multiplier: 1.0349542934660856\n",
      "  Initialization Multiplier: 0.607498607934708\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.98it/s, loss=-0.000286, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 14:43:26,797] Trial 643 finished with value: -0.0002857172525878605 and parameters: {'learning_rate': 0.015557248551441192, 'sigma_multiplier': 1.0349542934660856, 'num_layers': 2, 'initialization_multiplier': 0.607498607934708}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 643 final loss: -0.00028572\n",
      "Trial 644:\n",
      "  Learning Rate: 0.007780953306923447\n",
      "  Sigma Multiplier: 0.9908502080183662\n",
      "  Initialization Multiplier: 0.6461519935110712\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.94it/s, loss=-0.000356, elapsed time=0.12, total time=11.1]\n",
      "[I 2025-06-07 14:43:37,947] Trial 644 finished with value: -0.0003560483411582621 and parameters: {'learning_rate': 0.007780953306923447, 'sigma_multiplier': 0.9908502080183662, 'num_layers': 2, 'initialization_multiplier': 0.6461519935110712}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 644 final loss: -0.00035605\n",
      "Trial 645:\n",
      "  Learning Rate: 0.009857572616489868\n",
      "  Sigma Multiplier: 1.072892704598926\n",
      "  Initialization Multiplier: 0.5104687994873869\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.30it/s, loss=-0.000434, elapsed time=0.08, total time=10.8]\n",
      "[I 2025-06-07 14:43:48,826] Trial 645 finished with value: -0.000433973310333205 and parameters: {'learning_rate': 0.009857572616489868, 'sigma_multiplier': 1.072892704598926, 'num_layers': 2, 'initialization_multiplier': 0.5104687994873869}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 645 final loss: -0.00043397\n",
      "Trial 646:\n",
      "  Learning Rate: 0.002481436274723902\n",
      "  Sigma Multiplier: 0.8386541838649169\n",
      "  Initialization Multiplier: 0.40104383814178807\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.06it/s, loss=-0.000320, elapsed time=0.07, total time=13.9]\n",
      "[I 2025-06-07 14:44:02,787] Trial 646 finished with value: -0.0003196441864049145 and parameters: {'learning_rate': 0.002481436274723902, 'sigma_multiplier': 0.8386541838649169, 'num_layers': 3, 'initialization_multiplier': 0.40104383814178807}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 646 final loss: -0.00031964\n",
      "Trial 647:\n",
      "  Learning Rate: 0.0032486999134658835\n",
      "  Sigma Multiplier: 0.9246635878184022\n",
      "  Initialization Multiplier: 0.4639487583767515\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.72it/s, loss=-0.000299, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:44:14,086] Trial 647 finished with value: -0.0002992214943549796 and parameters: {'learning_rate': 0.0032486999134658835, 'sigma_multiplier': 0.9246635878184022, 'num_layers': 2, 'initialization_multiplier': 0.4639487583767515}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 647 final loss: -0.00029922\n",
      "Trial 648:\n",
      "  Learning Rate: 0.005176128801950891\n",
      "  Sigma Multiplier: 1.0270191532186064\n",
      "  Initialization Multiplier: 0.7216708251388455\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.98it/s, loss=-0.000386, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 14:44:25,262] Trial 648 finished with value: -0.0003861849032979524 and parameters: {'learning_rate': 0.005176128801950891, 'sigma_multiplier': 1.0270191532186064, 'num_layers': 2, 'initialization_multiplier': 0.7216708251388455}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 648 final loss: -0.00038618\n",
      "Trial 649:\n",
      "  Learning Rate: 0.011385517933544817\n",
      "  Sigma Multiplier: 0.9635104633093768\n",
      "  Initialization Multiplier: 0.5669554583700864\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.35it/s, loss=-0.000280, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 14:44:36,839] Trial 649 finished with value: -0.00028048834255751985 and parameters: {'learning_rate': 0.011385517933544817, 'sigma_multiplier': 0.9635104633093768, 'num_layers': 2, 'initialization_multiplier': 0.5669554583700864}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 649 final loss: -0.00028049\n",
      "Trial 650:\n",
      "  Learning Rate: 0.006976802424806823\n",
      "  Sigma Multiplier: 1.003623504942829\n",
      "  Initialization Multiplier: 0.6004444059596981\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.44it/s, loss=-0.000394, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:44:48,394] Trial 650 finished with value: -0.000393787966576028 and parameters: {'learning_rate': 0.006976802424806823, 'sigma_multiplier': 1.003623504942829, 'num_layers': 2, 'initialization_multiplier': 0.6004444059596981}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 650 final loss: -0.00039379\n",
      "Trial 651:\n",
      "  Learning Rate: 0.009012890190049683\n",
      "  Sigma Multiplier: 1.052536975616817\n",
      "  Initialization Multiplier: 0.5361540684533688\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.02it/s, loss=-0.000405, elapsed time=0.06, total time=9.73]\n",
      "[I 2025-06-07 14:44:58,189] Trial 651 finished with value: -0.00040490326117094557 and parameters: {'learning_rate': 0.009012890190049683, 'sigma_multiplier': 1.052536975616817, 'num_layers': 2, 'initialization_multiplier': 0.5361540684533688}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 651 final loss: -0.00040490\n",
      "Trial 652:\n",
      "  Learning Rate: 0.013793385280376507\n",
      "  Sigma Multiplier: 1.1395921450155488\n",
      "  Initialization Multiplier: 0.6689077318691241\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.91it/s, loss=-0.000324, elapsed time=0.06, total time=10.5]\n",
      "[I 2025-06-07 14:45:08,906] Trial 652 finished with value: -0.0003243273370881184 and parameters: {'learning_rate': 0.013793385280376507, 'sigma_multiplier': 1.1395921450155488, 'num_layers': 2, 'initialization_multiplier': 0.6689077318691241}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 652 final loss: -0.00032433\n",
      "Trial 653:\n",
      "  Learning Rate: 0.018987142578845352\n",
      "  Sigma Multiplier: 0.9039149063660635\n",
      "  Initialization Multiplier: 0.49841647929783345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.25it/s, loss=-0.000315, elapsed time=0.05, total time=11.8]\n",
      "[I 2025-06-07 14:45:20,846] Trial 653 finished with value: -0.0003153061818690022 and parameters: {'learning_rate': 0.018987142578845352, 'sigma_multiplier': 0.9039149063660635, 'num_layers': 2, 'initialization_multiplier': 0.49841647929783345}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 653 final loss: -0.00031531\n",
      "Trial 654:\n",
      "  Learning Rate: 0.006052180536087992\n",
      "  Sigma Multiplier: 0.1887411474112507\n",
      "  Initialization Multiplier: 0.6300072525507769\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.12it/s, loss=0.000108, elapsed time=0.11, total time=15.1] \n",
      "[I 2025-06-07 14:45:35,999] Trial 654 finished with value: 0.00010752363832089477 and parameters: {'learning_rate': 0.006052180536087992, 'sigma_multiplier': 0.1887411474112507, 'num_layers': 2, 'initialization_multiplier': 0.6300072525507769}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 654 final loss: 0.00010752\n",
      "Trial 655:\n",
      "  Learning Rate: 0.008094967473322322\n",
      "  Sigma Multiplier: 0.9526241233122964\n",
      "  Initialization Multiplier: 0.5778283963779736\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.13it/s, loss=-0.000266, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:45:47,779] Trial 655 finished with value: -0.00026625819385652454 and parameters: {'learning_rate': 0.008094967473322322, 'sigma_multiplier': 0.9526241233122964, 'num_layers': 2, 'initialization_multiplier': 0.5778283963779736}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 655 final loss: -0.00026626\n",
      "Trial 656:\n",
      "  Learning Rate: 0.010731650051984197\n",
      "  Sigma Multiplier: 1.0929567753990403\n",
      "  Initialization Multiplier: 0.4593727778969069\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.13it/s, loss=-0.000472, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 14:45:58,731] Trial 656 finished with value: -0.0004724922704045399 and parameters: {'learning_rate': 0.010731650051984197, 'sigma_multiplier': 1.0929567753990403, 'num_layers': 2, 'initialization_multiplier': 0.4593727778969069}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 656 final loss: -0.00047249\n",
      "Trial 657:\n",
      "  Learning Rate: 0.010207062343967866\n",
      "  Sigma Multiplier: 1.1745286222340885\n",
      "  Initialization Multiplier: 0.36924355686479193\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.21it/s, loss=-0.000335, elapsed time=0.06, total time=10.9]\n",
      "[I 2025-06-07 14:46:09,732] Trial 657 finished with value: -0.0003347172127049811 and parameters: {'learning_rate': 0.010207062343967866, 'sigma_multiplier': 1.1745286222340885, 'num_layers': 2, 'initialization_multiplier': 0.36924355686479193}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 657 final loss: -0.00033472\n",
      "Trial 658:\n",
      "  Learning Rate: 0.01615866806192552\n",
      "  Sigma Multiplier: 1.1121191642474257\n",
      "  Initialization Multiplier: 0.414714727747576\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.26it/s, loss=-0.000234, elapsed time=0.04, total time=9.66]\n",
      "[I 2025-06-07 14:46:19,446] Trial 658 finished with value: -0.00023388992279479222 and parameters: {'learning_rate': 0.01615866806192552, 'sigma_multiplier': 1.1121191642474257, 'num_layers': 1, 'initialization_multiplier': 0.414714727747576}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 658 final loss: -0.00023389\n",
      "Trial 659:\n",
      "  Learning Rate: 0.012276239725497401\n",
      "  Sigma Multiplier: 1.1469331880420526\n",
      "  Initialization Multiplier: 1.8429502249064549\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.35it/s, loss=-0.000241, elapsed time=0.05, total time=11.6]\n",
      "[I 2025-06-07 14:46:31,075] Trial 659 finished with value: -0.00024137614653018012 and parameters: {'learning_rate': 0.012276239725497401, 'sigma_multiplier': 1.1469331880420526, 'num_layers': 2, 'initialization_multiplier': 1.8429502249064549}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 659 final loss: -0.00024138\n",
      "Trial 660:\n",
      "  Learning Rate: 0.007990195488756336\n",
      "  Sigma Multiplier: 0.40048536354989384\n",
      "  Initialization Multiplier: 0.44044706013855806\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.45it/s, loss=0.000308, elapsed time=0.09, total time=14.7]\n",
      "[I 2025-06-07 14:46:45,813] Trial 660 finished with value: 0.00030750204930818446 and parameters: {'learning_rate': 0.007990195488756336, 'sigma_multiplier': 0.40048536354989384, 'num_layers': 2, 'initialization_multiplier': 0.44044706013855806}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 660 final loss: 0.00030750\n",
      "Trial 661:\n",
      "  Learning Rate: 0.006880774606610322\n",
      "  Sigma Multiplier: 1.0920810685107383\n",
      "  Initialization Multiplier: 0.46169258790261064\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.90it/s, loss=-0.000383, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 14:46:56,911] Trial 661 finished with value: -0.00038326210928583027 and parameters: {'learning_rate': 0.006880774606610322, 'sigma_multiplier': 1.0920810685107383, 'num_layers': 2, 'initialization_multiplier': 0.46169258790261064}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 661 final loss: -0.00038326\n",
      "Trial 662:\n",
      "  Learning Rate: 0.00955304827066354\n",
      "  Sigma Multiplier: 1.110268895087032\n",
      "  Initialization Multiplier: 0.44660129828124046\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000409, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:47:08,178] Trial 662 finished with value: -0.000409081649100893 and parameters: {'learning_rate': 0.00955304827066354, 'sigma_multiplier': 1.110268895087032, 'num_layers': 2, 'initialization_multiplier': 0.44660129828124046}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 662 final loss: -0.00040908\n",
      "Trial 663:\n",
      "  Learning Rate: 0.004224624505112666\n",
      "  Sigma Multiplier: 1.404614221296324\n",
      "  Initialization Multiplier: 0.3990110209860054\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.72it/s, loss=-0.000286, elapsed time=0.07, total time=10.6]\n",
      "[I 2025-06-07 14:47:18,800] Trial 663 finished with value: -0.0002864309717373391 and parameters: {'learning_rate': 0.004224624505112666, 'sigma_multiplier': 1.404614221296324, 'num_layers': 2, 'initialization_multiplier': 0.3990110209860054}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 663 final loss: -0.00028643\n",
      "Trial 664:\n",
      "  Learning Rate: 0.005529540409746293\n",
      "  Sigma Multiplier: 1.0761835639880566\n",
      "  Initialization Multiplier: 0.4966741940409274\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.16it/s, loss=-0.000182, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 14:47:29,716] Trial 664 finished with value: -0.00018232503188233718 and parameters: {'learning_rate': 0.005529540409746293, 'sigma_multiplier': 1.0761835639880566, 'num_layers': 2, 'initialization_multiplier': 0.4966741940409274}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 664 final loss: -0.00018233\n",
      "Trial 665:\n",
      "  Learning Rate: 0.012941860938613986\n",
      "  Sigma Multiplier: 1.1796371199626232\n",
      "  Initialization Multiplier: 0.48883190163388196\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.79it/s, loss=-0.000337, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 14:47:41,083] Trial 665 finished with value: -0.00033661916866461274 and parameters: {'learning_rate': 0.012941860938613986, 'sigma_multiplier': 1.1796371199626232, 'num_layers': 2, 'initialization_multiplier': 0.48883190163388196}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 665 final loss: -0.00033662\n",
      "Trial 666:\n",
      "  Learning Rate: 0.010682650052641936\n",
      "  Sigma Multiplier: 1.0475277664801694\n",
      "  Initialization Multiplier: 0.3320143764735526\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.24it/s, loss=-0.000198, elapsed time=0.05, total time=11.7]\n",
      "[I 2025-06-07 14:47:52,857] Trial 666 finished with value: -0.00019823236798993432 and parameters: {'learning_rate': 0.010682650052641936, 'sigma_multiplier': 1.0475277664801694, 'num_layers': 2, 'initialization_multiplier': 0.3320143764735526}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 666 final loss: -0.00019823\n",
      "Trial 667:\n",
      "  Learning Rate: 0.015461424530086918\n",
      "  Sigma Multiplier: 1.1345387148232122\n",
      "  Initialization Multiplier: 0.5312964013817978\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.42it/s, loss=-0.000332, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:48:04,495] Trial 667 finished with value: -0.00033241067523121366 and parameters: {'learning_rate': 0.015461424530086918, 'sigma_multiplier': 1.1345387148232122, 'num_layers': 2, 'initialization_multiplier': 0.5312964013817978}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 667 final loss: -0.00033241\n",
      "Trial 668:\n",
      "  Learning Rate: 0.008404509939760328\n",
      "  Sigma Multiplier: 1.0730132522585016\n",
      "  Initialization Multiplier: 0.45808749065195375\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000364, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 14:48:16,087] Trial 668 finished with value: -0.00036412293396891006 and parameters: {'learning_rate': 0.008404509939760328, 'sigma_multiplier': 1.0730132522585016, 'num_layers': 2, 'initialization_multiplier': 0.45808749065195375}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 668 final loss: -0.00036412\n",
      "Trial 669:\n",
      "  Learning Rate: 0.006761535764097453\n",
      "  Sigma Multiplier: 1.0208656204374615\n",
      "  Initialization Multiplier: 0.41051371270995196\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.26it/s, loss=-0.000374, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:48:27,756] Trial 669 finished with value: -0.00037426068260882364 and parameters: {'learning_rate': 0.006761535764097453, 'sigma_multiplier': 1.0208656204374615, 'num_layers': 2, 'initialization_multiplier': 0.41051371270995196}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 669 final loss: -0.00037426\n",
      "Trial 670:\n",
      "  Learning Rate: 0.011731197141763974\n",
      "  Sigma Multiplier: 0.9864169564414597\n",
      "  Initialization Multiplier: 0.5339003330426719\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.88it/s, loss=-0.000346, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 14:48:39,753] Trial 670 finished with value: -0.0003460483276849732 and parameters: {'learning_rate': 0.011731197141763974, 'sigma_multiplier': 0.9864169564414597, 'num_layers': 2, 'initialization_multiplier': 0.5339003330426719}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 670 final loss: -0.00034605\n",
      "Trial 671:\n",
      "  Learning Rate: 0.004961607961064224\n",
      "  Sigma Multiplier: 0.921928585394061\n",
      "  Initialization Multiplier: 0.49074126291280884\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.97it/s, loss=-0.000340, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 14:48:51,682] Trial 671 finished with value: -0.0003399008247615718 and parameters: {'learning_rate': 0.004961607961064224, 'sigma_multiplier': 0.921928585394061, 'num_layers': 2, 'initialization_multiplier': 0.49074126291280884}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 671 final loss: -0.00033990\n",
      "Trial 672:\n",
      "  Learning Rate: 0.009242734422850372\n",
      "  Sigma Multiplier: 1.08411008136022\n",
      "  Initialization Multiplier: 0.6496154919576812\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.18it/s, loss=-0.000333, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:49:03,441] Trial 672 finished with value: -0.00033294704362143735 and parameters: {'learning_rate': 0.009242734422850372, 'sigma_multiplier': 1.08411008136022, 'num_layers': 2, 'initialization_multiplier': 0.6496154919576812}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 672 final loss: -0.00033295\n",
      "Trial 673:\n",
      "  Learning Rate: 0.020446185748399456\n",
      "  Sigma Multiplier: 0.8692298779338599\n",
      "  Initialization Multiplier: 0.7040042644819298\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.46it/s, loss=-0.000290, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 14:49:14,237] Trial 673 finished with value: -0.00029003246914341977 and parameters: {'learning_rate': 0.020446185748399456, 'sigma_multiplier': 0.8692298779338599, 'num_layers': 1, 'initialization_multiplier': 0.7040042644819298}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 673 final loss: -0.00029003\n",
      "Trial 674:\n",
      "  Learning Rate: 0.05629749833871668\n",
      "  Sigma Multiplier: 1.0407369853119681\n",
      "  Initialization Multiplier: 0.45507417052326254\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.55it/s, loss=-0.000269, elapsed time=0.06, total time=12.3]\n",
      "[I 2025-06-07 14:49:26,572] Trial 674 finished with value: -0.00026850306046821216 and parameters: {'learning_rate': 0.05629749833871668, 'sigma_multiplier': 1.0407369853119681, 'num_layers': 2, 'initialization_multiplier': 0.45507417052326254}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 674 final loss: -0.00026850\n",
      "Trial 675:\n",
      "  Learning Rate: 0.03182151471582531\n",
      "  Sigma Multiplier: 0.9570979300581508\n",
      "  Initialization Multiplier: 0.595653923591096\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.29it/s, loss=0.000018, elapsed time=0.07, total time=14.9] \n",
      "[I 2025-06-07 14:49:41,576] Trial 675 finished with value: 1.7976073504433184e-05 and parameters: {'learning_rate': 0.03182151471582531, 'sigma_multiplier': 0.9570979300581508, 'num_layers': 3, 'initialization_multiplier': 0.595653923591096}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 675 final loss: 0.00001798\n",
      "Trial 676:\n",
      "  Learning Rate: 0.0143527636720158\n",
      "  Sigma Multiplier: 0.1086598865903915\n",
      "  Initialization Multiplier: 0.5277742350149405\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.50it/s, loss=-0.000037, elapsed time=0.11, total time=16.2]\n",
      "[I 2025-06-07 14:49:57,925] Trial 676 finished with value: -3.6960161076825345e-05 and parameters: {'learning_rate': 0.0143527636720158, 'sigma_multiplier': 0.1086598865903915, 'num_layers': 2, 'initialization_multiplier': 0.5277742350149405}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 676 final loss: -0.00003696\n",
      "Trial 677:\n",
      "  Learning Rate: 0.007939637968226622\n",
      "  Sigma Multiplier: 1.0020396307705814\n",
      "  Initialization Multiplier: 0.5604925147213604\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000397, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:50:09,684] Trial 677 finished with value: -0.00039695816380608864 and parameters: {'learning_rate': 0.007939637968226622, 'sigma_multiplier': 1.0020396307705814, 'num_layers': 2, 'initialization_multiplier': 0.5604925147213604}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 677 final loss: -0.00039696\n",
      "Trial 678:\n",
      "  Learning Rate: 0.01095225230791773\n",
      "  Sigma Multiplier: 1.1162791830180734\n",
      "  Initialization Multiplier: 0.4958938793119181\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.06it/s, loss=-0.000413, elapsed time=0.08, total time=11.9]\n",
      "[I 2025-06-07 14:50:21,780] Trial 678 finished with value: -0.00041311979509484965 and parameters: {'learning_rate': 0.01095225230791773, 'sigma_multiplier': 1.1162791830180734, 'num_layers': 2, 'initialization_multiplier': 0.4958938793119181}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 678 final loss: -0.00041312\n",
      "Trial 679:\n",
      "  Learning Rate: 0.005765921396768379\n",
      "  Sigma Multiplier: 1.0517032664354202\n",
      "  Initialization Multiplier: 1.0032510633604776\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.97it/s, loss=0.000002, elapsed time=0.09, total time=11.9] \n",
      "[I 2025-06-07 14:50:33,729] Trial 679 finished with value: 2.171645437408748e-06 and parameters: {'learning_rate': 0.005765921396768379, 'sigma_multiplier': 1.0517032664354202, 'num_layers': 2, 'initialization_multiplier': 1.0032510633604776}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 679 final loss: 0.00000217\n",
      "Trial 680:\n",
      "  Learning Rate: 0.00910059883124547\n",
      "  Sigma Multiplier: 0.9787984538041062\n",
      "  Initialization Multiplier: 0.34984699136749364\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.74it/s, loss=-0.000371, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:50:45,923] Trial 680 finished with value: -0.00037143051435907276 and parameters: {'learning_rate': 0.00910059883124547, 'sigma_multiplier': 0.9787984538041062, 'num_layers': 2, 'initialization_multiplier': 0.34984699136749364}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 680 final loss: -0.00037143\n",
      "Trial 681:\n",
      "  Learning Rate: 0.012956143603835204\n",
      "  Sigma Multiplier: 0.9330124271630531\n",
      "  Initialization Multiplier: 0.6214961640223511\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.38it/s, loss=-0.000306, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 14:50:58,402] Trial 681 finished with value: -0.0003057237080564801 and parameters: {'learning_rate': 0.012956143603835204, 'sigma_multiplier': 0.9330124271630531, 'num_layers': 2, 'initialization_multiplier': 0.6214961640223511}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 681 final loss: -0.00030572\n",
      "Trial 682:\n",
      "  Learning Rate: 0.007463632260387162\n",
      "  Sigma Multiplier: 0.5381826881511591\n",
      "  Initialization Multiplier: 0.5560172396021971\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.67it/s, loss=0.000499, elapsed time=0.1, total time=14.4] \n",
      "[I 2025-06-07 14:51:12,847] Trial 682 finished with value: 0.0004990336114147165 and parameters: {'learning_rate': 0.007463632260387162, 'sigma_multiplier': 0.5381826881511591, 'num_layers': 2, 'initialization_multiplier': 0.5560172396021971}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 682 final loss: 0.00049903\n",
      "Trial 683:\n",
      "  Learning Rate: 0.003839319704834077\n",
      "  Sigma Multiplier: 1.009371204969356\n",
      "  Initialization Multiplier: 0.424116005488882\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.28it/s, loss=-0.000354, elapsed time=0.05, total time=11.6]\n",
      "[I 2025-06-07 14:51:24,539] Trial 683 finished with value: -0.0003540777214903338 and parameters: {'learning_rate': 0.003839319704834077, 'sigma_multiplier': 1.009371204969356, 'num_layers': 2, 'initialization_multiplier': 0.424116005488882}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 683 final loss: -0.00035408\n",
      "Trial 684:\n",
      "  Learning Rate: 0.016792686174739863\n",
      "  Sigma Multiplier: 0.8930932580444382\n",
      "  Initialization Multiplier: 0.6794179070834894\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.73it/s, loss=-0.000276, elapsed time=0.1, total time=12.1] \n",
      "[I 2025-06-07 14:51:36,700] Trial 684 finished with value: -0.0002757985788556281 and parameters: {'learning_rate': 0.016792686174739863, 'sigma_multiplier': 0.8930932580444382, 'num_layers': 2, 'initialization_multiplier': 0.6794179070834894}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 684 final loss: -0.00027580\n",
      "Trial 685:\n",
      "  Learning Rate: 0.009824357723397487\n",
      "  Sigma Multiplier: 1.0858017900842174\n",
      "  Initialization Multiplier: 0.5900947798138143\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.51it/s, loss=-0.000442, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 14:51:48,173] Trial 685 finished with value: -0.00044197161688646876 and parameters: {'learning_rate': 0.009824357723397487, 'sigma_multiplier': 1.0858017900842174, 'num_layers': 2, 'initialization_multiplier': 0.5900947798138143}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 685 final loss: -0.00044197\n",
      "Trial 686:\n",
      "  Learning Rate: 0.010683104662881745\n",
      "  Sigma Multiplier: 1.1050669353940499\n",
      "  Initialization Multiplier: 0.5195292886298754\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.78it/s, loss=-0.000325, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:51:59,482] Trial 686 finished with value: -0.0003245026007086369 and parameters: {'learning_rate': 0.010683104662881745, 'sigma_multiplier': 1.1050669353940499, 'num_layers': 2, 'initialization_multiplier': 0.5195292886298754}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 686 final loss: -0.00032450\n",
      "Trial 687:\n",
      "  Learning Rate: 0.012911438997816684\n",
      "  Sigma Multiplier: 1.1602938910774778\n",
      "  Initialization Multiplier: 0.48315084500581773\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.76it/s, loss=-0.000299, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:52:10,769] Trial 687 finished with value: -0.0002988042195869196 and parameters: {'learning_rate': 0.012911438997816684, 'sigma_multiplier': 1.1602938910774778, 'num_layers': 2, 'initialization_multiplier': 0.48315084500581773}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 687 final loss: -0.00029880\n",
      "Trial 688:\n",
      "  Learning Rate: 0.011098572546921322\n",
      "  Sigma Multiplier: 1.1952945973628775\n",
      "  Initialization Multiplier: 0.5654729791849159\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.79it/s, loss=-0.000372, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 14:52:21,954] Trial 688 finished with value: -0.0003721440295627403 and parameters: {'learning_rate': 0.011098572546921322, 'sigma_multiplier': 1.1952945973628775, 'num_layers': 2, 'initialization_multiplier': 0.5654729791849159}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 688 final loss: -0.00037214\n",
      "Trial 689:\n",
      "  Learning Rate: 0.01486562449523167\n",
      "  Sigma Multiplier: 1.1391257145945133\n",
      "  Initialization Multiplier: 0.5937317460218111\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.71it/s, loss=-0.000371, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:52:33,236] Trial 689 finished with value: -0.0003706853666314314 and parameters: {'learning_rate': 0.01486562449523167, 'sigma_multiplier': 1.1391257145945133, 'num_layers': 2, 'initialization_multiplier': 0.5937317460218111}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 689 final loss: -0.00037069\n",
      "Trial 690:\n",
      "  Learning Rate: 0.009861334739564243\n",
      "  Sigma Multiplier: 1.0729676101256678\n",
      "  Initialization Multiplier: 0.4582345621712268\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.38it/s, loss=-0.000424, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 14:52:44,831] Trial 690 finished with value: -0.0004235016656750626 and parameters: {'learning_rate': 0.009861334739564243, 'sigma_multiplier': 1.0729676101256678, 'num_layers': 2, 'initialization_multiplier': 0.4582345621712268}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 690 final loss: -0.00042350\n",
      "Trial 691:\n",
      "  Learning Rate: 0.01325875100714584\n",
      "  Sigma Multiplier: 1.1092291150136104\n",
      "  Initialization Multiplier: 0.5219125291744774\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.02it/s, loss=-0.000390, elapsed time=0.08, total time=11.9]\n",
      "[I 2025-06-07 14:52:56,768] Trial 691 finished with value: -0.00038985829724772896 and parameters: {'learning_rate': 0.01325875100714584, 'sigma_multiplier': 1.1092291150136104, 'num_layers': 2, 'initialization_multiplier': 0.5219125291744774}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 691 final loss: -0.00038986\n",
      "Trial 692:\n",
      "  Learning Rate: 0.009554630859029157\n",
      "  Sigma Multiplier: 1.0796621053537905\n",
      "  Initialization Multiplier: 0.5862208243786744\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000365, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 14:53:08,473] Trial 692 finished with value: -0.0003650859538189092 and parameters: {'learning_rate': 0.009554630859029157, 'sigma_multiplier': 1.0796621053537905, 'num_layers': 2, 'initialization_multiplier': 0.5862208243786744}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 692 final loss: -0.00036509\n",
      "Trial 693:\n",
      "  Learning Rate: 0.011865011889422659\n",
      "  Sigma Multiplier: 1.0482563204396456\n",
      "  Initialization Multiplier: 0.5412228192041886\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:15<00:00,  9.72it/s, loss=-0.000062, elapsed time=0.11, total time=15.7]\n",
      "[I 2025-06-07 14:53:24,280] Trial 693 finished with value: -6.236536848141586e-05 and parameters: {'learning_rate': 0.011865011889422659, 'sigma_multiplier': 1.0482563204396456, 'num_layers': 4, 'initialization_multiplier': 0.5412228192041886}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 693 final loss: -0.00006237\n",
      "Trial 694:\n",
      "  Learning Rate: 0.017035441397953113\n",
      "  Sigma Multiplier: 1.0879774737770591\n",
      "  Initialization Multiplier: 0.4007535412053056\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.32it/s, loss=-0.000437, elapsed time=0.05, total time=11.7]\n",
      "[I 2025-06-07 14:53:35,996] Trial 694 finished with value: -0.0004372130519330987 and parameters: {'learning_rate': 0.017035441397953113, 'sigma_multiplier': 1.0879774737770591, 'num_layers': 2, 'initialization_multiplier': 0.4007535412053056}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 694 final loss: -0.00043721\n",
      "Trial 695:\n",
      "  Learning Rate: 0.01898412652314497\n",
      "  Sigma Multiplier: 1.2253357076331821\n",
      "  Initialization Multiplier: 0.43818901668456295\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000273, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:53:47,258] Trial 695 finished with value: -0.000273336646122475 and parameters: {'learning_rate': 0.01898412652314497, 'sigma_multiplier': 1.2253357076331821, 'num_layers': 2, 'initialization_multiplier': 0.43818901668456295}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 695 final loss: -0.00027334\n",
      "Trial 696:\n",
      "  Learning Rate: 0.027220908370074348\n",
      "  Sigma Multiplier: 1.1557171157447683\n",
      "  Initialization Multiplier: 0.32217331125380794\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000293, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 14:53:58,967] Trial 696 finished with value: -0.00029265771353549863 and parameters: {'learning_rate': 0.027220908370074348, 'sigma_multiplier': 1.1557171157447683, 'num_layers': 2, 'initialization_multiplier': 0.32217331125380794}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 696 final loss: -0.00029266\n",
      "Trial 697:\n",
      "  Learning Rate: 0.02424058068433244\n",
      "  Sigma Multiplier: 1.1300774561842701\n",
      "  Initialization Multiplier: 0.4147621730712452\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.00it/s, loss=-0.000247, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 14:54:10,059] Trial 697 finished with value: -0.00024722607864892615 and parameters: {'learning_rate': 0.02424058068433244, 'sigma_multiplier': 1.1300774561842701, 'num_layers': 2, 'initialization_multiplier': 0.4147621730712452}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 697 final loss: -0.00024723\n",
      "Trial 698:\n",
      "  Learning Rate: 0.015605645526991077\n",
      "  Sigma Multiplier: 1.0901158886482192\n",
      "  Initialization Multiplier: 0.36060140990384687\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.19it/s, loss=-0.000296, elapsed time=0.05, total time=9.63]\n",
      "[I 2025-06-07 14:54:19,742] Trial 698 finished with value: -0.00029581093565982504 and parameters: {'learning_rate': 0.015605645526991077, 'sigma_multiplier': 1.0901158886482192, 'num_layers': 1, 'initialization_multiplier': 0.36060140990384687}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 698 final loss: -0.00029581\n",
      "Trial 699:\n",
      "  Learning Rate: 0.01958176260249642\n",
      "  Sigma Multiplier: 1.1223180392275556\n",
      "  Initialization Multiplier: 0.38817622036495825\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.25it/s, loss=-0.000258, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 14:54:30,674] Trial 699 finished with value: -0.00025765474071019246 and parameters: {'learning_rate': 0.01958176260249642, 'sigma_multiplier': 1.1223180392275556, 'num_layers': 2, 'initialization_multiplier': 0.38817622036495825}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 699 final loss: -0.00025765\n",
      "Trial 700:\n",
      "  Learning Rate: 0.021977203273361196\n",
      "  Sigma Multiplier: 1.0807482168383138\n",
      "  Initialization Multiplier: 0.422709610034917\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.74it/s, loss=-0.000372, elapsed time=0.05, total time=11.2]\n",
      "[I 2025-06-07 14:54:41,969] Trial 700 finished with value: -0.00037215581923910954 and parameters: {'learning_rate': 0.021977203273361196, 'sigma_multiplier': 1.0807482168383138, 'num_layers': 2, 'initialization_multiplier': 0.422709610034917}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 700 final loss: -0.00037216\n",
      "Trial 701:\n",
      "  Learning Rate: 0.017697676783968542\n",
      "  Sigma Multiplier: 1.173983051284736\n",
      "  Initialization Multiplier: 0.3610054920748237\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.98it/s, loss=-0.000319, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 14:54:53,027] Trial 701 finished with value: -0.0003187871227496458 and parameters: {'learning_rate': 0.017697676783968542, 'sigma_multiplier': 1.173983051284736, 'num_layers': 2, 'initialization_multiplier': 0.3610054920748237}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 701 final loss: -0.00031879\n",
      "Trial 702:\n",
      "  Learning Rate: 0.01412020580936548\n",
      "  Sigma Multiplier: 1.0624611692837607\n",
      "  Initialization Multiplier: 0.38749130251585945\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.71it/s, loss=-0.000290, elapsed time=0.08, total time=11.3]\n",
      "[I 2025-06-07 14:55:04,419] Trial 702 finished with value: -0.00029027058224554136 and parameters: {'learning_rate': 0.01412020580936548, 'sigma_multiplier': 1.0624611692837607, 'num_layers': 2, 'initialization_multiplier': 0.38749130251585945}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 702 final loss: -0.00029027\n",
      "Trial 703:\n",
      "  Learning Rate: 0.017780847208877123\n",
      "  Sigma Multiplier: 1.1203932152415963\n",
      "  Initialization Multiplier: 0.4626361988000485\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.97it/s, loss=-0.000354, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 14:55:15,596] Trial 703 finished with value: -0.0003538740922751803 and parameters: {'learning_rate': 0.017780847208877123, 'sigma_multiplier': 1.1203932152415963, 'num_layers': 2, 'initialization_multiplier': 0.4626361988000485}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 703 final loss: -0.00035387\n",
      "Trial 704:\n",
      "  Learning Rate: 0.01684367591197933\n",
      "  Sigma Multiplier: 1.044263622170647\n",
      "  Initialization Multiplier: 0.3967816767899135\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.85it/s, loss=-0.000310, elapsed time=0.06, total time=11.1]\n",
      "[I 2025-06-07 14:55:26,802] Trial 704 finished with value: -0.0003102975129483081 and parameters: {'learning_rate': 0.01684367591197933, 'sigma_multiplier': 1.044263622170647, 'num_layers': 2, 'initialization_multiplier': 0.3967816767899135}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 704 final loss: -0.00031030\n",
      "Trial 705:\n",
      "  Learning Rate: 0.012448644729237212\n",
      "  Sigma Multiplier: 1.0920286204863596\n",
      "  Initialization Multiplier: 0.3275971604636846\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.87it/s, loss=-0.000395, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 14:55:38,030] Trial 705 finished with value: -0.000395013507892746 and parameters: {'learning_rate': 0.012448644729237212, 'sigma_multiplier': 1.0920286204863596, 'num_layers': 2, 'initialization_multiplier': 0.3275971604636846}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 705 final loss: -0.00039501\n",
      "Trial 706:\n",
      "  Learning Rate: 0.01495031391986899\n",
      "  Sigma Multiplier: 1.03772177395292\n",
      "  Initialization Multiplier: 0.4810389923863753\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.95it/s, loss=-0.000346, elapsed time=0.05, total time=11]  \n",
      "[I 2025-06-07 14:55:49,115] Trial 706 finished with value: -0.0003457128915098667 and parameters: {'learning_rate': 0.01495031391986899, 'sigma_multiplier': 1.03772177395292, 'num_layers': 2, 'initialization_multiplier': 0.4810389923863753}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 706 final loss: -0.00034571\n",
      "Trial 707:\n",
      "  Learning Rate: 0.01100076127166456\n",
      "  Sigma Multiplier: 1.1324683476924757\n",
      "  Initialization Multiplier: 0.4364692879944317\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:17<00:00,  8.64it/s, loss=-0.000030, elapsed time=0.13, total time=17.8]\n",
      "[I 2025-06-07 14:56:06,964] Trial 707 finished with value: -3.0233844067362896e-05 and parameters: {'learning_rate': 0.01100076127166456, 'sigma_multiplier': 1.1324683476924757, 'num_layers': 5, 'initialization_multiplier': 0.4364692879944317}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 707 final loss: -0.00003023\n",
      "Trial 708:\n",
      "  Learning Rate: 0.008838436224836136\n",
      "  Sigma Multiplier: 1.0799907450678683\n",
      "  Initialization Multiplier: 1.6533061327903766\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.43it/s, loss=-0.000021, elapsed time=0.08, total time=13.5]\n",
      "[I 2025-06-07 14:56:20,541] Trial 708 finished with value: -2.076999429610814e-05 and parameters: {'learning_rate': 0.008838436224836136, 'sigma_multiplier': 1.0799907450678683, 'num_layers': 3, 'initialization_multiplier': 1.6533061327903766}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 708 final loss: -0.00002077\n",
      "Trial 709:\n",
      "  Learning Rate: 0.01263660487577371\n",
      "  Sigma Multiplier: 1.028133735070744\n",
      "  Initialization Multiplier: 0.528381587285808\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.88it/s, loss=-0.000311, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:56:31,779] Trial 709 finished with value: -0.00031071278312378705 and parameters: {'learning_rate': 0.01263660487577371, 'sigma_multiplier': 1.028133735070744, 'num_layers': 2, 'initialization_multiplier': 0.528381587285808}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 709 final loss: -0.00031071\n",
      "Trial 710:\n",
      "  Learning Rate: 0.01068581027422156\n",
      "  Sigma Multiplier: 1.1686392437867237\n",
      "  Initialization Multiplier: 0.49221753348326086\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.34it/s, loss=-0.000314, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 14:56:42,571] Trial 710 finished with value: -0.00031392464635039203 and parameters: {'learning_rate': 0.01068581027422156, 'sigma_multiplier': 1.1686392437867237, 'num_layers': 2, 'initialization_multiplier': 0.49221753348326086}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 710 final loss: -0.00031392\n",
      "Trial 711:\n",
      "  Learning Rate: 0.014729699648761384\n",
      "  Sigma Multiplier: 1.0504329824064094\n",
      "  Initialization Multiplier: 0.8350621428871237\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.75it/s, loss=-0.000153, elapsed time=0.07, total time=11.2]\n",
      "[I 2025-06-07 14:56:53,827] Trial 711 finished with value: -0.0001529206595297692 and parameters: {'learning_rate': 0.014729699648761384, 'sigma_multiplier': 1.0504329824064094, 'num_layers': 2, 'initialization_multiplier': 0.8350621428871237}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 711 final loss: -0.00015292\n",
      "Trial 712:\n",
      "  Learning Rate: 0.008668310615911917\n",
      "  Sigma Multiplier: 1.7681393836485024\n",
      "  Initialization Multiplier: 0.46510441783497664\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.15it/s, loss=-0.000258, elapsed time=0.04, total time=10.2]\n",
      "[I 2025-06-07 14:57:04,088] Trial 712 finished with value: -0.00025843485101281137 and parameters: {'learning_rate': 0.008668310615911917, 'sigma_multiplier': 1.7681393836485024, 'num_layers': 2, 'initialization_multiplier': 0.46510441783497664}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 712 final loss: -0.00025843\n",
      "Trial 713:\n",
      "  Learning Rate: 0.00740280183627509\n",
      "  Sigma Multiplier: 1.0144284849358738\n",
      "  Initialization Multiplier: 0.5022754039088486\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.60it/s, loss=-0.000335, elapsed time=0.07, total time=11.4]\n",
      "[I 2025-06-07 14:57:15,556] Trial 713 finished with value: -0.0003354202781129376 and parameters: {'learning_rate': 0.00740280183627509, 'sigma_multiplier': 1.0144284849358738, 'num_layers': 2, 'initialization_multiplier': 0.5022754039088486}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 713 final loss: -0.00033542\n",
      "Trial 714:\n",
      "  Learning Rate: 0.019910810026564262\n",
      "  Sigma Multiplier: 1.1129457497602848\n",
      "  Initialization Multiplier: 0.38058234770595006\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.41it/s, loss=-0.000388, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 14:57:26,313] Trial 714 finished with value: -0.0003884895693556323 and parameters: {'learning_rate': 0.019910810026564262, 'sigma_multiplier': 1.1129457497602848, 'num_layers': 2, 'initialization_multiplier': 0.38058234770595006}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 714 final loss: -0.00038849\n",
      "Trial 715:\n",
      "  Learning Rate: 0.010084157427012509\n",
      "  Sigma Multiplier: 1.0786615370039951\n",
      "  Initialization Multiplier: 0.2723730004528202\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.31it/s, loss=-0.000292, elapsed time=0.05, total time=9.04]\n",
      "[I 2025-06-07 14:57:35,395] Trial 715 finished with value: -0.00029204033445634416 and parameters: {'learning_rate': 0.010084157427012509, 'sigma_multiplier': 1.0786615370039951, 'num_layers': 1, 'initialization_multiplier': 0.2723730004528202}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 715 final loss: -0.00029204\n",
      "Trial 716:\n",
      "  Learning Rate: 0.09989775617068188\n",
      "  Sigma Multiplier: 1.0084502680311604\n",
      "  Initialization Multiplier: 0.4434593451164424\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.95it/s, loss=0.000268, elapsed time=0.06, total time=11.1] \n",
      "[I 2025-06-07 14:57:46,539] Trial 716 finished with value: 0.000268096293037651 and parameters: {'learning_rate': 0.09989775617068188, 'sigma_multiplier': 1.0084502680311604, 'num_layers': 2, 'initialization_multiplier': 0.4434593451164424}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 716 final loss: 0.00026810\n",
      "Trial 717:\n",
      "  Learning Rate: 0.0005709781506346984\n",
      "  Sigma Multiplier: 1.0510876238426796\n",
      "  Initialization Multiplier: 1.2693412075023647\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.53it/s, loss=0.120033, elapsed time=0.05, total time=12.3]\n",
      "[I 2025-06-07 14:57:58,856] Trial 717 finished with value: 0.12003298539947149 and parameters: {'learning_rate': 0.0005709781506346984, 'sigma_multiplier': 1.0510876238426796, 'num_layers': 2, 'initialization_multiplier': 1.2693412075023647}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 717 final loss: 0.12003299\n",
      "Trial 718:\n",
      "  Learning Rate: 0.012528641427232229\n",
      "  Sigma Multiplier: 1.2029157049410548\n",
      "  Initialization Multiplier: 0.5499414088546191\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.86it/s, loss=-0.000365, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 14:58:10,064] Trial 718 finished with value: -0.00036518097991277554 and parameters: {'learning_rate': 0.012528641427232229, 'sigma_multiplier': 1.2029157049410548, 'num_layers': 2, 'initialization_multiplier': 0.5499414088546191}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 718 final loss: -0.00036518\n",
      "Trial 719:\n",
      "  Learning Rate: 0.015736203468117733\n",
      "  Sigma Multiplier: 1.007346952076405\n",
      "  Initialization Multiplier: 0.5009242870021928\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.25it/s, loss=-0.000390, elapsed time=0.07, total time=12.6]\n",
      "[I 2025-06-07 14:58:22,717] Trial 719 finished with value: -0.00038994906104798145 and parameters: {'learning_rate': 0.015736203468117733, 'sigma_multiplier': 1.007346952076405, 'num_layers': 2, 'initialization_multiplier': 0.5009242870021928}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 719 final loss: -0.00038995\n",
      "Trial 720:\n",
      "  Learning Rate: 0.009346984424080619\n",
      "  Sigma Multiplier: 1.102177292698064\n",
      "  Initialization Multiplier: 0.6124568967552991\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.89it/s, loss=-0.000413, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 14:58:33,906] Trial 720 finished with value: -0.0004129200523295701 and parameters: {'learning_rate': 0.009346984424080619, 'sigma_multiplier': 1.102177292698064, 'num_layers': 2, 'initialization_multiplier': 0.6124568967552991}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 720 final loss: -0.00041292\n",
      "Trial 721:\n",
      "  Learning Rate: 6.790148566744838e-05\n",
      "  Sigma Multiplier: 1.0546262017772166\n",
      "  Initialization Multiplier: 0.5663793480086711\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.78it/s, loss=0.056004, elapsed time=0.06, total time=12.1]\n",
      "[I 2025-06-07 14:58:46,024] Trial 721 finished with value: 0.05600399375529993 and parameters: {'learning_rate': 6.790148566744838e-05, 'sigma_multiplier': 1.0546262017772166, 'num_layers': 2, 'initialization_multiplier': 0.5663793480086711}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 721 final loss: 0.05600399\n",
      "Trial 722:\n",
      "  Learning Rate: 0.007978871971005651\n",
      "  Sigma Multiplier: 0.9876443156865546\n",
      "  Initialization Multiplier: 0.5220970465361662\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.19it/s, loss=-0.000454, elapsed time=0.09, total time=12.8]\n",
      "[I 2025-06-07 14:58:58,883] Trial 722 finished with value: -0.0004544466546560395 and parameters: {'learning_rate': 0.007978871971005651, 'sigma_multiplier': 0.9876443156865546, 'num_layers': 2, 'initialization_multiplier': 0.5220970465361662}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 722 final loss: -0.00045445\n",
      "Trial 723:\n",
      "  Learning Rate: 0.0068879753394987505\n",
      "  Sigma Multiplier: 0.9729219933104395\n",
      "  Initialization Multiplier: 0.6544212874238073\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.63it/s, loss=-0.000445, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 14:59:11,167] Trial 723 finished with value: -0.00044528176210073913 and parameters: {'learning_rate': 0.0068879753394987505, 'sigma_multiplier': 0.9729219933104395, 'num_layers': 2, 'initialization_multiplier': 0.6544212874238073}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 723 final loss: -0.00044528\n",
      "Trial 724:\n",
      "  Learning Rate: 0.006451335838850762\n",
      "  Sigma Multiplier: 0.9645208141105678\n",
      "  Initialization Multiplier: 0.7565773569113421\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.49it/s, loss=-0.000133, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 14:59:23,550] Trial 724 finished with value: -0.00013251419435078305 and parameters: {'learning_rate': 0.006451335838850762, 'sigma_multiplier': 0.9645208141105678, 'num_layers': 2, 'initialization_multiplier': 0.7565773569113421}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 724 final loss: -0.00013251\n",
      "Trial 725:\n",
      "  Learning Rate: 0.006654958440340148\n",
      "  Sigma Multiplier: 0.9740274940879385\n",
      "  Initialization Multiplier: 0.6769096867102657\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.50it/s, loss=-0.000359, elapsed time=0.05, total time=12.5]\n",
      "[I 2025-06-07 14:59:36,176] Trial 725 finished with value: -0.0003591361686811808 and parameters: {'learning_rate': 0.006654958440340148, 'sigma_multiplier': 0.9740274940879385, 'num_layers': 2, 'initialization_multiplier': 0.6769096867102657}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 725 final loss: -0.00035914\n",
      "Trial 726:\n",
      "  Learning Rate: 0.00743647041910782\n",
      "  Sigma Multiplier: 0.991739841005479\n",
      "  Initialization Multiplier: 0.6493619483824485\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.82it/s, loss=-0.000357, elapsed time=0.07, total time=12]  \n",
      "[I 2025-06-07 14:59:48,276] Trial 726 finished with value: -0.0003572620636701813 and parameters: {'learning_rate': 0.00743647041910782, 'sigma_multiplier': 0.991739841005479, 'num_layers': 2, 'initialization_multiplier': 0.6493619483824485}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 726 final loss: -0.00035726\n",
      "Trial 727:\n",
      "  Learning Rate: 0.006127808884488671\n",
      "  Sigma Multiplier: 0.9497950049421064\n",
      "  Initialization Multiplier: 0.649388748508519\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:19<00:00,  7.50it/s, loss=-0.000111, elapsed time=0.09, total time=20.3]\n",
      "[I 2025-06-07 15:00:08,699] Trial 727 finished with value: -0.0001114034018248895 and parameters: {'learning_rate': 0.006127808884488671, 'sigma_multiplier': 0.9497950049421064, 'num_layers': 4, 'initialization_multiplier': 0.649388748508519}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 727 final loss: -0.00011140\n",
      "Trial 728:\n",
      "  Learning Rate: 0.00701393589558548\n",
      "  Sigma Multiplier: 1.0268889627058444\n",
      "  Initialization Multiplier: 0.9573241683293483\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.85it/s, loss=-0.000198, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 15:00:20,883] Trial 728 finished with value: -0.00019840935465352994 and parameters: {'learning_rate': 0.00701393589558548, 'sigma_multiplier': 1.0268889627058444, 'num_layers': 2, 'initialization_multiplier': 0.9573241683293483}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 728 final loss: -0.00019841\n",
      "Trial 729:\n",
      "  Learning Rate: 0.007650999070922918\n",
      "  Sigma Multiplier: 0.9832668038586734\n",
      "  Initialization Multiplier: 0.6414309545482871\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.19it/s, loss=-0.000400, elapsed time=0.07, total time=11.7]\n",
      "[I 2025-06-07 15:00:32,641] Trial 729 finished with value: -0.0004002737755506098 and parameters: {'learning_rate': 0.007650999070922918, 'sigma_multiplier': 0.9832668038586734, 'num_layers': 2, 'initialization_multiplier': 0.6414309545482871}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 729 final loss: -0.00040027\n",
      "Trial 730:\n",
      "  Learning Rate: 0.0059692558117027264\n",
      "  Sigma Multiplier: 0.8187134221515187\n",
      "  Initialization Multiplier: 0.717837552909417\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.48it/s, loss=-0.000149, elapsed time=0.05, total time=12.4]\n",
      "[I 2025-06-07 15:00:45,083] Trial 730 finished with value: -0.00014921936795214832 and parameters: {'learning_rate': 0.0059692558117027264, 'sigma_multiplier': 0.8187134221515187, 'num_layers': 2, 'initialization_multiplier': 0.717837552909417}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 730 final loss: -0.00014922\n",
      "Trial 731:\n",
      "  Learning Rate: 0.007795814161832459\n",
      "  Sigma Multiplier: 0.9221428960725251\n",
      "  Initialization Multiplier: 0.688552478335344\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000417, elapsed time=0.11, total time=11.8]\n",
      "[I 2025-06-07 15:00:56,980] Trial 731 finished with value: -0.0004168626283561131 and parameters: {'learning_rate': 0.007795814161832459, 'sigma_multiplier': 0.9221428960725251, 'num_layers': 2, 'initialization_multiplier': 0.688552478335344}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 731 final loss: -0.00041686\n",
      "Trial 732:\n",
      "  Learning Rate: 0.008313423023785887\n",
      "  Sigma Multiplier: 1.1454689678931562\n",
      "  Initialization Multiplier: 0.62416075874884\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.46it/s, loss=-0.000327, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 15:01:07,719] Trial 732 finished with value: -0.00032745919769177424 and parameters: {'learning_rate': 0.008313423023785887, 'sigma_multiplier': 1.1454689678931562, 'num_layers': 2, 'initialization_multiplier': 0.62416075874884}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 732 final loss: -0.00032746\n",
      "Trial 733:\n",
      "  Learning Rate: 0.00038962357434424487\n",
      "  Sigma Multiplier: 1.070496390233562\n",
      "  Initialization Multiplier: 0.2976206293624062\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.52it/s, loss=0.006517, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 15:01:19,122] Trial 733 finished with value: 0.0065165662502419935 and parameters: {'learning_rate': 0.00038962357434424487, 'sigma_multiplier': 1.070496390233562, 'num_layers': 2, 'initialization_multiplier': 0.2976206293624062}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 733 final loss: 0.00651657\n",
      "Trial 734:\n",
      "  Learning Rate: 0.00627766382640825\n",
      "  Sigma Multiplier: 1.0191513601480704\n",
      "  Initialization Multiplier: 0.7325931391897375\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.23it/s, loss=-0.000127, elapsed time=0.11, total time=11.7]\n",
      "[I 2025-06-07 15:01:30,862] Trial 734 finished with value: -0.00012748841867197186 and parameters: {'learning_rate': 0.00627766382640825, 'sigma_multiplier': 1.0191513601480704, 'num_layers': 2, 'initialization_multiplier': 0.7325931391897375}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 734 final loss: -0.00012749\n",
      "Trial 735:\n",
      "  Learning Rate: 0.008710630603701844\n",
      "  Sigma Multiplier: 0.9604666612822583\n",
      "  Initialization Multiplier: 0.5889265916556229\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=-0.000475, elapsed time=0.05, total time=11.3]\n",
      "[I 2025-06-07 15:01:42,192] Trial 735 finished with value: -0.00047462951300322785 and parameters: {'learning_rate': 0.008710630603701844, 'sigma_multiplier': 0.9604666612822583, 'num_layers': 2, 'initialization_multiplier': 0.5889265916556229}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 735 final loss: -0.00047463\n",
      "Trial 736:\n",
      "  Learning Rate: 0.008517251234864178\n",
      "  Sigma Multiplier: 0.8566495082859401\n",
      "  Initialization Multiplier: 0.6069931827776934\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.94it/s, loss=-0.000326, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 15:01:54,125] Trial 736 finished with value: -0.000326480151808102 and parameters: {'learning_rate': 0.008517251234864178, 'sigma_multiplier': 0.8566495082859401, 'num_layers': 2, 'initialization_multiplier': 0.6069931827776934}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 736 final loss: -0.00032648\n",
      "Trial 737:\n",
      "  Learning Rate: 0.007538148828449586\n",
      "  Sigma Multiplier: 0.8859896083162806\n",
      "  Initialization Multiplier: 0.6905065535871612\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.20it/s, loss=-0.000249, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:02:04,348] Trial 737 finished with value: -0.00024871285880695356 and parameters: {'learning_rate': 0.007538148828449586, 'sigma_multiplier': 0.8859896083162806, 'num_layers': 1, 'initialization_multiplier': 0.6905065535871612}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 737 final loss: -0.00024871\n",
      "Trial 738:\n",
      "  Learning Rate: 0.005514817167202739\n",
      "  Sigma Multiplier: 0.9416077391804544\n",
      "  Initialization Multiplier: 0.6431480171803092\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.89it/s, loss=-0.000383, elapsed time=0.08, total time=12]  \n",
      "[I 2025-06-07 15:02:16,404] Trial 738 finished with value: -0.0003826657072619391 and parameters: {'learning_rate': 0.005514817167202739, 'sigma_multiplier': 0.9416077391804544, 'num_layers': 2, 'initialization_multiplier': 0.6431480171803092}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 738 final loss: -0.00038267\n",
      "Trial 739:\n",
      "  Learning Rate: 0.009977632056505063\n",
      "  Sigma Multiplier: 0.9037529661146658\n",
      "  Initialization Multiplier: 0.5950908102632885\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.00it/s, loss=-0.000305, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 15:02:28,273] Trial 739 finished with value: -0.00030503120111254804 and parameters: {'learning_rate': 0.009977632056505063, 'sigma_multiplier': 0.9037529661146658, 'num_layers': 2, 'initialization_multiplier': 0.5950908102632885}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 739 final loss: -0.00030503\n",
      "Trial 740:\n",
      "  Learning Rate: 0.00664296891710113\n",
      "  Sigma Multiplier: 0.9622132225507553\n",
      "  Initialization Multiplier: 0.6644900704212108\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.41it/s, loss=-0.000143, elapsed time=0.14, total time=14.7]\n",
      "[I 2025-06-07 15:02:43,057] Trial 740 finished with value: -0.0001432392957392749 and parameters: {'learning_rate': 0.00664296891710113, 'sigma_multiplier': 0.9622132225507553, 'num_layers': 3, 'initialization_multiplier': 0.6644900704212108}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 740 final loss: -0.00014324\n",
      "Trial 741:\n",
      "  Learning Rate: 0.008955836014379052\n",
      "  Sigma Multiplier: 1.0916940025425221\n",
      "  Initialization Multiplier: 0.602975565606296\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.34it/s, loss=-0.000319, elapsed time=0.09, total time=11.6]\n",
      "[I 2025-06-07 15:02:54,664] Trial 741 finished with value: -0.0003192897174317213 and parameters: {'learning_rate': 0.008955836014379052, 'sigma_multiplier': 1.0916940025425221, 'num_layers': 2, 'initialization_multiplier': 0.602975565606296}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 741 final loss: -0.00031929\n",
      "Trial 742:\n",
      "  Learning Rate: 0.007318179543903815\n",
      "  Sigma Multiplier: 0.9958487351836545\n",
      "  Initialization Multiplier: 0.5709146489161401\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.78it/s, loss=-0.000295, elapsed time=0.06, total time=12.2]\n",
      "[I 2025-06-07 15:03:06,937] Trial 742 finished with value: -0.00029543031250360785 and parameters: {'learning_rate': 0.007318179543903815, 'sigma_multiplier': 0.9958487351836545, 'num_layers': 2, 'initialization_multiplier': 0.5709146489161401}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 742 final loss: -0.00029543\n",
      "Trial 743:\n",
      "  Learning Rate: 0.009441327548132364\n",
      "  Sigma Multiplier: 0.9439634117802873\n",
      "  Initialization Multiplier: 0.6282952456352904\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.64it/s, loss=-0.000299, elapsed time=0.08, total time=12.3]\n",
      "[I 2025-06-07 15:03:19,339] Trial 743 finished with value: -0.00029884375325855457 and parameters: {'learning_rate': 0.009441327548132364, 'sigma_multiplier': 0.9439634117802873, 'num_layers': 2, 'initialization_multiplier': 0.6282952456352904}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 743 final loss: -0.00029884\n",
      "Trial 744:\n",
      "  Learning Rate: 0.005052166485213425\n",
      "  Sigma Multiplier: 1.1435448264188903\n",
      "  Initialization Multiplier: 0.5321030036858307\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.26it/s, loss=-0.000370, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 15:03:30,958] Trial 744 finished with value: -0.00036996345319951015 and parameters: {'learning_rate': 0.005052166485213425, 'sigma_multiplier': 1.1435448264188903, 'num_layers': 2, 'initialization_multiplier': 0.5321030036858307}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 744 final loss: -0.00036996\n",
      "Trial 745:\n",
      "  Learning Rate: 0.011392202498667781\n",
      "  Sigma Multiplier: 1.0485327145868943\n",
      "  Initialization Multiplier: 0.4044264477394042\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.50it/s, loss=-0.000404, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 15:03:42,468] Trial 745 finished with value: -0.00040398254115558963 and parameters: {'learning_rate': 0.011392202498667781, 'sigma_multiplier': 1.0485327145868943, 'num_layers': 2, 'initialization_multiplier': 0.4044264477394042}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 745 final loss: -0.00040398\n",
      "Trial 746:\n",
      "  Learning Rate: 0.008383514411823265\n",
      "  Sigma Multiplier: 0.974673543034704\n",
      "  Initialization Multiplier: 0.5862669740165236\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.74it/s, loss=-0.000352, elapsed time=0.08, total time=12.2]\n",
      "[I 2025-06-07 15:03:54,715] Trial 746 finished with value: -0.00035232270101300466 and parameters: {'learning_rate': 0.008383514411823265, 'sigma_multiplier': 0.974673543034704, 'num_layers': 2, 'initialization_multiplier': 0.5862669740165236}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 746 final loss: -0.00035232\n",
      "Trial 747:\n",
      "  Learning Rate: 0.006901026066111823\n",
      "  Sigma Multiplier: 0.794644007965185\n",
      "  Initialization Multiplier: 0.716503679591368\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.50it/s, loss=-0.000171, elapsed time=0.08, total time=13.4]\n",
      "[I 2025-06-07 15:04:08,153] Trial 747 finished with value: -0.00017093738571495937 and parameters: {'learning_rate': 0.006901026066111823, 'sigma_multiplier': 0.794644007965185, 'num_layers': 2, 'initialization_multiplier': 0.716503679591368}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 747 final loss: -0.00017094\n",
      "Trial 748:\n",
      "  Learning Rate: 0.009906238265482115\n",
      "  Sigma Multiplier: 1.026270822759051\n",
      "  Initialization Multiplier: 0.7820647243963994\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.44it/s, loss=-0.000089, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 15:04:20,620] Trial 748 finished with value: -8.949644568183601e-05 and parameters: {'learning_rate': 0.009906238265482115, 'sigma_multiplier': 1.026270822759051, 'num_layers': 2, 'initialization_multiplier': 0.7820647243963994}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 748 final loss: -0.00008950\n",
      "Trial 749:\n",
      "  Learning Rate: 0.00845106397380253\n",
      "  Sigma Multiplier: 1.092812863690611\n",
      "  Initialization Multiplier: 0.47220227323922476\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.39it/s, loss=-0.000231, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 15:04:32,244] Trial 749 finished with value: -0.00023125385889709389 and parameters: {'learning_rate': 0.00845106397380253, 'sigma_multiplier': 1.092812863690611, 'num_layers': 2, 'initialization_multiplier': 0.47220227323922476}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 749 final loss: -0.00023125\n",
      "Trial 750:\n",
      "  Learning Rate: 0.005882771387326149\n",
      "  Sigma Multiplier: 0.9159002034401242\n",
      "  Initialization Multiplier: 0.5259690211756264\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.52it/s, loss=-0.000434, elapsed time=0.07, total time=12.3]\n",
      "[I 2025-06-07 15:04:44,665] Trial 750 finished with value: -0.0004339045880816505 and parameters: {'learning_rate': 0.005882771387326149, 'sigma_multiplier': 0.9159002034401242, 'num_layers': 2, 'initialization_multiplier': 0.5259690211756264}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 750 final loss: -0.00043390\n",
      "Trial 751:\n",
      "  Learning Rate: 0.011120166278461427\n",
      "  Sigma Multiplier: 0.9946519412859451\n",
      "  Initialization Multiplier: 0.671085701092148\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.82it/s, loss=-0.000353, elapsed time=0.07, total time=12.1]\n",
      "[I 2025-06-07 15:04:56,781] Trial 751 finished with value: -0.00035251662928179864 and parameters: {'learning_rate': 0.011120166278461427, 'sigma_multiplier': 0.9946519412859451, 'num_layers': 2, 'initialization_multiplier': 0.671085701092148}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 751 final loss: -0.00035252\n",
      "Trial 752:\n",
      "  Learning Rate: 0.007283313674922107\n",
      "  Sigma Multiplier: 1.0562006579136578\n",
      "  Initialization Multiplier: 0.6118741632340825\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.42it/s, loss=-0.000408, elapsed time=0.05, total time=11.4]\n",
      "[I 2025-06-07 15:05:08,284] Trial 752 finished with value: -0.0004076410948232848 and parameters: {'learning_rate': 0.007283313674922107, 'sigma_multiplier': 1.0562006579136578, 'num_layers': 2, 'initialization_multiplier': 0.6118741632340825}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 752 final loss: -0.00040764\n",
      "Trial 753:\n",
      "  Learning Rate: 0.009538213219091186\n",
      "  Sigma Multiplier: 0.9549057945778774\n",
      "  Initialization Multiplier: 0.554683807275005\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.73it/s, loss=-0.000294, elapsed time=0.1, total time=12.1] \n",
      "[I 2025-06-07 15:05:20,476] Trial 753 finished with value: -0.00029412622467978614 and parameters: {'learning_rate': 0.009538213219091186, 'sigma_multiplier': 0.9549057945778774, 'num_layers': 2, 'initialization_multiplier': 0.554683807275005}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 753 final loss: -0.00029413\n",
      "Trial 754:\n",
      "  Learning Rate: 0.01187658640722841\n",
      "  Sigma Multiplier: 1.2571083474659495\n",
      "  Initialization Multiplier: 0.4415447866189659\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.32it/s, loss=-0.000362, elapsed time=0.05, total time=10.8]\n",
      "[I 2025-06-07 15:05:31,357] Trial 754 finished with value: -0.00036167672343396384 and parameters: {'learning_rate': 0.01187658640722841, 'sigma_multiplier': 1.2571083474659495, 'num_layers': 2, 'initialization_multiplier': 0.4415447866189659}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 754 final loss: -0.00036168\n",
      "Trial 755:\n",
      "  Learning Rate: 0.008183252689031077\n",
      "  Sigma Multiplier: 0.7478884385103077\n",
      "  Initialization Multiplier: 0.5060092212068742\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.69it/s, loss=-0.000241, elapsed time=0.06, total time=13.2]\n",
      "[I 2025-06-07 15:05:44,690] Trial 755 finished with value: -0.0002411644889080703 and parameters: {'learning_rate': 0.008183252689031077, 'sigma_multiplier': 0.7478884385103077, 'num_layers': 2, 'initialization_multiplier': 0.5060092212068742}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 755 final loss: -0.00024116\n",
      "Trial 756:\n",
      "  Learning Rate: 0.00199567521802995\n",
      "  Sigma Multiplier: 1.1158319760055952\n",
      "  Initialization Multiplier: 0.5803587683925568\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.22it/s, loss=-0.000312, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 15:05:56,576] Trial 756 finished with value: -0.0003120550637056797 and parameters: {'learning_rate': 0.00199567521802995, 'sigma_multiplier': 1.1158319760055952, 'num_layers': 2, 'initialization_multiplier': 0.5803587683925568}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 756 final loss: -0.00031206\n",
      "Trial 757:\n",
      "  Learning Rate: 0.005340291803272617\n",
      "  Sigma Multiplier: 1.0306641309094366\n",
      "  Initialization Multiplier: 0.35469287517325826\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.65it/s, loss=-0.000318, elapsed time=0.06, total time=12.2]\n",
      "[I 2025-06-07 15:06:08,815] Trial 757 finished with value: -0.0003177023448711156 and parameters: {'learning_rate': 0.005340291803272617, 'sigma_multiplier': 1.0306641309094366, 'num_layers': 2, 'initialization_multiplier': 0.35469287517325826}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 757 final loss: -0.00031770\n",
      "Trial 758:\n",
      "  Learning Rate: 0.006629543878297159\n",
      "  Sigma Multiplier: 0.8491114025202073\n",
      "  Initialization Multiplier: 0.6363293258127467\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.26it/s, loss=-0.000263, elapsed time=0.07, total time=12.5]\n",
      "[I 2025-06-07 15:06:21,402] Trial 758 finished with value: -0.00026256926552911127 and parameters: {'learning_rate': 0.006629543878297159, 'sigma_multiplier': 0.8491114025202073, 'num_layers': 2, 'initialization_multiplier': 0.6363293258127467}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 758 final loss: -0.00026257\n",
      "Trial 759:\n",
      "  Learning Rate: 0.010257957467814634\n",
      "  Sigma Multiplier: 1.1752336956815697\n",
      "  Initialization Multiplier: 0.4686795498862622\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.89it/s, loss=-0.000335, elapsed time=0.08, total time=11.2]\n",
      "[I 2025-06-07 15:06:32,659] Trial 759 finished with value: -0.00033493757226763356 and parameters: {'learning_rate': 0.010257957467814634, 'sigma_multiplier': 1.1752336956815697, 'num_layers': 2, 'initialization_multiplier': 0.4686795498862622}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 759 final loss: -0.00033494\n",
      "Trial 760:\n",
      "  Learning Rate: 0.012911723480021769\n",
      "  Sigma Multiplier: 0.8993293629460986\n",
      "  Initialization Multiplier: 0.5341500920274204\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.74it/s, loss=-0.000211, elapsed time=0.06, total time=10.6]\n",
      "[I 2025-06-07 15:06:43,284] Trial 760 finished with value: -0.00021074241000690563 and parameters: {'learning_rate': 0.012911723480021769, 'sigma_multiplier': 0.8993293629460986, 'num_layers': 1, 'initialization_multiplier': 0.5341500920274204}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 760 final loss: -0.00021074\n",
      "Trial 761:\n",
      "  Learning Rate: 0.008807423497733977\n",
      "  Sigma Multiplier: 0.9942691466106034\n",
      "  Initialization Multiplier: 0.4148869601333131\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.54it/s, loss=-0.000340, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 15:06:55,762] Trial 761 finished with value: -0.0003404617473087335 and parameters: {'learning_rate': 0.008807423497733977, 'sigma_multiplier': 0.9942691466106034, 'num_layers': 2, 'initialization_multiplier': 0.4148869601333131}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 761 final loss: -0.00034046\n",
      "Trial 762:\n",
      "  Learning Rate: 0.010631475813958667\n",
      "  Sigma Multiplier: 1.0547965649173343\n",
      "  Initialization Multiplier: 0.6849331445169439\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.77it/s, loss=-0.000271, elapsed time=0.09, total time=12.1]\n",
      "[I 2025-06-07 15:07:07,917] Trial 762 finished with value: -0.0002709641051884987 and parameters: {'learning_rate': 0.010631475813958667, 'sigma_multiplier': 1.0547965649173343, 'num_layers': 2, 'initialization_multiplier': 0.6849331445169439}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 762 final loss: -0.00027096\n",
      "Trial 763:\n",
      "  Learning Rate: 0.00022464768308505078\n",
      "  Sigma Multiplier: 0.954288318677023\n",
      "  Initialization Multiplier: 0.5694378714806018\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.65it/s, loss=0.044411, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 15:07:20,210] Trial 763 finished with value: 0.04441083878688734 and parameters: {'learning_rate': 0.00022464768308505078, 'sigma_multiplier': 0.954288318677023, 'num_layers': 2, 'initialization_multiplier': 0.5694378714806018}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 763 final loss: 0.04441084\n",
      "Trial 764:\n",
      "  Learning Rate: 0.006299874590496089\n",
      "  Sigma Multiplier: 1.0916492123778279\n",
      "  Initialization Multiplier: 0.6137584083678528\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.26it/s, loss=-0.000359, elapsed time=0.05, total time=12.6]\n",
      "[I 2025-06-07 15:07:32,851] Trial 764 finished with value: -0.00035946117939722667 and parameters: {'learning_rate': 0.006299874590496089, 'sigma_multiplier': 1.0916492123778279, 'num_layers': 2, 'initialization_multiplier': 0.6137584083678528}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 764 final loss: -0.00035946\n",
      "Trial 765:\n",
      "  Learning Rate: 0.007999071810496847\n",
      "  Sigma Multiplier: 1.0124182740160572\n",
      "  Initialization Multiplier: 0.49661356718096866\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.42it/s, loss=-0.000343, elapsed time=0.08, total time=12.4]\n",
      "[I 2025-06-07 15:07:45,412] Trial 765 finished with value: -0.0003429341883686654 and parameters: {'learning_rate': 0.007999071810496847, 'sigma_multiplier': 1.0124182740160572, 'num_layers': 2, 'initialization_multiplier': 0.49661356718096866}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 765 final loss: -0.00034293\n",
      "Trial 766:\n",
      "  Learning Rate: 0.012029640500095314\n",
      "  Sigma Multiplier: 0.9240010133828582\n",
      "  Initialization Multiplier: 0.547590147263409\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.75it/s, loss=-0.000324, elapsed time=0.09, total time=13.1]\n",
      "[I 2025-06-07 15:07:58,627] Trial 766 finished with value: -0.0003243128020035604 and parameters: {'learning_rate': 0.012029640500095314, 'sigma_multiplier': 0.9240010133828582, 'num_layers': 2, 'initialization_multiplier': 0.547590147263409}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 766 final loss: -0.00032431\n",
      "Trial 767:\n",
      "  Learning Rate: 0.009851581368106514\n",
      "  Sigma Multiplier: 1.1477681429857882\n",
      "  Initialization Multiplier: 0.6337447999780225\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.47it/s, loss=-0.000328, elapsed time=0.05, total time=12.4]\n",
      "[I 2025-06-07 15:08:11,253] Trial 767 finished with value: -0.00032786808917350797 and parameters: {'learning_rate': 0.009851581368106514, 'sigma_multiplier': 1.1477681429857882, 'num_layers': 2, 'initialization_multiplier': 0.6337447999780225}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 767 final loss: -0.00032787\n",
      "Trial 768:\n",
      "  Learning Rate: 0.005238619317208971\n",
      "  Sigma Multiplier: 0.9803233127558972\n",
      "  Initialization Multiplier: 0.4637651453638353\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.80it/s, loss=-0.000396, elapsed time=0.06, total time=11.2]\n",
      "[I 2025-06-07 15:08:22,516] Trial 768 finished with value: -0.00039552275328540957 and parameters: {'learning_rate': 0.005238619317208971, 'sigma_multiplier': 0.9803233127558972, 'num_layers': 2, 'initialization_multiplier': 0.4637651453638353}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 768 final loss: -0.00039552\n",
      "Trial 769:\n",
      "  Learning Rate: 0.01374160358818277\n",
      "  Sigma Multiplier: 1.0761642932450721\n",
      "  Initialization Multiplier: 0.5803510507429608\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.17it/s, loss=-0.000305, elapsed time=0.08, total time=11.9]\n",
      "[I 2025-06-07 15:08:34,566] Trial 769 finished with value: -0.0003053344939619738 and parameters: {'learning_rate': 0.01374160358818277, 'sigma_multiplier': 1.0761642932450721, 'num_layers': 2, 'initialization_multiplier': 0.5803510507429608}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 769 final loss: -0.00030533\n",
      "Trial 770:\n",
      "  Learning Rate: 0.007401550603813541\n",
      "  Sigma Multiplier: 1.0289218186618858\n",
      "  Initialization Multiplier: 0.5089632214838017\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.85it/s, loss=-0.000259, elapsed time=0.05, total time=12.1]\n",
      "[I 2025-06-07 15:08:46,766] Trial 770 finished with value: -0.0002588623177898789 and parameters: {'learning_rate': 0.007401550603813541, 'sigma_multiplier': 1.0289218186618858, 'num_layers': 2, 'initialization_multiplier': 0.5089632214838017}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 770 final loss: -0.00025886\n",
      "Trial 771:\n",
      "  Learning Rate: 0.001669740057928426\n",
      "  Sigma Multiplier: 1.1162092026069537\n",
      "  Initialization Multiplier: 0.7049779087078298\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.45it/s, loss=0.012896, elapsed time=0.09, total time=14.7]\n",
      "[I 2025-06-07 15:09:01,563] Trial 771 finished with value: 0.012896303653961886 and parameters: {'learning_rate': 0.001669740057928426, 'sigma_multiplier': 1.1162092026069537, 'num_layers': 3, 'initialization_multiplier': 0.7049779087078298}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 771 final loss: 0.01289630\n",
      "Trial 772:\n",
      "  Learning Rate: 0.00955228873486367\n",
      "  Sigma Multiplier: 0.9708110085585626\n",
      "  Initialization Multiplier: 0.3860676260240215\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.47it/s, loss=-0.000390, elapsed time=0.06, total time=13.6]\n",
      "[I 2025-06-07 15:09:15,357] Trial 772 finished with value: -0.0003896391684508469 and parameters: {'learning_rate': 0.00955228873486367, 'sigma_multiplier': 0.9708110085585626, 'num_layers': 2, 'initialization_multiplier': 0.3860676260240215}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 772 final loss: -0.00038964\n",
      "Trial 773:\n",
      "  Learning Rate: 0.0060842412150032285\n",
      "  Sigma Multiplier: 0.6944940207193762\n",
      "  Initialization Multiplier: 0.6610985890602492\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.65it/s, loss=-0.000051, elapsed time=0.07, total time=13.2]\n",
      "[I 2025-06-07 15:09:28,663] Trial 773 finished with value: -5.093349891368047e-05 and parameters: {'learning_rate': 0.0060842412150032285, 'sigma_multiplier': 0.6944940207193762, 'num_layers': 2, 'initialization_multiplier': 0.6610985890602492}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 773 final loss: -0.00005093\n",
      "Trial 774:\n",
      "  Learning Rate: 0.01111860611235807\n",
      "  Sigma Multiplier: 1.8562284909949285\n",
      "  Initialization Multiplier: 0.54233112304956\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.23it/s, loss=-0.000206, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:09:38,956] Trial 774 finished with value: -0.00020631122589626698 and parameters: {'learning_rate': 0.01111860611235807, 'sigma_multiplier': 1.8562284909949285, 'num_layers': 2, 'initialization_multiplier': 0.54233112304956}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 774 final loss: -0.00020631\n",
      "Trial 775:\n",
      "  Learning Rate: 0.008492296495631064\n",
      "  Sigma Multiplier: 1.0606920823424346\n",
      "  Initialization Multiplier: 0.6042921892607332\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.36it/s, loss=-0.000363, elapsed time=0.06, total time=12.7]\n",
      "[I 2025-06-07 15:09:51,869] Trial 775 finished with value: -0.0003634181296578732 and parameters: {'learning_rate': 0.008492296495631064, 'sigma_multiplier': 1.0606920823424346, 'num_layers': 2, 'initialization_multiplier': 0.6042921892607332}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 775 final loss: -0.00036342\n",
      "Trial 776:\n",
      "  Learning Rate: 0.0007829053823633073\n",
      "  Sigma Multiplier: 0.9299409849440209\n",
      "  Initialization Multiplier: 0.4328058561405605\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.44it/s, loss=0.001442, elapsed time=0.06, total time=12.4]\n",
      "[I 2025-06-07 15:10:04,361] Trial 776 finished with value: 0.001441888245659329 and parameters: {'learning_rate': 0.0007829053823633073, 'sigma_multiplier': 0.9299409849440209, 'num_layers': 2, 'initialization_multiplier': 0.4328058561405605}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 776 final loss: 0.00144189\n",
      "Trial 777:\n",
      "  Learning Rate: 0.006911990331797882\n",
      "  Sigma Multiplier: 1.0187028126014515\n",
      "  Initialization Multiplier: 0.4889583444425235\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.98it/s, loss=-0.000263, elapsed time=0.05, total time=9.74]\n",
      "[I 2025-06-07 15:10:14,164] Trial 777 finished with value: -0.0002627724487639863 and parameters: {'learning_rate': 0.006911990331797882, 'sigma_multiplier': 1.0187028126014515, 'num_layers': 1, 'initialization_multiplier': 0.4889583444425235}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 777 final loss: -0.00026277\n",
      "Trial 778:\n",
      "  Learning Rate: 0.012723091014509956\n",
      "  Sigma Multiplier: 0.9867712709146709\n",
      "  Initialization Multiplier: 0.5775193884916331\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000384, elapsed time=0.07, total time=11.5]\n",
      "[I 2025-06-07 15:10:25,771] Trial 778 finished with value: -0.0003844595167124354 and parameters: {'learning_rate': 0.012723091014509956, 'sigma_multiplier': 0.9867712709146709, 'num_layers': 2, 'initialization_multiplier': 0.5775193884916331}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 778 final loss: -0.00038446\n",
      "Trial 779:\n",
      "  Learning Rate: 0.008826763207888406\n",
      "  Sigma Multiplier: 0.8863783746975852\n",
      "  Initialization Multiplier: 0.7461291818048269\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.31it/s, loss=-0.000284, elapsed time=0.1, total time=12.5] \n",
      "[I 2025-06-07 15:10:38,389] Trial 779 finished with value: -0.0002838189165356858 and parameters: {'learning_rate': 0.008826763207888406, 'sigma_multiplier': 0.8863783746975852, 'num_layers': 2, 'initialization_multiplier': 0.7461291818048269}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 779 final loss: -0.00028382\n",
      "Trial 780:\n",
      "  Learning Rate: 0.004926247951479959\n",
      "  Sigma Multiplier: 1.5416386575939462\n",
      "  Initialization Multiplier: 0.5257972092718188\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.09it/s, loss=-0.000296, elapsed time=0.1, total time=11.1] \n",
      "[I 2025-06-07 15:10:49,687] Trial 780 finished with value: -0.000296045408005288 and parameters: {'learning_rate': 0.004926247951479959, 'sigma_multiplier': 1.5416386575939462, 'num_layers': 2, 'initialization_multiplier': 0.5257972092718188}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 780 final loss: -0.00029605\n",
      "Trial 781:\n",
      "  Learning Rate: 0.010841327100409314\n",
      "  Sigma Multiplier: 1.0459022880471203\n",
      "  Initialization Multiplier: 1.5206487176362646\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.01it/s, loss=-0.000020, elapsed time=0.06, total time=12.7]\n",
      "[I 2025-06-07 15:11:02,501] Trial 781 finished with value: -1.9613304867595148e-05 and parameters: {'learning_rate': 0.010841327100409314, 'sigma_multiplier': 1.0459022880471203, 'num_layers': 2, 'initialization_multiplier': 1.5206487176362646}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 781 final loss: -0.00001961\n",
      "Trial 782:\n",
      "  Learning Rate: 0.01372110457757233\n",
      "  Sigma Multiplier: 1.117102895026668\n",
      "  Initialization Multiplier: 0.6565332033488502\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.87it/s, loss=-0.000298, elapsed time=0.07, total time=12.2]\n",
      "[I 2025-06-07 15:11:14,932] Trial 782 finished with value: -0.00029810704049899276 and parameters: {'learning_rate': 0.01372110457757233, 'sigma_multiplier': 1.117102895026668, 'num_layers': 2, 'initialization_multiplier': 0.6565332033488502}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 782 final loss: -0.00029811\n",
      "Trial 783:\n",
      "  Learning Rate: 0.007663865874844277\n",
      "  Sigma Multiplier: 0.9388370585760918\n",
      "  Initialization Multiplier: 1.1885588104642664\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.23it/s, loss=0.000126, elapsed time=0.07, total time=13.7] \n",
      "[I 2025-06-07 15:11:28,751] Trial 783 finished with value: 0.0001261800061946075 and parameters: {'learning_rate': 0.007663865874844277, 'sigma_multiplier': 0.9388370585760918, 'num_layers': 2, 'initialization_multiplier': 1.1885588104642664}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 783 final loss: 0.00012618\n",
      "Trial 784:\n",
      "  Learning Rate: 0.006394950507468848\n",
      "  Sigma Multiplier: 1.2099682364650572\n",
      "  Initialization Multiplier: 0.9015115916745051\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.46it/s, loss=-0.000221, elapsed time=0.05, total time=11.7]\n",
      "[I 2025-06-07 15:11:40,675] Trial 784 finished with value: -0.00022070542359269444 and parameters: {'learning_rate': 0.006394950507468848, 'sigma_multiplier': 1.2099682364650572, 'num_layers': 2, 'initialization_multiplier': 0.9015115916745051}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 784 final loss: -0.00022071\n",
      "Trial 785:\n",
      "  Learning Rate: 0.009559497341567335\n",
      "  Sigma Multiplier: 1.0086988678611835\n",
      "  Initialization Multiplier: 0.6106442709246497\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.97it/s, loss=-0.000325, elapsed time=0.06, total time=11.9]\n",
      "[I 2025-06-07 15:11:52,650] Trial 785 finished with value: -0.0003250699739244674 and parameters: {'learning_rate': 0.009559497341567335, 'sigma_multiplier': 1.0086988678611835, 'num_layers': 2, 'initialization_multiplier': 0.6106442709246497}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 785 final loss: -0.00032507\n",
      "Trial 786:\n",
      "  Learning Rate: 0.016265142236929007\n",
      "  Sigma Multiplier: 1.0856388784132056\n",
      "  Initialization Multiplier: 0.4676500349805427\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.00it/s, loss=-0.000312, elapsed time=0.06, total time=12]  \n",
      "[I 2025-06-07 15:12:04,841] Trial 786 finished with value: -0.00031207350120250995 and parameters: {'learning_rate': 0.016265142236929007, 'sigma_multiplier': 1.0856388784132056, 'num_layers': 2, 'initialization_multiplier': 0.4676500349805427}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 786 final loss: -0.00031207\n",
      "Trial 787:\n",
      "  Learning Rate: 0.010735597142020152\n",
      "  Sigma Multiplier: 0.9649739741805445\n",
      "  Initialization Multiplier: 0.5514725417701013\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.70it/s, loss=-0.000331, elapsed time=0.07, total time=13.2]\n",
      "[I 2025-06-07 15:12:18,134] Trial 787 finished with value: -0.0003310553845135491 and parameters: {'learning_rate': 0.010735597142020152, 'sigma_multiplier': 0.9649739741805445, 'num_layers': 2, 'initialization_multiplier': 0.5514725417701013}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 787 final loss: -0.00033106\n",
      "Trial 788:\n",
      "  Learning Rate: 0.007981870845601903\n",
      "  Sigma Multiplier: 1.03751480753576\n",
      "  Initialization Multiplier: 0.5035573502126024\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.14it/s, loss=-0.000369, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 15:12:29,458] Trial 788 finished with value: -0.00036890406525684786 and parameters: {'learning_rate': 0.007981870845601903, 'sigma_multiplier': 1.03751480753576, 'num_layers': 2, 'initialization_multiplier': 0.5035573502126024}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 788 final loss: -0.00036890\n",
      "Trial 789:\n",
      "  Learning Rate: 0.013862160921192607\n",
      "  Sigma Multiplier: 1.0010311886807903\n",
      "  Initialization Multiplier: 0.4108423820559486\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.18it/s, loss=-0.000419, elapsed time=0.04, total time=10.2]\n",
      "[I 2025-06-07 15:12:39,675] Trial 789 finished with value: -0.0004190550191208203 and parameters: {'learning_rate': 0.013862160921192607, 'sigma_multiplier': 1.0010311886807903, 'num_layers': 2, 'initialization_multiplier': 0.4108423820559486}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 789 final loss: -0.00041906\n",
      "Trial 790:\n",
      "  Learning Rate: 0.011762848535083345\n",
      "  Sigma Multiplier: 1.0710710377875154\n",
      "  Initialization Multiplier: 0.6362158823745308\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.34it/s, loss=-0.000352, elapsed time=0.06, total time=9.44]\n",
      "[I 2025-06-07 15:12:49,189] Trial 790 finished with value: -0.0003520492552294676 and parameters: {'learning_rate': 0.011762848535083345, 'sigma_multiplier': 1.0710710377875154, 'num_layers': 2, 'initialization_multiplier': 0.6362158823745308}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 790 final loss: -0.00035205\n",
      "Trial 791:\n",
      "  Learning Rate: 0.006046076160870519\n",
      "  Sigma Multiplier: 1.150888187639642\n",
      "  Initialization Multiplier: 0.5904731015109667\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.57it/s, loss=-0.000278, elapsed time=0.04, total time=10]  \n",
      "[I 2025-06-07 15:12:59,282] Trial 791 finished with value: -0.0002782082936781984 and parameters: {'learning_rate': 0.006046076160870519, 'sigma_multiplier': 1.150888187639642, 'num_layers': 2, 'initialization_multiplier': 0.5904731015109667}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 791 final loss: -0.00027821\n",
      "Trial 792:\n",
      "  Learning Rate: 0.00900613400120749\n",
      "  Sigma Multiplier: 0.8890014693884452\n",
      "  Initialization Multiplier: 0.5543117120039345\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.32it/s, loss=-0.000272, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 15:13:09,469] Trial 792 finished with value: -0.00027201797461134166 and parameters: {'learning_rate': 0.00900613400120749, 'sigma_multiplier': 0.8890014693884452, 'num_layers': 2, 'initialization_multiplier': 0.5543117120039345}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 792 final loss: -0.00027202\n",
      "Trial 793:\n",
      "  Learning Rate: 0.007282263924239518\n",
      "  Sigma Multiplier: 0.9608687584982691\n",
      "  Initialization Multiplier: 0.33974387285284485\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.41it/s, loss=-0.000212, elapsed time=0.07, total time=9.97]\n",
      "[I 2025-06-07 15:13:19,492] Trial 793 finished with value: -0.0002119945895783372 and parameters: {'learning_rate': 0.007282263924239518, 'sigma_multiplier': 0.9608687584982691, 'num_layers': 2, 'initialization_multiplier': 0.33974387285284485}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 793 final loss: -0.00021199\n",
      "Trial 794:\n",
      "  Learning Rate: 0.00475360590236568\n",
      "  Sigma Multiplier: 1.0434658736150815\n",
      "  Initialization Multiplier: 0.44618413266159335\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.48it/s, loss=-0.000337, elapsed time=0.04, total time=10]  \n",
      "[I 2025-06-07 15:13:29,595] Trial 794 finished with value: -0.0003365555856623432 and parameters: {'learning_rate': 0.00475360590236568, 'sigma_multiplier': 1.0434658736150815, 'num_layers': 2, 'initialization_multiplier': 0.44618413266159335}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 794 final loss: -0.00033656\n",
      "Trial 795:\n",
      "  Learning Rate: 0.01020004073744031\n",
      "  Sigma Multiplier: 0.8429799737289729\n",
      "  Initialization Multiplier: 0.6873104685367178\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.87it/s, loss=-0.000298, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:13:39,958] Trial 795 finished with value: -0.00029780177551043884 and parameters: {'learning_rate': 0.01020004073744031, 'sigma_multiplier': 0.8429799737289729, 'num_layers': 2, 'initialization_multiplier': 0.6873104685367178}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 795 final loss: -0.00029780\n",
      "Trial 796:\n",
      "  Learning Rate: 0.008170297411060378\n",
      "  Sigma Multiplier: 1.0918976255797324\n",
      "  Initialization Multiplier: 0.5131062046240609\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.27it/s, loss=-0.000227, elapsed time=0.04, total time=8.04]\n",
      "[I 2025-06-07 15:13:48,044] Trial 796 finished with value: -0.00022663880807321891 and parameters: {'learning_rate': 0.008170297411060378, 'sigma_multiplier': 1.0918976255797324, 'num_layers': 1, 'initialization_multiplier': 0.5131062046240609}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 796 final loss: -0.00022664\n",
      "Trial 797:\n",
      "  Learning Rate: 0.01215194971343665\n",
      "  Sigma Multiplier: 0.9207105218500327\n",
      "  Initialization Multiplier: 0.6002108495754672\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.59it/s, loss=-0.000362, elapsed time=0.06, total time=9.96]\n",
      "[I 2025-06-07 15:13:58,055] Trial 797 finished with value: -0.00036211575289913766 and parameters: {'learning_rate': 0.01215194971343665, 'sigma_multiplier': 0.9207105218500327, 'num_layers': 2, 'initialization_multiplier': 0.6002108495754672}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 797 final loss: -0.00036212\n",
      "Trial 798:\n",
      "  Learning Rate: 0.014447767069749394\n",
      "  Sigma Multiplier: 1.001206331093995\n",
      "  Initialization Multiplier: 0.4781830977324313\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.87it/s, loss=-0.000408, elapsed time=0.07, total time=9.73]\n",
      "[I 2025-06-07 15:14:07,836] Trial 798 finished with value: -0.0004083978742646118 and parameters: {'learning_rate': 0.014447767069749394, 'sigma_multiplier': 1.001206331093995, 'num_layers': 2, 'initialization_multiplier': 0.4781830977324313}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 798 final loss: -0.00040840\n",
      "Trial 799:\n",
      "  Learning Rate: 0.005520586132742357\n",
      "  Sigma Multiplier: 1.125651051929583\n",
      "  Initialization Multiplier: 0.5523667944892048\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.00it/s, loss=-0.000383, elapsed time=0.07, total time=9.17]\n",
      "[I 2025-06-07 15:14:17,069] Trial 799 finished with value: -0.0003828248374844622 and parameters: {'learning_rate': 0.005520586132742357, 'sigma_multiplier': 1.125651051929583, 'num_layers': 2, 'initialization_multiplier': 0.5523667944892048}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 799 final loss: -0.00038282\n",
      "Trial 800:\n",
      "  Learning Rate: 0.01709898709059642\n",
      "  Sigma Multiplier: 0.9741173447894558\n",
      "  Initialization Multiplier: 0.6637621260647208\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.33it/s, loss=-0.000377, elapsed time=0.04, total time=10.1]\n",
      "[I 2025-06-07 15:14:27,170] Trial 800 finished with value: -0.00037711517586648346 and parameters: {'learning_rate': 0.01709898709059642, 'sigma_multiplier': 0.9741173447894558, 'num_layers': 2, 'initialization_multiplier': 0.6637621260647208}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 800 final loss: -0.00037712\n",
      "Trial 801:\n",
      "  Learning Rate: 0.006876821728706214\n",
      "  Sigma Multiplier: 1.028244737475856\n",
      "  Initialization Multiplier: 0.5273592282576541\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.08it/s, loss=-0.000306, elapsed time=0.08, total time=11.8]\n",
      "[I 2025-06-07 15:14:39,006] Trial 801 finished with value: -0.0003061195880757682 and parameters: {'learning_rate': 0.006876821728706214, 'sigma_multiplier': 1.028244737475856, 'num_layers': 3, 'initialization_multiplier': 0.5273592282576541}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 801 final loss: -0.00030612\n",
      "Trial 802:\n",
      "  Learning Rate: 0.009327113846615566\n",
      "  Sigma Multiplier: 1.0620308868761619\n",
      "  Initialization Multiplier: 0.6274746466129119\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.14it/s, loss=-0.000295, elapsed time=0.06, total time=9.54]\n",
      "[I 2025-06-07 15:14:48,598] Trial 802 finished with value: -0.00029458977838625085 and parameters: {'learning_rate': 0.009327113846615566, 'sigma_multiplier': 1.0620308868761619, 'num_layers': 2, 'initialization_multiplier': 0.6274746466129119}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 802 final loss: -0.00029459\n",
      "Trial 803:\n",
      "  Learning Rate: 0.01159184296724169\n",
      "  Sigma Multiplier: 0.9374710420215147\n",
      "  Initialization Multiplier: 0.38188814196815324\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.08it/s, loss=-0.000348, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:14:58,882] Trial 803 finished with value: -0.00034830083047287586 and parameters: {'learning_rate': 0.01159184296724169, 'sigma_multiplier': 0.9374710420215147, 'num_layers': 2, 'initialization_multiplier': 0.38188814196815324}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 803 final loss: -0.00034830\n",
      "Trial 804:\n",
      "  Learning Rate: 0.0012806045304591062\n",
      "  Sigma Multiplier: 0.99938654067567\n",
      "  Initialization Multiplier: 0.5819016770259975\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.22it/s, loss=0.001224, elapsed time=0.06, total time=10.1]\n",
      "[I 2025-06-07 15:15:09,067] Trial 804 finished with value: 0.0012239132419631313 and parameters: {'learning_rate': 0.0012806045304591062, 'sigma_multiplier': 0.99938654067567, 'num_layers': 2, 'initialization_multiplier': 0.5819016770259975}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 804 final loss: 0.00122391\n",
      "Trial 805:\n",
      "  Learning Rate: 0.00792347235596719\n",
      "  Sigma Multiplier: 1.0885891869345161\n",
      "  Initialization Multiplier: 1.7119007228270857\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.26it/s, loss=-0.000220, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 15:15:19,257] Trial 805 finished with value: -0.0002201700940307721 and parameters: {'learning_rate': 0.00792347235596719, 'sigma_multiplier': 1.0885891869345161, 'num_layers': 2, 'initialization_multiplier': 1.7119007228270857}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 805 final loss: -0.00022017\n",
      "Trial 806:\n",
      "  Learning Rate: 0.009841395554653293\n",
      "  Sigma Multiplier: 1.0272550943039587\n",
      "  Initialization Multiplier: 0.43206700675531007\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.59it/s, loss=-0.000375, elapsed time=0.06, total time=9.86]\n",
      "[I 2025-06-07 15:15:29,184] Trial 806 finished with value: -0.0003750302428453417 and parameters: {'learning_rate': 0.009841395554653293, 'sigma_multiplier': 1.0272550943039587, 'num_layers': 2, 'initialization_multiplier': 0.43206700675531007}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 806 final loss: -0.00037503\n",
      "Trial 807:\n",
      "  Learning Rate: 0.0140388255566882\n",
      "  Sigma Multiplier: 0.9657999744368496\n",
      "  Initialization Multiplier: 0.49613147634695004\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.46it/s, loss=-0.000327, elapsed time=0.04, total time=10]  \n",
      "[I 2025-06-07 15:15:39,244] Trial 807 finished with value: -0.0003266568659049196 and parameters: {'learning_rate': 0.0140388255566882, 'sigma_multiplier': 0.9657999744368496, 'num_layers': 2, 'initialization_multiplier': 0.49613147634695004}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 807 final loss: -0.00032666\n",
      "Trial 808:\n",
      "  Learning Rate: 0.005904540315625267\n",
      "  Sigma Multiplier: 0.9088357360755787\n",
      "  Initialization Multiplier: 0.559875250359085\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.56it/s, loss=-0.000343, elapsed time=0.06, total time=9.93]\n",
      "[I 2025-06-07 15:15:49,228] Trial 808 finished with value: -0.00034316914262590614 and parameters: {'learning_rate': 0.005904540315625267, 'sigma_multiplier': 0.9088357360755787, 'num_layers': 2, 'initialization_multiplier': 0.559875250359085}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 808 final loss: -0.00034317\n",
      "Trial 809:\n",
      "  Learning Rate: 0.007254891115452406\n",
      "  Sigma Multiplier: 1.062096797358205\n",
      "  Initialization Multiplier: 0.7187035259102503\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.49it/s, loss=-0.000281, elapsed time=0.08, total time=9.93]\n",
      "[I 2025-06-07 15:15:59,208] Trial 809 finished with value: -0.0002805728307745051 and parameters: {'learning_rate': 0.007254891115452406, 'sigma_multiplier': 1.062096797358205, 'num_layers': 2, 'initialization_multiplier': 0.7187035259102503}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 809 final loss: -0.00028057\n",
      "Trial 810:\n",
      "  Learning Rate: 0.011138313444470832\n",
      "  Sigma Multiplier: 0.994593000605113\n",
      "  Initialization Multiplier: 1.3827527832520472\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.12it/s, loss=-0.000193, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:16:09,443] Trial 810 finished with value: -0.00019344542453804688 and parameters: {'learning_rate': 0.011138313444470832, 'sigma_multiplier': 0.994593000605113, 'num_layers': 2, 'initialization_multiplier': 1.3827527832520472}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 810 final loss: -0.00019345\n",
      "Trial 811:\n",
      "  Learning Rate: 0.004505189869288956\n",
      "  Sigma Multiplier: 1.1243595931876686\n",
      "  Initialization Multiplier: 0.6272425650517468\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.81it/s, loss=-0.000447, elapsed time=0.05, total time=9.2] \n",
      "[I 2025-06-07 15:16:18,701] Trial 811 finished with value: -0.0004470739296767425 and parameters: {'learning_rate': 0.004505189869288956, 'sigma_multiplier': 1.1243595931876686, 'num_layers': 2, 'initialization_multiplier': 0.6272425650517468}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 811 final loss: -0.00044707\n",
      "Trial 812:\n",
      "  Learning Rate: 0.0033558796162382483\n",
      "  Sigma Multiplier: 1.1885652289825872\n",
      "  Initialization Multiplier: 0.6616699661355819\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.61it/s, loss=-0.000351, elapsed time=0.05, total time=9.3] \n",
      "[I 2025-06-07 15:16:28,047] Trial 812 finished with value: -0.0003507141995114227 and parameters: {'learning_rate': 0.0033558796162382483, 'sigma_multiplier': 1.1885652289825872, 'num_layers': 2, 'initialization_multiplier': 0.6616699661355819}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 812 final loss: -0.00035071\n",
      "Trial 813:\n",
      "  Learning Rate: 0.004526694769615638\n",
      "  Sigma Multiplier: 1.1680008501799835\n",
      "  Initialization Multiplier: 0.6311963375305709\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.63it/s, loss=-0.000205, elapsed time=0.11, total time=14.4]\n",
      "[I 2025-06-07 15:16:42,547] Trial 813 finished with value: -0.00020520006738151175 and parameters: {'learning_rate': 0.004526694769615638, 'sigma_multiplier': 1.1680008501799835, 'num_layers': 5, 'initialization_multiplier': 0.6311963375305709}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 813 final loss: -0.00020520\n",
      "Trial 814:\n",
      "  Learning Rate: 0.004635655750294839\n",
      "  Sigma Multiplier: 1.2417421458407372\n",
      "  Initialization Multiplier: 0.6920570744299263\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.97it/s, loss=-0.000383, elapsed time=0.05, total time=9.1] \n",
      "[I 2025-06-07 15:16:51,702] Trial 814 finished with value: -0.0003825151111534234 and parameters: {'learning_rate': 0.004635655750294839, 'sigma_multiplier': 1.2417421458407372, 'num_layers': 2, 'initialization_multiplier': 0.6920570744299263}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 814 final loss: -0.00038252\n",
      "Trial 815:\n",
      "  Learning Rate: 0.0035491460312575256\n",
      "  Sigma Multiplier: 1.1627941995590365\n",
      "  Initialization Multiplier: 0.6202925612362986\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.04it/s, loss=-0.000369, elapsed time=0.05, total time=9.06]\n",
      "[I 2025-06-07 15:17:00,813] Trial 815 finished with value: -0.00036857218500318503 and parameters: {'learning_rate': 0.0035491460312575256, 'sigma_multiplier': 1.1627941995590365, 'num_layers': 2, 'initialization_multiplier': 0.6202925612362986}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 815 final loss: -0.00036857\n",
      "Trial 816:\n",
      "  Learning Rate: 0.003927912993201798\n",
      "  Sigma Multiplier: 1.125297131793365\n",
      "  Initialization Multiplier: 0.5923703417135886\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.81it/s, loss=-0.000344, elapsed time=0.06, total time=9.2] \n",
      "[I 2025-06-07 15:17:10,067] Trial 816 finished with value: -0.0003436565358736733 and parameters: {'learning_rate': 0.003927912993201798, 'sigma_multiplier': 1.125297131793365, 'num_layers': 2, 'initialization_multiplier': 0.5923703417135886}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 816 final loss: -0.00034366\n",
      "Trial 817:\n",
      "  Learning Rate: 0.005351795160696857\n",
      "  Sigma Multiplier: 0.8700116941406566\n",
      "  Initialization Multiplier: 0.7743718600556896\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.97it/s, loss=-0.000017, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 15:17:21,216] Trial 817 finished with value: -1.7024841435123666e-05 and parameters: {'learning_rate': 0.005351795160696857, 'sigma_multiplier': 0.8700116941406566, 'num_layers': 2, 'initialization_multiplier': 0.7743718600556896}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 817 final loss: -0.00001702\n",
      "Trial 818:\n",
      "  Learning Rate: 0.004679955600453607\n",
      "  Sigma Multiplier: 0.9443130614824553\n",
      "  Initialization Multiplier: 0.6570131717626503\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.30it/s, loss=-0.000330, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:17:31,563] Trial 818 finished with value: -0.0003302479941156724 and parameters: {'learning_rate': 0.004679955600453607, 'sigma_multiplier': 0.9443130614824553, 'num_layers': 2, 'initialization_multiplier': 0.6570131717626503}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 818 final loss: -0.00033025\n",
      "Trial 819:\n",
      "  Learning Rate: 0.004179606643320815\n",
      "  Sigma Multiplier: 1.1148637920623727\n",
      "  Initialization Multiplier: 0.7315986191010624\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.90it/s, loss=-0.000325, elapsed time=0.04, total time=8.63]\n",
      "[I 2025-06-07 15:17:40,246] Trial 819 finished with value: -0.00032456909461267417 and parameters: {'learning_rate': 0.004179606643320815, 'sigma_multiplier': 1.1148637920623727, 'num_layers': 1, 'initialization_multiplier': 0.7315986191010624}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 819 final loss: -0.00032457\n",
      "Trial 820:\n",
      "  Learning Rate: 0.005197105858822613\n",
      "  Sigma Multiplier: 1.0214978952467126\n",
      "  Initialization Multiplier: 0.6004418989369132\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.98it/s, loss=-0.000289, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 15:17:50,579] Trial 820 finished with value: -0.00028909078572887426 and parameters: {'learning_rate': 0.005197105858822613, 'sigma_multiplier': 1.0214978952467126, 'num_layers': 2, 'initialization_multiplier': 0.6004418989369132}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 820 final loss: -0.00028909\n",
      "Trial 821:\n",
      "  Learning Rate: 0.002316823411861299\n",
      "  Sigma Multiplier: 0.9663073002466772\n",
      "  Initialization Multiplier: 0.6378269288933038\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.83it/s, loss=-0.000407, elapsed time=0.05, total time=9.73]\n",
      "[I 2025-06-07 15:18:00,370] Trial 821 finished with value: -0.00040691117941037743 and parameters: {'learning_rate': 0.002316823411861299, 'sigma_multiplier': 0.9663073002466772, 'num_layers': 2, 'initialization_multiplier': 0.6378269288933038}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 821 final loss: -0.00040691\n",
      "Trial 822:\n",
      "  Learning Rate: 0.006009322505078024\n",
      "  Sigma Multiplier: 0.9025001765886692\n",
      "  Initialization Multiplier: 0.5745840863487707\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.20it/s, loss=-0.000369, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:18:10,598] Trial 822 finished with value: -0.0003687135254358111 and parameters: {'learning_rate': 0.006009322505078024, 'sigma_multiplier': 0.9025001765886692, 'num_layers': 2, 'initialization_multiplier': 0.5745840863487707}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 822 final loss: -0.00036871\n",
      "Trial 823:\n",
      "  Learning Rate: 0.004326254011918599\n",
      "  Sigma Multiplier: 1.0526910175006188\n",
      "  Initialization Multiplier: 0.6959782831173532\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.37it/s, loss=-0.000399, elapsed time=0.05, total time=9.43]\n",
      "[I 2025-06-07 15:18:20,088] Trial 823 finished with value: -0.00039921956370437173 and parameters: {'learning_rate': 0.004326254011918599, 'sigma_multiplier': 1.0526910175006188, 'num_layers': 2, 'initialization_multiplier': 0.6959782831173532}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 823 final loss: -0.00039922\n",
      "Trial 824:\n",
      "  Learning Rate: 0.002801062753752911\n",
      "  Sigma Multiplier: 0.9935885205990213\n",
      "  Initialization Multiplier: 0.5299197244072468\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.25it/s, loss=-0.000306, elapsed time=0.05, total time=9.51]\n",
      "[I 2025-06-07 15:18:29,654] Trial 824 finished with value: -0.0003064417456354855 and parameters: {'learning_rate': 0.002801062753752911, 'sigma_multiplier': 0.9935885205990213, 'num_layers': 2, 'initialization_multiplier': 0.5299197244072468}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 824 final loss: -0.00030644\n",
      "Trial 825:\n",
      "  Learning Rate: 0.006363039379997926\n",
      "  Sigma Multiplier: 1.1378765489673666\n",
      "  Initialization Multiplier: 0.622100935899545\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 11.70it/s, loss=-0.000254, elapsed time=0.1, total time=13.2] \n",
      "[I 2025-06-07 15:18:42,897] Trial 825 finished with value: -0.0002543720626364553 and parameters: {'learning_rate': 0.006363039379997926, 'sigma_multiplier': 1.1378765489673666, 'num_layers': 4, 'initialization_multiplier': 0.622100935899545}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 825 final loss: -0.00025437\n",
      "Trial 826:\n",
      "  Learning Rate: 0.005614327231648608\n",
      "  Sigma Multiplier: 0.813670265375014\n",
      "  Initialization Multiplier: 0.5548131749590091\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.83it/s, loss=-0.000205, elapsed time=0.05, total time=10.4]\n",
      "[I 2025-06-07 15:18:53,381] Trial 826 finished with value: -0.00020464610079880315 and parameters: {'learning_rate': 0.005614327231648608, 'sigma_multiplier': 0.813670265375014, 'num_layers': 2, 'initialization_multiplier': 0.5548131749590091}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 826 final loss: -0.00020465\n",
      "Trial 827:\n",
      "  Learning Rate: 0.006856976851783148\n",
      "  Sigma Multiplier: 0.9403512327044645\n",
      "  Initialization Multiplier: 0.6704102376901655\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.60it/s, loss=-0.000338, elapsed time=0.05, total time=9.92]\n",
      "[I 2025-06-07 15:19:03,356] Trial 827 finished with value: -0.0003376761505801388 and parameters: {'learning_rate': 0.006856976851783148, 'sigma_multiplier': 0.9403512327044645, 'num_layers': 2, 'initialization_multiplier': 0.6704102376901655}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 827 final loss: -0.00033768\n",
      "Trial 828:\n",
      "  Learning Rate: 0.008669536740922761\n",
      "  Sigma Multiplier: 1.0294221239994172\n",
      "  Initialization Multiplier: 0.5889436410246932\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.02it/s, loss=-0.000389, elapsed time=0.05, total time=9.68]\n",
      "[I 2025-06-07 15:19:13,084] Trial 828 finished with value: -0.00038891242345675604 and parameters: {'learning_rate': 0.008669536740922761, 'sigma_multiplier': 1.0294221239994172, 'num_layers': 2, 'initialization_multiplier': 0.5889436410246932}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 828 final loss: -0.00038891\n",
      "Trial 829:\n",
      "  Learning Rate: 0.0037905268922803085\n",
      "  Sigma Multiplier: 1.0907194582716473\n",
      "  Initialization Multiplier: 0.5271124836099538\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.48it/s, loss=-0.000317, elapsed time=0.06, total time=9.36]\n",
      "[I 2025-06-07 15:19:22,503] Trial 829 finished with value: -0.0003169021011720211 and parameters: {'learning_rate': 0.0037905268922803085, 'sigma_multiplier': 1.0907194582716473, 'num_layers': 2, 'initialization_multiplier': 0.5271124836099538}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 829 final loss: -0.00031690\n",
      "Trial 830:\n",
      "  Learning Rate: 0.005040700503135329\n",
      "  Sigma Multiplier: 1.1997332931352338\n",
      "  Initialization Multiplier: 0.6139876103582882\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.81it/s, loss=-0.000331, elapsed time=0.05, total time=9.2] \n",
      "[I 2025-06-07 15:19:31,758] Trial 830 finished with value: -0.0003309130557723501 and parameters: {'learning_rate': 0.005040700503135329, 'sigma_multiplier': 1.1997332931352338, 'num_layers': 2, 'initialization_multiplier': 0.6139876103582882}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 830 final loss: -0.00033091\n",
      "Trial 831:\n",
      "  Learning Rate: 0.007764237391167974\n",
      "  Sigma Multiplier: 0.9973171996505562\n",
      "  Initialization Multiplier: 0.5590003830570832\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.45it/s, loss=-0.000345, elapsed time=0.05, total time=9.98]\n",
      "[I 2025-06-07 15:19:41,799] Trial 831 finished with value: -0.000345287468149406 and parameters: {'learning_rate': 0.007764237391167974, 'sigma_multiplier': 0.9973171996505562, 'num_layers': 2, 'initialization_multiplier': 0.5590003830570832}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 831 final loss: -0.00034529\n",
      "Trial 832:\n",
      "  Learning Rate: 0.00908654972307385\n",
      "  Sigma Multiplier: 1.0592886520088716\n",
      "  Initialization Multiplier: 0.645792696607312\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.94it/s, loss=-0.000350, elapsed time=0.05, total time=9.74]\n",
      "[I 2025-06-07 15:19:51,640] Trial 832 finished with value: -0.0003504956669409363 and parameters: {'learning_rate': 0.00908654972307385, 'sigma_multiplier': 1.0592886520088716, 'num_layers': 2, 'initialization_multiplier': 0.645792696607312}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 832 final loss: -0.00035050\n",
      "Trial 833:\n",
      "  Learning Rate: 0.007141994193254009\n",
      "  Sigma Multiplier: 0.9579531638322487\n",
      "  Initialization Multiplier: 0.5039460325342293\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.33it/s, loss=-0.000323, elapsed time=0.06, total time=11.5]\n",
      "[I 2025-06-07 15:20:03,237] Trial 833 finished with value: -0.0003232180490391533 and parameters: {'learning_rate': 0.007141994193254009, 'sigma_multiplier': 0.9579531638322487, 'num_layers': 3, 'initialization_multiplier': 0.5039460325342293}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 833 final loss: -0.00032322\n",
      "Trial 834:\n",
      "  Learning Rate: 0.010026418362140174\n",
      "  Sigma Multiplier: 0.9164852112854417\n",
      "  Initialization Multiplier: 0.5818617129556338\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.44it/s, loss=-0.000354, elapsed time=0.05, total time=9.98]\n",
      "[I 2025-06-07 15:20:13,270] Trial 834 finished with value: -0.0003537467329707726 and parameters: {'learning_rate': 0.010026418362140174, 'sigma_multiplier': 0.9164852112854417, 'num_layers': 2, 'initialization_multiplier': 0.5818617129556338}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 834 final loss: -0.00035375\n",
      "Trial 835:\n",
      "  Learning Rate: 0.005884267217019267\n",
      "  Sigma Multiplier: 1.0234216596004961\n",
      "  Initialization Multiplier: 0.7067153814130861\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.49it/s, loss=-0.000363, elapsed time=0.04, total time=8.42]\n",
      "[I 2025-06-07 15:20:21,732] Trial 835 finished with value: -0.00036260961034135543 and parameters: {'learning_rate': 0.005884267217019267, 'sigma_multiplier': 1.0234216596004961, 'num_layers': 1, 'initialization_multiplier': 0.7067153814130861}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 835 final loss: -0.00036261\n",
      "Trial 836:\n",
      "  Learning Rate: 0.008614676296545424\n",
      "  Sigma Multiplier: 1.1146873039628062\n",
      "  Initialization Multiplier: 0.5578126072563072\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.37it/s, loss=-0.000384, elapsed time=0.05, total time=9.46]\n",
      "[I 2025-06-07 15:20:31,258] Trial 836 finished with value: -0.00038359857666028297 and parameters: {'learning_rate': 0.008614676296545424, 'sigma_multiplier': 1.1146873039628062, 'num_layers': 2, 'initialization_multiplier': 0.5578126072563072}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 836 final loss: -0.00038360\n",
      "Trial 837:\n",
      "  Learning Rate: 0.0068732063339704795\n",
      "  Sigma Multiplier: 0.8595933421112005\n",
      "  Initialization Multiplier: 0.6541794551637641\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.60it/s, loss=-0.000273, elapsed time=0.06, total time=10.5]\n",
      "[I 2025-06-07 15:20:41,846] Trial 837 finished with value: -0.00027292124277870656 and parameters: {'learning_rate': 0.0068732063339704795, 'sigma_multiplier': 0.8595933421112005, 'num_layers': 2, 'initialization_multiplier': 0.6541794551637641}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 837 final loss: -0.00027292\n",
      "Trial 838:\n",
      "  Learning Rate: 0.0030412927034137545\n",
      "  Sigma Multiplier: 0.9805015202674785\n",
      "  Initialization Multiplier: 0.5126853855167061\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.54it/s, loss=-0.000397, elapsed time=0.05, total time=9.33]\n",
      "[I 2025-06-07 15:20:51,231] Trial 838 finished with value: -0.0003973333465588652 and parameters: {'learning_rate': 0.0030412927034137545, 'sigma_multiplier': 0.9805015202674785, 'num_layers': 2, 'initialization_multiplier': 0.5126853855167061}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 838 final loss: -0.00039733\n",
      "Trial 839:\n",
      "  Learning Rate: 0.011649594566926309\n",
      "  Sigma Multiplier: 1.0600396591120667\n",
      "  Initialization Multiplier: 0.611202495240911\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.31it/s, loss=-0.000380, elapsed time=0.06, total time=9.48]\n",
      "[I 2025-06-07 15:21:00,771] Trial 839 finished with value: -0.0003801186312869341 and parameters: {'learning_rate': 0.011649594566926309, 'sigma_multiplier': 1.0600396591120667, 'num_layers': 2, 'initialization_multiplier': 0.611202495240911}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 839 final loss: -0.00038012\n",
      "Trial 840:\n",
      "  Learning Rate: 0.004647288421866366\n",
      "  Sigma Multiplier: 0.9353894710552421\n",
      "  Initialization Multiplier: 0.536263593942159\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.04it/s, loss=-0.000412, elapsed time=0.05, total time=9.62]\n",
      "[I 2025-06-07 15:21:10,448] Trial 840 finished with value: -0.00041161044806120974 and parameters: {'learning_rate': 0.004647288421866366, 'sigma_multiplier': 0.9353894710552421, 'num_layers': 2, 'initialization_multiplier': 0.536263593942159}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 840 final loss: -0.00041161\n",
      "Trial 841:\n",
      "  Learning Rate: 0.009999917428555783\n",
      "  Sigma Multiplier: 1.0236795850203118\n",
      "  Initialization Multiplier: 0.47449399585367735\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.94it/s, loss=-0.000389, elapsed time=0.05, total time=9.06]\n",
      "[I 2025-06-07 15:21:19,558] Trial 841 finished with value: -0.00038917038864300725 and parameters: {'learning_rate': 0.009999917428555783, 'sigma_multiplier': 1.0236795850203118, 'num_layers': 2, 'initialization_multiplier': 0.47449399585367735}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 841 final loss: -0.00038917\n",
      "Trial 842:\n",
      "  Learning Rate: 0.008305509194189367\n",
      "  Sigma Multiplier: 0.9769484890284982\n",
      "  Initialization Multiplier: 0.5913993156133762\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.33it/s, loss=-0.000368, elapsed time=0.05, total time=9.46]\n",
      "[I 2025-06-07 15:21:29,074] Trial 842 finished with value: -0.0003677573831052089 and parameters: {'learning_rate': 0.008305509194189367, 'sigma_multiplier': 0.9769484890284982, 'num_layers': 2, 'initialization_multiplier': 0.5913993156133762}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 842 final loss: -0.00036776\n",
      "Trial 843:\n",
      "  Learning Rate: 0.006472028454967815\n",
      "  Sigma Multiplier: 1.1471036974281896\n",
      "  Initialization Multiplier: 0.6803650060924319\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.42it/s, loss=-0.000416, elapsed time=0.05, total time=9.38]\n",
      "[I 2025-06-07 15:21:38,515] Trial 843 finished with value: -0.00041596263188611263 and parameters: {'learning_rate': 0.006472028454967815, 'sigma_multiplier': 1.1471036974281896, 'num_layers': 2, 'initialization_multiplier': 0.6803650060924319}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 843 final loss: -0.00041596\n",
      "Trial 844:\n",
      "  Learning Rate: 0.005381891306788822\n",
      "  Sigma Multiplier: 1.1018324623324542\n",
      "  Initialization Multiplier: 0.751296172826495\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.51it/s, loss=-0.000334, elapsed time=0.06, total time=9.34]\n",
      "[I 2025-06-07 15:21:47,913] Trial 844 finished with value: -0.0003336812341442761 and parameters: {'learning_rate': 0.005381891306788822, 'sigma_multiplier': 1.1018324623324542, 'num_layers': 2, 'initialization_multiplier': 0.751296172826495}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 844 final loss: -0.00033368\n",
      "Trial 845:\n",
      "  Learning Rate: 0.012238485202735032\n",
      "  Sigma Multiplier: 1.061854898693757\n",
      "  Initialization Multiplier: 0.6300550892159751\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.24it/s, loss=-0.000387, elapsed time=0.06, total time=13.7]\n",
      "[I 2025-06-07 15:22:01,612] Trial 845 finished with value: -0.00038745987149961866 and parameters: {'learning_rate': 0.012238485202735032, 'sigma_multiplier': 1.061854898693757, 'num_layers': 2, 'initialization_multiplier': 0.6300550892159751}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 845 final loss: -0.00038746\n",
      "Trial 846:\n",
      "  Learning Rate: 0.010521552802839552\n",
      "  Sigma Multiplier: 0.9038830829920216\n",
      "  Initialization Multiplier: 0.5671887727075212\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.29it/s, loss=-0.000311, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 15:22:11,758] Trial 846 finished with value: -0.0003106750990644704 and parameters: {'learning_rate': 0.010521552802839552, 'sigma_multiplier': 0.9038830829920216, 'num_layers': 2, 'initialization_multiplier': 0.5671887727075212}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 846 final loss: -0.00031068\n",
      "Trial 847:\n",
      "  Learning Rate: 0.007734627868652664\n",
      "  Sigma Multiplier: 1.003400104608978\n",
      "  Initialization Multiplier: 0.47471782204881346\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.52it/s, loss=-0.000413, elapsed time=0.06, total time=10.6]\n",
      "[I 2025-06-07 15:22:22,395] Trial 847 finished with value: -0.0004132845360144074 and parameters: {'learning_rate': 0.007734627868652664, 'sigma_multiplier': 1.003400104608978, 'num_layers': 2, 'initialization_multiplier': 0.47471782204881346}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 847 final loss: -0.00041328\n",
      "Trial 848:\n",
      "  Learning Rate: 0.008792192512637981\n",
      "  Sigma Multiplier: 0.9685684866438995\n",
      "  Initialization Multiplier: 0.5181964829504752\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.07it/s, loss=-0.000334, elapsed time=0.07, total time=10.3]\n",
      "[I 2025-06-07 15:22:32,828] Trial 848 finished with value: -0.0003344337960470937 and parameters: {'learning_rate': 0.008792192512637981, 'sigma_multiplier': 0.9685684866438995, 'num_layers': 2, 'initialization_multiplier': 0.5181964829504752}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 848 final loss: -0.00033443\n",
      "Trial 849:\n",
      "  Learning Rate: 0.009649402363510098\n",
      "  Sigma Multiplier: 1.2908914456198555\n",
      "  Initialization Multiplier: 0.6058594025450772\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.09it/s, loss=-0.000403, elapsed time=0.06, total time=9.02]\n",
      "[I 2025-06-07 15:22:41,905] Trial 849 finished with value: -0.0004030856463998481 and parameters: {'learning_rate': 0.009649402363510098, 'sigma_multiplier': 1.2908914456198555, 'num_layers': 2, 'initialization_multiplier': 0.6058594025450772}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 849 final loss: -0.00040309\n",
      "Trial 850:\n",
      "  Learning Rate: 0.004265151586372884\n",
      "  Sigma Multiplier: 1.0338592219166138\n",
      "  Initialization Multiplier: 0.5539155559084934\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.75it/s, loss=-0.000340, elapsed time=0.04, total time=9.21]\n",
      "[I 2025-06-07 15:22:51,174] Trial 850 finished with value: -0.00034040557609208523 and parameters: {'learning_rate': 0.004265151586372884, 'sigma_multiplier': 1.0338592219166138, 'num_layers': 2, 'initialization_multiplier': 0.5539155559084934}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 850 final loss: -0.00034041\n",
      "Trial 851:\n",
      "  Learning Rate: 0.01215417498595026\n",
      "  Sigma Multiplier: 1.3427645908282342\n",
      "  Initialization Multiplier: 1.9583168082391618\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.55it/s, loss=-0.000318, elapsed time=0.06, total time=9.38]\n",
      "[I 2025-06-07 15:23:00,609] Trial 851 finished with value: -0.0003183300423173059 and parameters: {'learning_rate': 0.01215417498595026, 'sigma_multiplier': 1.3427645908282342, 'num_layers': 2, 'initialization_multiplier': 1.9583168082391618}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 851 final loss: -0.00031833\n",
      "Trial 852:\n",
      "  Learning Rate: 0.006271125086301817\n",
      "  Sigma Multiplier: 1.0849397376642655\n",
      "  Initialization Multiplier: 0.6627677621626445\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.04it/s, loss=-0.000275, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:23:10,938] Trial 852 finished with value: -0.00027533377394962254 and parameters: {'learning_rate': 0.006271125086301817, 'sigma_multiplier': 1.0849397376642655, 'num_layers': 2, 'initialization_multiplier': 0.6627677621626445}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 852 final loss: -0.00027533\n",
      "Trial 853:\n",
      "  Learning Rate: 0.006996108896247611\n",
      "  Sigma Multiplier: 0.8760033715162219\n",
      "  Initialization Multiplier: 0.5216139659210145\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.27it/s, loss=-0.000323, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:23:21,180] Trial 853 finished with value: -0.00032308553101687275 and parameters: {'learning_rate': 0.006996108896247611, 'sigma_multiplier': 0.8760033715162219, 'num_layers': 2, 'initialization_multiplier': 0.5216139659210145}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 853 final loss: -0.00032309\n",
      "Trial 854:\n",
      "  Learning Rate: 0.010813753457915182\n",
      "  Sigma Multiplier: 0.9443365322133761\n",
      "  Initialization Multiplier: 0.47709539305378473\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.21it/s, loss=-0.000227, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:23:31,431] Trial 854 finished with value: -0.00022704667359183585 and parameters: {'learning_rate': 0.010813753457915182, 'sigma_multiplier': 0.9443365322133761, 'num_layers': 2, 'initialization_multiplier': 0.47709539305378473}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 854 final loss: -0.00022705\n",
      "Trial 855:\n",
      "  Learning Rate: 4.162986646309142e-05\n",
      "  Sigma Multiplier: 1.0072043397712982\n",
      "  Initialization Multiplier: 0.5797157998554141\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.00it/s, loss=0.036728, elapsed time=0.05, total time=8.62]\n",
      "[I 2025-06-07 15:23:40,117] Trial 855 finished with value: 0.0367277757903798 and parameters: {'learning_rate': 4.162986646309142e-05, 'sigma_multiplier': 1.0072043397712982, 'num_layers': 1, 'initialization_multiplier': 0.5797157998554141}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 855 final loss: 0.03672778\n",
      "Trial 856:\n",
      "  Learning Rate: 0.007920001174565313\n",
      "  Sigma Multiplier: 1.1596456890357103\n",
      "  Initialization Multiplier: 0.6239912184497821\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.01it/s, loss=-0.000405, elapsed time=0.04, total time=9.11]\n",
      "[I 2025-06-07 15:23:49,290] Trial 856 finished with value: -0.000405419781604074 and parameters: {'learning_rate': 0.007920001174565313, 'sigma_multiplier': 1.1596456890357103, 'num_layers': 2, 'initialization_multiplier': 0.6239912184497821}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 856 final loss: -0.00040542\n",
      "Trial 857:\n",
      "  Learning Rate: 0.013600934246771265\n",
      "  Sigma Multiplier: 1.0576024759714164\n",
      "  Initialization Multiplier: 0.7203023115055343\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.56it/s, loss=-0.000294, elapsed time=0.07, total time=10.5]\n",
      "[I 2025-06-07 15:23:59,886] Trial 857 finished with value: -0.00029443182489815434 and parameters: {'learning_rate': 0.013600934246771265, 'sigma_multiplier': 1.0576024759714164, 'num_layers': 2, 'initialization_multiplier': 0.7203023115055343}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 857 final loss: -0.00029443\n",
      "Trial 858:\n",
      "  Learning Rate: 0.0052531971800577025\n",
      "  Sigma Multiplier: 1.1097567541150857\n",
      "  Initialization Multiplier: 0.5493822060071458\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.98it/s, loss=-0.000405, elapsed time=0.06, total time=9.72]\n",
      "[I 2025-06-07 15:24:09,662] Trial 858 finished with value: -0.0004051159846155994 and parameters: {'learning_rate': 0.0052531971800577025, 'sigma_multiplier': 1.1097567541150857, 'num_layers': 2, 'initialization_multiplier': 0.5493822060071458}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 858 final loss: -0.00040512\n",
      "Trial 859:\n",
      "  Learning Rate: 0.00942733946974963\n",
      "  Sigma Multiplier: 0.9735940343947829\n",
      "  Initialization Multiplier: 0.45012051874996495\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.79it/s, loss=-0.000383, elapsed time=0.05, total time=9.87]\n",
      "[I 2025-06-07 15:24:19,605] Trial 859 finished with value: -0.0003827417136394438 and parameters: {'learning_rate': 0.00942733946974963, 'sigma_multiplier': 0.9735940343947829, 'num_layers': 2, 'initialization_multiplier': 0.45012051874996495}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 859 final loss: -0.00038274\n",
      "Trial 860:\n",
      "  Learning Rate: 0.010985038525376157\n",
      "  Sigma Multiplier: 1.0281926618001818\n",
      "  Initialization Multiplier: 0.5006353236226444\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.78it/s, loss=-0.000378, elapsed time=0.06, total time=9.8] \n",
      "[I 2025-06-07 15:24:29,455] Trial 860 finished with value: -0.0003782726375078969 and parameters: {'learning_rate': 0.010985038525376157, 'sigma_multiplier': 1.0281926618001818, 'num_layers': 2, 'initialization_multiplier': 0.5006353236226444}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 860 final loss: -0.00037827\n",
      "Trial 861:\n",
      "  Learning Rate: 0.008773356866339016\n",
      "  Sigma Multiplier: 0.9231798402055437\n",
      "  Initialization Multiplier: 0.5913531104403473\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.95it/s, loss=-0.000359, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 15:24:39,818] Trial 861 finished with value: -0.0003586430736144315 and parameters: {'learning_rate': 0.008773356866339016, 'sigma_multiplier': 0.9231798402055437, 'num_layers': 2, 'initialization_multiplier': 0.5913531104403473}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 861 final loss: -0.00035864\n",
      "Trial 862:\n",
      "  Learning Rate: 0.005958920866962708\n",
      "  Sigma Multiplier: 0.9990931553389228\n",
      "  Initialization Multiplier: 0.6559665416129504\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 12.85it/s, loss=-0.000233, elapsed time=0.04, total time=11.9]\n",
      "[I 2025-06-07 15:24:51,844] Trial 862 finished with value: -0.00023295936737688033 and parameters: {'learning_rate': 0.005958920866962708, 'sigma_multiplier': 0.9990931553389228, 'num_layers': 3, 'initialization_multiplier': 0.6559665416129504}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 862 final loss: -0.00023296\n",
      "Trial 863:\n",
      "  Learning Rate: 0.0071990892065526444\n",
      "  Sigma Multiplier: 1.075817161451557\n",
      "  Initialization Multiplier: 0.5360392675027332\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.37it/s, loss=-0.000328, elapsed time=0.06, total time=9.95]\n",
      "[I 2025-06-07 15:25:01,846] Trial 863 finished with value: -0.0003276131031546956 and parameters: {'learning_rate': 0.0071990892065526444, 'sigma_multiplier': 1.075817161451557, 'num_layers': 2, 'initialization_multiplier': 0.5360392675027332}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 863 final loss: -0.00032761\n",
      "Trial 864:\n",
      "  Learning Rate: 0.0037502002728355957\n",
      "  Sigma Multiplier: 0.9456437587038968\n",
      "  Initialization Multiplier: 0.6180331025164003\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.98it/s, loss=-0.000367, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:25:12,199] Trial 864 finished with value: -0.00036666202756581467 and parameters: {'learning_rate': 0.0037502002728355957, 'sigma_multiplier': 0.9456437587038968, 'num_layers': 2, 'initialization_multiplier': 0.6180331025164003}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 864 final loss: -0.00036666\n",
      "Trial 865:\n",
      "  Learning Rate: 0.0123972036555753\n",
      "  Sigma Multiplier: 1.1316260690539939\n",
      "  Initialization Multiplier: 0.7996207535465907\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.68it/s, loss=-0.000212, elapsed time=0.06, total time=9.89]\n",
      "[I 2025-06-07 15:25:22,144] Trial 865 finished with value: -0.00021209678914594593 and parameters: {'learning_rate': 0.0123972036555753, 'sigma_multiplier': 1.1316260690539939, 'num_layers': 2, 'initialization_multiplier': 0.7996207535465907}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 865 final loss: -0.00021210\n",
      "Trial 866:\n",
      "  Learning Rate: 0.014170968056942861\n",
      "  Sigma Multiplier: 1.0475193317181248\n",
      "  Initialization Multiplier: 0.6874278740464024\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.35it/s, loss=-0.000189, elapsed time=0.06, total time=10.1]\n",
      "[I 2025-06-07 15:25:32,278] Trial 866 finished with value: -0.00018850513744266914 and parameters: {'learning_rate': 0.014170968056942861, 'sigma_multiplier': 1.0475193317181248, 'num_layers': 2, 'initialization_multiplier': 0.6874278740464024}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 866 final loss: -0.00018851\n",
      "Trial 867:\n",
      "  Learning Rate: 0.0009538967976799997\n",
      "  Sigma Multiplier: 1.2232139620925846\n",
      "  Initialization Multiplier: 0.4827034075669615\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.09it/s, loss=0.001273, elapsed time=0.05, total time=9.61]\n",
      "[I 2025-06-07 15:25:41,945] Trial 867 finished with value: 0.0012732041197662447 and parameters: {'learning_rate': 0.0009538967976799997, 'sigma_multiplier': 1.2232139620925846, 'num_layers': 2, 'initialization_multiplier': 0.4827034075669615}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 867 final loss: 0.00127320\n",
      "Trial 868:\n",
      "  Learning Rate: 0.008482541317569751\n",
      "  Sigma Multiplier: 0.9877182555134906\n",
      "  Initialization Multiplier: 0.5698337804795316\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.35it/s, loss=-0.000339, elapsed time=0.08, total time=10.1]\n",
      "[I 2025-06-07 15:25:52,126] Trial 868 finished with value: -0.000338903456771053 and parameters: {'learning_rate': 0.008482541317569751, 'sigma_multiplier': 0.9877182555134906, 'num_layers': 2, 'initialization_multiplier': 0.5698337804795316}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 868 final loss: -0.00033890\n",
      "Trial 869:\n",
      "  Learning Rate: 0.010135154104855595\n",
      "  Sigma Multiplier: 1.9961163161668949\n",
      "  Initialization Multiplier: 0.6447230927171609\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.15it/s, loss=-0.000198, elapsed time=0.04, total time=8.5] \n",
      "[I 2025-06-07 15:26:00,681] Trial 869 finished with value: -0.00019771392059959658 and parameters: {'learning_rate': 0.010135154104855595, 'sigma_multiplier': 1.9961163161668949, 'num_layers': 2, 'initialization_multiplier': 0.6447230927171609}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 869 final loss: -0.00019771\n",
      "Trial 870:\n",
      "  Learning Rate: 0.0076134211287027355\n",
      "  Sigma Multiplier: 0.649324378350064\n",
      "  Initialization Multiplier: 0.517790383602111\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000148, elapsed time=0.06, total time=11.6]\n",
      "[I 2025-06-07 15:26:12,373] Trial 870 finished with value: -0.00014796450675417727 and parameters: {'learning_rate': 0.0076134211287027355, 'sigma_multiplier': 0.649324378350064, 'num_layers': 2, 'initialization_multiplier': 0.517790383602111}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 870 final loss: -0.00014796\n",
      "Trial 871:\n",
      "  Learning Rate: 0.006292855936162343\n",
      "  Sigma Multiplier: 1.0279509272182825\n",
      "  Initialization Multiplier: 0.4487906720586336\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.11it/s, loss=-0.000409, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:26:22,732] Trial 871 finished with value: -0.00040924078157777223 and parameters: {'learning_rate': 0.006292855936162343, 'sigma_multiplier': 1.0279509272182825, 'num_layers': 2, 'initialization_multiplier': 0.4487906720586336}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 871 final loss: -0.00040924\n",
      "Trial 872:\n",
      "  Learning Rate: 0.004790131725339676\n",
      "  Sigma Multiplier: 0.9597678250014812\n",
      "  Initialization Multiplier: 0.5950419175784964\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.24it/s, loss=-0.000354, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:26:32,948] Trial 872 finished with value: -0.00035391021187498157 and parameters: {'learning_rate': 0.004790131725339676, 'sigma_multiplier': 0.9597678250014812, 'num_layers': 2, 'initialization_multiplier': 0.5950419175784964}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 872 final loss: -0.00035391\n",
      "Trial 873:\n",
      "  Learning Rate: 0.010989344357869434\n",
      "  Sigma Multiplier: 0.8996238865169826\n",
      "  Initialization Multiplier: 0.8542940223106296\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.94it/s, loss=0.000075, elapsed time=0.06, total time=11.1] \n",
      "[I 2025-06-07 15:26:44,127] Trial 873 finished with value: 7.51630424266834e-05 and parameters: {'learning_rate': 0.010989344357869434, 'sigma_multiplier': 0.8996238865169826, 'num_layers': 2, 'initialization_multiplier': 0.8542940223106296}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 873 final loss: 0.00007516\n",
      "Trial 874:\n",
      "  Learning Rate: 0.009369228676477886\n",
      "  Sigma Multiplier: 1.086008516555585\n",
      "  Initialization Multiplier: 0.5451958555010139\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.99it/s, loss=-0.000218, elapsed time=0.05, total time=8.2] \n",
      "[I 2025-06-07 15:26:52,377] Trial 874 finished with value: -0.00021805249745972675 and parameters: {'learning_rate': 0.009369228676477886, 'sigma_multiplier': 1.086008516555585, 'num_layers': 1, 'initialization_multiplier': 0.5451958555010139}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 874 final loss: -0.00021805\n",
      "Trial 875:\n",
      "  Learning Rate: 0.012870845252440546\n",
      "  Sigma Multiplier: 1.0006177173054331\n",
      "  Initialization Multiplier: 0.5010337484406306\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.97it/s, loss=-0.000448, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 15:27:02,708] Trial 875 finished with value: -0.0004481912845556237 and parameters: {'learning_rate': 0.012870845252440546, 'sigma_multiplier': 1.0006177173054331, 'num_layers': 2, 'initialization_multiplier': 0.5010337484406306}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 875 final loss: -0.00044819\n",
      "Trial 876:\n",
      "  Learning Rate: 0.014100856472079974\n",
      "  Sigma Multiplier: 0.2711901973659212\n",
      "  Initialization Multiplier: 0.07939647113624981\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.21it/s, loss=0.001533, elapsed time=0.09, total time=13.7]\n",
      "[I 2025-06-07 15:27:16,438] Trial 876 finished with value: 0.0015332582932590696 and parameters: {'learning_rate': 0.014100856472079974, 'sigma_multiplier': 0.2711901973659212, 'num_layers': 2, 'initialization_multiplier': 0.07939647113624981}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 876 final loss: 0.00153326\n",
      "Trial 877:\n",
      "  Learning Rate: 0.012986205437375614\n",
      "  Sigma Multiplier: 0.9267573190517251\n",
      "  Initialization Multiplier: 0.4381666159628285\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.97it/s, loss=-0.000305, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:27:26,799] Trial 877 finished with value: -0.0003047809918173005 and parameters: {'learning_rate': 0.012986205437375614, 'sigma_multiplier': 0.9267573190517251, 'num_layers': 2, 'initialization_multiplier': 0.4381666159628285}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 877 final loss: -0.00030478\n",
      "Trial 878:\n",
      "  Learning Rate: 0.016235279278925326\n",
      "  Sigma Multiplier: 0.9775130316668585\n",
      "  Initialization Multiplier: 0.4843737259930274\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.67it/s, loss=-0.000252, elapsed time=0.05, total time=9.84]\n",
      "[I 2025-06-07 15:27:36,706] Trial 878 finished with value: -0.00025211269682637696 and parameters: {'learning_rate': 0.016235279278925326, 'sigma_multiplier': 0.9775130316668585, 'num_layers': 2, 'initialization_multiplier': 0.4843737259930274}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 878 final loss: -0.00025211\n",
      "Trial 879:\n",
      "  Learning Rate: 0.011895633391484504\n",
      "  Sigma Multiplier: 0.8599990594691641\n",
      "  Initialization Multiplier: 0.4939471204379513\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.48it/s, loss=-0.000247, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 15:27:47,471] Trial 879 finished with value: -0.00024667800708552597 and parameters: {'learning_rate': 0.011895633391484504, 'sigma_multiplier': 0.8599990594691641, 'num_layers': 2, 'initialization_multiplier': 0.4939471204379513}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 879 final loss: -0.00024668\n",
      "Trial 880:\n",
      "  Learning Rate: 0.015400420088254197\n",
      "  Sigma Multiplier: 0.9972923763486555\n",
      "  Initialization Multiplier: 0.44901642579477363\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.10it/s, loss=-0.000321, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:27:57,717] Trial 880 finished with value: -0.00032076119792978874 and parameters: {'learning_rate': 0.015400420088254197, 'sigma_multiplier': 0.9972923763486555, 'num_layers': 2, 'initialization_multiplier': 0.44901642579477363}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 880 final loss: -0.00032076\n",
      "Trial 881:\n",
      "  Learning Rate: 0.013203785942741481\n",
      "  Sigma Multiplier: 0.9515646962405133\n",
      "  Initialization Multiplier: 0.5018010388828276\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.35it/s, loss=-0.000411, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 15:28:08,591] Trial 881 finished with value: -0.00041102578078599833 and parameters: {'learning_rate': 0.013203785942741481, 'sigma_multiplier': 0.9515646962405133, 'num_layers': 2, 'initialization_multiplier': 0.5018010388828276}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 881 final loss: -0.00041103\n",
      "Trial 882:\n",
      "  Learning Rate: 0.011070810749894086\n",
      "  Sigma Multiplier: 1.015460056498316\n",
      "  Initialization Multiplier: 0.5264423418872161\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.09it/s, loss=-0.000354, elapsed time=0.08, total time=11.1]\n",
      "[I 2025-06-07 15:28:19,878] Trial 882 finished with value: -0.0003536386723851458 and parameters: {'learning_rate': 0.011070810749894086, 'sigma_multiplier': 1.015460056498316, 'num_layers': 2, 'initialization_multiplier': 0.5264423418872161}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 882 final loss: -0.00035364\n",
      "Trial 883:\n",
      "  Learning Rate: 0.014592426100122532\n",
      "  Sigma Multiplier: 0.9137698665022642\n",
      "  Initialization Multiplier: 0.47850487112488516\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.80it/s, loss=-0.000330, elapsed time=0.06, total time=10.4]\n",
      "[I 2025-06-07 15:28:30,366] Trial 883 finished with value: -0.0003303609997519016 and parameters: {'learning_rate': 0.014592426100122532, 'sigma_multiplier': 0.9137698665022642, 'num_layers': 2, 'initialization_multiplier': 0.47850487112488516}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 883 final loss: -0.00033036\n",
      "Trial 884:\n",
      "  Learning Rate: 0.01015620800351391\n",
      "  Sigma Multiplier: 0.9669890877471192\n",
      "  Initialization Multiplier: 0.4287686596581082\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.45it/s, loss=-0.000357, elapsed time=0.09, total time=10.8]\n",
      "[I 2025-06-07 15:28:41,246] Trial 884 finished with value: -0.00035659506903805335 and parameters: {'learning_rate': 0.01015620800351391, 'sigma_multiplier': 0.9669890877471192, 'num_layers': 2, 'initialization_multiplier': 0.4287686596581082}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 884 final loss: -0.00035660\n",
      "Trial 885:\n",
      "  Learning Rate: 0.012443696736264154\n",
      "  Sigma Multiplier: 1.7282269625961844\n",
      "  Initialization Multiplier: 0.5377971164844962\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.70it/s, loss=-0.000252, elapsed time=0.05, total time=8.8] \n",
      "[I 2025-06-07 15:28:50,103] Trial 885 finished with value: -0.00025196301352531044 and parameters: {'learning_rate': 0.012443696736264154, 'sigma_multiplier': 1.7282269625961844, 'num_layers': 2, 'initialization_multiplier': 0.5377971164844962}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 885 final loss: -0.00025196\n",
      "Trial 886:\n",
      "  Learning Rate: 0.009403560183163037\n",
      "  Sigma Multiplier: 0.7834107295026518\n",
      "  Initialization Multiplier: 0.5693111236579573\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000323, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 15:29:00,882] Trial 886 finished with value: -0.00032335919163625597 and parameters: {'learning_rate': 0.009403560183163037, 'sigma_multiplier': 0.7834107295026518, 'num_layers': 2, 'initialization_multiplier': 0.5693111236579573}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 886 final loss: -0.00032336\n",
      "Trial 887:\n",
      "  Learning Rate: 0.01163496528144572\n",
      "  Sigma Multiplier: 0.8341260953755864\n",
      "  Initialization Multiplier: 0.5105731363083474\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.73it/s, loss=-0.000193, elapsed time=0.05, total time=10.5]\n",
      "[I 2025-06-07 15:29:11,435] Trial 887 finished with value: -0.00019344164474918292 and parameters: {'learning_rate': 0.01163496528144572, 'sigma_multiplier': 0.8341260953755864, 'num_layers': 2, 'initialization_multiplier': 0.5105731363083474}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 887 final loss: -0.00019344\n",
      "Trial 888:\n",
      "  Learning Rate: 0.018394430895587868\n",
      "  Sigma Multiplier: 1.0019874895434708\n",
      "  Initialization Multiplier: 0.48257277713625907\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.21it/s, loss=-0.000294, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:29:21,743] Trial 888 finished with value: -0.00029410256556239235 and parameters: {'learning_rate': 0.018394430895587868, 'sigma_multiplier': 1.0019874895434708, 'num_layers': 2, 'initialization_multiplier': 0.48257277713625907}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 888 final loss: -0.00029410\n",
      "Trial 889:\n",
      "  Learning Rate: 0.008571538354703223\n",
      "  Sigma Multiplier: 0.8939740914247086\n",
      "  Initialization Multiplier: 0.4523880399521599\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.67it/s, loss=-0.000273, elapsed time=0.06, total time=11.3]\n",
      "[I 2025-06-07 15:29:33,093] Trial 889 finished with value: -0.00027306345785340876 and parameters: {'learning_rate': 0.008571538354703223, 'sigma_multiplier': 0.8939740914247086, 'num_layers': 2, 'initialization_multiplier': 0.4523880399521599}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 889 final loss: -0.00027306\n",
      "Trial 890:\n",
      "  Learning Rate: 0.010766751879575\n",
      "  Sigma Multiplier: 0.9414376040750428\n",
      "  Initialization Multiplier: 0.5537215456055115\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.76it/s, loss=-0.000339, elapsed time=0.05, total time=10.5]\n",
      "[I 2025-06-07 15:29:43,615] Trial 890 finished with value: -0.0003385598271286038 and parameters: {'learning_rate': 0.010766751879575, 'sigma_multiplier': 0.9414376040750428, 'num_layers': 2, 'initialization_multiplier': 0.5537215456055115}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 890 final loss: -0.00033856\n",
      "Trial 891:\n",
      "  Learning Rate: 0.015023452664639657\n",
      "  Sigma Multiplier: 1.0384018285387993\n",
      "  Initialization Multiplier: 0.4187156387949576\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.89it/s, loss=-0.000410, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 15:29:54,786] Trial 891 finished with value: -0.00040964437674837053 and parameters: {'learning_rate': 0.015023452664639657, 'sigma_multiplier': 1.0384018285387993, 'num_layers': 2, 'initialization_multiplier': 0.4187156387949576}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 891 final loss: -0.00040964\n",
      "Trial 892:\n",
      "  Learning Rate: 0.012861249147713132\n",
      "  Sigma Multiplier: 0.9866541388934394\n",
      "  Initialization Multiplier: 0.5240143637964606\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000373, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 15:30:05,731] Trial 892 finished with value: -0.00037336717163644897 and parameters: {'learning_rate': 0.012861249147713132, 'sigma_multiplier': 0.9866541388934394, 'num_layers': 2, 'initialization_multiplier': 0.5240143637964606}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 892 final loss: -0.00037337\n",
      "Trial 893:\n",
      "  Learning Rate: 0.009629690171655434\n",
      "  Sigma Multiplier: 1.0284625414731206\n",
      "  Initialization Multiplier: 1.5754685413969611\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.74it/s, loss=-0.000078, elapsed time=0.07, total time=11.3]\n",
      "[I 2025-06-07 15:30:17,205] Trial 893 finished with value: -7.80480199930482e-05 and parameters: {'learning_rate': 0.009629690171655434, 'sigma_multiplier': 1.0284625414731206, 'num_layers': 2, 'initialization_multiplier': 1.5754685413969611}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 893 final loss: -0.00007805\n",
      "Trial 894:\n",
      "  Learning Rate: 0.008014206084465002\n",
      "  Sigma Multiplier: 0.9519527650326882\n",
      "  Initialization Multiplier: 0.5745557596905667\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 13.96it/s, loss=-0.000262, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 15:30:28,299] Trial 894 finished with value: -0.00026203423046639637 and parameters: {'learning_rate': 0.008014206084465002, 'sigma_multiplier': 0.9519527650326882, 'num_layers': 2, 'initialization_multiplier': 0.5745557596905667}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 894 final loss: -0.00026203\n",
      "Trial 895:\n",
      "  Learning Rate: 0.010830630031721161\n",
      "  Sigma Multiplier: 0.9971089572296671\n",
      "  Initialization Multiplier: 0.4690421986116034\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.97it/s, loss=-0.000352, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 15:30:38,629] Trial 895 finished with value: -0.00035225676535739417 and parameters: {'learning_rate': 0.010830630031721161, 'sigma_multiplier': 0.9971089572296671, 'num_layers': 2, 'initialization_multiplier': 0.4690421986116034}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 895 final loss: -0.00035226\n",
      "Trial 896:\n",
      "  Learning Rate: 0.013106988120117694\n",
      "  Sigma Multiplier: 0.9170041145976252\n",
      "  Initialization Multiplier: 0.5918969481283619\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.13it/s, loss=-0.000350, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:30:48,870] Trial 896 finished with value: -0.0003503719996958127 and parameters: {'learning_rate': 0.013106988120117694, 'sigma_multiplier': 0.9170041145976252, 'num_layers': 2, 'initialization_multiplier': 0.5918969481283619}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 896 final loss: -0.00035037\n",
      "Trial 897:\n",
      "  Learning Rate: 0.008745426680665594\n",
      "  Sigma Multiplier: 1.0551075018128733\n",
      "  Initialization Multiplier: 0.5212140619604206\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.68it/s, loss=-0.000327, elapsed time=0.07, total time=10.5]\n",
      "[I 2025-06-07 15:30:59,446] Trial 897 finished with value: -0.0003273238494479227 and parameters: {'learning_rate': 0.008745426680665594, 'sigma_multiplier': 1.0551075018128733, 'num_layers': 2, 'initialization_multiplier': 0.5212140619604206}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 897 final loss: -0.00032732\n",
      "Trial 898:\n",
      "  Learning Rate: 0.016701930241651494\n",
      "  Sigma Multiplier: 0.9807242652282391\n",
      "  Initialization Multiplier: 0.5604241230559934\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.16it/s, loss=-0.000444, elapsed time=0.04, total time=10.2]\n",
      "[I 2025-06-07 15:31:09,728] Trial 898 finished with value: -0.00044396674507511614 and parameters: {'learning_rate': 0.016701930241651494, 'sigma_multiplier': 0.9807242652282391, 'num_layers': 2, 'initialization_multiplier': 0.5604241230559934}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 898 final loss: -0.00044397\n",
      "Trial 899:\n",
      "  Learning Rate: 0.0181367593283496\n",
      "  Sigma Multiplier: 0.95892849255308\n",
      "  Initialization Multiplier: 0.6021102932630022\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.11it/s, loss=-0.000362, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 15:31:20,765] Trial 899 finished with value: -0.0003617528086461154 and parameters: {'learning_rate': 0.0181367593283496, 'sigma_multiplier': 0.95892849255308, 'num_layers': 2, 'initialization_multiplier': 0.6021102932630022}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 899 final loss: -0.00036175\n",
      "Trial 900:\n",
      "  Learning Rate: 0.020779277809807623\n",
      "  Sigma Multiplier: 0.8747466119988282\n",
      "  Initialization Multiplier: 0.5570712346793113\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.57it/s, loss=-0.000280, elapsed time=0.07, total time=10.6]\n",
      "[I 2025-06-07 15:31:31,424] Trial 900 finished with value: -0.0002797819015391951 and parameters: {'learning_rate': 0.020779277809807623, 'sigma_multiplier': 0.8747466119988282, 'num_layers': 2, 'initialization_multiplier': 0.5570712346793113}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 900 final loss: -0.00027978\n",
      "Trial 901:\n",
      "  Learning Rate: 0.018866974786069312\n",
      "  Sigma Multiplier: 1.018875063661493\n",
      "  Initialization Multiplier: 0.625388869225922\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.07it/s, loss=-0.000337, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:31:41,816] Trial 901 finished with value: -0.000337219959187835 and parameters: {'learning_rate': 0.018866974786069312, 'sigma_multiplier': 1.018875063661493, 'num_layers': 2, 'initialization_multiplier': 0.625388869225922}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 901 final loss: -0.00033722\n",
      "Trial 902:\n",
      "  Learning Rate: 0.01666111719012241\n",
      "  Sigma Multiplier: 1.0979909105109833\n",
      "  Initialization Multiplier: 0.5045144132380744\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.07it/s, loss=-0.000383, elapsed time=0.07, total time=10.2]\n",
      "[I 2025-06-07 15:31:52,136] Trial 902 finished with value: -0.0003834601094627151 and parameters: {'learning_rate': 0.01666111719012241, 'sigma_multiplier': 1.0979909105109833, 'num_layers': 2, 'initialization_multiplier': 0.5045144132380744}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 902 final loss: -0.00038346\n",
      "Trial 903:\n",
      "  Learning Rate: 0.015148606255129276\n",
      "  Sigma Multiplier: 0.9355200955629763\n",
      "  Initialization Multiplier: 0.4049166860016499\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.39it/s, loss=-0.000323, elapsed time=0.04, total time=10.7]\n",
      "[I 2025-06-07 15:32:02,872] Trial 903 finished with value: -0.000323248349344318 and parameters: {'learning_rate': 0.015148606255129276, 'sigma_multiplier': 0.9355200955629763, 'num_layers': 2, 'initialization_multiplier': 0.4049166860016499}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 903 final loss: -0.00032325\n",
      "Trial 904:\n",
      "  Learning Rate: 0.021166126345694397\n",
      "  Sigma Multiplier: 1.1718179352493119\n",
      "  Initialization Multiplier: 0.5877925388547495\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.57it/s, loss=-0.000322, elapsed time=0.07, total time=10]  \n",
      "[I 2025-06-07 15:32:12,929] Trial 904 finished with value: -0.00032229334648704524 and parameters: {'learning_rate': 0.021166126345694397, 'sigma_multiplier': 1.1718179352493119, 'num_layers': 2, 'initialization_multiplier': 0.5877925388547495}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 904 final loss: -0.00032229\n",
      "Trial 905:\n",
      "  Learning Rate: 0.015101874121313273\n",
      "  Sigma Multiplier: 1.049996399160759\n",
      "  Initialization Multiplier: 0.5528313627996039\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.38it/s, loss=-0.000303, elapsed time=0.09, total time=10.8]\n",
      "[I 2025-06-07 15:32:23,760] Trial 905 finished with value: -0.0003030191372212348 and parameters: {'learning_rate': 0.015101874121313273, 'sigma_multiplier': 1.049996399160759, 'num_layers': 2, 'initialization_multiplier': 0.5528313627996039}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 905 final loss: -0.00030302\n",
      "Trial 906:\n",
      "  Learning Rate: 0.02628299947449508\n",
      "  Sigma Multiplier: 0.9831627605096884\n",
      "  Initialization Multiplier: 0.4929451207737733\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.01it/s, loss=-0.000328, elapsed time=0.05, total time=11.1]\n",
      "[I 2025-06-07 15:32:34,885] Trial 906 finished with value: -0.000328106051868223 and parameters: {'learning_rate': 0.02628299947449508, 'sigma_multiplier': 0.9831627605096884, 'num_layers': 2, 'initialization_multiplier': 0.4929451207737733}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 906 final loss: -0.00032811\n",
      "Trial 907:\n",
      "  Learning Rate: 0.024339165668863558\n",
      "  Sigma Multiplier: 1.018142709067512\n",
      "  Initialization Multiplier: 0.4554139377222715\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.30it/s, loss=-0.000307, elapsed time=0.08, total time=11.6]\n",
      "[I 2025-06-07 15:32:46,558] Trial 907 finished with value: -0.0003071638661908237 and parameters: {'learning_rate': 0.024339165668863558, 'sigma_multiplier': 1.018142709067512, 'num_layers': 2, 'initialization_multiplier': 0.4554139377222715}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 907 final loss: -0.00030716\n",
      "Trial 908:\n",
      "  Learning Rate: 0.016417903532985768\n",
      "  Sigma Multiplier: 0.89917347077956\n",
      "  Initialization Multiplier: 0.628534496572215\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.35it/s, loss=-0.000408, elapsed time=0.06, total time=10.8]\n",
      "[I 2025-06-07 15:32:57,524] Trial 908 finished with value: -0.0004076141116000268 and parameters: {'learning_rate': 0.016417903532985768, 'sigma_multiplier': 0.89917347077956, 'num_layers': 2, 'initialization_multiplier': 0.628534496572215}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 908 final loss: -0.00040761\n",
      "Trial 909:\n",
      "  Learning Rate: 0.01799936461575598\n",
      "  Sigma Multiplier: 1.0762338039430908\n",
      "  Initialization Multiplier: 0.5380043027797428\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.83it/s, loss=-0.000360, elapsed time=0.05, total time=10.4]\n",
      "[I 2025-06-07 15:33:07,971] Trial 909 finished with value: -0.0003602155314514124 and parameters: {'learning_rate': 0.01799936461575598, 'sigma_multiplier': 1.0762338039430908, 'num_layers': 2, 'initialization_multiplier': 0.5380043027797428}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 909 final loss: -0.00036022\n",
      "Trial 910:\n",
      "  Learning Rate: 0.02148842596722561\n",
      "  Sigma Multiplier: 0.9706394222151868\n",
      "  Initialization Multiplier: 0.6152914878393387\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.10it/s, loss=-0.000344, elapsed time=0.06, total time=11]  \n",
      "[I 2025-06-07 15:33:18,990] Trial 910 finished with value: -0.00034421380783799984 and parameters: {'learning_rate': 0.02148842596722561, 'sigma_multiplier': 0.9706394222151868, 'num_layers': 2, 'initialization_multiplier': 0.6152914878393387}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 910 final loss: -0.00034421\n",
      "Trial 911:\n",
      "  Learning Rate: 0.014287950120440339\n",
      "  Sigma Multiplier: 1.1223172626075828\n",
      "  Initialization Multiplier: 0.5770531104536109\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.65it/s, loss=-0.000352, elapsed time=0.07, total time=9.92]\n",
      "[I 2025-06-07 15:33:28,972] Trial 911 finished with value: -0.00035152345741242165 and parameters: {'learning_rate': 0.014287950120440339, 'sigma_multiplier': 1.1223172626075828, 'num_layers': 2, 'initialization_multiplier': 0.5770531104536109}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 911 final loss: -0.00035152\n",
      "Trial 912:\n",
      "  Learning Rate: 0.012722937381049872\n",
      "  Sigma Multiplier: 1.0482990558608623\n",
      "  Initialization Multiplier: 0.5075927403099767\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.01it/s, loss=-0.000385, elapsed time=0.08, total time=10.3]\n",
      "[I 2025-06-07 15:33:39,322] Trial 912 finished with value: -0.0003853433296202336 and parameters: {'learning_rate': 0.012722937381049872, 'sigma_multiplier': 1.0482990558608623, 'num_layers': 2, 'initialization_multiplier': 0.5075927403099767}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 912 final loss: -0.00038534\n",
      "Trial 913:\n",
      "  Learning Rate: 0.015873766798478635\n",
      "  Sigma Multiplier: 1.0009845048530934\n",
      "  Initialization Multiplier: 0.44097276176170963\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.55it/s, loss=-0.000298, elapsed time=0.07, total time=9.95]\n",
      "[I 2025-06-07 15:33:49,338] Trial 913 finished with value: -0.00029780526822886387 and parameters: {'learning_rate': 0.015873766798478635, 'sigma_multiplier': 1.0009845048530934, 'num_layers': 2, 'initialization_multiplier': 0.44097276176170963}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 913 final loss: -0.00029781\n",
      "Trial 914:\n",
      "  Learning Rate: 0.01255451930680294\n",
      "  Sigma Multiplier: 0.9408040684445463\n",
      "  Initialization Multiplier: 0.6645064417667299\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.45it/s, loss=-0.000367, elapsed time=0.07, total time=10.7]\n",
      "[I 2025-06-07 15:34:00,088] Trial 914 finished with value: -0.0003669722532810535 and parameters: {'learning_rate': 0.01255451930680294, 'sigma_multiplier': 0.9408040684445463, 'num_layers': 2, 'initialization_multiplier': 0.6645064417667299}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 914 final loss: -0.00036697\n",
      "Trial 915:\n",
      "  Learning Rate: 0.011177115921385292\n",
      "  Sigma Multiplier: 1.0915672921417536\n",
      "  Initialization Multiplier: 0.584599548089443\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.27it/s, loss=-0.000349, elapsed time=0.05, total time=10.9]\n",
      "[I 2025-06-07 15:34:11,069] Trial 915 finished with value: -0.0003492862273347694 and parameters: {'learning_rate': 0.011177115921385292, 'sigma_multiplier': 1.0915672921417536, 'num_layers': 2, 'initialization_multiplier': 0.584599548089443}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 915 final loss: -0.00034929\n",
      "Trial 916:\n",
      "  Learning Rate: 0.014150660703514858\n",
      "  Sigma Multiplier: 1.0249355840507206\n",
      "  Initialization Multiplier: 0.5492078980980982\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.46it/s, loss=-0.000455, elapsed time=0.05, total time=10.6]\n",
      "[I 2025-06-07 15:34:21,773] Trial 916 finished with value: -0.00045526134166227783 and parameters: {'learning_rate': 0.014150660703514858, 'sigma_multiplier': 1.0249355840507206, 'num_layers': 2, 'initialization_multiplier': 0.5492078980980982}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 916 final loss: -0.00045526\n",
      "Trial 917:\n",
      "  Learning Rate: 0.019872037916942194\n",
      "  Sigma Multiplier: 1.0544304867972634\n",
      "  Initialization Multiplier: 0.5645357670232406\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.14it/s, loss=-0.000398, elapsed time=0.05, total time=10.2]\n",
      "[I 2025-06-07 15:34:32,025] Trial 917 finished with value: -0.00039799478268703014 and parameters: {'learning_rate': 0.019872037916942194, 'sigma_multiplier': 1.0544304867972634, 'num_layers': 2, 'initialization_multiplier': 0.5645357670232406}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 917 final loss: -0.00039799\n",
      "Trial 918:\n",
      "  Learning Rate: 0.07152203562761499\n",
      "  Sigma Multiplier: 1.1370692456152014\n",
      "  Initialization Multiplier: 0.6464278558252133\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.77it/s, loss=-0.000128, elapsed time=0.06, total time=9.8] \n",
      "[I 2025-06-07 15:34:41,893] Trial 918 finished with value: -0.00012790718399064888 and parameters: {'learning_rate': 0.07152203562761499, 'sigma_multiplier': 1.1370692456152014, 'num_layers': 2, 'initialization_multiplier': 0.6464278558252133}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 918 final loss: -0.00012791\n",
      "Trial 919:\n",
      "  Learning Rate: 0.023406228901557583\n",
      "  Sigma Multiplier: 1.0822511984885006\n",
      "  Initialization Multiplier: 0.6148335941971423\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.21it/s, loss=-0.000325, elapsed time=0.06, total time=9.56]\n",
      "[I 2025-06-07 15:34:51,509] Trial 919 finished with value: -0.000324705286995425 and parameters: {'learning_rate': 0.023406228901557583, 'sigma_multiplier': 1.0822511984885006, 'num_layers': 2, 'initialization_multiplier': 0.6148335941971423}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 919 final loss: -0.00032471\n",
      "Trial 920:\n",
      "  Learning Rate: 0.01668063796923407\n",
      "  Sigma Multiplier: 1.034342610187125\n",
      "  Initialization Multiplier: 0.5440282722725677\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.21it/s, loss=-0.000349, elapsed time=0.06, total time=9.57]\n",
      "[I 2025-06-07 15:35:01,144] Trial 920 finished with value: -0.0003486043190627338 and parameters: {'learning_rate': 0.01668063796923407, 'sigma_multiplier': 1.034342610187125, 'num_layers': 2, 'initialization_multiplier': 0.5440282722725677}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 920 final loss: -0.00034860\n",
      "Trial 921:\n",
      "  Learning Rate: 0.018981020281713445\n",
      "  Sigma Multiplier: 1.0697888121466672\n",
      "  Initialization Multiplier: 0.5881466079266812\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.24it/s, loss=-0.000402, elapsed time=0.05, total time=9.47]\n",
      "[I 2025-06-07 15:35:10,669] Trial 921 finished with value: -0.00040174140546546367 and parameters: {'learning_rate': 0.018981020281713445, 'sigma_multiplier': 1.0697888121466672, 'num_layers': 2, 'initialization_multiplier': 0.5881466079266812}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 921 final loss: -0.00040174\n",
      "Trial 922:\n",
      "  Learning Rate: 0.01461867939018723\n",
      "  Sigma Multiplier: 1.1112836375119095\n",
      "  Initialization Multiplier: 0.5355764781609483\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.63it/s, loss=-0.000367, elapsed time=0.05, total time=9.28]\n",
      "[I 2025-06-07 15:35:20,014] Trial 922 finished with value: -0.00036650991876149586 and parameters: {'learning_rate': 0.01461867939018723, 'sigma_multiplier': 1.1112836375119095, 'num_layers': 2, 'initialization_multiplier': 0.5355764781609483}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 922 final loss: -0.00036651\n",
      "Trial 923:\n",
      "  Learning Rate: 0.01720452827707901\n",
      "  Sigma Multiplier: 1.0274474345438696\n",
      "  Initialization Multiplier: 0.6224536103225422\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.64it/s, loss=-0.000360, elapsed time=0.06, total time=9.28]\n",
      "[I 2025-06-07 15:35:29,355] Trial 923 finished with value: -0.0003601874300674179 and parameters: {'learning_rate': 0.01720452827707901, 'sigma_multiplier': 1.0274474345438696, 'num_layers': 2, 'initialization_multiplier': 0.6224536103225422}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 923 final loss: -0.00036019\n",
      "Trial 924:\n",
      "  Learning Rate: 0.01465440338560261\n",
      "  Sigma Multiplier: 1.1901781965602938\n",
      "  Initialization Multiplier: 0.556384801589809\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.64it/s, loss=-0.000330, elapsed time=0.05, total time=9.27]\n",
      "[I 2025-06-07 15:35:38,673] Trial 924 finished with value: -0.00032959209102462027 and parameters: {'learning_rate': 0.01465440338560261, 'sigma_multiplier': 1.1901781965602938, 'num_layers': 2, 'initialization_multiplier': 0.556384801589809}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 924 final loss: -0.00032959\n",
      "Trial 925:\n",
      "  Learning Rate: 0.012641387799938248\n",
      "  Sigma Multiplier: 1.0164752903461765\n",
      "  Initialization Multiplier: 0.5774243003892772\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.82it/s, loss=-0.000400, elapsed time=0.05, total time=9.77]\n",
      "[I 2025-06-07 15:35:48,500] Trial 925 finished with value: -0.0003995940776527892 and parameters: {'learning_rate': 0.012641387799938248, 'sigma_multiplier': 1.0164752903461765, 'num_layers': 2, 'initialization_multiplier': 0.5774243003892772}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 925 final loss: -0.00039959\n",
      "Trial 926:\n",
      "  Learning Rate: 0.01378865499180923\n",
      "  Sigma Multiplier: 0.7469599284970533\n",
      "  Initialization Multiplier: 0.6781810520720621\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.49it/s, loss=-0.000153, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 15:35:59,201] Trial 926 finished with value: -0.0001527291363867408 and parameters: {'learning_rate': 0.01378865499180923, 'sigma_multiplier': 0.7469599284970533, 'num_layers': 2, 'initialization_multiplier': 0.6781810520720621}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 926 final loss: -0.00015273\n",
      "Trial 927:\n",
      "  Learning Rate: 0.017441781365808023\n",
      "  Sigma Multiplier: 1.1030742089603158\n",
      "  Initialization Multiplier: 0.5063508286090121\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.43it/s, loss=-0.000321, elapsed time=0.05, total time=9.39]\n",
      "[I 2025-06-07 15:36:08,649] Trial 927 finished with value: -0.00032077787049097255 and parameters: {'learning_rate': 0.017441781365808023, 'sigma_multiplier': 1.1030742089603158, 'num_layers': 2, 'initialization_multiplier': 0.5063508286090121}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 927 final loss: -0.00032078\n",
      "Trial 928:\n",
      "  Learning Rate: 0.013360148141917525\n",
      "  Sigma Multiplier: 1.0531127733300065\n",
      "  Initialization Multiplier: 0.6078770848431574\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.03it/s, loss=-0.000434, elapsed time=0.04, total time=9.64]\n",
      "[I 2025-06-07 15:36:18,353] Trial 928 finished with value: -0.00043447373792806213 and parameters: {'learning_rate': 0.013360148141917525, 'sigma_multiplier': 1.0531127733300065, 'num_layers': 2, 'initialization_multiplier': 0.6078770848431574}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 928 final loss: -0.00043447\n",
      "Trial 929:\n",
      "  Learning Rate: 0.015466905748585212\n",
      "  Sigma Multiplier: 1.1421531346292042\n",
      "  Initialization Multiplier: 0.6411014752245134\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.06it/s, loss=-0.000365, elapsed time=0.05, total time=9.67]\n",
      "[I 2025-06-07 15:36:28,137] Trial 929 finished with value: -0.00036462786788118057 and parameters: {'learning_rate': 0.015466905748585212, 'sigma_multiplier': 1.1421531346292042, 'num_layers': 2, 'initialization_multiplier': 0.6411014752245134}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 929 final loss: -0.00036463\n",
      "Trial 930:\n",
      "  Learning Rate: 0.020845388843452054\n",
      "  Sigma Multiplier: 1.0146923311110159\n",
      "  Initialization Multiplier: 0.5269387158508204\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.67it/s, loss=-0.000276, elapsed time=0.06, total time=9.89]\n",
      "[I 2025-06-07 15:36:38,090] Trial 930 finished with value: -0.00027631842967631726 and parameters: {'learning_rate': 0.020845388843452054, 'sigma_multiplier': 1.0146923311110159, 'num_layers': 2, 'initialization_multiplier': 0.5269387158508204}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 930 final loss: -0.00027632\n",
      "Trial 931:\n",
      "  Learning Rate: 0.012344477719793467\n",
      "  Sigma Multiplier: 1.0742807407437787\n",
      "  Initialization Multiplier: 0.583186121203068\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.03it/s, loss=-0.000278, elapsed time=0.05, total time=9.63]\n",
      "[I 2025-06-07 15:36:47,773] Trial 931 finished with value: -0.00027817115787841007 and parameters: {'learning_rate': 0.012344477719793467, 'sigma_multiplier': 1.0742807407437787, 'num_layers': 2, 'initialization_multiplier': 0.583186121203068}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 931 final loss: -0.00027817\n",
      "Trial 932:\n",
      "  Learning Rate: 0.006957258492456497\n",
      "  Sigma Multiplier: 0.515049226256023\n",
      "  Initialization Multiplier: 0.5436912949205639\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.09it/s, loss=0.000280, elapsed time=0.07, total time=11.8]\n",
      "[I 2025-06-07 15:36:59,631] Trial 932 finished with value: 0.00027981363241464275 and parameters: {'learning_rate': 0.006957258492456497, 'sigma_multiplier': 0.515049226256023, 'num_layers': 2, 'initialization_multiplier': 0.5436912949205639}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 932 final loss: 0.00027981\n",
      "Trial 933:\n",
      "  Learning Rate: 0.011046624496748257\n",
      "  Sigma Multiplier: 1.4467544613439256\n",
      "  Initialization Multiplier: 0.5036960120135004\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.92it/s, loss=-0.000330, elapsed time=0.05, total time=8.62]\n",
      "[I 2025-06-07 15:37:08,310] Trial 933 finished with value: -0.00032969003085628616 and parameters: {'learning_rate': 0.011046624496748257, 'sigma_multiplier': 1.4467544613439256, 'num_layers': 2, 'initialization_multiplier': 0.5036960120135004}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 933 final loss: -0.00032969\n",
      "Trial 934:\n",
      "  Learning Rate: 0.0001484693387230326\n",
      "  Sigma Multiplier: 1.0037940063871302\n",
      "  Initialization Multiplier: 0.6135786494186535\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.95it/s, loss=0.067598, elapsed time=0.05, total time=9.74]\n",
      "[I 2025-06-07 15:37:18,105] Trial 934 finished with value: 0.06759807654600454 and parameters: {'learning_rate': 0.0001484693387230326, 'sigma_multiplier': 1.0037940063871302, 'num_layers': 2, 'initialization_multiplier': 0.6135786494186535}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 934 final loss: 0.06759808\n",
      "Trial 935:\n",
      "  Learning Rate: 0.007663918178072212\n",
      "  Sigma Multiplier: 0.9920590392332251\n",
      "  Initialization Multiplier: 0.6595943931666747\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.98it/s, loss=-0.000424, elapsed time=0.06, total time=10.3]\n",
      "[I 2025-06-07 15:37:28,480] Trial 935 finished with value: -0.00042382464912207407 and parameters: {'learning_rate': 0.007663918178072212, 'sigma_multiplier': 0.9920590392332251, 'num_layers': 2, 'initialization_multiplier': 0.6595943931666747}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 935 final loss: -0.00042382\n",
      "Trial 936:\n",
      "  Learning Rate: 0.010537656080535631\n",
      "  Sigma Multiplier: 1.0470205696554664\n",
      "  Initialization Multiplier: 0.5648442186902444\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.76it/s, loss=-0.000422, elapsed time=0.06, total time=9.97]\n",
      "[I 2025-06-07 15:37:38,537] Trial 936 finished with value: -0.00042195025048515615 and parameters: {'learning_rate': 0.010537656080535631, 'sigma_multiplier': 1.0470205696554664, 'num_layers': 2, 'initialization_multiplier': 0.5648442186902444}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 936 final loss: -0.00042195\n",
      "Trial 937:\n",
      "  Learning Rate: 0.014444794202249077\n",
      "  Sigma Multiplier: 1.1236606138535108\n",
      "  Initialization Multiplier: 0.493319839944981\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.97it/s, loss=-0.000268, elapsed time=0.06, total time=9.14]\n",
      "[I 2025-06-07 15:37:47,746] Trial 937 finished with value: -0.00026815316931761487 and parameters: {'learning_rate': 0.014444794202249077, 'sigma_multiplier': 1.1236606138535108, 'num_layers': 2, 'initialization_multiplier': 0.493319839944981}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 937 final loss: -0.00026815\n",
      "Trial 938:\n",
      "  Learning Rate: 0.017042261851075487\n",
      "  Sigma Multiplier: 0.9840912164237817\n",
      "  Initialization Multiplier: 0.5385492025561593\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.42it/s, loss=-0.000349, elapsed time=0.05, total time=9.42]\n",
      "[I 2025-06-07 15:37:57,221] Trial 938 finished with value: -0.0003489551491799645 and parameters: {'learning_rate': 0.017042261851075487, 'sigma_multiplier': 0.9840912164237817, 'num_layers': 2, 'initialization_multiplier': 0.5385492025561593}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 938 final loss: -0.00034896\n",
      "Trial 939:\n",
      "  Learning Rate: 0.01227539096381832\n",
      "  Sigma Multiplier: 1.0766193138341478\n",
      "  Initialization Multiplier: 0.6961498670802553\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.50it/s, loss=-0.000200, elapsed time=0.04, total time=9.98]\n",
      "[I 2025-06-07 15:38:07,274] Trial 939 finished with value: -0.0002004877235389071 and parameters: {'learning_rate': 0.01227539096381832, 'sigma_multiplier': 1.0766193138341478, 'num_layers': 2, 'initialization_multiplier': 0.6961498670802553}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 939 final loss: -0.00020049\n",
      "Trial 940:\n",
      "  Learning Rate: 0.009438866936721836\n",
      "  Sigma Multiplier: 1.04013507470643\n",
      "  Initialization Multiplier: 0.6039888242680019\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.98it/s, loss=-0.000404, elapsed time=0.06, total time=9.76]\n",
      "[I 2025-06-07 15:38:17,148] Trial 940 finished with value: -0.000403716619641213 and parameters: {'learning_rate': 0.009438866936721836, 'sigma_multiplier': 1.04013507470643, 'num_layers': 2, 'initialization_multiplier': 0.6039888242680019}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 940 final loss: -0.00040372\n",
      "Trial 941:\n",
      "  Learning Rate: 0.006693583363702875\n",
      "  Sigma Multiplier: 0.9651290492660097\n",
      "  Initialization Multiplier: 0.47084943304758886\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.15it/s, loss=-0.000368, elapsed time=0.05, total time=9.57]\n",
      "[I 2025-06-07 15:38:26,781] Trial 941 finished with value: -0.00036773594083570806 and parameters: {'learning_rate': 0.006693583363702875, 'sigma_multiplier': 0.9651290492660097, 'num_layers': 2, 'initialization_multiplier': 0.47084943304758886}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 941 final loss: -0.00036774\n",
      "Trial 942:\n",
      "  Learning Rate: 0.011116273823285856\n",
      "  Sigma Multiplier: 1.1661232675376574\n",
      "  Initialization Multiplier: 0.6416931370424532\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.45it/s, loss=-0.000378, elapsed time=0.05, total time=9.39]\n",
      "[I 2025-06-07 15:38:36,237] Trial 942 finished with value: -0.00037771835708315794 and parameters: {'learning_rate': 0.011116273823285856, 'sigma_multiplier': 1.1661232675376574, 'num_layers': 2, 'initialization_multiplier': 0.6416931370424532}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 942 final loss: -0.00037772\n",
      "Trial 943:\n",
      "  Learning Rate: 0.030425042427697023\n",
      "  Sigma Multiplier: 1.0170648204236776\n",
      "  Initialization Multiplier: 0.5752449246158906\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.60it/s, loss=-0.000398, elapsed time=0.05, total time=9.31]\n",
      "[I 2025-06-07 15:38:45,603] Trial 943 finished with value: -0.00039763247160838855 and parameters: {'learning_rate': 0.030425042427697023, 'sigma_multiplier': 1.0170648204236776, 'num_layers': 2, 'initialization_multiplier': 0.5752449246158906}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 943 final loss: -0.00039763\n",
      "Trial 944:\n",
      "  Learning Rate: 0.007967531311995063\n",
      "  Sigma Multiplier: 1.1109361253580574\n",
      "  Initialization Multiplier: 0.5252057457570672\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.78it/s, loss=-0.000343, elapsed time=0.04, total time=8.69]\n",
      "[I 2025-06-07 15:38:54,376] Trial 944 finished with value: -0.00034285263724945626 and parameters: {'learning_rate': 0.007967531311995063, 'sigma_multiplier': 1.1109361253580574, 'num_layers': 2, 'initialization_multiplier': 0.5252057457570672}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 944 final loss: -0.00034285\n",
      "Trial 945:\n",
      "  Learning Rate: 0.01395434235935516\n",
      "  Sigma Multiplier: 1.0758837447520766\n",
      "  Initialization Multiplier: 0.5939847496348638\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.99it/s, loss=-0.000432, elapsed time=0.06, total time=10.4]\n",
      "[I 2025-06-07 15:39:04,887] Trial 945 finished with value: -0.0004323944052831441 and parameters: {'learning_rate': 0.01395434235935516, 'sigma_multiplier': 1.0758837447520766, 'num_layers': 2, 'initialization_multiplier': 0.5939847496348638}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 945 final loss: -0.00043239\n",
      "Trial 946:\n",
      "  Learning Rate: 0.009638491452377074\n",
      "  Sigma Multiplier: 0.984579482183042\n",
      "  Initialization Multiplier: 0.6395291556032228\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.40it/s, loss=-0.000366, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 15:39:15,656] Trial 946 finished with value: -0.0003664023171585835 and parameters: {'learning_rate': 0.009638491452377074, 'sigma_multiplier': 0.984579482183042, 'num_layers': 2, 'initialization_multiplier': 0.6395291556032228}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 946 final loss: -0.00036640\n",
      "Trial 947:\n",
      "  Learning Rate: 0.005975486851035149\n",
      "  Sigma Multiplier: 1.0340900893265703\n",
      "  Initialization Multiplier: 0.47814715508193856\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.04it/s, loss=-0.000363, elapsed time=0.05, total time=10.3]\n",
      "[I 2025-06-07 15:39:26,039] Trial 947 finished with value: -0.00036258801251993876 and parameters: {'learning_rate': 0.005975486851035149, 'sigma_multiplier': 1.0340900893265703, 'num_layers': 2, 'initialization_multiplier': 0.47814715508193856}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 947 final loss: -0.00036259\n",
      "Trial 948:\n",
      "  Learning Rate: 0.007595871540359409\n",
      "  Sigma Multiplier: 0.9665641760824144\n",
      "  Initialization Multiplier: 0.5409679667261157\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.59it/s, loss=-0.000372, elapsed time=0.07, total time=10.5]\n",
      "[I 2025-06-07 15:39:36,588] Trial 948 finished with value: -0.0003716224636718591 and parameters: {'learning_rate': 0.007595871540359409, 'sigma_multiplier': 0.9665641760824144, 'num_layers': 2, 'initialization_multiplier': 0.5409679667261157}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 948 final loss: -0.00037162\n",
      "Trial 949:\n",
      "  Learning Rate: 0.001546284224046698\n",
      "  Sigma Multiplier: 0.3543045777257604\n",
      "  Initialization Multiplier: 0.683302140244652\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 11.52it/s, loss=0.002882, elapsed time=0.1, total time=13.3] \n",
      "[I 2025-06-07 15:39:49,965] Trial 949 finished with value: 0.0028819624862078553 and parameters: {'learning_rate': 0.001546284224046698, 'sigma_multiplier': 0.3543045777257604, 'num_layers': 2, 'initialization_multiplier': 0.683302140244652}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 949 final loss: 0.00288196\n",
      "Trial 950:\n",
      "  Learning Rate: 0.012039219453374213\n",
      "  Sigma Multiplier: 1.0971585166790954\n",
      "  Initialization Multiplier: 0.5852451675379516\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.55it/s, loss=-0.000376, elapsed time=0.08, total time=9.96]\n",
      "[I 2025-06-07 15:39:59,979] Trial 950 finished with value: -0.0003758975389242505 and parameters: {'learning_rate': 0.012039219453374213, 'sigma_multiplier': 1.0971585166790954, 'num_layers': 2, 'initialization_multiplier': 0.5852451675379516}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 950 final loss: -0.00037590\n",
      "Trial 951:\n",
      "  Learning Rate: 0.015893129811290697\n",
      "  Sigma Multiplier: 1.0428923696585009\n",
      "  Initialization Multiplier: 0.501175259434903\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.35it/s, loss=-0.000346, elapsed time=0.06, total time=10.1]\n",
      "[I 2025-06-07 15:40:10,150] Trial 951 finished with value: -0.00034628412610587854 and parameters: {'learning_rate': 0.015893129811290697, 'sigma_multiplier': 1.0428923696585009, 'num_layers': 2, 'initialization_multiplier': 0.501175259434903}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 951 final loss: -0.00034628\n",
      "Trial 952:\n",
      "  Learning Rate: 0.008603520944606664\n",
      "  Sigma Multiplier: 1.0036593595993968\n",
      "  Initialization Multiplier: 0.5501228166870145\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.59it/s, loss=-0.000284, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 15:40:20,988] Trial 952 finished with value: -0.0002836667672844112 and parameters: {'learning_rate': 0.008603520944606664, 'sigma_multiplier': 1.0036593595993968, 'num_layers': 2, 'initialization_multiplier': 0.5501228166870145}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 952 final loss: -0.00028367\n",
      "Trial 953:\n",
      "  Learning Rate: 0.018465621806595195\n",
      "  Sigma Multiplier: 1.1496533011859917\n",
      "  Initialization Multiplier: 0.6084226145793199\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.72it/s, loss=-0.000405, elapsed time=0.05, total time=9.26]\n",
      "[I 2025-06-07 15:40:30,308] Trial 953 finished with value: -0.00040510285179630413 and parameters: {'learning_rate': 0.018465621806595195, 'sigma_multiplier': 1.1496533011859917, 'num_layers': 2, 'initialization_multiplier': 0.6084226145793199}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 953 final loss: -0.00040510\n",
      "Trial 954:\n",
      "  Learning Rate: 0.006849503166090917\n",
      "  Sigma Multiplier: 0.933161820703618\n",
      "  Initialization Multiplier: 0.48126203572807236\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.67it/s, loss=-0.000362, elapsed time=0.05, total time=9.81]\n",
      "[I 2025-06-07 15:40:40,174] Trial 954 finished with value: -0.00036222075413327364 and parameters: {'learning_rate': 0.006849503166090917, 'sigma_multiplier': 0.933161820703618, 'num_layers': 2, 'initialization_multiplier': 0.48126203572807236}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 954 final loss: -0.00036222\n",
      "Trial 955:\n",
      "  Learning Rate: 0.010185736800508126\n",
      "  Sigma Multiplier: 1.067979760617431\n",
      "  Initialization Multiplier: 0.6437358495685264\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.92it/s, loss=-0.000366, elapsed time=0.06, total time=9.68]\n",
      "[I 2025-06-07 15:40:49,907] Trial 955 finished with value: -0.0003656437304779344 and parameters: {'learning_rate': 0.010185736800508126, 'sigma_multiplier': 1.067979760617431, 'num_layers': 2, 'initialization_multiplier': 0.6437358495685264}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 955 final loss: -0.00036564\n",
      "Trial 956:\n",
      "  Learning Rate: 0.013262849912806395\n",
      "  Sigma Multiplier: 0.9739103742164696\n",
      "  Initialization Multiplier: 0.5218291597253819\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.44it/s, loss=-0.000350, elapsed time=0.04, total time=9.39]\n",
      "[I 2025-06-07 15:40:59,358] Trial 956 finished with value: -0.00034982327796379264 and parameters: {'learning_rate': 0.013262849912806395, 'sigma_multiplier': 0.9739103742164696, 'num_layers': 2, 'initialization_multiplier': 0.5218291597253819}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 956 final loss: -0.00034982\n",
      "Trial 957:\n",
      "  Learning Rate: 0.005666714826798747\n",
      "  Sigma Multiplier: 1.0114170927651873\n",
      "  Initialization Multiplier: 0.5671525275599781\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.10it/s, loss=-0.000387, elapsed time=0.06, total time=9.54]\n",
      "[I 2025-06-07 15:41:09,006] Trial 957 finished with value: -0.00038737956849639355 and parameters: {'learning_rate': 0.005666714826798747, 'sigma_multiplier': 1.0114170927651873, 'num_layers': 2, 'initialization_multiplier': 0.5671525275599781}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 957 final loss: -0.00038738\n",
      "Trial 958:\n",
      "  Learning Rate: 0.008714650392563666\n",
      "  Sigma Multiplier: 1.0498717613368282\n",
      "  Initialization Multiplier: 0.15865387993426544\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.87it/s, loss=-0.000205, elapsed time=0.05, total time=9.71]\n",
      "[I 2025-06-07 15:41:18,775] Trial 958 finished with value: -0.00020533207750420552 and parameters: {'learning_rate': 0.008714650392563666, 'sigma_multiplier': 1.0498717613368282, 'num_layers': 2, 'initialization_multiplier': 0.15865387993426544}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 958 final loss: -0.00020533\n",
      "Trial 959:\n",
      "  Learning Rate: 0.011162347804194379\n",
      "  Sigma Multiplier: 1.10712873406219\n",
      "  Initialization Multiplier: 0.4389303343624797\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.92it/s, loss=-0.000354, elapsed time=0.07, total time=9.11]\n",
      "[I 2025-06-07 15:41:27,951] Trial 959 finished with value: -0.0003544233048280788 and parameters: {'learning_rate': 0.011162347804194379, 'sigma_multiplier': 1.10712873406219, 'num_layers': 2, 'initialization_multiplier': 0.4389303343624797}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 959 final loss: -0.00035442\n",
      "Trial 960:\n",
      "  Learning Rate: 0.01483490043218006\n",
      "  Sigma Multiplier: 0.9255681164399694\n",
      "  Initialization Multiplier: 0.7071787717452751\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.05it/s, loss=-0.000308, elapsed time=0.06, total time=10.2]\n",
      "[I 2025-06-07 15:41:38,228] Trial 960 finished with value: -0.0003083092048626354 and parameters: {'learning_rate': 0.01483490043218006, 'sigma_multiplier': 0.9255681164399694, 'num_layers': 2, 'initialization_multiplier': 0.7071787717452751}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 960 final loss: -0.00030831\n",
      "Trial 961:\n",
      "  Learning Rate: 0.02333267088050482\n",
      "  Sigma Multiplier: 1.0158618444392917\n",
      "  Initialization Multiplier: 0.6149055061884463\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.82it/s, loss=-0.000182, elapsed time=0.05, total time=9.79]\n",
      "[I 2025-06-07 15:41:48,138] Trial 961 finished with value: -0.00018178461278823237 and parameters: {'learning_rate': 0.02333267088050482, 'sigma_multiplier': 1.0158618444392917, 'num_layers': 2, 'initialization_multiplier': 0.6149055061884463}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 961 final loss: -0.00018178\n",
      "Trial 962:\n",
      "  Learning Rate: 0.007585040071803404\n",
      "  Sigma Multiplier: 1.2028043726547386\n",
      "  Initialization Multiplier: 0.5182800990875237\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.26it/s, loss=-0.000387, elapsed time=0.04, total time=8.98]\n",
      "[I 2025-06-07 15:41:57,172] Trial 962 finished with value: -0.0003868799282252299 and parameters: {'learning_rate': 0.007585040071803404, 'sigma_multiplier': 1.2028043726547386, 'num_layers': 2, 'initialization_multiplier': 0.5182800990875237}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 962 final loss: -0.00038688\n",
      "Trial 963:\n",
      "  Learning Rate: 0.00984393877666644\n",
      "  Sigma Multiplier: 0.9647488945852623\n",
      "  Initialization Multiplier: 0.5526901188182229\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.16it/s, loss=-0.000398, elapsed time=0.06, total time=9.58]\n",
      "[I 2025-06-07 15:42:06,814] Trial 963 finished with value: -0.00039824336090687297 and parameters: {'learning_rate': 0.00984393877666644, 'sigma_multiplier': 0.9647488945852623, 'num_layers': 2, 'initialization_multiplier': 0.5526901188182229}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 963 final loss: -0.00039824\n",
      "Trial 964:\n",
      "  Learning Rate: 0.011876307282291193\n",
      "  Sigma Multiplier: 1.0716532020492702\n",
      "  Initialization Multiplier: 1.403894940387699\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.19it/s, loss=-0.000212, elapsed time=0.04, total time=9.58]\n",
      "[I 2025-06-07 15:42:16,459] Trial 964 finished with value: -0.000211691822203972 and parameters: {'learning_rate': 0.011876307282291193, 'sigma_multiplier': 1.0716532020492702, 'num_layers': 2, 'initialization_multiplier': 1.403894940387699}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 964 final loss: -0.00021169\n",
      "Trial 965:\n",
      "  Learning Rate: 0.0068967560834984655\n",
      "  Sigma Multiplier: 0.995627239857176\n",
      "  Initialization Multiplier: 0.6513062495075763\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.92it/s, loss=-0.000410, elapsed time=0.05, total time=9.74]\n",
      "[I 2025-06-07 15:42:26,256] Trial 965 finished with value: -0.0004097679286125485 and parameters: {'learning_rate': 0.0068967560834984655, 'sigma_multiplier': 0.995627239857176, 'num_layers': 2, 'initialization_multiplier': 0.6513062495075763}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 965 final loss: -0.00040977\n",
      "Trial 966:\n",
      "  Learning Rate: 0.019632148720670765\n",
      "  Sigma Multiplier: 1.1371146528551124\n",
      "  Initialization Multiplier: 0.4656951524219086\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.02it/s, loss=-0.000368, elapsed time=0.05, total time=9.09]\n",
      "[I 2025-06-07 15:42:35,405] Trial 966 finished with value: -0.00036778910967494516 and parameters: {'learning_rate': 0.019632148720670765, 'sigma_multiplier': 1.1371146528551124, 'num_layers': 2, 'initialization_multiplier': 0.4656951524219086}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 966 final loss: -0.00036779\n",
      "Trial 967:\n",
      "  Learning Rate: 0.008835329162678918\n",
      "  Sigma Multiplier: 1.0384654030773899\n",
      "  Initialization Multiplier: 0.5851912891382413\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.71it/s, loss=-0.000467, elapsed time=0.04, total time=9.26]\n",
      "[I 2025-06-07 15:42:44,725] Trial 967 finished with value: -0.0004667630646655456 and parameters: {'learning_rate': 0.008835329162678918, 'sigma_multiplier': 1.0384654030773899, 'num_layers': 2, 'initialization_multiplier': 0.5851912891382413}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 967 final loss: -0.00046676\n",
      "Trial 968:\n",
      "  Learning Rate: 0.007683588709335489\n",
      "  Sigma Multiplier: 0.9591762058823726\n",
      "  Initialization Multiplier: 0.6101157402277106\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.90it/s, loss=-0.000275, elapsed time=0.06, total time=9.75]\n",
      "[I 2025-06-07 15:42:54,537] Trial 968 finished with value: -0.00027455577525511976 and parameters: {'learning_rate': 0.007683588709335489, 'sigma_multiplier': 0.9591762058823726, 'num_layers': 2, 'initialization_multiplier': 0.6101157402277106}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 968 final loss: -0.00027456\n",
      "Trial 969:\n",
      "  Learning Rate: 0.008662577655818245\n",
      "  Sigma Multiplier: 1.0325364099997092\n",
      "  Initialization Multiplier: 0.6656659056653977\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.16it/s, loss=-0.000429, elapsed time=0.04, total time=9.59]\n",
      "[I 2025-06-07 15:43:04,199] Trial 969 finished with value: -0.00042874007451961806 and parameters: {'learning_rate': 0.008662577655818245, 'sigma_multiplier': 1.0325364099997092, 'num_layers': 2, 'initialization_multiplier': 0.6656659056653977}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 969 final loss: -0.00042874\n",
      "Trial 970:\n",
      "  Learning Rate: 0.006465028186559955\n",
      "  Sigma Multiplier: 0.8965082880163318\n",
      "  Initialization Multiplier: 0.5903639272403488\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.90it/s, loss=-0.000355, elapsed time=0.05, total time=9.66]\n",
      "[I 2025-06-07 15:43:13,916] Trial 970 finished with value: -0.0003547006745513932 and parameters: {'learning_rate': 0.006465028186559955, 'sigma_multiplier': 0.8965082880163318, 'num_layers': 2, 'initialization_multiplier': 0.5903639272403488}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 970 final loss: -0.00035470\n",
      "Trial 971:\n",
      "  Learning Rate: 0.009007040480783476\n",
      "  Sigma Multiplier: 0.9858401262236977\n",
      "  Initialization Multiplier: 0.6368639029493617\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.14it/s, loss=-0.000359, elapsed time=0.06, total time=9.58]\n",
      "[I 2025-06-07 15:43:23,560] Trial 971 finished with value: -0.0003587925452527878 and parameters: {'learning_rate': 0.009007040480783476, 'sigma_multiplier': 0.9858401262236977, 'num_layers': 2, 'initialization_multiplier': 0.6368639029493617}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 971 final loss: -0.00035879\n",
      "Trial 972:\n",
      "  Learning Rate: 0.005600401249061966\n",
      "  Sigma Multiplier: 0.8117284586606787\n",
      "  Initialization Multiplier: 0.5792802967024884\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.48it/s, loss=-0.000297, elapsed time=0.06, total time=10]  \n",
      "[I 2025-06-07 15:43:33,634] Trial 972 finished with value: -0.0002973446536005685 and parameters: {'learning_rate': 0.005600401249061966, 'sigma_multiplier': 0.8117284586606787, 'num_layers': 2, 'initialization_multiplier': 0.5792802967024884}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 972 final loss: -0.00029734\n",
      "Trial 973:\n",
      "  Learning Rate: 0.007393278582469441\n",
      "  Sigma Multiplier: 0.9260875126651358\n",
      "  Initialization Multiplier: 0.6933715068516902\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.66it/s, loss=-0.000257, elapsed time=0.05, total time=9.85]\n",
      "[I 2025-06-07 15:43:43,539] Trial 973 finished with value: -0.00025734809984033426 and parameters: {'learning_rate': 0.007393278582469441, 'sigma_multiplier': 0.9260875126651358, 'num_layers': 2, 'initialization_multiplier': 0.6933715068516902}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 973 final loss: -0.00025735\n",
      "Trial 974:\n",
      "  Learning Rate: 0.00982336299736804\n",
      "  Sigma Multiplier: 1.0230224726307975\n",
      "  Initialization Multiplier: 0.6247303892792383\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.22it/s, loss=-0.000371, elapsed time=0.07, total time=9.49]\n",
      "[I 2025-06-07 15:43:53,090] Trial 974 finished with value: -0.0003710526272834612 and parameters: {'learning_rate': 0.00982336299736804, 'sigma_multiplier': 1.0230224726307975, 'num_layers': 2, 'initialization_multiplier': 0.6247303892792383}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 974 final loss: -0.00037105\n",
      "Trial 975:\n",
      "  Learning Rate: 0.008374151393007245\n",
      "  Sigma Multiplier: 0.9664992710786987\n",
      "  Initialization Multiplier: 0.5704909150980324\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.02it/s, loss=-0.000308, elapsed time=0.05, total time=9.66]\n",
      "[I 2025-06-07 15:44:02,811] Trial 975 finished with value: -0.0003083430137396861 and parameters: {'learning_rate': 0.008374151393007245, 'sigma_multiplier': 0.9664992710786987, 'num_layers': 2, 'initialization_multiplier': 0.5704909150980324}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 975 final loss: -0.00030834\n",
      "Trial 976:\n",
      "  Learning Rate: 0.006615148036069185\n",
      "  Sigma Multiplier: 1.0049041459620354\n",
      "  Initialization Multiplier: 0.5976948099414148\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.68it/s, loss=-0.000463, elapsed time=0.06, total time=9.91]\n",
      "[I 2025-06-07 15:44:12,792] Trial 976 finished with value: -0.0004632974191307725 and parameters: {'learning_rate': 0.006615148036069185, 'sigma_multiplier': 1.0049041459620354, 'num_layers': 2, 'initialization_multiplier': 0.5976948099414148}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 976 final loss: -0.00046330\n",
      "Trial 977:\n",
      "  Learning Rate: 0.004905889748881154\n",
      "  Sigma Multiplier: 0.9372448668085999\n",
      "  Initialization Multiplier: 0.66562842314024\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.83it/s, loss=-0.000346, elapsed time=0.05, total time=9.75]\n",
      "[I 2025-06-07 15:44:22,603] Trial 977 finished with value: -0.00034625457329405697 and parameters: {'learning_rate': 0.004905889748881154, 'sigma_multiplier': 0.9372448668085999, 'num_layers': 2, 'initialization_multiplier': 0.66562842314024}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 977 final loss: -0.00034625\n",
      "Trial 978:\n",
      "  Learning Rate: 0.005402026130885621\n",
      "  Sigma Multiplier: 0.9929862892631617\n",
      "  Initialization Multiplier: 0.6169266607304988\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.72it/s, loss=-0.000431, elapsed time=0.07, total time=9.81]\n",
      "[I 2025-06-07 15:44:32,471] Trial 978 finished with value: -0.0004312095456862956 and parameters: {'learning_rate': 0.005402026130885621, 'sigma_multiplier': 0.9929862892631617, 'num_layers': 2, 'initialization_multiplier': 0.6169266607304988}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 978 final loss: -0.00043121\n",
      "Trial 979:\n",
      "  Learning Rate: 0.00612681727760583\n",
      "  Sigma Multiplier: 0.9677789456812217\n",
      "  Initialization Multiplier: 0.5585829700908691\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.97it/s, loss=-0.000346, elapsed time=0.05, total time=9.65]\n",
      "[I 2025-06-07 15:44:42,169] Trial 979 finished with value: -0.0003461382622802457 and parameters: {'learning_rate': 0.00612681727760583, 'sigma_multiplier': 0.9677789456812217, 'num_layers': 2, 'initialization_multiplier': 0.5585829700908691}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 979 final loss: -0.00034614\n",
      "Trial 980:\n",
      "  Learning Rate: 0.0059880079563173145\n",
      "  Sigma Multiplier: 0.9257089347235798\n",
      "  Initialization Multiplier: 0.637474868309978\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:13<00:00, 10.96it/s, loss=-0.000243, elapsed time=0.08, total time=14]  \n",
      "[I 2025-06-07 15:44:56,263] Trial 980 finished with value: -0.00024345381618111263 and parameters: {'learning_rate': 0.0059880079563173145, 'sigma_multiplier': 0.9257089347235798, 'num_layers': 2, 'initialization_multiplier': 0.637474868309978}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 980 final loss: -0.00024345\n",
      "Trial 981:\n",
      "  Learning Rate: 0.004295028034625137\n",
      "  Sigma Multiplier: 0.9984686555219818\n",
      "  Initialization Multiplier: 0.5883155579965132\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.16it/s, loss=-0.000386, elapsed time=0.04, total time=9.57]\n",
      "[I 2025-06-07 15:45:05,910] Trial 981 finished with value: -0.0003857876241830675 and parameters: {'learning_rate': 0.004295028034625137, 'sigma_multiplier': 0.9984686555219818, 'num_layers': 2, 'initialization_multiplier': 0.5883155579965132}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 981 final loss: -0.00038579\n",
      "Trial 982:\n",
      "  Learning Rate: 0.006678590836042641\n",
      "  Sigma Multiplier: 0.8683355266676767\n",
      "  Initialization Multiplier: 0.6937049033019124\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.24it/s, loss=-0.000222, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 15:45:16,111] Trial 982 finished with value: -0.00022240997948880315 and parameters: {'learning_rate': 0.006678590836042641, 'sigma_multiplier': 0.8683355266676767, 'num_layers': 2, 'initialization_multiplier': 0.6937049033019124}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 982 final loss: -0.00022241\n",
      "Trial 983:\n",
      "  Learning Rate: 0.005306362858751222\n",
      "  Sigma Multiplier: 0.9586590934979102\n",
      "  Initialization Multiplier: 0.5340397710237585\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.69it/s, loss=-0.000309, elapsed time=0.05, total time=9.82]\n",
      "[I 2025-06-07 15:45:25,991] Trial 983 finished with value: -0.00030912752068786367 and parameters: {'learning_rate': 0.005306362858751222, 'sigma_multiplier': 0.9586590934979102, 'num_layers': 2, 'initialization_multiplier': 0.5340397710237585}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 983 final loss: -0.00030913\n",
      "Trial 984:\n",
      "  Learning Rate: 0.007368721717467708\n",
      "  Sigma Multiplier: 1.027807810411579\n",
      "  Initialization Multiplier: 0.6090648266352094\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.10it/s, loss=-0.000474, elapsed time=0.05, total time=9]   \n",
      "[I 2025-06-07 15:45:35,045] Trial 984 finished with value: -0.0004736571262072813 and parameters: {'learning_rate': 0.007368721717467708, 'sigma_multiplier': 1.027807810411579, 'num_layers': 2, 'initialization_multiplier': 0.6090648266352094}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 984 final loss: -0.00047366\n",
      "Trial 985:\n",
      "  Learning Rate: 0.006030849509432131\n",
      "  Sigma Multiplier: 1.0333976070981423\n",
      "  Initialization Multiplier: 0.6643601243305577\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.24it/s, loss=-0.000302, elapsed time=0.06, total time=8.97]\n",
      "[I 2025-06-07 15:45:44,082] Trial 985 finished with value: -0.0003024229838217218 and parameters: {'learning_rate': 0.006030849509432131, 'sigma_multiplier': 1.0333976070981423, 'num_layers': 2, 'initialization_multiplier': 0.6643601243305577}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 985 final loss: -0.00030242\n",
      "Trial 986:\n",
      "  Learning Rate: 0.006836542785672479\n",
      "  Sigma Multiplier: 1.0398492489134923\n",
      "  Initialization Multiplier: 0.7414882934138918\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.06it/s, loss=-0.000111, elapsed time=0.06, total time=9.63]\n",
      "[I 2025-06-07 15:45:53,768] Trial 986 finished with value: -0.0001113720052846334 and parameters: {'learning_rate': 0.006836542785672479, 'sigma_multiplier': 1.0398492489134923, 'num_layers': 2, 'initialization_multiplier': 0.7414882934138918}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 986 final loss: -0.00011137\n",
      "Trial 987:\n",
      "  Learning Rate: 0.0049149483539041245\n",
      "  Sigma Multiplier: 1.0095321074421495\n",
      "  Initialization Multiplier: 0.632813878128251\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.17it/s, loss=-0.000384, elapsed time=0.07, total time=9.54]\n",
      "[I 2025-06-07 15:46:03,385] Trial 987 finished with value: -0.00038406111521000565 and parameters: {'learning_rate': 0.0049149483539041245, 'sigma_multiplier': 1.0095321074421495, 'num_layers': 2, 'initialization_multiplier': 0.632813878128251}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 987 final loss: -0.00038406\n",
      "Trial 988:\n",
      "  Learning Rate: 0.006317600864127386\n",
      "  Sigma Multiplier: 1.0473107050096218\n",
      "  Initialization Multiplier: 0.686961500358222\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.98it/s, loss=-0.000417, elapsed time=0.07, total time=9.66]\n",
      "[I 2025-06-07 15:46:13,134] Trial 988 finished with value: -0.0004170177566190985 and parameters: {'learning_rate': 0.006317600864127386, 'sigma_multiplier': 1.0473107050096218, 'num_layers': 2, 'initialization_multiplier': 0.686961500358222}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 988 final loss: -0.00041702\n",
      "Trial 989:\n",
      "  Learning Rate: 0.00720715090403372\n",
      "  Sigma Multiplier: 1.0066833323088196\n",
      "  Initialization Multiplier: 0.723162873222938\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.03it/s, loss=-0.000394, elapsed time=0.05, total time=9.65]\n",
      "[I 2025-06-07 15:46:22,847] Trial 989 finished with value: -0.0003937622152473024 and parameters: {'learning_rate': 0.00720715090403372, 'sigma_multiplier': 1.0066833323088196, 'num_layers': 2, 'initialization_multiplier': 0.723162873222938}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 989 final loss: -0.00039376\n",
      "Trial 990:\n",
      "  Learning Rate: 0.004322611828992662\n",
      "  Sigma Multiplier: 1.0498607010789582\n",
      "  Initialization Multiplier: 0.6404768141396155\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.92it/s, loss=-0.000293, elapsed time=0.05, total time=9.7] \n",
      "[I 2025-06-07 15:46:32,603] Trial 990 finished with value: -0.0002930881307424643 and parameters: {'learning_rate': 0.004322611828992662, 'sigma_multiplier': 1.0498607010789582, 'num_layers': 2, 'initialization_multiplier': 0.6404768141396155}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 990 final loss: -0.00029309\n",
      "Trial 991:\n",
      "  Learning Rate: 0.003138696537243557\n",
      "  Sigma Multiplier: 0.9990997804502083\n",
      "  Initialization Multiplier: 0.602711231133788\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.11it/s, loss=-0.000325, elapsed time=0.04, total time=8.58]\n",
      "[I 2025-06-07 15:46:41,248] Trial 991 finished with value: -0.0003246842442475048 and parameters: {'learning_rate': 0.003138696537243557, 'sigma_multiplier': 0.9990997804502083, 'num_layers': 2, 'initialization_multiplier': 0.602711231133788}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 991 final loss: -0.00032468\n",
      "Trial 992:\n",
      "  Learning Rate: 0.005583274089707817\n",
      "  Sigma Multiplier: 0.9543569941129825\n",
      "  Initialization Multiplier: 1.035056100469835\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.73it/s, loss=0.000601, elapsed time=0.04, total time=8.27]\n",
      "[I 2025-06-07 15:46:49,587] Trial 992 finished with value: 0.0006013461737401668 and parameters: {'learning_rate': 0.005583274089707817, 'sigma_multiplier': 0.9543569941129825, 'num_layers': 2, 'initialization_multiplier': 1.035056100469835}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 992 final loss: 0.00060135\n",
      "Trial 993:\n",
      "  Learning Rate: 0.007404304781391532\n",
      "  Sigma Multiplier: 1.0272130155380497\n",
      "  Initialization Multiplier: 0.5968185599110258\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.12it/s, loss=-0.000366, elapsed time=0.04, total time=8.25]\n",
      "[I 2025-06-07 15:46:57,945] Trial 993 finished with value: -0.0003664970706170483 and parameters: {'learning_rate': 0.007404304781391532, 'sigma_multiplier': 1.0272130155380497, 'num_layers': 2, 'initialization_multiplier': 0.5968185599110258}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 993 final loss: -0.00036650\n",
      "Trial 994:\n",
      "  Learning Rate: 0.006468855759732768\n",
      "  Sigma Multiplier: 1.0654710628988562\n",
      "  Initialization Multiplier: 0.658159387836087\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.28it/s, loss=-0.000379, elapsed time=0.05, total time=8.64]\n",
      "[I 2025-06-07 15:47:06,824] Trial 994 finished with value: -0.0003785112473632533 and parameters: {'learning_rate': 0.006468855759732768, 'sigma_multiplier': 1.0654710628988562, 'num_layers': 2, 'initialization_multiplier': 0.658159387836087}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 994 final loss: -0.00037851\n",
      "Trial 995:\n",
      "  Learning Rate: 0.005398190925630912\n",
      "  Sigma Multiplier: 0.9016917897387358\n",
      "  Initialization Multiplier: 0.6166130228038761\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.46it/s, loss=-0.000269, elapsed time=0.05, total time=10.1]\n",
      "[I 2025-06-07 15:47:17,122] Trial 995 finished with value: -0.0002694635615636314 and parameters: {'learning_rate': 0.005398190925630912, 'sigma_multiplier': 0.9016917897387358, 'num_layers': 2, 'initialization_multiplier': 0.6166130228038761}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 995 final loss: -0.00026946\n",
      "Trial 996:\n",
      "  Learning Rate: 0.007732462385378712\n",
      "  Sigma Multiplier: 0.9816834432590008\n",
      "  Initialization Multiplier: 0.5703732296822861\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.41it/s, loss=-0.000278, elapsed time=0.05, total time=9.4] \n",
      "[I 2025-06-07 15:47:26,579] Trial 996 finished with value: -0.0002782105569957163 and parameters: {'learning_rate': 0.007732462385378712, 'sigma_multiplier': 0.9816834432590008, 'num_layers': 2, 'initialization_multiplier': 0.5703732296822861}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 996 final loss: -0.00027821\n",
      "Trial 997:\n",
      "  Learning Rate: 0.006829369172147538\n",
      "  Sigma Multiplier: 1.0252400901128047\n",
      "  Initialization Multiplier: 0.6126278526509031\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.04it/s, loss=-0.000382, elapsed time=0.05, total time=9.03]\n",
      "[I 2025-06-07 15:47:35,668] Trial 997 finished with value: -0.0003821121324590795 and parameters: {'learning_rate': 0.006829369172147538, 'sigma_multiplier': 1.0252400901128047, 'num_layers': 2, 'initialization_multiplier': 0.6126278526509031}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 997 final loss: -0.00038211\n",
      "Trial 998:\n",
      "  Learning Rate: 0.0037553398241162773\n",
      "  Sigma Multiplier: 0.9667225575577277\n",
      "  Initialization Multiplier: 0.6707339856105733\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:14<00:00, 10.27it/s, loss=-0.000012, elapsed time=0.1, total time=14.9] \n",
      "[I 2025-06-07 15:47:50,607] Trial 998 finished with value: -1.225031571757472e-05 and parameters: {'learning_rate': 0.0037553398241162773, 'sigma_multiplier': 0.9667225575577277, 'num_layers': 5, 'initialization_multiplier': 0.6707339856105733}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 998 final loss: -0.00001225\n",
      "Trial 999:\n",
      "  Learning Rate: 0.008082341164931207\n",
      "  Sigma Multiplier: 1.0567413158765422\n",
      "  Initialization Multiplier: 0.5627801212154002\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.54it/s, loss=-0.000476, elapsed time=0.05, total time=9.37]\n",
      "[I 2025-06-07 15:48:00,041] Trial 999 finished with value: -0.00047559306693846395 and parameters: {'learning_rate': 0.008082341164931207, 'sigma_multiplier': 1.0567413158765422, 'num_layers': 2, 'initialization_multiplier': 0.5627801212154002}. Best is trial 248 with value: -0.00048807768206494604.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 999 final loss: -0.00047559\n"
     ]
    }
   ],
   "source": [
    "study = run_hpo(\n",
    "    grid_conn,\n",
    "    QUBITS,\n",
    "    base_sigma,\n",
    "    train_ds = train_ds,\n",
    "    n_trials = 1000,\n",
    "    n_iters_hpo = 150,\n",
    "    n_ops = 2000,\n",
    "    n_samples = 2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Best hyperparameters found: {'learning_rate': 0.006115521401940773, 'sigma_multiplier': 1.0372657813112909, 'num_layers': 2, 'initialization_multiplier': 0.6303388864180629}\n",
      "Best loss value: -0.00048807768206494604\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = study.best_params\n",
    "best_loss_value = study.best_value\n",
    "\n",
    "print(\"\\nOptimization Finished!\")\n",
    "print(f\"Best hyperparameters found: {best_hyperparams}\")\n",
    "print(f\"Best loss value: {best_loss_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = best_hyperparams['learning_rate']\n",
    "SIGMA_M = best_hyperparams['sigma_multiplier']\n",
    "NUM_LAYERS = best_hyperparams['num_layers']\n",
    "INIT_M = best_hyperparams['initialization_multiplier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_dataset(dataset=train_ds):\n",
    "    grid_conn= aachen_connectivity()\n",
    "    num_qubits = NODES * (NODES - 1) // 2\n",
    "    gates = efficient_connectivity_gates(grid_conn, num_qubits, NUM_LAYERS)\n",
    "    \n",
    "    circuit = iqp.IqpSimulator(num_qubits, gates, device=\"lightning.qubit\")\n",
    "    \n",
    "    initial_params = initialize_from_data(gates, dataset) * INIT_M\n",
    "    loss = iqp.gen_qml.mmd_loss_iqp\n",
    "    learning_rate = LR\n",
    "    sigma = median_heuristic(dataset) * SIGMA_M\n",
    "    \n",
    "    loss_kwarg = {\n",
    "        \"params\": initial_params,\n",
    "        \"iqp_circuit\": circuit,\n",
    "        \"ground_truth\": dataset,\n",
    "        \"sigma\": [sigma],\n",
    "        \"n_ops\": 2000,\n",
    "        \"n_samples\": 2000,\n",
    "        \"key\": jax.random.PRNGKey(42),\n",
    "    }\n",
    "    \n",
    "    trainer = iqp.Trainer(\"Adam\", loss, stepsize=learning_rate)\n",
    "    trainer.train(n_iters= 2000,loss_kwargs=loss_kwarg, turbo=1)\n",
    "    \n",
    "    return trainer.final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 2000/2000 [02:15<00:00, 14.73it/s, loss=-0.000344, elapsed time=0.04, total time=136] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 2000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = train_on_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'./results/params/params_{NODES}N_{TYPE}_{CONN}_LR{LR}_SIGMA{SIGMA_M}_INIT{INIT_M}_NUMLAYERS{NUM_LAYERS}.npy', params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
