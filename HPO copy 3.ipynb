{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iqpopt as iqp\n",
    "from iqpopt.utils import initialize_from_data, local_gates\n",
    "import iqpopt.gen_qml as genq\n",
    "from iqpopt.gen_qml.utils import median_heuristic\n",
    "import optuna\n",
    "import pennylane as qml\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from utils.nisq import aachen_connectivity, efficient_connectivity_gates\n",
    "from datasets.bipartites import BipartiteGraphDataset\n",
    "from datasets.er import ErdosRenyiGraphDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 8\n",
    "TYPE = \"Bipartite\"\n",
    "CONN = \"Dense\"\n",
    "NUM_LAYERS = 1\n",
    "QUBITS = NODES * (NODES - 1) //2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset] Loaded 261 samples from ./datasets/raw_data/8N_Bipartite_Dense.pkl\n",
      "  Created: 2025-05-30T13:15:24.181251\n",
      "  Unique graphs: 261\n",
      "  Version: 1.0\n"
     ]
    }
   ],
   "source": [
    "ds_path = f'./datasets/raw_data/{NODES}N_{TYPE}_{CONN}.pkl'\n",
    "train_ds = jnp.array(BipartiteGraphDataset(nodes = 1, edge_prob=0.1).from_file(ds_path).vectors.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_conn = aachen_connectivity()\n",
    "gates = efficient_connectivity_gates(grid_conn, QUBITS, 1) \n",
    "circ = iqp.IqpSimulator(QUBITS, gates, device='lightning.qubit')\n",
    "\n",
    "base_key = jax.random.PRNGKey(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_sigma = median_heuristic(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.hpo import run_hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-07 22:03:35,056] A new study created in memory with name: no-name-caceac5a-f838-43aa-ac74-167e4a12b958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0:\n",
      "  Learning Rate: 0.00020920610965706498\n",
      "  Sigma Multiplier: 0.9267376474182981\n",
      "  Initialization Multiplier: 0.13506239907877726\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.59it/s, loss=0.114332, elapsed time=0.02, total time=12.1]\n",
      "[I 2025-06-07 22:03:47,872] Trial 0 finished with value: 0.11433172891666163 and parameters: {'learning_rate': 0.00020920610965706498, 'sigma_multiplier': 0.9267376474182981, 'num_layers': 3, 'initialization_multiplier': 0.13506239907877726}. Best is trial 0 with value: 0.11433172891666163.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 0 final loss: 0.11433173\n",
      "Trial 1:\n",
      "  Learning Rate: 7.51420071708812e-05\n",
      "  Sigma Multiplier: 1.5294635965663048\n",
      "  Initialization Multiplier: 1.1435756946141078\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.12it/s, loss=0.018020, elapsed time=0.02, total time=5.85]\n",
      "[I 2025-06-07 22:03:53,736] Trial 1 finished with value: 0.018020203110270947 and parameters: {'learning_rate': 7.51420071708812e-05, 'sigma_multiplier': 1.5294635965663048, 'num_layers': 1, 'initialization_multiplier': 1.1435756946141078}. Best is trial 1 with value: 0.018020203110270947.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 1 final loss: 0.01802020\n",
      "Trial 2:\n",
      "  Learning Rate: 0.04000568971210246\n",
      "  Sigma Multiplier: 0.5381078045165725\n",
      "  Initialization Multiplier: 1.370773077704032\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 16.07it/s, loss=0.004363, elapsed time=0.05, total time=9.62]\n",
      "[I 2025-06-07 22:04:03,383] Trial 2 finished with value: 0.004363404669375494 and parameters: {'learning_rate': 0.04000568971210246, 'sigma_multiplier': 0.5381078045165725, 'num_layers': 4, 'initialization_multiplier': 1.370773077704032}. Best is trial 2 with value: 0.004363404669375494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 2 final loss: 0.00436340\n",
      "Trial 3:\n",
      "  Learning Rate: 0.00514086401122043\n",
      "  Sigma Multiplier: 0.9925262129312334\n",
      "  Initialization Multiplier: 0.7739460491380102\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.24it/s, loss=0.000369, elapsed time=0.04, total time=7.67]\n",
      "[I 2025-06-07 22:04:11,081] Trial 3 finished with value: 0.0003688149532599076 and parameters: {'learning_rate': 0.00514086401122043, 'sigma_multiplier': 0.9925262129312334, 'num_layers': 4, 'initialization_multiplier': 0.7739460491380102}. Best is trial 3 with value: 0.0003688149532599076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 3 final loss: 0.00036881\n",
      "Trial 4:\n",
      "  Learning Rate: 0.011160144371724835\n",
      "  Sigma Multiplier: 0.822162679134401\n",
      "  Initialization Multiplier: 0.9507635805228539\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.42it/s, loss=0.002079, elapsed time=0.04, total time=7.97]\n",
      "[I 2025-06-07 22:04:19,084] Trial 4 finished with value: 0.002078611101040876 and parameters: {'learning_rate': 0.011160144371724835, 'sigma_multiplier': 0.822162679134401, 'num_layers': 4, 'initialization_multiplier': 0.9507635805228539}. Best is trial 3 with value: 0.0003688149532599076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 4 final loss: 0.00207861\n",
      "Trial 5:\n",
      "  Learning Rate: 0.0002975799938363662\n",
      "  Sigma Multiplier: 1.081358768696012\n",
      "  Initialization Multiplier: 1.9160880901419215\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.18it/s, loss=0.038761, elapsed time=0.05, total time=7.66]\n",
      "[I 2025-06-07 22:04:26,780] Trial 5 finished with value: 0.0387611396634556 and parameters: {'learning_rate': 0.0002975799938363662, 'sigma_multiplier': 1.081358768696012, 'num_layers': 4, 'initialization_multiplier': 1.9160880901419215}. Best is trial 3 with value: 0.0003688149532599076.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 5 final loss: 0.03876114\n",
      "Trial 6:\n",
      "  Learning Rate: 0.012629329881867102\n",
      "  Sigma Multiplier: 1.838514082887099\n",
      "  Initialization Multiplier: 1.7939158083987674\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.71it/s, loss=-0.000336, elapsed time=0.03, total time=5.66]\n",
      "[I 2025-06-07 22:04:32,463] Trial 6 finished with value: -0.0003361187228255863 and parameters: {'learning_rate': 0.012629329881867102, 'sigma_multiplier': 1.838514082887099, 'num_layers': 2, 'initialization_multiplier': 1.7939158083987674}. Best is trial 6 with value: -0.0003361187228255863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 6 final loss: -0.00033612\n",
      "Trial 7:\n",
      "  Learning Rate: 0.001319043412210596\n",
      "  Sigma Multiplier: 0.42277540425098276\n",
      "  Initialization Multiplier: 1.3478970500431473\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.30it/s, loss=0.006207, elapsed time=0.05, total time=10.7]\n",
      "[I 2025-06-07 22:04:43,244] Trial 7 finished with value: 0.006206554550001129 and parameters: {'learning_rate': 0.001319043412210596, 'sigma_multiplier': 0.42277540425098276, 'num_layers': 5, 'initialization_multiplier': 1.3478970500431473}. Best is trial 6 with value: -0.0003361187228255863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 7 final loss: 0.00620655\n",
      "Trial 8:\n",
      "  Learning Rate: 0.0012507092089153599\n",
      "  Sigma Multiplier: 1.3600556657259646\n",
      "  Initialization Multiplier: 0.9640975915951372\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.43it/s, loss=0.011949, elapsed time=0.04, total time=5.93]\n",
      "[I 2025-06-07 22:04:49,191] Trial 8 finished with value: 0.011948768373695495 and parameters: {'learning_rate': 0.0012507092089153599, 'sigma_multiplier': 1.3600556657259646, 'num_layers': 2, 'initialization_multiplier': 0.9640975915951372}. Best is trial 6 with value: -0.0003361187228255863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 8 final loss: 0.01194877\n",
      "Trial 9:\n",
      "  Learning Rate: 0.022958211202527706\n",
      "  Sigma Multiplier: 0.9544882658995565\n",
      "  Initialization Multiplier: 0.12086150898256745\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.62it/s, loss=0.000648, elapsed time=0.04, total time=8.32]\n",
      "[I 2025-06-07 22:04:57,541] Trial 9 finished with value: 0.0006483842793655133 and parameters: {'learning_rate': 0.022958211202527706, 'sigma_multiplier': 0.9544882658995565, 'num_layers': 3, 'initialization_multiplier': 0.12086150898256745}. Best is trial 6 with value: -0.0003361187228255863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 9 final loss: 0.00064838\n",
      "Trial 10:\n",
      "  Learning Rate: 0.06891118461271599\n",
      "  Sigma Multiplier: 1.9507511093848413\n",
      "  Initialization Multiplier: 1.9389297331725006\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.03it/s, loss=-0.000290, elapsed time=0.04, total time=6.03]\n",
      "[I 2025-06-07 22:05:03,659] Trial 10 finished with value: -0.00029012639934173024 and parameters: {'learning_rate': 0.06891118461271599, 'sigma_multiplier': 1.9507511093848413, 'num_layers': 1, 'initialization_multiplier': 1.9389297331725006}. Best is trial 6 with value: -0.0003361187228255863.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 10 final loss: -0.00029013\n",
      "Trial 11:\n",
      "  Learning Rate: 0.09387375438851604\n",
      "  Sigma Multiplier: 1.9516127656581836\n",
      "  Initialization Multiplier: 1.9806914385831318\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.44it/s, loss=-0.000346, elapsed time=0.05, total time=6.41]\n",
      "[I 2025-06-07 22:05:10,095] Trial 11 finished with value: -0.00034612709592001466 and parameters: {'learning_rate': 0.09387375438851604, 'sigma_multiplier': 1.9516127656581836, 'num_layers': 1, 'initialization_multiplier': 1.9806914385831318}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 11 final loss: -0.00034613\n",
      "Trial 12:\n",
      "  Learning Rate: 0.09785240191603475\n",
      "  Sigma Multiplier: 1.997662075570952\n",
      "  Initialization Multiplier: 1.639503865034247\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.30it/s, loss=-0.000133, elapsed time=0.04, total time=8.03]\n",
      "[I 2025-06-07 22:05:18,158] Trial 12 finished with value: -0.0001334364690882209 and parameters: {'learning_rate': 0.09785240191603475, 'sigma_multiplier': 1.997662075570952, 'num_layers': 2, 'initialization_multiplier': 1.639503865034247}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 12 final loss: -0.00013344\n",
      "Trial 13:\n",
      "  Learning Rate: 0.005526835486367488\n",
      "  Sigma Multiplier: 1.698407230447402\n",
      "  Initialization Multiplier: 1.6603271041292278\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.68it/s, loss=0.002302, elapsed time=0.03, total time=7.52]\n",
      "[I 2025-06-07 22:05:25,713] Trial 13 finished with value: 0.002302252379908779 and parameters: {'learning_rate': 0.005526835486367488, 'sigma_multiplier': 1.698407230447402, 'num_layers': 2, 'initialization_multiplier': 1.6603271041292278}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 13 final loss: 0.00230225\n",
      "Trial 14:\n",
      "  Learning Rate: 0.014849750345100034\n",
      "  Sigma Multiplier: 1.6899694913332264\n",
      "  Initialization Multiplier: 1.9926703102046042\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:04<00:00, 32.76it/s, loss=-0.000120, elapsed time=0.05, total time=4.81]\n",
      "[I 2025-06-07 22:05:30,542] Trial 14 finished with value: -0.00012033992403754947 and parameters: {'learning_rate': 0.014849750345100034, 'sigma_multiplier': 1.6899694913332264, 'num_layers': 1, 'initialization_multiplier': 1.9926703102046042}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 14 final loss: -0.00012034\n",
      "Trial 15:\n",
      "  Learning Rate: 0.0042556613550545335\n",
      "  Sigma Multiplier: 1.3274780419902708\n",
      "  Initialization Multiplier: 1.6561734654175266\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 28.29it/s, loss=0.003316, elapsed time=0.03, total time=5.52]\n",
      "[I 2025-06-07 22:05:36,088] Trial 15 finished with value: 0.0033156504700621622 and parameters: {'learning_rate': 0.0042556613550545335, 'sigma_multiplier': 1.3274780419902708, 'num_layers': 2, 'initialization_multiplier': 1.6561734654175266}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 15 final loss: 0.00331565\n",
      "Trial 16:\n",
      "  Learning Rate: 0.0357986583088428\n",
      "  Sigma Multiplier: 0.1781265177473519\n",
      "  Initialization Multiplier: 0.5496153006997349\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.56it/s, loss=0.000361, elapsed time=0.04, total time=7.89] \n",
      "[I 2025-06-07 22:05:44,008] Trial 16 finished with value: 0.000361493676564525 and parameters: {'learning_rate': 0.0357986583088428, 'sigma_multiplier': 0.1781265177473519, 'num_layers': 1, 'initialization_multiplier': 0.5496153006997349}. Best is trial 11 with value: -0.00034612709592001466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 16 final loss: 0.00036149\n",
      "Trial 17:\n",
      "  Learning Rate: 0.09994731840237957\n",
      "  Sigma Multiplier: 1.7602808486134311\n",
      "  Initialization Multiplier: 1.4332747964443837\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.10it/s, loss=-0.000367, elapsed time=0.03, total time=5.98]\n",
      "[I 2025-06-07 22:05:50,017] Trial 17 finished with value: -0.00036698287928743525 and parameters: {'learning_rate': 0.09994731840237957, 'sigma_multiplier': 1.7602808486134311, 'num_layers': 2, 'initialization_multiplier': 1.4332747964443837}. Best is trial 17 with value: -0.00036698287928743525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 17 final loss: -0.00036698\n",
      "Trial 18:\n",
      "  Learning Rate: 0.0868500559714475\n",
      "  Sigma Multiplier: 1.4619911481613728\n",
      "  Initialization Multiplier: 1.3920218928655408\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 25.95it/s, loss=-0.000145, elapsed time=0.03, total time=6.03]\n",
      "[I 2025-06-07 22:05:56,080] Trial 18 finished with value: -0.00014507790997673155 and parameters: {'learning_rate': 0.0868500559714475, 'sigma_multiplier': 1.4619911481613728, 'num_layers': 1, 'initialization_multiplier': 1.3920218928655408}. Best is trial 17 with value: -0.00036698287928743525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 18 final loss: -0.00014508\n",
      "Trial 19:\n",
      "  Learning Rate: 0.0006366808442579972\n",
      "  Sigma Multiplier: 1.6517161597417962\n",
      "  Initialization Multiplier: 1.520038372576414\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.86it/s, loss=0.007399, elapsed time=0.03, total time=7.44]\n",
      "[I 2025-06-07 22:06:03,564] Trial 19 finished with value: 0.007399377933493516 and parameters: {'learning_rate': 0.0006366808442579972, 'sigma_multiplier': 1.6517161597417962, 'num_layers': 3, 'initialization_multiplier': 1.520038372576414}. Best is trial 17 with value: -0.00036698287928743525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 19 final loss: 0.00739938\n",
      "Trial 20:\n",
      "  Learning Rate: 0.04351901696536566\n",
      "  Sigma Multiplier: 1.22612870624712\n",
      "  Initialization Multiplier: 1.1860780419139454\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.25it/s, loss=-0.000085, elapsed time=0.04, total time=7.05]\n",
      "[I 2025-06-07 22:06:10,649] Trial 20 finished with value: -8.534886554171908e-05 and parameters: {'learning_rate': 0.04351901696536566, 'sigma_multiplier': 1.22612870624712, 'num_layers': 2, 'initialization_multiplier': 1.1860780419139454}. Best is trial 17 with value: -0.00036698287928743525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 20 final loss: -0.00008535\n",
      "Trial 21:\n",
      "  Learning Rate: 0.013620871098161187\n",
      "  Sigma Multiplier: 1.8485217070488034\n",
      "  Initialization Multiplier: 1.7492182754962307\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.40it/s, loss=-0.000096, elapsed time=0.04, total time=7.65]\n",
      "[I 2025-06-07 22:06:18,338] Trial 21 finished with value: -9.621573030069966e-05 and parameters: {'learning_rate': 0.013620871098161187, 'sigma_multiplier': 1.8485217070488034, 'num_layers': 2, 'initialization_multiplier': 1.7492182754962307}. Best is trial 17 with value: -0.00036698287928743525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 21 final loss: -0.00009622\n",
      "Trial 22:\n",
      "  Learning Rate: 0.026359374288530257\n",
      "  Sigma Multiplier: 1.8016854412787044\n",
      "  Initialization Multiplier: 1.8412789371372236\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.14it/s, loss=-0.000454, elapsed time=0.04, total time=7.39]\n",
      "[I 2025-06-07 22:06:25,768] Trial 22 finished with value: -0.0004539468517293779 and parameters: {'learning_rate': 0.026359374288530257, 'sigma_multiplier': 1.8016854412787044, 'num_layers': 2, 'initialization_multiplier': 1.8412789371372236}. Best is trial 22 with value: -0.0004539468517293779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 22 final loss: -0.00045395\n",
      "Trial 23:\n",
      "  Learning Rate: 0.045861767103238374\n",
      "  Sigma Multiplier: 1.80240894184778\n",
      "  Initialization Multiplier: 1.8358221762851235\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.37it/s, loss=-0.000191, elapsed time=0.02, total time=7.06]\n",
      "[I 2025-06-07 22:06:32,853] Trial 23 finished with value: -0.0001912272464445882 and parameters: {'learning_rate': 0.045861767103238374, 'sigma_multiplier': 1.80240894184778, 'num_layers': 1, 'initialization_multiplier': 1.8358221762851235}. Best is trial 22 with value: -0.0004539468517293779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 23 final loss: -0.00019123\n",
      "Trial 24:\n",
      "  Learning Rate: 0.03503399141610891\n",
      "  Sigma Multiplier: 1.546727116369354\n",
      "  Initialization Multiplier: 1.5616535204189042\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.37it/s, loss=-0.000146, elapsed time=0.04, total time=7.79]\n",
      "[I 2025-06-07 22:06:40,694] Trial 24 finished with value: -0.00014598326328430194 and parameters: {'learning_rate': 0.03503399141610891, 'sigma_multiplier': 1.546727116369354, 'num_layers': 3, 'initialization_multiplier': 1.5616535204189042}. Best is trial 22 with value: -0.0004539468517293779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 24 final loss: -0.00014598\n",
      "Trial 25:\n",
      "  Learning Rate: 0.09233126682289218\n",
      "  Sigma Multiplier: 1.9645005738179964\n",
      "  Initialization Multiplier: 1.471281888537898\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.01it/s, loss=-0.000241, elapsed time=0.02, total time=5.87]\n",
      "[I 2025-06-07 22:06:46,600] Trial 25 finished with value: -0.00024095794288473888 and parameters: {'learning_rate': 0.09233126682289218, 'sigma_multiplier': 1.9645005738179964, 'num_layers': 2, 'initialization_multiplier': 1.471281888537898}. Best is trial 22 with value: -0.0004539468517293779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 25 final loss: -0.00024096\n",
      "Trial 26:\n",
      "  Learning Rate: 0.0029037648387455757\n",
      "  Sigma Multiplier: 1.752581118301449\n",
      "  Initialization Multiplier: 1.2296341075468127\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:04<00:00, 30.18it/s, loss=-0.000101, elapsed time=0.03, total time=5.25]\n",
      "[I 2025-06-07 22:06:51,877] Trial 26 finished with value: -0.00010056025494571478 and parameters: {'learning_rate': 0.0029037648387455757, 'sigma_multiplier': 1.752581118301449, 'num_layers': 1, 'initialization_multiplier': 1.2296341075468127}. Best is trial 22 with value: -0.0004539468517293779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 26 final loss: -0.00010056\n",
      "Trial 27:\n",
      "  Learning Rate: 0.02167126748942985\n",
      "  Sigma Multiplier: 1.5788824264871768\n",
      "  Initialization Multiplier: 1.799034414697425\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.44it/s, loss=-0.000474, elapsed time=0.02, total time=5.93]\n",
      "[I 2025-06-07 22:06:57,847] Trial 27 finished with value: -0.00047425718078470113 and parameters: {'learning_rate': 0.02167126748942985, 'sigma_multiplier': 1.5788824264871768, 'num_layers': 2, 'initialization_multiplier': 1.799034414697425}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 27 final loss: -0.00047426\n",
      "Trial 28:\n",
      "  Learning Rate: 0.021599807944814465\n",
      "  Sigma Multiplier: 1.19740063222513\n",
      "  Initialization Multiplier: 1.7596734601267159\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.95it/s, loss=0.000201, elapsed time=0.04, total time=7.46] \n",
      "[I 2025-06-07 22:07:05,396] Trial 28 finished with value: 0.00020147406446063452 and parameters: {'learning_rate': 0.021599807944814465, 'sigma_multiplier': 1.19740063222513, 'num_layers': 3, 'initialization_multiplier': 1.7596734601267159}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 28 final loss: 0.00020147\n",
      "Trial 29:\n",
      "  Learning Rate: 0.008255335474161168\n",
      "  Sigma Multiplier: 1.5484565027056698\n",
      "  Initialization Multiplier: 0.6970625491689337\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.48it/s, loss=-0.000068, elapsed time=0.05, total time=7.2] \n",
      "[I 2025-06-07 22:07:12,635] Trial 29 finished with value: -6.785228385802209e-05 and parameters: {'learning_rate': 0.008255335474161168, 'sigma_multiplier': 1.5484565027056698, 'num_layers': 3, 'initialization_multiplier': 0.6970625491689337}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 29 final loss: -0.00006785\n",
      "Trial 30:\n",
      "  Learning Rate: 0.023429631933878446\n",
      "  Sigma Multiplier: 1.4205407929356983\n",
      "  Initialization Multiplier: 0.48663792321888777\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.12it/s, loss=-0.000103, elapsed time=0.03, total time=6.49]\n",
      "[I 2025-06-07 22:07:19,167] Trial 30 finished with value: -0.00010310648017322793 and parameters: {'learning_rate': 0.023429631933878446, 'sigma_multiplier': 1.4205407929356983, 'num_layers': 2, 'initialization_multiplier': 0.48663792321888777}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 30 final loss: -0.00010311\n",
      "Trial 31:\n",
      "  Learning Rate: 0.0592453284380825\n",
      "  Sigma Multiplier: 1.8694815694184315\n",
      "  Initialization Multiplier: 1.8747319601942816\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.32it/s, loss=-0.000425, elapsed time=0.03, total time=5.98]\n",
      "[I 2025-06-07 22:07:25,183] Trial 31 finished with value: -0.0004245900355791742 and parameters: {'learning_rate': 0.0592453284380825, 'sigma_multiplier': 1.8694815694184315, 'num_layers': 2, 'initialization_multiplier': 1.8747319601942816}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 31 final loss: -0.00042459\n",
      "Trial 32:\n",
      "  Learning Rate: 0.0510764472685366\n",
      "  Sigma Multiplier: 1.5906550437828584\n",
      "  Initialization Multiplier: 1.8578605248225821\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 25.29it/s, loss=-0.000124, elapsed time=0.04, total time=6.25]\n",
      "[I 2025-06-07 22:07:31,464] Trial 32 finished with value: -0.00012365361262614387 and parameters: {'learning_rate': 0.0510764472685366, 'sigma_multiplier': 1.5906550437828584, 'num_layers': 2, 'initialization_multiplier': 1.8578605248225821}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 32 final loss: -0.00012365\n",
      "Trial 33:\n",
      "  Learning Rate: 0.02507855627287595\n",
      "  Sigma Multiplier: 1.8175819636218042\n",
      "  Initialization Multiplier: 1.6969157859510455\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.72it/s, loss=-0.000242, elapsed time=0.05, total time=7.16]\n",
      "[I 2025-06-07 22:07:38,670] Trial 33 finished with value: -0.00024213736645075398 and parameters: {'learning_rate': 0.02507855627287595, 'sigma_multiplier': 1.8175819636218042, 'num_layers': 3, 'initialization_multiplier': 1.6969157859510455}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 33 final loss: -0.00024214\n",
      "Trial 34:\n",
      "  Learning Rate: 4.542360596000181e-05\n",
      "  Sigma Multiplier: 1.649788170039798\n",
      "  Initialization Multiplier: 1.289559826456636\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 29.24it/s, loss=0.072158, elapsed time=0.06, total time=5.39]\n",
      "[I 2025-06-07 22:07:44,099] Trial 34 finished with value: 0.0721575449859564 and parameters: {'learning_rate': 4.542360596000181e-05, 'sigma_multiplier': 1.649788170039798, 'num_layers': 2, 'initialization_multiplier': 1.289559826456636}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 34 final loss: 0.07215754\n",
      "Trial 35:\n",
      "  Learning Rate: 0.052265347977629883\n",
      "  Sigma Multiplier: 1.8687404749334249\n",
      "  Initialization Multiplier: 1.554769631467488\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.50it/s, loss=-0.000240, elapsed time=0.03, total time=5.93]\n",
      "[I 2025-06-07 22:07:50,155] Trial 35 finished with value: -0.00024014617070025564 and parameters: {'learning_rate': 0.052265347977629883, 'sigma_multiplier': 1.8687404749334249, 'num_layers': 2, 'initialization_multiplier': 1.554769631467488}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 35 final loss: -0.00024015\n",
      "Trial 36:\n",
      "  Learning Rate: 0.007832848277154511\n",
      "  Sigma Multiplier: 0.6539524304968511\n",
      "  Initialization Multiplier: 1.1119983333713421\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.60it/s, loss=0.003539, elapsed time=0.06, total time=10]  \n",
      "[I 2025-06-07 22:08:00,280] Trial 36 finished with value: 0.0035389589014103696 and parameters: {'learning_rate': 0.007832848277154511, 'sigma_multiplier': 0.6539524304968511, 'num_layers': 3, 'initialization_multiplier': 1.1119983333713421}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 36 final loss: 0.00353896\n",
      "Trial 37:\n",
      "  Learning Rate: 0.0026742381197305018\n",
      "  Sigma Multiplier: 1.4973092113572497\n",
      "  Initialization Multiplier: 1.4384267566681628\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.04it/s, loss=-0.000284, elapsed time=0.04, total time=9.12]\n",
      "[I 2025-06-07 22:08:09,488] Trial 37 finished with value: -0.0002838263798032352 and parameters: {'learning_rate': 0.0026742381197305018, 'sigma_multiplier': 1.4973092113572497, 'num_layers': 5, 'initialization_multiplier': 1.4384267566681628}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 37 final loss: -0.00028383\n",
      "Trial 38:\n",
      "  Learning Rate: 9.393253785354055e-05\n",
      "  Sigma Multiplier: 0.793207152562847\n",
      "  Initialization Multiplier: 1.8528933256088305\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.95it/s, loss=0.111619, elapsed time=0.06, total time=8.22]\n",
      "[I 2025-06-07 22:08:17,739] Trial 38 finished with value: 0.1116191899656015 and parameters: {'learning_rate': 9.393253785354055e-05, 'sigma_multiplier': 0.793207152562847, 'num_layers': 2, 'initialization_multiplier': 1.8528933256088305}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 38 final loss: 0.11161919\n",
      "Trial 39:\n",
      "  Learning Rate: 0.06129429132616737\n",
      "  Sigma Multiplier: 1.7471568750704534\n",
      "  Initialization Multiplier: 1.6043909603148614\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.52it/s, loss=-0.000144, elapsed time=0.05, total time=7.97]\n",
      "[I 2025-06-07 22:08:25,756] Trial 39 finished with value: -0.00014431342928715275 and parameters: {'learning_rate': 0.06129429132616737, 'sigma_multiplier': 1.7471568750704534, 'num_layers': 4, 'initialization_multiplier': 1.6043909603148614}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 39 final loss: -0.00014431\n",
      "Trial 40:\n",
      "  Learning Rate: 0.027890060498484727\n",
      "  Sigma Multiplier: 1.1297128118194177\n",
      "  Initialization Multiplier: 1.7732183046497476\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.96it/s, loss=-0.000202, elapsed time=0.04, total time=7.12]\n",
      "[I 2025-06-07 22:08:32,912] Trial 40 finished with value: -0.0002023788632002656 and parameters: {'learning_rate': 0.027890060498484727, 'sigma_multiplier': 1.1297128118194177, 'num_layers': 2, 'initialization_multiplier': 1.7732183046497476}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 40 final loss: -0.00020238\n",
      "Trial 41:\n",
      "  Learning Rate: 0.06857540640653849\n",
      "  Sigma Multiplier: 1.8970076883927194\n",
      "  Initialization Multiplier: 1.9471652134138777\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 28.33it/s, loss=-0.000257, elapsed time=0.03, total time=5.59]\n",
      "[I 2025-06-07 22:08:38,525] Trial 41 finished with value: -0.0002566452303396292 and parameters: {'learning_rate': 0.06857540640653849, 'sigma_multiplier': 1.8970076883927194, 'num_layers': 1, 'initialization_multiplier': 1.9471652134138777}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 41 final loss: -0.00025665\n",
      "Trial 42:\n",
      "  Learning Rate: 0.01748920236126756\n",
      "  Sigma Multiplier: 1.9350211660638401\n",
      "  Initialization Multiplier: 1.8908124552320873\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.89it/s, loss=-0.000157, elapsed time=0.03, total time=5.65]\n",
      "[I 2025-06-07 22:08:44,200] Trial 42 finished with value: -0.00015650553616400938 and parameters: {'learning_rate': 0.01748920236126756, 'sigma_multiplier': 1.9350211660638401, 'num_layers': 1, 'initialization_multiplier': 1.8908124552320873}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 42 final loss: -0.00015651\n",
      "Trial 43:\n",
      "  Learning Rate: 0.035325395219902855\n",
      "  Sigma Multiplier: 1.7551722172489408\n",
      "  Initialization Multiplier: 1.9915712815611992\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 27.18it/s, loss=-0.000213, elapsed time=0.03, total time=5.79]\n",
      "[I 2025-06-07 22:08:50,028] Trial 43 finished with value: -0.00021293315636557118 and parameters: {'learning_rate': 0.035325395219902855, 'sigma_multiplier': 1.7551722172489408, 'num_layers': 1, 'initialization_multiplier': 1.9915712815611992}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 43 final loss: -0.00021293\n",
      "Trial 44:\n",
      "  Learning Rate: 0.0980158637004381\n",
      "  Sigma Multiplier: 1.9932176936201396\n",
      "  Initialization Multiplier: 0.24454824790456497\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 23.75it/s, loss=-0.000207, elapsed time=0.02, total time=6.61]\n",
      "[I 2025-06-07 22:08:56,680] Trial 44 finished with value: -0.00020658290659830733 and parameters: {'learning_rate': 0.0980158637004381, 'sigma_multiplier': 1.9932176936201396, 'num_layers': 2, 'initialization_multiplier': 0.24454824790456497}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 44 final loss: -0.00020658\n",
      "Trial 45:\n",
      "  Learning Rate: 0.009856470408459536\n",
      "  Sigma Multiplier: 1.6352418541969003\n",
      "  Initialization Multiplier: 1.7340029640749062\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 26.33it/s, loss=0.000029, elapsed time=0.04, total time=5.95] \n",
      "[I 2025-06-07 22:09:02,666] Trial 45 finished with value: 2.887356120386702e-05 and parameters: {'learning_rate': 0.009856470408459536, 'sigma_multiplier': 1.6352418541969003, 'num_layers': 1, 'initialization_multiplier': 1.7340029640749062}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 45 final loss: 0.00002887\n",
      "Trial 46:\n",
      "  Learning Rate: 0.07241686475951102\n",
      "  Sigma Multiplier: 1.8927838871536724\n",
      "  Initialization Multiplier: 1.0933049105430312\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.25it/s, loss=-0.000091, elapsed time=0.04, total time=6.47]\n",
      "[I 2025-06-07 22:09:09,181] Trial 46 finished with value: -9.144891854317671e-05 and parameters: {'learning_rate': 0.07241686475951102, 'sigma_multiplier': 1.8927838871536724, 'num_layers': 2, 'initialization_multiplier': 1.0933049105430312}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 46 final loss: -0.00009145\n",
      "Trial 47:\n",
      "  Learning Rate: 0.01756554940161855\n",
      "  Sigma Multiplier: 1.3036271260600787\n",
      "  Initialization Multiplier: 1.9163395356915527\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.02it/s, loss=-0.000320, elapsed time=0.05, total time=8.16]\n",
      "[I 2025-06-07 22:09:17,383] Trial 47 finished with value: -0.0003198314896564871 and parameters: {'learning_rate': 0.01756554940161855, 'sigma_multiplier': 1.3036271260600787, 'num_layers': 3, 'initialization_multiplier': 1.9163395356915527}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 47 final loss: -0.00031983\n",
      "Trial 48:\n",
      "  Learning Rate: 0.0004677158656954059\n",
      "  Sigma Multiplier: 1.718112303597083\n",
      "  Initialization Multiplier: 1.828557125186225\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 25.68it/s, loss=0.037528, elapsed time=0.03, total time=6.14]\n",
      "[I 2025-06-07 22:09:23,557] Trial 48 finished with value: 0.0375282206881929 and parameters: {'learning_rate': 0.0004677158656954059, 'sigma_multiplier': 1.718112303597083, 'num_layers': 1, 'initialization_multiplier': 1.828557125186225}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 48 final loss: 0.03752822\n",
      "Trial 49:\n",
      "  Learning Rate: 0.05873915622440126\n",
      "  Sigma Multiplier: 1.797850501261806\n",
      "  Initialization Multiplier: 1.698046242175229\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 23.10it/s, loss=-0.000119, elapsed time=0.04, total time=6.85]\n",
      "[I 2025-06-07 22:09:30,445] Trial 49 finished with value: -0.00011888983249356086 and parameters: {'learning_rate': 0.05873915622440126, 'sigma_multiplier': 1.797850501261806, 'num_layers': 2, 'initialization_multiplier': 1.698046242175229}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 49 final loss: -0.00011889\n",
      "Trial 50:\n",
      "  Learning Rate: 0.030572994478039132\n",
      "  Sigma Multiplier: 1.4254154298557948\n",
      "  Initialization Multiplier: 1.6258529230924772\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.82it/s, loss=-0.000410, elapsed time=0.05, total time=8.83]\n",
      "[I 2025-06-07 22:09:39,329] Trial 50 finished with value: -0.000410021881850518 and parameters: {'learning_rate': 0.030572994478039132, 'sigma_multiplier': 1.4254154298557948, 'num_layers': 4, 'initialization_multiplier': 1.6258529230924772}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 50 final loss: -0.00041002\n",
      "Trial 51:\n",
      "  Learning Rate: 0.03163023483604532\n",
      "  Sigma Multiplier: 1.4464564318848205\n",
      "  Initialization Multiplier: 1.645853591602018\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.89it/s, loss=-0.000232, elapsed time=0.04, total time=8.65]\n",
      "[I 2025-06-07 22:09:48,025] Trial 51 finished with value: -0.00023160621091444385 and parameters: {'learning_rate': 0.03163023483604532, 'sigma_multiplier': 1.4464564318848205, 'num_layers': 4, 'initialization_multiplier': 1.645853591602018}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 51 final loss: -0.00023161\n",
      "Trial 52:\n",
      "  Learning Rate: 0.040704582151166936\n",
      "  Sigma Multiplier: 1.5892980736802667\n",
      "  Initialization Multiplier: 1.9764607236215066\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.28it/s, loss=-0.000262, elapsed time=0.06, total time=10.7]\n",
      "[I 2025-06-07 22:09:58,853] Trial 52 finished with value: -0.0002617291470634223 and parameters: {'learning_rate': 0.040704582151166936, 'sigma_multiplier': 1.5892980736802667, 'num_layers': 5, 'initialization_multiplier': 1.9764607236215066}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 52 final loss: -0.00026173\n",
      "Trial 53:\n",
      "  Learning Rate: 0.07134512311895524\n",
      "  Sigma Multiplier: 1.3700364203368376\n",
      "  Initialization Multiplier: 1.494694396627461\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:09<00:00, 15.44it/s, loss=0.000043, elapsed time=0.14, total time=10.1] \n",
      "[I 2025-06-07 22:10:09,021] Trial 53 finished with value: 4.2598419374518695e-05 and parameters: {'learning_rate': 0.07134512311895524, 'sigma_multiplier': 1.3700364203368376, 'num_layers': 4, 'initialization_multiplier': 1.494694396627461}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 53 final loss: 0.00004260\n",
      "Trial 54:\n",
      "  Learning Rate: 0.011848907404342886\n",
      "  Sigma Multiplier: 1.8594728777163367\n",
      "  Initialization Multiplier: 0.8775789566249511\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.95it/s, loss=-0.000266, elapsed time=0.05, total time=10.4]\n",
      "[I 2025-06-07 22:10:19,425] Trial 54 finished with value: -0.0002663726756645543 and parameters: {'learning_rate': 0.011848907404342886, 'sigma_multiplier': 1.8594728777163367, 'num_layers': 4, 'initialization_multiplier': 0.8775789566249511}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 54 final loss: -0.00026637\n",
      "Trial 55:\n",
      "  Learning Rate: 0.006129267309218792\n",
      "  Sigma Multiplier: 1.7006586442517804\n",
      "  Initialization Multiplier: 1.363873955660007\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:12<00:00, 12.41it/s, loss=-0.000003, elapsed time=0.06, total time=12.5]\n",
      "[I 2025-06-07 22:10:32,019] Trial 55 finished with value: -3.1762081059188015e-06 and parameters: {'learning_rate': 0.006129267309218792, 'sigma_multiplier': 1.7006586442517804, 'num_layers': 3, 'initialization_multiplier': 1.363873955660007}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 55 final loss: -0.00000318\n",
      "Trial 56:\n",
      "  Learning Rate: 0.04746092935598124\n",
      "  Sigma Multiplier: 1.6152997351240845\n",
      "  Initialization Multiplier: 1.7901239003525307\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.21it/s, loss=-0.000418, elapsed time=0.04, total time=9.56]\n",
      "[I 2025-06-07 22:10:41,672] Trial 56 finished with value: -0.00041812107993382294 and parameters: {'learning_rate': 0.04746092935598124, 'sigma_multiplier': 1.6152997351240845, 'num_layers': 2, 'initialization_multiplier': 1.7901239003525307}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 56 final loss: -0.00041812\n",
      "Trial 57:\n",
      "  Learning Rate: 0.017427945879660473\n",
      "  Sigma Multiplier: 1.6086039861205075\n",
      "  Initialization Multiplier: 1.5677497730519503\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.84it/s, loss=-0.000080, elapsed time=0.04, total time=8.27]\n",
      "[I 2025-06-07 22:10:49,978] Trial 57 finished with value: -8.047593943355148e-05 and parameters: {'learning_rate': 0.017427945879660473, 'sigma_multiplier': 1.6086039861205075, 'num_layers': 2, 'initialization_multiplier': 1.5677497730519503}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 57 final loss: -0.00008048\n",
      "Trial 58:\n",
      "  Learning Rate: 0.04133540513623128\n",
      "  Sigma Multiplier: 1.5232113692450726\n",
      "  Initialization Multiplier: 1.8111137829633281\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.15it/s, loss=-0.000244, elapsed time=0.06, total time=8.19]\n",
      "[I 2025-06-07 22:10:58,205] Trial 58 finished with value: -0.00024352833213934724 and parameters: {'learning_rate': 0.04133540513623128, 'sigma_multiplier': 1.5232113692450726, 'num_layers': 2, 'initialization_multiplier': 1.8111137829633281}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 58 final loss: -0.00024353\n",
      "Trial 59:\n",
      "  Learning Rate: 0.02642664524837777\n",
      "  Sigma Multiplier: 1.264790250967699\n",
      "  Initialization Multiplier: 1.6407492984292578\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.62it/s, loss=0.000210, elapsed time=0.03, total time=7.25] \n",
      "[I 2025-06-07 22:11:05,489] Trial 59 finished with value: 0.000209996624061583 and parameters: {'learning_rate': 0.02642664524837777, 'sigma_multiplier': 1.264790250967699, 'num_layers': 2, 'initialization_multiplier': 1.6407492984292578}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 59 final loss: 0.00021000\n",
      "Trial 60:\n",
      "  Learning Rate: 0.0012493563981450654\n",
      "  Sigma Multiplier: 1.0295028912208453\n",
      "  Initialization Multiplier: 1.4202450007855245\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.77it/s, loss=0.006812, elapsed time=0.05, total time=8.3] \n",
      "[I 2025-06-07 22:11:13,831] Trial 60 finished with value: 0.006811879187682794 and parameters: {'learning_rate': 0.0012493563981450654, 'sigma_multiplier': 1.0295028912208453, 'num_layers': 3, 'initialization_multiplier': 1.4202450007855245}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 60 final loss: 0.00681188\n",
      "Trial 61:\n",
      "  Learning Rate: 0.08172082696539787\n",
      "  Sigma Multiplier: 1.7645995913476145\n",
      "  Initialization Multiplier: 1.9032627366646204\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.69it/s, loss=-0.000188, elapsed time=0.03, total time=6.39]\n",
      "[I 2025-06-07 22:11:20,251] Trial 61 finished with value: -0.00018797048185115596 and parameters: {'learning_rate': 0.08172082696539787, 'sigma_multiplier': 1.7645995913476145, 'num_layers': 2, 'initialization_multiplier': 1.9032627366646204}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 61 final loss: -0.00018797\n",
      "Trial 62:\n",
      "  Learning Rate: 0.09975630265075709\n",
      "  Sigma Multiplier: 1.9247206038043627\n",
      "  Initialization Multiplier: 1.783049636445993\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 24.80it/s, loss=-0.000203, elapsed time=0.05, total time=6.34]\n",
      "[I 2025-06-07 22:11:26,623] Trial 62 finished with value: -0.00020258547117336118 and parameters: {'learning_rate': 0.09975630265075709, 'sigma_multiplier': 1.9247206038043627, 'num_layers': 2, 'initialization_multiplier': 1.783049636445993}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 62 final loss: -0.00020259\n",
      "Trial 63:\n",
      "  Learning Rate: 0.05279438151488817\n",
      "  Sigma Multiplier: 1.6658408186381726\n",
      "  Initialization Multiplier: 1.7083674572556862\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 25.04it/s, loss=-0.000096, elapsed time=0.03, total time=6.27]\n",
      "[I 2025-06-07 22:11:32,931] Trial 63 finished with value: -9.62948892751458e-05 and parameters: {'learning_rate': 0.05279438151488817, 'sigma_multiplier': 1.6658408186381726, 'num_layers': 1, 'initialization_multiplier': 1.7083674572556862}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 63 final loss: -0.00009629\n",
      "Trial 64:\n",
      "  Learning Rate: 0.03167152707811468\n",
      "  Sigma Multiplier: 0.22263902299867833\n",
      "  Initialization Multiplier: 1.8872799409788026\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:11<00:00, 13.62it/s, loss=0.000643, elapsed time=0.08, total time=11.4]\n",
      "[I 2025-06-07 22:11:44,377] Trial 64 finished with value: 0.0006431216300553471 and parameters: {'learning_rate': 0.03167152707811468, 'sigma_multiplier': 0.22263902299867833, 'num_layers': 2, 'initialization_multiplier': 1.8872799409788026}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 64 final loss: 0.00064312\n",
      "Trial 65:\n",
      "  Learning Rate: 0.04654201064184498\n",
      "  Sigma Multiplier: 1.818790708586034\n",
      "  Initialization Multiplier: 1.9977649129507018\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.11it/s, loss=-0.000176, elapsed time=0.04, total time=7.75]\n",
      "[I 2025-06-07 22:11:52,171] Trial 65 finished with value: -0.00017645463469771717 and parameters: {'learning_rate': 0.04654201064184498, 'sigma_multiplier': 1.818790708586034, 'num_layers': 3, 'initialization_multiplier': 1.9977649129507018}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 65 final loss: -0.00017645\n",
      "Trial 66:\n",
      "  Learning Rate: 0.019660560402592273\n",
      "  Sigma Multiplier: 1.379780608750491\n",
      "  Initialization Multiplier: 1.801459118107482\n",
      "  Number of Layers: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:10<00:00, 14.48it/s, loss=-0.000295, elapsed time=0.07, total time=10.7]\n",
      "[I 2025-06-07 22:12:02,958] Trial 66 finished with value: -0.0002945770555231525 and parameters: {'learning_rate': 0.019660560402592273, 'sigma_multiplier': 1.379780608750491, 'num_layers': 5, 'initialization_multiplier': 1.801459118107482}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 66 final loss: -0.00029458\n",
      "Trial 67:\n",
      "  Learning Rate: 0.06488767736757338\n",
      "  Sigma Multiplier: 1.4859691317873698\n",
      "  Initialization Multiplier: 1.2963772392316921\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.84it/s, loss=-0.000335, elapsed time=0.06, total time=8.71]\n",
      "[I 2025-06-07 22:12:11,719] Trial 67 finished with value: -0.0003353690925175674 and parameters: {'learning_rate': 0.06488767736757338, 'sigma_multiplier': 1.4859691317873698, 'num_layers': 3, 'initialization_multiplier': 1.2963772392316921}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 67 final loss: -0.00033537\n",
      "Trial 68:\n",
      "  Learning Rate: 0.013291851095853728\n",
      "  Sigma Multiplier: 1.577407052214372\n",
      "  Initialization Multiplier: 1.6127306615145311\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.49it/s, loss=0.000003, elapsed time=0.05, total time=7.61] \n",
      "[I 2025-06-07 22:12:19,377] Trial 68 finished with value: 2.899518696924369e-06 and parameters: {'learning_rate': 0.013291851095853728, 'sigma_multiplier': 1.577407052214372, 'num_layers': 2, 'initialization_multiplier': 1.6127306615145311}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 68 final loss: 0.00000290\n",
      "Trial 69:\n",
      "  Learning Rate: 0.04023331600565887\n",
      "  Sigma Multiplier: 1.9878373772623255\n",
      "  Initialization Multiplier: 1.5178058852867256\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:05<00:00, 25.83it/s, loss=-0.000239, elapsed time=0.03, total time=6.15]\n",
      "[I 2025-06-07 22:12:25,561] Trial 69 finished with value: -0.0002394060748751112 and parameters: {'learning_rate': 0.04023331600565887, 'sigma_multiplier': 1.9878373772623255, 'num_layers': 1, 'initialization_multiplier': 1.5178058852867256}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 69 final loss: -0.00023941\n",
      "Trial 70:\n",
      "  Learning Rate: 0.00017328158138110383\n",
      "  Sigma Multiplier: 1.8097698721870255\n",
      "  Initialization Multiplier: 1.7232253676729454\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.84it/s, loss=0.032089, elapsed time=0.05, total time=9.18]\n",
      "[I 2025-06-07 22:12:34,800] Trial 70 finished with value: 0.03208913090223839 and parameters: {'learning_rate': 0.00017328158138110383, 'sigma_multiplier': 1.8097698721870255, 'num_layers': 4, 'initialization_multiplier': 1.7232253676729454}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 70 final loss: 0.03208913\n",
      "Trial 71:\n",
      "  Learning Rate: 0.027162739294348127\n",
      "  Sigma Multiplier: 1.6810450904145575\n",
      "  Initialization Multiplier: 1.8514844971217779\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.56it/s, loss=-0.000104, elapsed time=0.05, total time=7.58]\n",
      "[I 2025-06-07 22:12:42,423] Trial 71 finished with value: -0.00010358746478931466 and parameters: {'learning_rate': 0.027162739294348127, 'sigma_multiplier': 1.6810450904145575, 'num_layers': 2, 'initialization_multiplier': 1.8514844971217779}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 71 final loss: -0.00010359\n",
      "Trial 72:\n",
      "  Learning Rate: 0.058256064289291275\n",
      "  Sigma Multiplier: 1.8656552730747247\n",
      "  Initialization Multiplier: 1.9226804811389857\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.51it/s, loss=-0.000176, elapsed time=0.04, total time=7.32]\n",
      "[I 2025-06-07 22:12:49,782] Trial 72 finished with value: -0.00017636715655907509 and parameters: {'learning_rate': 0.058256064289291275, 'sigma_multiplier': 1.8656552730747247, 'num_layers': 2, 'initialization_multiplier': 1.9226804811389857}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 72 final loss: -0.00017637\n",
      "Trial 73:\n",
      "  Learning Rate: 0.02190441277645796\n",
      "  Sigma Multiplier: 1.944216782910633\n",
      "  Initialization Multiplier: 1.668763959607582\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.72it/s, loss=0.000119, elapsed time=0.03, total time=7.24] \n",
      "[I 2025-06-07 22:12:57,054] Trial 73 finished with value: 0.00011907601183458378 and parameters: {'learning_rate': 0.02190441277645796, 'sigma_multiplier': 1.944216782910633, 'num_layers': 2, 'initialization_multiplier': 1.668763959607582}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 73 final loss: 0.00011908\n",
      "Trial 74:\n",
      "  Learning Rate: 0.08192495579694715\n",
      "  Sigma Multiplier: 1.7701231354966986\n",
      "  Initialization Multiplier: 1.775796964208485\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.01it/s, loss=-0.000072, elapsed time=0.04, total time=7.51]\n",
      "[I 2025-06-07 22:13:04,642] Trial 74 finished with value: -7.199637142557443e-05 and parameters: {'learning_rate': 0.08192495579694715, 'sigma_multiplier': 1.7701231354966986, 'num_layers': 2, 'initialization_multiplier': 1.775796964208485}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 74 final loss: -0.00007200\n",
      "Trial 75:\n",
      "  Learning Rate: 0.0495116698727127\n",
      "  Sigma Multiplier: 1.7234133654495243\n",
      "  Initialization Multiplier: 1.5774178869589892\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.54it/s, loss=-0.000007, elapsed time=0.05, total time=7.62]\n",
      "[I 2025-06-07 22:13:12,302] Trial 75 finished with value: -6.858433220558166e-06 and parameters: {'learning_rate': 0.0495116698727127, 'sigma_multiplier': 1.7234133654495243, 'num_layers': 2, 'initialization_multiplier': 1.5774178869589892}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 75 final loss: -0.00000686\n",
      "Trial 76:\n",
      "  Learning Rate: 0.015392511344347807\n",
      "  Sigma Multiplier: 0.8795183903375874\n",
      "  Initialization Multiplier: 1.855500441375747\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 19.04it/s, loss=0.001264, elapsed time=0.03, total time=8.15]\n",
      "[I 2025-06-07 22:13:20,485] Trial 76 finished with value: 0.0012641918163020169 and parameters: {'learning_rate': 0.015392511344347807, 'sigma_multiplier': 0.8795183903375874, 'num_layers': 1, 'initialization_multiplier': 1.855500441375747}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 76 final loss: 0.00126419\n",
      "Trial 77:\n",
      "  Learning Rate: 0.009691045950539448\n",
      "  Sigma Multiplier: 1.907697069800095\n",
      "  Initialization Multiplier: 1.937554318925241\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.70it/s, loss=-0.000170, elapsed time=0.06, total time=7.12]\n",
      "[I 2025-06-07 22:13:27,658] Trial 77 finished with value: -0.00017048766582467188 and parameters: {'learning_rate': 0.009691045950539448, 'sigma_multiplier': 1.907697069800095, 'num_layers': 2, 'initialization_multiplier': 1.937554318925241}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 77 final loss: -0.00017049\n",
      "Trial 78:\n",
      "  Learning Rate: 0.004311920558865493\n",
      "  Sigma Multiplier: 1.8435565277820678\n",
      "  Initialization Multiplier: 1.741160098963658\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.78it/s, loss=-0.000311, elapsed time=0.03, total time=8.3] \n",
      "[I 2025-06-07 22:13:35,998] Trial 78 finished with value: -0.0003105811832953188 and parameters: {'learning_rate': 0.004311920558865493, 'sigma_multiplier': 1.8435565277820678, 'num_layers': 3, 'initialization_multiplier': 1.741160098963658}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 78 final loss: -0.00031058\n",
      "Trial 79:\n",
      "  Learning Rate: 0.03300167442491218\n",
      "  Sigma Multiplier: 1.6279014921038732\n",
      "  Initialization Multiplier: 1.8089507247802457\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 21.64it/s, loss=-0.000048, elapsed time=0.03, total time=7.25]\n",
      "[I 2025-06-07 22:13:43,281] Trial 79 finished with value: -4.785613241199123e-05 and parameters: {'learning_rate': 0.03300167442491218, 'sigma_multiplier': 1.6279014921038732, 'num_layers': 1, 'initialization_multiplier': 1.8089507247802457}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 79 final loss: -0.00004786\n",
      "Trial 80:\n",
      "  Learning Rate: 0.07199368315295626\n",
      "  Sigma Multiplier: 1.523435508663694\n",
      "  Initialization Multiplier: 1.6853858489223021\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.65it/s, loss=0.000006, elapsed time=0.04, total time=7.58] \n",
      "[I 2025-06-07 22:13:50,898] Trial 80 finished with value: 5.711108758201248e-06 and parameters: {'learning_rate': 0.07199368315295626, 'sigma_multiplier': 1.523435508663694, 'num_layers': 2, 'initialization_multiplier': 1.6853858489223021}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 80 final loss: 0.00000571\n",
      "Trial 81:\n",
      "  Learning Rate: 0.06211510433265009\n",
      "  Sigma Multiplier: 1.43682078485947\n",
      "  Initialization Multiplier: 1.2919897533769555\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.43it/s, loss=0.000260, elapsed time=0.06, total time=8.98] \n",
      "[I 2025-06-07 22:13:59,920] Trial 81 finished with value: 0.0002602493489196517 and parameters: {'learning_rate': 0.06211510433265009, 'sigma_multiplier': 1.43682078485947, 'num_layers': 3, 'initialization_multiplier': 1.2919897533769555}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 81 final loss: 0.00026025\n",
      "Trial 82:\n",
      "  Learning Rate: 0.08571185801014838\n",
      "  Sigma Multiplier: 1.554191617437629\n",
      "  Initialization Multiplier: 1.321942944294464\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.67it/s, loss=-0.000199, elapsed time=0.05, total time=8.45]\n",
      "[I 2025-06-07 22:14:08,419] Trial 82 finished with value: -0.00019905778528085845 and parameters: {'learning_rate': 0.08571185801014838, 'sigma_multiplier': 1.554191617437629, 'num_layers': 3, 'initialization_multiplier': 1.321942944294464}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 82 final loss: -0.00019906\n",
      "Trial 83:\n",
      "  Learning Rate: 0.04689120736878944\n",
      "  Sigma Multiplier: 1.4927155262722849\n",
      "  Initialization Multiplier: 1.4570392111342405\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.22it/s, loss=-0.000026, elapsed time=0.05, total time=7.79]\n",
      "[I 2025-06-07 22:14:16,242] Trial 83 finished with value: -2.6030873230600062e-05 and parameters: {'learning_rate': 0.04689120736878944, 'sigma_multiplier': 1.4927155262722849, 'num_layers': 2, 'initialization_multiplier': 1.4570392111342405}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 83 final loss: -0.00002603\n",
      "Trial 84:\n",
      "  Learning Rate: 0.03596265190449891\n",
      "  Sigma Multiplier: 1.6870956192073387\n",
      "  Initialization Multiplier: 0.9948917216517178\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.13it/s, loss=-0.000286, elapsed time=0.06, total time=9.08]\n",
      "[I 2025-06-07 22:14:25,387] Trial 84 finished with value: -0.000286335418588381 and parameters: {'learning_rate': 0.03596265190449891, 'sigma_multiplier': 1.6870956192073387, 'num_layers': 4, 'initialization_multiplier': 0.9948917216517178}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 84 final loss: -0.00028634\n",
      "Trial 85:\n",
      "  Learning Rate: 0.06244009024715363\n",
      "  Sigma Multiplier: 1.1392617346536447\n",
      "  Initialization Multiplier: 0.0032607436962678316\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.12it/s, loss=-0.000021, elapsed time=0.05, total time=9.05]\n",
      "[I 2025-06-07 22:14:34,504] Trial 85 finished with value: -2.1237891867075123e-05 and parameters: {'learning_rate': 0.06244009024715363, 'sigma_multiplier': 1.1392617346536447, 'num_layers': 3, 'initialization_multiplier': 0.0032607436962678316}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 85 final loss: -0.00002124\n",
      "Trial 86:\n",
      "  Learning Rate: 0.028164924676318842\n",
      "  Sigma Multiplier: 1.7922077013877578\n",
      "  Initialization Multiplier: 1.953429094491557\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 22.39it/s, loss=-0.000153, elapsed time=0.04, total time=6.98]\n",
      "[I 2025-06-07 22:14:41,513] Trial 86 finished with value: -0.0001532615872555898 and parameters: {'learning_rate': 0.028164924676318842, 'sigma_multiplier': 1.7922077013877578, 'num_layers': 2, 'initialization_multiplier': 1.953429094491557}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 86 final loss: -0.00015326\n",
      "Trial 87:\n",
      "  Learning Rate: 0.022872642202796622\n",
      "  Sigma Multiplier: 1.4044530738163339\n",
      "  Initialization Multiplier: 1.1877380263836947\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.32it/s, loss=-0.000256, elapsed time=0.04, total time=7.63]\n",
      "[I 2025-06-07 22:14:49,175] Trial 87 finished with value: -0.00025607627895180235 and parameters: {'learning_rate': 0.022872642202796622, 'sigma_multiplier': 1.4044530738163339, 'num_layers': 2, 'initialization_multiplier': 1.1877380263836947}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 87 final loss: -0.00025608\n",
      "Trial 88:\n",
      "  Learning Rate: 0.09989733047770494\n",
      "  Sigma Multiplier: 1.469662371434616\n",
      "  Initialization Multiplier: 1.5420814314123168\n",
      "  Number of Layers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:06<00:00, 23.62it/s, loss=-0.000047, elapsed time=0.04, total time=6.68]\n",
      "[I 2025-06-07 22:14:55,881] Trial 88 finished with value: -4.657083968518515e-05 and parameters: {'learning_rate': 0.09989733047770494, 'sigma_multiplier': 1.469662371434616, 'num_layers': 1, 'initialization_multiplier': 1.5420814314123168}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 88 final loss: -0.00004657\n",
      "Trial 89:\n",
      "  Learning Rate: 0.07585406053011139\n",
      "  Sigma Multiplier: 1.7174402390563577\n",
      "  Initialization Multiplier: 1.056216366255758\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.04it/s, loss=-0.000276, elapsed time=0.03, total time=7.47]\n",
      "[I 2025-06-07 22:15:03,391] Trial 89 finished with value: -0.00027648730396646003 and parameters: {'learning_rate': 0.07585406053011139, 'sigma_multiplier': 1.7174402390563577, 'num_layers': 2, 'initialization_multiplier': 1.056216366255758}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 89 final loss: -0.00027649\n",
      "Trial 90:\n",
      "  Learning Rate: 0.04136174984844723\n",
      "  Sigma Multiplier: 1.6195075552129028\n",
      "  Initialization Multiplier: 1.2368628726264244\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.12it/s, loss=-0.000308, elapsed time=0.04, total time=7.37]\n",
      "[I 2025-06-07 22:15:10,799] Trial 90 finished with value: -0.0003083329513299154 and parameters: {'learning_rate': 0.04136174984844723, 'sigma_multiplier': 1.6195075552129028, 'num_layers': 2, 'initialization_multiplier': 1.2368628726264244}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 90 final loss: -0.00030833\n",
      "Trial 91:\n",
      "  Learning Rate: 0.019272112105533857\n",
      "  Sigma Multiplier: 1.3007612965567663\n",
      "  Initialization Multiplier: 1.8869470466528115\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.46it/s, loss=-0.000196, elapsed time=0.05, total time=8.37]\n",
      "[I 2025-06-07 22:15:19,206] Trial 91 finished with value: -0.00019572086878849726 and parameters: {'learning_rate': 0.019272112105533857, 'sigma_multiplier': 1.3007612965567663, 'num_layers': 3, 'initialization_multiplier': 1.8869470466528115}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 91 final loss: -0.00019572\n",
      "Trial 92:\n",
      "  Learning Rate: 0.007113139254216233\n",
      "  Sigma Multiplier: 1.2374263312368892\n",
      "  Initialization Multiplier: 1.9098768237994816\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.18it/s, loss=-0.000052, elapsed time=0.04, total time=8.61]\n",
      "[I 2025-06-07 22:15:27,856] Trial 92 finished with value: -5.188850415356144e-05 and parameters: {'learning_rate': 0.007113139254216233, 'sigma_multiplier': 1.2374263312368892, 'num_layers': 3, 'initialization_multiplier': 1.9098768237994816}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 92 final loss: -0.00005189\n",
      "Trial 93:\n",
      "  Learning Rate: 0.01572011032102045\n",
      "  Sigma Multiplier: 1.356076191154326\n",
      "  Initialization Multiplier: 1.7488003363098965\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.53it/s, loss=0.000131, elapsed time=0.05, total time=8.46] \n",
      "[I 2025-06-07 22:15:36,353] Trial 93 finished with value: 0.00013141579043722174 and parameters: {'learning_rate': 0.01572011032102045, 'sigma_multiplier': 1.356076191154326, 'num_layers': 3, 'initialization_multiplier': 1.7488003363098965}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 93 final loss: 0.00013142\n",
      "Trial 94:\n",
      "  Learning Rate: 0.054811570880095965\n",
      "  Sigma Multiplier: 1.3111706545583046\n",
      "  Initialization Multiplier: 1.8219423740140779\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 18.76it/s, loss=0.000209, elapsed time=0.04, total time=8.26] \n",
      "[I 2025-06-07 22:15:44,652] Trial 94 finished with value: 0.00020929658927333673 and parameters: {'learning_rate': 0.054811570880095965, 'sigma_multiplier': 1.3111706545583046, 'num_layers': 3, 'initialization_multiplier': 1.8219423740140779}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 94 final loss: 0.00020930\n",
      "Trial 95:\n",
      "  Learning Rate: 0.01152949459053567\n",
      "  Sigma Multiplier: 1.9613160737054467\n",
      "  Initialization Multiplier: 1.6071889363287606\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 17.04it/s, loss=-0.000151, elapsed time=0.06, total time=9.05]\n",
      "[I 2025-06-07 22:15:53,752] Trial 95 finished with value: -0.00015077194850325655 and parameters: {'learning_rate': 0.01152949459053567, 'sigma_multiplier': 1.9613160737054467, 'num_layers': 4, 'initialization_multiplier': 1.6071889363287606}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 95 final loss: -0.00015077\n",
      "Trial 96:\n",
      "  Learning Rate: 0.002024953847980762\n",
      "  Sigma Multiplier: 1.8822128191699552\n",
      "  Initialization Multiplier: 1.4017910456512914\n",
      "  Number of Layers: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 16.81it/s, loss=0.001459, elapsed time=0.06, total time=9.25]\n",
      "[I 2025-06-07 22:16:03,065] Trial 96 finished with value: 0.0014594912734652485 and parameters: {'learning_rate': 0.002024953847980762, 'sigma_multiplier': 1.8822128191699552, 'num_layers': 4, 'initialization_multiplier': 1.4017910456512914}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 96 final loss: 0.00145949\n",
      "Trial 97:\n",
      "  Learning Rate: 0.03139565349442192\n",
      "  Sigma Multiplier: 1.5627346111731033\n",
      "  Initialization Multiplier: 1.8777347274190936\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 20.45it/s, loss=-0.000206, elapsed time=0.04, total time=7.62]\n",
      "[I 2025-06-07 22:16:10,729] Trial 97 finished with value: -0.00020586225034842725 and parameters: {'learning_rate': 0.03139565349442192, 'sigma_multiplier': 1.5627346111731033, 'num_layers': 2, 'initialization_multiplier': 1.8777347274190936}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 97 final loss: -0.00020586\n",
      "Trial 98:\n",
      "  Learning Rate: 0.02485282260747327\n",
      "  Sigma Multiplier: 1.481228928450545\n",
      "  Initialization Multiplier: 1.9715520167214606\n",
      "  Number of Layers: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:08<00:00, 18.28it/s, loss=-0.000351, elapsed time=0.04, total time=8.47]\n",
      "[I 2025-06-07 22:16:19,240] Trial 98 finished with value: -0.00035082656698641153 and parameters: {'learning_rate': 0.02485282260747327, 'sigma_multiplier': 1.481228928450545, 'num_layers': 3, 'initialization_multiplier': 1.9715520167214606}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 98 final loss: -0.00035083\n",
      "Trial 99:\n",
      "  Learning Rate: 0.06686125067211865\n",
      "  Sigma Multiplier: 1.7385674997693565\n",
      "  Initialization Multiplier: 1.9613485933236798\n",
      "  Number of Layers: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 150/150 [00:07<00:00, 21.29it/s, loss=-0.000133, elapsed time=0.03, total time=7.4] \n",
      "[I 2025-06-07 22:16:26,676] Trial 99 finished with value: -0.00013263673188893216 and parameters: {'learning_rate': 0.06686125067211865, 'sigma_multiplier': 1.7385674997693565, 'num_layers': 2, 'initialization_multiplier': 1.9613485933236798}. Best is trial 27 with value: -0.00047425718078470113.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 150 steps\n",
      "Trial 99 final loss: -0.00013264\n"
     ]
    }
   ],
   "source": [
    "study = run_hpo(\n",
    "    grid_conn,\n",
    "    QUBITS,\n",
    "    base_sigma,\n",
    "    train_ds = train_ds,\n",
    "    n_trials = 100,\n",
    "    n_iters_hpo = 150,\n",
    "    n_ops = 2000,\n",
    "    n_samples = 2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimization Finished!\n",
      "Best hyperparameters found: {'learning_rate': 0.02167126748942985, 'sigma_multiplier': 1.5788824264871768, 'num_layers': 2, 'initialization_multiplier': 1.799034414697425}\n",
      "Best loss value: -0.00047425718078470113\n"
     ]
    }
   ],
   "source": [
    "best_hyperparams = study.best_params\n",
    "best_loss_value = study.best_value\n",
    "\n",
    "print(\"\\nOptimization Finished!\")\n",
    "print(f\"Best hyperparameters found: {best_hyperparams}\")\n",
    "print(f\"Best loss value: {best_loss_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = best_hyperparams['learning_rate']\n",
    "SIGMA_M = best_hyperparams['sigma_multiplier']\n",
    "NUM_LAYERS = best_hyperparams['num_layers']\n",
    "INIT_M = best_hyperparams['initialization_multiplier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_dataset(dataset=train_ds):\n",
    "    grid_conn= aachen_connectivity()\n",
    "    num_qubits = NODES * (NODES - 1) // 2\n",
    "    gates = efficient_connectivity_gates(grid_conn, num_qubits, NUM_LAYERS)\n",
    "    \n",
    "    circuit = iqp.IqpSimulator(num_qubits, gates, device=\"lightning.qubit\")\n",
    "    \n",
    "    initial_params = initialize_from_data(gates, dataset) * INIT_M\n",
    "    loss = iqp.gen_qml.mmd_loss_iqp\n",
    "    learning_rate = LR\n",
    "    sigma = median_heuristic(dataset) * SIGMA_M\n",
    "    \n",
    "    loss_kwarg = {\n",
    "        \"params\": initial_params,\n",
    "        \"iqp_circuit\": circuit,\n",
    "        \"ground_truth\": dataset,\n",
    "        \"sigma\": [sigma],\n",
    "        \"n_ops\": 2000,\n",
    "        \"n_samples\": 2000,\n",
    "        \"key\": jax.random.PRNGKey(42),\n",
    "    }\n",
    "    \n",
    "    trainer = iqp.Trainer(\"Adam\", loss, stepsize=learning_rate)\n",
    "    trainer.train(n_iters= 2000,loss_kwargs=loss_kwarg, turbo=1)\n",
    "    \n",
    "    return trainer.final_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|██████████| 2000/2000 [01:25<00:00, 23.44it/s, loss=-0.000423, elapsed time=0.04, total time=85.7]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has not converged after 2000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params = train_on_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(f'./results/params/params_{NODES}N_{TYPE}_{CONN}_LR{LR}_SIGMA{SIGMA_M}_INIT{INIT_M}_MAX_WEIGHT{NUM_LAYERS}.npy', params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
